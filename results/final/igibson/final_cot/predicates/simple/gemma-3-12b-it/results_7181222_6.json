{"data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Benevolence_1_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable cabinet_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 5.787797758421975e-12, 2.2891183740214593e-11, "The agent is the robotic arm. The cabinet_1 is located on the right side of the image. The robotic arm is located on the left side of the image. The distance between the robotic arm and the cabinet_1 is too far for the robotic arm to reach. Therefore, the cabinet_1 is not in reach of the agent.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The cabinet_1 is located on the right side of the image. The robotic arm is located on the left side of the image. The distance between the robotic arm and the cabinet_1 is too far for the robotic arm to reach. Therefore, the cabinet_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable cabinet_2": ["yes", 3.510975364606761e-12, 1.3886178665267757e-11, "The agent is the robotic arm. The cabinet_2 is located on the right side of the image. The robotic arm is located on the right side of the image as well. The robotic arm appears to be close enough to the cabinet_2 to reach it.", false, "Question: Is the cabinet_2 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The cabinet_2 is located on the right side of the image. The robotic arm is located on the right side of the image as well. The robotic arm appears to be close enough to the cabinet_2 to reach it.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}, "reachable sink_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 5.787797758421975e-12, 2.2891183740214593e-11, "The agent is the robotic arm. The cabinet_1 is located on the right side of the image. The robotic arm is located on the left side of the image. The distance between the robotic arm and the cabinet_1 is too far for the robotic arm to reach. Therefore, the cabinet_1 is not in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The cabinet_1 is located on the right side of the image. The robotic arm is located on the left side of the image. The distance between the robotic arm and the cabinet_1 is too far for the robotic arm to reach. Therefore, the cabinet_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 1.0060210043488782e-12, 1.879494606824017e-12, "The image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm is positioned such that it appears to be close to the cabinet. Based on the visual proximity, it seems likely that the agent can reach the cabinet.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm is positioned such that it appears to be close to the cabinet. Based on the visual proximity, it seems likely that the agent can reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_2": ["yes", 1.291762053226564e-12, 3.0987762269368835e-12, "The agent is the robotic arm. The cabinet_2 is located in the foreground of the image. The robotic arm appears to be positioned such that it could potentially reach the cabinet_2. Therefore, the answer is \"Yes\".", false, "Question: Is the cabinet_2 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The cabinet_2 is located in the foreground of the image. The robotic arm appears to be positioned such that it could potentially reach the cabinet_2. Therefore, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable sink_1": ["yes", 3.0987309072860736e-12, 6.560013816880872e-12, "The image shows a robotic arm (the agent) and a sink labeled \"sink_1\". The robotic arm appears to be positioned near the sink. Based on the visual proximity, it seems the sink is within the agent's reach.", false, "Question: Is the sink_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a sink labeled \"sink_1\". The robotic arm appears to be positioned near the sink. Based on the visual proximity, it seems the sink is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(cabinet_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable cabinet_1": ["yes", 1.0060210043488782e-12, 1.879494606824017e-12, "The image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm is positioned such that it appears to be close to the cabinet. Based on the visual proximity, it seems likely that the agent can reach the cabinet.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm is positioned such that it appears to be close to the cabinet. Based on the visual proximity, it seems likely that the agent can reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 1.0060091865451981e-12, 2.7346165696467972e-12, "The image shows a cabinet labeled \"cabinet_1\". The cabinet doors are closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a cabinet labeled \"cabinet_1\". The cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding bowl_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["yes", 3.0982618814262564e-12, 4.507944365017558e-12, "The image shows a cabinet labeled \"cabinet_1\". The cabinet door is clearly open, revealing the contents inside. Therefore, the cabinet is open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a cabinet labeled \"cabinet_1\". The cabinet door is clearly open, revealing the contents inside. Therefore, the cabinet is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable bowl_1": ["yes", 6.913513273150429e-13, 2.1295120614800434e-12, "The agent is the robotic arm. The bowl_1 is a green sphere. The robotic arm is holding a brown box. The bowl_1 is on the table, and the robotic arm is also near the table. The robotic arm can reach the bowl_1.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The bowl_1 is a green sphere. The robotic arm is holding a brown box. The bowl_1 is on the table, and the robotic arm is also near the table. The robotic arm can reach the bowl_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 6.913513273150429e-13, 2.1295120614800434e-12, "The agent is the robotic arm. The bowl_1 is a green sphere. The robotic arm is holding a brown box. The bowl_1 is on the table, and the robotic arm is also near the table. The robotic arm can reach the bowl_1.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The bowl_1 is a green sphere. The robotic arm is holding a brown box. The bowl_1 is on the table, and the robotic arm is also near the table. The robotic arm can reach the bowl_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"holding bowl_1": ["no", 1.0815502139716049e-11, 1.493034029742546e-10, "The image shows a virtual kitchen environment. There is a robotic arm, which is the agent. The image has labels indicating objects. The label \"bowl_1\" is present in the image. However, the robotic arm is not holding the bowl_1.", false, "Question: Is the agent holding the bowl_1\n<explanation>\nThe image shows a virtual kitchen environment. There is a robotic arm, which is the agent. The image has labels indicating objects. The label \"bowl_1\" is present in the image. However, the robotic arm is not holding the bowl_1.\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop bowl_1,cabinet_1": ["no", 1.381885664925031e-11, 4.823254642905006e-11, "The image shows a kitchen scene. The bowl_1 is labeled and appears to be on the counter. The cabinet_1 is labeled and is a wall-mounted cabinet. The bowl_1 is not on top of the cabinet_1.", true, "Question: Is the bowl_1 on top of the cabinet_1\n<explanation>\nThe image shows a kitchen scene. The bowl_1 is labeled and appears to be on the counter. The cabinet_1 is labeled and is a wall-mounted cabinet. The bowl_1 is not on top of the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop bowl_1,sink_1": ["no", 2.0113499407670155e-11, 5.4674157562439873e-11, "The image shows a kitchen scene. I need to determine if bowl_1 is on top of sink_1. Looking at the image, bowl_1 is on the counter, and sink_1 is below the counter. Therefore, bowl_1 is not on top of sink_1.", true, "Question: Is the bowl_1 on top of the sink_1\n<explanation>\nThe image shows a kitchen scene. I need to determine if bowl_1 is on top of sink_1. Looking at the image, bowl_1 is on the counter, and sink_1 is below the counter. Therefore, bowl_1 is not on top of sink_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto bowl_1,cabinet_1": ["no", 2.5858397020850354e-11, 3.762374439775229e-11, "The image shows a kitchen scene. The bowl_1 is labeled near a green fruit bowl. The cabinet_1 is labeled near a set of wooden cabinets. The bowl_1 is not next to the cabinet_1.", true, "Question: Is the bowl_1 next to the cabinet_1?\n<explanation>\nThe image shows a kitchen scene. The bowl_1 is labeled near a green fruit bowl. The cabinet_1 is labeled near a set of wooden cabinets. The bowl_1 is not next to the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto bowl_1,sink_1": ["yes", 6.195389340435398e-11, 7.020296843851526e-11, "The image shows a kitchen scene. I need to determine if the object labeled \"bowl_1\" is next to the object labeled \"sink_1\". Looking at the image, \"bowl_1\" is on the counter, and \"sink_1\" is also on the counter, and they are adjacent to each other. Therefore, the bowl_1 is next to the sink_1.", false, "Question: Is the bowl_1 next to the sink_1?\n<explanation>\nThe image shows a kitchen scene. I need to determine if the object labeled \"bowl_1\" is next to the object labeled \"sink_1\". Looking at the image, \"bowl_1\" is on the counter, and \"sink_1\" is also on the counter, and they are adjacent to each other. Therefore, the bowl_1 is next to the sink_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "inside bowl_1,cabinet_1": ["no", 6.557994598754835e-12, 2.59373703070942e-11, "The image shows a kitchen scene. The label \"bowl_1\" points to a green bowl on the counter. The label \"cabinet_1\" points to a cabinet on the wall. The bowl is on the counter, and the cabinet is on the wall. Therefore, the bowl is not inside the cabinet.", true, "Question: Is the bowl_1 inside the cabinet_1\n<explanation>\nThe image shows a kitchen scene. The label \"bowl_1\" points to a green bowl on the counter. The label \"cabinet_1\" points to a cabinet on the wall. The bowl is on the counter, and the cabinet is on the wall. Therefore, the bowl is not inside the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop bowl_1,bowl_1": {"before": null, "after": false}, "ontop bowl_1,cabinet_2": {"before": false, "after": false}, "nextto bowl_1,bowl_1": {"before": null, "after": false}, "nextto bowl_1,cabinet_2": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 2.129425542146679e-12, 9.543422475888352e-12, "The image shows a kitchen environment with a robotic arm (the agent). The bowl_1 is labeled in the image and appears to be on a countertop. The robotic arm is positioned in the kitchen, and based on the visual perspective, the bowl_1 seems to be within the arm's potential reach.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a kitchen environment with a robotic arm (the agent). The bowl_1 is labeled in the image and appears to be on a countertop. The robotic arm is positioned in the kitchen, and based on the visual perspective, the bowl_1 seems to be within the arm's potential reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable cabinet_1": ["no", "yes"], "reachable cabinet_2": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open cabinet_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.75, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}}}, "step": 1, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "no"], "reachable sink_1": ["yes", "no"], "open cabinet_1": ["no", "no"], "open cabinet_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 2, "no_total": 4, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}}}, "step": 2, "actions": ["open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable bowl_2": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable piece_of_cloth_1": ["yes", "yes"], "reachable sink_1": ["yes", "no"], "holding bowl_1": ["no", "yes"], "holding bowl_2": ["no", "no"], "holding piece_of_cloth_1": ["yes", "no"], "open cabinet_1": ["no", "yes"], "ontop bowl_1,bowl_2": ["no", "no"], "ontop bowl_1,cabinet_1": ["no", "no"], "ontop bowl_1,piece_of_cloth_1": ["no", "no"], "ontop bowl_1,sink_1": ["no", "no"], "ontop bowl_2,bowl_1": ["no", "no"], "ontop bowl_2,cabinet_1": ["no", "no"], "ontop bowl_2,piece_of_cloth_1": ["no", "no"], "ontop bowl_2,sink_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_2": ["yes", "no"], "ontop piece_of_cloth_1,cabinet_1": ["no", "no"], "ontop piece_of_cloth_1,sink_1": ["no", "no"], "inside bowl_1,cabinet_1": ["no", "no"], "inside bowl_2,cabinet_1": ["no", "yes"], "inside piece_of_cloth_1,cabinet_1": ["no", "yes"], "nextto bowl_1,bowl_2": ["no", "no"], "nextto bowl_1,cabinet_1": ["no", "no"], "nextto bowl_1,piece_of_cloth_1": ["no", "no"], "nextto bowl_1,sink_1": ["yes", "no"], "nextto bowl_2,bowl_1": ["no", "no"], "nextto bowl_2,cabinet_1": ["no", "yes"], "nextto bowl_2,piece_of_cloth_1": ["yes", "no"], "nextto bowl_2,sink_1": ["yes", "no"], "nextto piece_of_cloth_1,bowl_1": ["yes", "no"], "nextto piece_of_cloth_1,bowl_2": ["yes", "no"], "nextto piece_of_cloth_1,cabinet_1": ["no", "yes"], "nextto piece_of_cloth_1,sink_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.5555555555555556, "yes_accuracy": 0.3, "yes_correct": 3, "yes_total": 10, "no_accuracy": 0.6538461538461539, "no_correct": 17, "no_total": 26, "predicates": {"reachable": {"accuracy": 0.6, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.9166666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.9166666666666666, "no_correct": 11, "no_total": 12}, "inside": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.4, "no_correct": 4, "no_total": 10}}}, "step": 4, "actions": ["grasp(bowl_1)", "place-on(bowl_1, sink_1)"]}], "remaining_actions": ["place-on(bowl_1, sink_1)"]}, "data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Benevolence_1_int_20": {"all_correct": false, "goal_reached": true, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable cabinet_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 5.78166854670048e-12, 8.412278686142916e-12, "The agent is the robotic arm. The cabinet_1 is labeled in the image. The robotic arm is holding a green sphere. The cabinet_1 is on the other side of the room, and the robotic arm is holding an object. It is unlikely that the cabinet_1 is in reach of the agent.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The cabinet_1 is labeled in the image. The robotic arm is holding a green sphere. The cabinet_1 is on the other side of the room, and the robotic arm is holding an object. It is unlikely that the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable cabinet_2": ["no", 4.504091110496544e-12, 8.414749799734444e-12, "The agent is the robotic arm. The cabinet_2 is a cabinet in the image. The robotic arm is holding a green sphere. The cabinet_2 is on the right side of the image, and the robotic arm is on the left side of the image. The robotic arm is holding an object, so it cannot reach the cabinet_2.", true, "Question: Is the cabinet_2 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The cabinet_2 is a cabinet in the image. The robotic arm is holding a green sphere. The cabinet_2 is on the right side of the image, and the robotic arm is on the left side of the image. The robotic arm is holding an object, so it cannot reach the cabinet_2.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}, "reachable sink_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 5.78166854670048e-12, 8.412278686142916e-12, "The agent is the robotic arm. The cabinet_1 is labeled in the image. The robotic arm is holding a green sphere. The cabinet_1 is on the other side of the room, and the robotic arm is holding an object. It is unlikely that the cabinet_1 is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The cabinet_1 is labeled in the image. The robotic arm is holding a green sphere. The cabinet_1 is on the other side of the room, and the robotic arm is holding an object. It is unlikely that the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 3.977487176426431e-12, 1.081193121144075e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet in the image. The robotic arm is holding a green object and is positioned near a table. The cabinet is further away from the robotic arm than the table. Therefore, the cabinet is not in reach of the agent.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet in the image. The robotic arm is holding a green object and is positioned near a table. The cabinet is further away from the robotic arm than the table. Therefore, the cabinet is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}, "reachable cabinet_2": {"before": false, "after": false}, "reachable sink_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 3.977487176426431e-12, 1.081193121144075e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet in the image. The robotic arm is holding a green object and is positioned near a table. The cabinet is further away from the robotic arm than the table. Therefore, the cabinet is not in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet in the image. The robotic arm is holding a green object and is positioned near a table. The cabinet is further away from the robotic arm than the table. Therefore, the cabinet is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 6.913476410276564e-13, 1.6584567920363558e-12, "The agent is a robotic arm. The cabinet_1 is labeled in the image and is a counter. The robotic arm is positioned above the counter. Therefore, the cabinet_1 is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is labeled in the image and is a counter. The robotic arm is positioned above the counter. Therefore, the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_2": ["yes", 1.139752897096058e-12, 3.5106858826267073e-12, "The agent is the robotic arm. The cabinet_2 is labeled in the image and is located on the counter. The robotic arm is positioned above the counter and appears to be able to reach the cabinet_2.", false, "Question: Is the cabinet_2 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The cabinet_2 is labeled in the image and is located on the counter. The robotic arm is positioned above the counter and appears to be able to reach the cabinet_2.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}, "reachable sink_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(cabinet_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable cabinet_1": ["yes", 6.913476410276564e-13, 1.6584567920363558e-12, "The agent is a robotic arm. The cabinet_1 is labeled in the image and is a counter. The robotic arm is positioned above the counter. Therefore, the cabinet_1 is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is labeled in the image and is a counter. The robotic arm is positioned above the counter. Therefore, the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 8.875755490821147e-13, 3.5104293603926973e-12, "The image shows a cabinet labeled \"cabinet_1\". The cabinet doors are closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a cabinet labeled \"cabinet_1\". The cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding bowl_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["yes", 3.0923590511183763e-12, 1.875610560961305e-12, "The image shows a cabinet labeled \"cabinet_1\". The doors of the cabinet are clearly open. Therefore, the cabinet is open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a cabinet labeled \"cabinet_1\". The doors of the cabinet are clearly open. Therefore, the cabinet is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable bowl_1": ["yes", 1.5426473033014476e-13, 4.751688409063148e-13, "The image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm is extended towards the bowl. Based on the visual proximity and the arm's position, it appears the bowl is within the agent's reach.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm is extended towards the bowl. Based on the visual proximity and the arm's position, it appears the bowl is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 1.5426473033014476e-13, 4.751688409063148e-13, "The image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm is extended towards the bowl. Based on the visual proximity and the arm's position, it appears the bowl is within the agent's reach.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm is extended towards the bowl. Based on the visual proximity and the arm's position, it appears the bowl is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"holding bowl_1": ["yes", 7.052348982572454e-11, 3.3312939212715165e-11, "The image shows a robotic arm (the agent) and several bowls labeled bowl_1, bowl_2, and bowl_3. The robotic arm is positioned above bowl_1 and appears to be grasping it. Therefore, the agent is holding the bowl_1.", true, "Question: Is the agent holding the bowl_1\n<explanation>\nThe image shows a robotic arm (the agent) and several bowls labeled bowl_1, bowl_2, and bowl_3. The robotic arm is positioned above bowl_1 and appears to be grasping it. Therefore, the agent is holding the bowl_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop bowl_1,cabinet_1": ["no", 7.430269073627205e-12, 1.7824290654555597e-11, "The image shows a robotic arm holding a bowl labeled \"bowl_1\". The bowl is positioned above a counter or table-like structure. There is also a cabinet labeled \"cabinet_1\" visible in the image. However, the bowl is not on top of the cabinet. It is above a counter.", true, "Question: Is the bowl_1 on top of the cabinet_1\n<explanation>\nThe image shows a robotic arm holding a bowl labeled \"bowl_1\". The bowl is positioned above a counter or table-like structure. There is also a cabinet labeled \"cabinet_1\" visible in the image. However, the bowl is not on top of the cabinet. It is above a counter.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop bowl_1,cabinet_2": ["yes", 6.556335769430932e-12, 1.7821967859821264e-11, "The image shows a robotic arm holding a bowl labeled \"bowl_1\". The bowl is positioned above a cabinet labeled \"cabinet_2\". Therefore, the bowl is on top of the cabinet.", false, "Question: Is the bowl_1 on top of the cabinet_2\n<explanation>\nThe image shows a robotic arm holding a bowl labeled \"bowl_1\". The bowl is positioned above a cabinet labeled \"cabinet_2\". Therefore, the bowl is on top of the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto bowl_1,cabinet_1": ["no", 2.01869701510482e-11, 2.2874832236730036e-11, "The image shows a robotic arm holding a bowl labeled \"bowl_1\". There is also a cabinet labeled \"cabinet_1\". The bowl is being held in the air, and the cabinet is on the wall. The bowl is not next to the cabinet.", true, "Question: Is the bowl_1 next to the cabinet_1\n<explanation>\nThe image shows a robotic arm holding a bowl labeled \"bowl_1\". There is also a cabinet labeled \"cabinet_1\". The bowl is being held in the air, and the cabinet is on the wall. The bowl is not next to the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto bowl_1,cabinet_2": ["yes", 2.930985315563461e-11, 2.586585459707358e-11, "The image shows a robotic arm holding a bowl labeled \"bowl_1\". There is also a cabinet labeled \"cabinet_2\". The bowl_1 is on the countertop, and the cabinet_2 is below the countertop. Therefore, bowl_1 is next to cabinet_2.", false, "Question: Is the bowl_1 next to the cabinet_2\n<explanation>\nThe image shows a robotic arm holding a bowl labeled \"bowl_1\". There is also a cabinet labeled \"cabinet_2\". The bowl_1 is on the countertop, and the cabinet_2 is below the countertop. Therefore, bowl_1 is next to cabinet_2.\n</explanation>\n<answer>\nYes\n</answer>", false], "inside bowl_1,cabinet_1": ["no", 1.879461863918408e-12, 6.5599678467087585e-12, "The image shows a robotic arm holding a bowl labeled \"bowl_1\". The bowl is positioned above a countertop, and next to a cabinet labeled \"cabinet_1\". The bowl is not inside the cabinet.", true, "Question: Is the bowl_1 inside the cabinet_1\n<explanation>\nThe image shows a robotic arm holding a bowl labeled \"bowl_1\". The bowl is positioned above a countertop, and next to a cabinet labeled \"cabinet_1\". The bowl is not inside the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop bowl_1,bowl_1": {"before": null, "after": false}, "ontop bowl_1,sink_1": {"before": false, "after": false}, "nextto bowl_1,bowl_1": {"before": null, "after": false}, "nextto bowl_1,sink_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(sink_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable sink_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable sink_1": ["yes", 3.974076276391791e-12, 7.424551425050385e-12, "The image shows a robotic arm. The sink is located below the arm. The arm appears to be extended towards the sink. Therefore, the sink is in reach of the agent.", true, "Question: Is the sink_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The sink is located below the arm. The arm appears to be extended towards the sink. Therefore, the sink is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable bowl_1": ["yes", 2.1290352293645842e-12, 4.507167642581189e-12, "The agent is a robotic arm. The bowl_1 is located on the counter. The robotic arm is positioned above the counter. Therefore, the bowl_1 is in reach of the agent.", false, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The bowl_1 is located on the counter. The robotic arm is positioned above the counter. Therefore, the bowl_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable cabinet_1": {"before": false, "after": false}, "reachable cabinet_2": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-on(bowl_1, sink_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding bowl_1": ["yes", 2.5936832542816646e-11, 2.019962495880545e-11, "The image shows a robotic arm holding a black object. The objects in the scene are a sink, a counter, a bowl, and some towels. The bowl is labeled as bowl_1. The robotic arm is holding the bowl. Therefore, the answer is \"Yes\".", true, "Question: Is the agent holding the bowl_1\n<explanation>\nThe image shows a robotic arm holding a black object. The objects in the scene are a sink, a counter, a bowl, and some towels. The bowl is labeled as bowl_1. The robotic arm is holding the bowl. Therefore, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sink_1": ["yes", 3.974076276391791e-12, 7.424551425050385e-12, "The image shows a robotic arm. The sink is located below the arm. The arm appears to be extended towards the sink. Therefore, the sink is in reach of the agent.", true, "Question: Is the sink_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The sink is located below the arm. The arm appears to be extended towards the sink. Therefore, the sink is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"ontop bowl_1,sink_1": ["no", 3.978279945054952e-12, 8.422019158460525e-12, "The image shows a sink and a bowl. The bowl is inside the sink. Therefore, the bowl is not on top of the sink.", false, "Question: Is the bowl_1 on top of the sink_1\n<explanation>\nThe image shows a sink and a bowl. The bowl is inside the sink. Therefore, the bowl is not on top of the sink.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding bowl_1": ["yes", 3.7748405096182935e-11, 7.052330247558913e-11, "The image shows a robotic arm. The robotic arm is holding a bowl. The bowl is labeled as bowl_1. Therefore, the agent is holding the bowl_1.", false, "Question: Is the agent holding the bowl_1\n<explanation>\nThe image shows a robotic arm. The robotic arm is holding a bowl. The bowl is labeled as bowl_1. Therefore, the agent is holding the bowl_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "place-on(bowl_1, sink_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding bowl_1": ["yes", 3.7748405096182935e-11, 7.052330247558913e-11, "The image shows a robotic arm. The robotic arm is holding a bowl. The bowl is labeled as bowl_1. Therefore, the agent is holding the bowl_1.", true, "Question: Is the agent holding the bowl_1\n<explanation>\nThe image shows a robotic arm. The robotic arm is holding a bowl. The bowl is labeled as bowl_1. Therefore, the agent is holding the bowl_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable sink_1": ["yes", 1.879342384839e-12, 3.978568342832833e-12, "The image shows a robotic arm (the agent) and a sink labeled \"sink_1\". The arm is positioned above the sink. The arm appears to be close enough to the sink to interact with it. Therefore, the sink is in reach of the agent.", true, "Question: Is the sink_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a sink labeled \"sink_1\". The arm is positioned above the sink. The arm appears to be close enough to the sink to interact with it. Therefore, the sink is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable cabinet_1": ["no", "yes"], "reachable cabinet_2": ["no", "yes"], "open cabinet_1": ["no", "no"], "open cabinet_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}}}, "step": 1, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["no", "yes"], "open cabinet_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 2, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open cabinet_2": ["no", "no"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}}}, "step": 3, "actions": ["open-container(cabinet_1)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable bowl_2": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable cabinet_2": ["no", "yes"], "reachable piece_of_cloth_1": ["no", "yes"], "holding bowl_1": ["yes", "yes"], "holding bowl_2": ["no", "no"], "holding piece_of_cloth_1": ["no", "no"], "open cabinet_1": ["yes", "yes"], "open cabinet_2": ["yes", "no"], "ontop bowl_1,bowl_2": ["no", "no"], "ontop bowl_1,cabinet_1": ["no", "no"], "ontop bowl_1,cabinet_2": ["yes", "no"], "ontop bowl_1,piece_of_cloth_1": ["no", "no"], "ontop bowl_2,bowl_1": ["yes", "no"], "ontop bowl_2,cabinet_1": ["no", "no"], "ontop bowl_2,cabinet_2": ["yes", "no"], "ontop bowl_2,piece_of_cloth_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_2": ["no", "no"], "ontop piece_of_cloth_1,cabinet_1": ["no", "no"], "ontop piece_of_cloth_1,cabinet_2": ["no", "no"], "inside bowl_1,cabinet_1": ["no", "no"], "inside bowl_1,cabinet_2": ["no", "no"], "inside bowl_2,cabinet_1": ["no", "yes"], "inside bowl_2,cabinet_2": ["no", "no"], "inside piece_of_cloth_1,cabinet_1": ["no", "yes"], "inside piece_of_cloth_1,cabinet_2": ["no", "no"], "nextto bowl_1,bowl_2": ["no", "no"], "nextto bowl_1,cabinet_1": ["no", "no"], "nextto bowl_1,cabinet_2": ["yes", "no"], "nextto bowl_1,piece_of_cloth_1": ["no", "no"], "nextto bowl_2,bowl_1": ["yes", "no"], "nextto bowl_2,cabinet_1": ["no", "yes"], "nextto bowl_2,cabinet_2": ["yes", "no"], "nextto bowl_2,piece_of_cloth_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_1": ["yes", "no"], "nextto piece_of_cloth_1,bowl_2": ["no", "no"], "nextto piece_of_cloth_1,cabinet_1": ["no", "yes"], "nextto piece_of_cloth_1,cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6, "yes_accuracy": 0.36363636363636365, "yes_correct": 4, "yes_total": 11, "no_accuracy": 0.6896551724137931, "no_correct": 20, "no_total": 29, "predicates": {"reachable": {"accuracy": 0.4, "yes_accuracy": 0.4, "yes_correct": 2, "yes_total": 5, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 9, "no_total": 12}, "inside": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.4166666666666667, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.5, "no_correct": 5, "no_total": 10}}}, "step": 5, "actions": ["navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "holding bowl_1": ["yes", "yes"], "ontop bowl_1,sink_1": ["no", "no"], "nextto bowl_1,sink_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.8, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}}}, "step": 6, "actions": ["place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "holding bowl_1": ["yes", "no"], "ontop bowl_1,sink_1": ["no", "yes"], "nextto bowl_1,sink_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.6, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 7, "actions": ["place-on(bowl_1, sink_1)"]}], "remaining_actions": []}, "data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Benevolence_1_int_21": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable cabinet_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 4.50756402689545e-12, 9.542512613425203e-12, "The agent is a robotic arm. The cabinet_1 is the cabinet on the right side of the image. The robotic arm is holding a green apple. The robotic arm is close to the countertop. The cabinet is further away than the countertop. Therefore, the cabinet is not in reach of the agent.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the right side of the image. The robotic arm is holding a green apple. The robotic arm is close to the countertop. The cabinet is further away than the countertop. Therefore, the cabinet is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}, "reachable cabinet_2": {"before": true, "after": false}, "reachable sink_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "open-container(cabinet_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable cabinet_1": ["yes", 4.50756402689545e-12, 9.542512613425203e-12, "The agent is a robotic arm. The cabinet_1 is the cabinet on the right side of the image. The robotic arm is holding a green apple. The arm is close to the countertop, and the cabinet is also on the countertop. The arm appears to be able to reach the cabinet.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the right side of the image. The robotic arm is holding a green apple. The arm is close to the countertop, and the cabinet is also on the countertop. The arm appears to be able to reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 3.978721432179588e-12, 5.108779718709933e-12, "The image shows a kitchen counter with cabinets below. The cabinet labeled \"cabinet_1\" has its doors closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen counter with cabinets below. The cabinet labeled \"cabinet_1\" has its doors closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding bowl_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["yes", 3.5104076763492476e-12, 2.412665553452875e-12, "The image shows a cabinet labeled \"cabinet_1\". The door of the cabinet is clearly open. Therefore, the answer is \"Yes\".", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a cabinet labeled \"cabinet_1\". The door of the cabinet is clearly open. Therefore, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable bowl_1": ["yes", 5.384739962949192e-13, 1.879458828152325e-12, "The image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm is holding a green sphere. The bowl_1 is on a cabinet. The robotic arm is positioned such that it could potentially reach the bowl_1. Therefore, the bowl_1 is in reach of the agent.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm is holding a green sphere. The bowl_1 is on a cabinet. The robotic arm is positioned such that it could potentially reach the bowl_1. Therefore, the bowl_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 5.384739962949192e-13, 1.879458828152325e-12, "The image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm is holding a green sphere. The bowl_1 is on a cabinet. The robotic arm is positioned such that it could potentially reach the bowl_1. Therefore, the bowl_1 is in reach of the agent.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm is holding a green sphere. The bowl_1 is on a cabinet. The robotic arm is positioned such that it could potentially reach the bowl_1. Therefore, the bowl_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"holding bowl_1": ["no", 2.0205842207743352e-11, 3.331379963555925e-11, "The image shows a robotic arm (the agent) and several objects. The label \"bowl_1\" points to a bowl that is suspended in the air. The robotic arm is positioned near the bowl, but it is not visibly grasping or holding the bowl. Therefore, the agent is not holding the bowl_1.", false, "Question: Is the agent holding the bowl_1\n<explanation>\nThe image shows a robotic arm (the agent) and several objects. The label \"bowl_1\" points to a bowl that is suspended in the air. The robotic arm is positioned near the bowl, but it is not visibly grasping or holding the bowl. Therefore, the agent is not holding the bowl_1.\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop bowl_1,cabinet_1": ["no", 8.414979650595011e-12, 1.0805047828688075e-11, "The image shows a kitchen scene. The bowl_1 is labeled and appears to be suspended in the air. The cabinet_1 is labeled and is a large piece of furniture below the bowl_1. The bowl_1 is not resting on top of the cabinet_1.", true, "Question: Is the bowl_1 on top of the cabinet_1\n<explanation>\nThe image shows a kitchen scene. The bowl_1 is labeled and appears to be suspended in the air. The cabinet_1 is labeled and is a large piece of furniture below the bowl_1. The bowl_1 is not resting on top of the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto bowl_1,cabinet_1": ["no", 1.0808247526139514e-11, 8.417471580868252e-12, "The image shows a kitchen scene. The bowl_1 is labeled and appears to be hanging from the ceiling. The cabinet_1 is labeled and is a part of the kitchen counter. The bowl_1 is not next to the cabinet_1.", true, "Question: Is the bowl_1 next to the cabinet_1\n<explanation>\nThe image shows a kitchen scene. The bowl_1 is labeled and appears to be hanging from the ceiling. The cabinet_1 is labeled and is a part of the kitchen counter. The bowl_1 is not next to the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "inside bowl_1,cabinet_1": ["no", 2.7343327255180405e-12, 5.108406319481729e-12, "The image shows a kitchen scene. The object labeled \"bowl_1\" is hanging from the ceiling. The object labeled \"cabinet_1\" is a cabinet on the counter. The bowl_1 is not inside the cabinet_1.", true, "Question: Is the bowl_1 inside the cabinet_1\n<explanation>\nThe image shows a kitchen scene. The object labeled \"bowl_1\" is hanging from the ceiling. The object labeled \"cabinet_1\" is a cabinet on the counter. The bowl_1 is not inside the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop bowl_1,bowl_1": {"before": null, "after": false}, "ontop bowl_1,cabinet_2": {"before": false, "after": false}, "ontop bowl_1,sink_1": {"before": false, "after": false}, "nextto bowl_1,bowl_1": {"before": null, "after": false}, "nextto bowl_1,cabinet_2": {"before": false, "after": false}, "nextto bowl_1,sink_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 6.101697922963889e-13, 1.879454925024504e-12, "The image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm appears to be positioned above the bowl. Based on the visual representation, it seems the bowl is within the arm's reach.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm appears to be positioned above the bowl. Based on the visual representation, it seems the bowl is within the arm's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable cabinet_1": ["yes", "yes"], "open cabinet_1": ["no", "no"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 1, "actions": ["open-container(cabinet_1)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable bowl_2": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable piece_of_cloth_1": ["yes", "yes"], "holding bowl_1": ["no", "yes"], "holding bowl_2": ["yes", "no"], "holding piece_of_cloth_1": ["no", "no"], "open cabinet_1": ["yes", "yes"], "ontop bowl_1,bowl_2": ["yes", "no"], "ontop bowl_1,cabinet_1": ["no", "no"], "ontop bowl_1,piece_of_cloth_1": ["no", "no"], "ontop bowl_2,bowl_1": ["no", "no"], "ontop bowl_2,cabinet_1": ["no", "no"], "ontop bowl_2,piece_of_cloth_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_2": ["no", "no"], "ontop piece_of_cloth_1,cabinet_1": ["yes", "no"], "inside bowl_1,cabinet_1": ["no", "no"], "inside bowl_2,cabinet_1": ["no", "yes"], "inside piece_of_cloth_1,cabinet_1": ["no", "yes"], "nextto bowl_1,bowl_2": ["no", "no"], "nextto bowl_1,cabinet_1": ["no", "no"], "nextto bowl_1,piece_of_cloth_1": ["no", "no"], "nextto bowl_2,bowl_1": ["no", "no"], "nextto bowl_2,cabinet_1": ["yes", "yes"], "nextto bowl_2,piece_of_cloth_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_2": ["no", "no"], "nextto piece_of_cloth_1,cabinet_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.7586206896551724, "yes_accuracy": 0.6, "yes_correct": 6, "yes_total": 10, "no_accuracy": 0.8421052631578947, "no_correct": 16, "no_total": 19, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.7777777777777778, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.7777777777777778, "no_correct": 7, "no_total": 9}, "inside": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}}}, "step": 3, "actions": ["grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}], "remaining_actions": ["navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, "data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Rs_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable cabinet_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 2.4128947537921386e-12, 3.978191040476808e-12, "The image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm appears to be positioned close to the cabinet. Based on the visual proximity, it seems the agent can reach the cabinet.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm appears to be positioned close to the cabinet. Based on the visual proximity, it seems the agent can reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_2": ["yes", 1.6584911612452236e-12, 2.413090343864055e-12, "The image shows a robotic arm (the agent) and several cabinets. The question asks if cabinet_2 is within the agent's reach. Looking at the image, the robotic arm is positioned close to cabinet_2. The arm appears to be able to reach the cabinet.", false, "Question: Is the cabinet_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and several cabinets. The question asks if cabinet_2 is within the agent's reach. Looking at the image, the robotic arm is positioned close to cabinet_2. The arm appears to be able to reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}, "reachable sink_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(bowl_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable bowl_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 1.4636839917175903e-12, 3.51119567448821e-12, "The image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The robotic arm is holding a black object. The question asks if the cabinet_1 is within reach of the agent. Based on the image, the robotic arm is positioned close to the cabinet_1. Therefore, the cabinet_1 is in reach of the agent.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The robotic arm is holding a black object. The question asks if the cabinet_1 is within reach of the agent. Based on the image, the robotic arm is positioned close to the cabinet_1. Therefore, the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_2": ["yes", 6.101707138682355e-13, 1.6586159529152766e-12, "The image shows a robotic arm (the agent) and several cabinets. The question asks if cabinet_2 is within reach of the agent. Looking at the image, the robotic arm is positioned close to cabinet_2. The arm appears to be holding an object and is oriented towards cabinet_2. Therefore, it is reasonable to assume that cabinet_2 is within reach of the agent.", false, "Question: Is the cabinet_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and several cabinets. The question asks if cabinet_2 is within reach of the agent. Looking at the image, the robotic arm is positioned close to cabinet_2. The arm appears to be holding an object and is oriented towards cabinet_2. Therefore, it is reasonable to assume that cabinet_2 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": true}, "reachable sink_1": {"before": false, "after": false}}}, "action_info": "executed but failed"}, {"action": "open-container(cabinet_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable cabinet_1": ["yes", 1.4636839917175903e-12, 3.51119567448821e-12, "The image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The robotic arm is holding a black object. The question asks if the cabinet_1 is within reach of the agent. Based on the image, the robotic arm is positioned close to the cabinet_1. Therefore, the cabinet_1 is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The robotic arm is holding a black object. The question asks if the cabinet_1 is within reach of the agent. Based on the image, the robotic arm is positioned close to the cabinet_1. Therefore, the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 6.913587540999244e-13, 2.413079068161461e-12, "The image shows a cabinet labeled 'cabinet_1'. The cabinet doors are closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a cabinet labeled 'cabinet_1'. The cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding bowl_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["yes", 1.005925811398134e-12, 8.87726415814416e-13, "The image shows a cabinet labeled \"cabinet_1\". The doors of the cabinet are clearly open. Therefore, the answer is \"Yes\".", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a cabinet labeled \"cabinet_1\". The doors of the cabinet are clearly open. Therefore, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable bowl_1": ["yes", 3.700921134223295e-13, 5.384808267686059e-13, "The image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm appears to be positioned close to the bowl. Based on the visual proximity, it seems likely that the bowl is within the agent's reach.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm appears to be positioned close to the bowl. Based on the visual proximity, it seems likely that the bowl is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 3.700921134223295e-13, 5.384808267686059e-13, "The image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm appears to be positioned close to the bowl. Based on the visual proximity, it seems likely that the bowl is within the agent's reach.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". The robotic arm appears to be positioned close to the bowl. Based on the visual proximity, it seems likely that the bowl is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"holding bowl_1": ["no", 1.573576165203594e-11, 5.210968323510201e-10, "The image shows a robotic arm. The question asks if the agent (robotic arm) is holding the bowl_1. There is a bowl labeled 'bowl_1' in the image, but the robotic arm is not holding it.", false, "Question: Is the agent holding the bowl_1\n<explanation>\nThe image shows a robotic arm. The question asks if the agent (robotic arm) is holding the bowl_1. There is a bowl labeled 'bowl_1' in the image, but the robotic arm is not holding it.\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop bowl_1,cabinet_1": ["no", 3.625556799224938e-11, 7.675303448362314e-11, "The image shows a cabinet labeled 'cabinet_1' and a bowl labeled 'bowl_1'. The bowl is not on top of the cabinet. It is to the right of the cabinet.", true, "Question: Is the bowl_1 on top of the cabinet_1\n<explanation>\nThe image shows a cabinet labeled 'cabinet_1' and a bowl labeled 'bowl_1'. The bowl is not on top of the cabinet. It is to the right of the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop bowl_1,cabinet_2": ["yes", 1.2127710294351779e-11, 3.7355979420894414e-11, "The image shows a bowl labeled 'bowl_1' and a cabinet labeled 'cabinet_2'. The bowl is positioned above the cabinet. Therefore, the bowl_1 is on top of the cabinet_2.", false, "Question: Is the bowl_1 on top of the cabinet_2\n<explanation>\nThe image shows a bowl labeled 'bowl_1' and a cabinet labeled 'cabinet_2'. The bowl is positioned above the cabinet. Therefore, the bowl_1 is on top of the cabinet_2.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto bowl_1,cabinet_1": ["yes", 1.2502844592976459e-10, 1.6053972040630526e-10, "The image shows a bowl labeled 'bowl_1' and a cabinet labeled 'cabinet_1'. The bowl is located on the right side of the cabinet. Therefore, the bowl is next to the cabinet.", false, "Question: Is the bowl_1 next to the cabinet_1?\n<explanation>\nThe image shows a bowl labeled 'bowl_1' and a cabinet labeled 'cabinet_1'. The bowl is located on the right side of the cabinet. Therefore, the bowl is next to the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto bowl_1,cabinet_2": ["yes", 4.207331358307975e-11, 6.936716479000182e-11, "The image shows a bowl labeled 'bowl_1' and a cabinet labeled 'cabinet_2'. The bowl is located on the right side of the cabinet. Therefore, the bowl is next to the cabinet.", false, "Question: Is the bowl_1 next to the cabinet_2\n<explanation>\nThe image shows a bowl labeled 'bowl_1' and a cabinet labeled 'cabinet_2'. The bowl is located on the right side of the cabinet. Therefore, the bowl is next to the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", false], "inside bowl_1,cabinet_1": ["no", 4.499635039567629e-12, 1.3859851634434595e-11, "The image shows a cabinet labeled 'cabinet_1'. There is a bowl labeled 'bowl_1' near the cabinet. However, the bowl is not inside the cabinet. It is next to the cabinet.", true, "Question: Is the bowl_1 inside the cabinet_1\n<explanation>\nThe image shows a cabinet labeled 'cabinet_1'. There is a bowl labeled 'bowl_1' near the cabinet. However, the bowl is not inside the cabinet. It is next to the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop bowl_1,bowl_1": {"before": null, "after": false}, "ontop bowl_1,sink_1": {"before": false, "after": false}, "nextto bowl_1,bowl_1": {"before": null, "after": false}, "nextto bowl_1,sink_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 1.8788792136709143e-12, 9.541736324669703e-12, "The image shows a robotic arm (the agent) and a bowl labeled 'bowl_1'. The bowl is located on the lower part of a cabinet labeled 'cabinet_1'. The robotic arm appears to be positioned near the cabinet. Based on the visual proximity, it seems likely that the robotic arm can reach the bowl.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled 'bowl_1'. The bowl is located on the lower part of a cabinet labeled 'cabinet_1'. The robotic arm appears to be positioned near the cabinet. Based on the visual proximity, it seems likely that the robotic arm can reach the bowl.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "open cabinet_1": ["yes", "no"], "open cabinet_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}}}, "step": 1, "actions": ["navigate-to(bowl_1)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}}}, "step": 2, "actions": ["open-container(cabinet_1)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable piece_of_cloth_1": ["yes", "yes"], "holding bowl_1": ["no", "yes"], "holding piece_of_cloth_1": ["no", "no"], "open cabinet_1": ["yes", "yes"], "open cabinet_2": ["yes", "no"], "ontop bowl_1,cabinet_1": ["no", "no"], "ontop bowl_1,cabinet_2": ["yes", "no"], "ontop bowl_1,piece_of_cloth_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_1": ["no", "no"], "ontop piece_of_cloth_1,cabinet_1": ["no", "no"], "ontop piece_of_cloth_1,cabinet_2": ["no", "no"], "inside bowl_1,cabinet_1": ["no", "no"], "inside bowl_1,cabinet_2": ["no", "no"], "inside piece_of_cloth_1,cabinet_1": ["no", "yes"], "inside piece_of_cloth_1,cabinet_2": ["no", "no"], "nextto bowl_1,cabinet_1": ["yes", "no"], "nextto bowl_1,cabinet_2": ["yes", "no"], "nextto bowl_1,piece_of_cloth_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_1": ["no", "no"], "nextto piece_of_cloth_1,cabinet_1": ["yes", "yes"], "nextto piece_of_cloth_1,cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7083333333333334, "yes_accuracy": 0.75, "yes_correct": 6, "yes_total": 8, "no_accuracy": 0.6875, "no_correct": 11, "no_total": 16, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 0.8333333333333334, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.8333333333333334, "no_correct": 5, "no_total": 6}, "inside": {"accuracy": 0.75, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "nextto": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.4, "no_correct": 2, "no_total": 5}}}, "step": 4, "actions": ["grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}], "remaining_actions": ["navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, "data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Rs_int_20": {"all_correct": false, "goal_reached": true, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable cabinet_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 1.463299967308096e-12, 3.510274319482032e-12, "The image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The robotic arm is positioned to the right of the cabinet. The arm appears to be extended towards the cabinet. Based on the visual proximity and the arm's orientation, it seems the cabinet is within the agent's reach.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The robotic arm is positioned to the right of the cabinet. The arm appears to be extended towards the cabinet. Based on the visual proximity and the arm's orientation, it seems the cabinet is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_2": ["yes", 7.833488632064123e-13, 1.6583494560212797e-12, "The image shows a robotic arm (the agent) and two cabinets labeled \"cabinet_1\" and \"cabinet_2\". The robotic arm is holding a blue object. The question asks if cabinet_2 is in reach of the agent. Cabinet_2 is located on the counter, and the robotic arm is positioned above the counter. Based on the image, the robotic arm appears to be close enough to reach cabinet_2.", false, "Question: Is the cabinet_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and two cabinets labeled \"cabinet_1\" and \"cabinet_2\". The robotic arm is holding a blue object. The question asks if cabinet_2 is in reach of the agent. Cabinet_2 is located on the counter, and the robotic arm is positioned above the counter. Based on the image, the robotic arm appears to be close enough to reach cabinet_2.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sink_1": ["no", 5.384535590839679e-13, 1.4636684876265238e-12, "The image shows a robotic arm (the agent) holding a blue object. The sink_1 is located on the left side of the image, near a window. The robotic arm is on the right side of the image, near a cabinet and oven. The distance between the robotic arm and the sink_1 appears to be too far for the arm to reach the sink without moving.", true, "Question: Is the sink_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) holding a blue object. The sink_1 is located on the left side of the image, near a window. The robotic arm is on the right side of the image, near a cabinet and oven. The distance between the robotic arm and the sink_1 appears to be too far for the arm to reach the sink without moving.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(bowl_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable bowl_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 2.7333159607206836e-12, 5.106506797275534e-12, "The image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm is positioned below the cabinet. Based on the visual perspective, the arm appears to be close enough to the cabinet to potentially reach it.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm is positioned below the cabinet. Based on the visual perspective, the arm appears to be close enough to the cabinet to potentially reach it.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_2": ["yes", 1.139819683949883e-12, 1.8792448066434764e-12, "The image shows a robotic arm (the agent) and two cabinets labeled \"cabinet_1\" and \"cabinet_2\". The agent is holding an object. I need to determine if \"cabinet_2\" is within the agent's reach. Based on the image, \"cabinet_2\" is located below the agent and appears to be within the agent's range of motion.", false, "Question: Is the cabinet_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and two cabinets labeled \"cabinet_1\" and \"cabinet_2\". The agent is holding an object. I need to determine if \"cabinet_2\" is within the agent's reach. Based on the image, \"cabinet_2\" is located below the agent and appears to be within the agent's range of motion.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sink_1": ["yes", 8.877842037902095e-13, 2.4132475531790654e-12, "The image shows a robotic arm (the agent) and a sink labeled \"sink_1\". I need to determine if the agent can reach the sink. Based on the image, the agent's arm is positioned near a countertop and appears to be close enough to the sink. Therefore, the sink is within reach of the agent.", false, "Question: Is the sink_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a sink labeled \"sink_1\". I need to determine if the agent can reach the sink. Based on the image, the agent's arm is positioned near a countertop and appears to be close enough to the sink. Therefore, the sink is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": true}}}, "action_info": "executed but failed"}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 2.7333159607206836e-12, 5.106506797275534e-12, "The image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm is positioned below the cabinet. Based on the visual perspective, the arm appears to be close enough to the cabinet to potentially reach it.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a cabinet labeled \"cabinet_1\". The arm is positioned below the cabinet. Based on the visual perspective, the arm appears to be close enough to the cabinet to potentially reach it.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 2.410866645208287e-12, 5.7833685757069375e-12, "The image shows a kitchen scene with cabinets. The label \"cabinet_1\" is pointing to a cabinet. The cabinet doors are closed. Therefore, the cabinet_1 is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen scene with cabinets. The label \"cabinet_1\" is pointing to a cabinet. The cabinet doors are closed. Therefore, the cabinet_1 is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding bowl_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["no", 2.0167824008043844e-11, 3.3251120606925255e-11, "The image shows a cabinet labeled \"cabinet_2\". The question asks about \"cabinet_1\". There is no \"cabinet_1\" visible in the image. Therefore, I cannot determine if it is open. However, since the question asks if it is open, and it is not present, the answer is No.", false, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a cabinet labeled \"cabinet_2\". The question asks about \"cabinet_1\". There is no \"cabinet_1\" visible in the image. Therefore, I cannot determine if it is open. However, since the question asks if it is open, and it is not present, the answer is No.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable bowl_1": ["yes", 2.9317406141649016e-11, 4.8336230851209194e-11, "The image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". I need to determine if the bowl is within the arm's reach. Looking at the image, the bowl is positioned on a shelf above a cabinet. The robotic arm is positioned below the shelf. The arm appears to be extended, and the distance between the arm's end effector and the bowl seems to be within a reasonable reach.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". I need to determine if the bowl is within the arm's reach. Looking at the image, the bowl is positioned on a shelf above a cabinet. The robotic arm is positioned below the shelf. The arm appears to be extended, and the distance between the arm's end effector and the bowl seems to be within a reasonable reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 2.9317406141649016e-11, 4.8336230851209194e-11, "The image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". I need to determine if the bowl is within the arm's reach. Looking at the image, the bowl is positioned on a shelf above a cabinet. The robotic arm is positioned below the shelf. Based on the relative positions, it appears the arm can reach the bowl.", true, "Question: Is the bowl_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a bowl labeled \"bowl_1\". I need to determine if the bowl is within the arm's reach. Looking at the image, the bowl is positioned on a shelf above a cabinet. The robotic arm is positioned below the shelf. Based on the relative positions, it appears the arm can reach the bowl.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"holding bowl_1": ["yes", 3.5113528838032204e-12, 3.97888449618633e-12, "The image shows a robotic arm (the agent) and several objects labeled \"bowl_1\", \"bowl_2\", and \"cabinet_2\". The robotic arm is grasping an object. The object being grasped is labeled \"bowl_1\". Therefore, the agent is holding the bowl_1.", true, "Question: Is the agent holding the bowl_1\n<explanation>\nThe image shows a robotic arm (the agent) and several objects labeled \"bowl_1\", \"bowl_2\", and \"cabinet_2\". The robotic arm is grasping an object. The object being grasped is labeled \"bowl_1\". Therefore, the agent is holding the bowl_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop bowl_1,cabinet_1": ["no", 1.4635123625136859e-12, 5.108160422429009e-12, "The image shows a kitchen scene with several objects labeled. I need to determine if bowl_1 is on top of cabinet_1. Looking at the image, bowl_1 is on the floor, and cabinet_1 is a tall, vertical structure. Therefore, bowl_1 is not on top of cabinet_1.", true, "Question: Is the bowl_1 on top of the cabinet_1\n<explanation>\nThe image shows a kitchen scene with several objects labeled. I need to determine if bowl_1 is on top of cabinet_1. Looking at the image, bowl_1 is on the floor, and cabinet_1 is a tall, vertical structure. Therefore, bowl_1 is not on top of cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop bowl_1,cabinet_2": ["no", 8.876855956026219e-13, 3.9783306857166245e-12, "The image shows a kitchen scene with several objects labeled. The question asks if bowl_1 is on top of cabinet_2. Looking at the image, bowl_1 is on the floor, and cabinet_2 is a cabinet on the wall. Therefore, bowl_1 is not on top of cabinet_2.", true, "Question: Is the bowl_1 on top of the cabinet_2\n<explanation>\nThe image shows a kitchen scene with several objects labeled. The question asks if bowl_1 is on top of cabinet_2. Looking at the image, bowl_1 is on the floor, and cabinet_2 is a cabinet on the wall. Therefore, bowl_1 is not on top of cabinet_2.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop bowl_1,sink_1": ["no", 2.1293236271424654e-12, 5.107981312230114e-12, "The image shows a sink labeled \"sink_1\" and a bowl labeled \"bowl_1\". The bowl is on the counter, and the sink is below the counter. Therefore, the bowl is not on top of the sink.", true, "Question: Is the bowl_1 on top of the sink_1\n<explanation>\nThe image shows a sink labeled \"sink_1\" and a bowl labeled \"bowl_1\". The bowl is on the counter, and the sink is below the counter. Therefore, the bowl is not on top of the sink.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto bowl_1,cabinet_1": ["yes", 9.53298898154209e-12, 5.782050185865195e-12, "The image shows a kitchen scene with several objects labeled. I need to determine if bowl_1 is next to cabinet_1. Looking at the image, bowl_1 is located on the floor near the bottom left corner. cabinet_1 is located on the left side of the image. They are close to each other and appear to be next to each other.", false, "Question: Is the bowl_1 next to the cabinet_1\n<explanation>\nThe image shows a kitchen scene with several objects labeled. I need to determine if bowl_1 is next to cabinet_1. Looking at the image, bowl_1 is located on the floor near the bottom left corner. cabinet_1 is located on the left side of the image. They are close to each other and appear to be next to each other.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto bowl_1,cabinet_2": ["no", 3.976883058975922e-12, 3.5095871521451105e-12, "The image shows a kitchen scene with several objects labeled. I need to determine if bowl_1 is next to cabinet_2. Looking at the image, bowl_1 is located on the floor, and cabinet_2 is on the wall. They are not directly adjacent to each other.", true, "Question: Is the bowl_1 next to the cabinet_2\n<explanation>\nThe image shows a kitchen scene with several objects labeled. I need to determine if bowl_1 is next to cabinet_2. Looking at the image, bowl_1 is located on the floor, and cabinet_2 is on the wall. They are not directly adjacent to each other.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto bowl_1,sink_1": ["no", 1.4636745591586897e-12, 1.8793952939050174e-12, "The image shows a kitchen scene with several objects labeled. I need to determine if bowl_1 is next to sink_1. Looking at the image, bowl_1 is located on the floor near the bottom left corner. sink_1 is located in the top left corner. They are not next to each other.", true, "Question: Is the bowl_1 next to the sink_1\n<explanation>\nThe image shows a kitchen scene with several objects labeled. I need to determine if bowl_1 is next to sink_1. Looking at the image, bowl_1 is located on the floor near the bottom left corner. sink_1 is located in the top left corner. They are not next to each other.\n</explanation>\n<answer>\nNo\n</answer>", true], "inside bowl_1,cabinet_1": ["no", 8.878026352271418e-13, 3.0987356777756325e-12, "The image shows a kitchen scene with several objects labeled. The question asks if bowl_1 is inside cabinet_1. Looking at the image, bowl_1 is on the floor, and cabinet_1 is a cabinet on the left side of the image. Bowl_1 is not inside cabinet_1.", true, "Question: Is the bowl_1 inside the cabinet_1\n<explanation>\nThe image shows a kitchen scene with several objects labeled. The question asks if bowl_1 is inside cabinet_1. Looking at the image, bowl_1 is on the floor, and cabinet_1 is a cabinet on the left side of the image. Bowl_1 is not inside cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop bowl_1,bowl_1": {"before": null, "after": false}, "nextto bowl_1,bowl_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "place-on(bowl_1, sink_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"holding bowl_1": ["yes", 3.5113528838032204e-12, 3.97888449618633e-12, "The image shows a robotic arm (the agent) and several objects labeled \"bowl_1\", \"bowl_2\", and \"cabinet_2\". The robotic arm is grasping an object. The object being grasped is labeled \"bowl_1\". Therefore, the agent is holding the bowl_1.", true, "Question: Is the agent holding the bowl_1\n<explanation>\nThe image shows a robotic arm (the agent) and several objects labeled \"bowl_1\", \"bowl_2\", and \"cabinet_2\". The robotic arm is grasping an object. The object being grasped is labeled \"bowl_1\". Therefore, the agent is holding the bowl_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sink_1": ["yes", 4.193765018416229e-13, 8.878200908821188e-13, "The image shows a robotic arm (the agent) and several objects in a kitchen setting. The sink_1 is located on the left side of the image. The robotic arm is holding a bowl. I need to determine if the sink_1 is within the arm's reach. Based on the image, the sink_1 appears to be relatively close to the robotic arm, and the arm is not obstructed from reaching it.", true, "Question: Is the sink_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and several objects in a kitchen setting. The sink_1 is located on the left side of the image. The robotic arm is holding a bowl. I need to determine if the sink_1 is within the arm's reach. Based on the image, the sink_1 appears to be relatively close to the robotic arm, and the arm is not obstructed from reaching it.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"updated_non_visible_preds": {"ontop bowl_1,sink_1": {"before": false, "after": true}, "holding bowl_1": {"before": true, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable sink_1": ["no", "yes"], "open cabinet_1": ["yes", "no"], "open cabinet_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}}}, "step": 1, "actions": ["navigate-to(bowl_1)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open cabinet_2": ["no", "no"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}}}, "step": 2, "actions": ["open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable bowl_2": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable piece_of_cloth_1": ["no", "yes"], "reachable sink_1": ["no", "yes"], "holding bowl_1": ["no", "no"], "holding bowl_2": ["no", "no"], "holding piece_of_cloth_1": ["no", "no"], "open cabinet_1": ["no", "yes"], "open cabinet_2": ["no", "no"], "ontop bowl_1,bowl_2": ["yes", "yes"], "ontop bowl_1,cabinet_1": ["yes", "no"], "ontop bowl_1,cabinet_2": ["yes", "no"], "ontop bowl_1,piece_of_cloth_1": ["no", "no"], "ontop bowl_1,sink_1": ["no", "no"], "ontop bowl_2,bowl_1": ["yes", "no"], "ontop bowl_2,cabinet_1": ["no", "no"], "ontop bowl_2,cabinet_2": ["yes", "no"], "ontop bowl_2,piece_of_cloth_1": ["no", "no"], "ontop bowl_2,sink_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_2": ["no", "no"], "ontop piece_of_cloth_1,cabinet_1": ["no", "no"], "ontop piece_of_cloth_1,cabinet_2": ["yes", "no"], "ontop piece_of_cloth_1,sink_1": ["no", "no"], "inside bowl_1,cabinet_1": ["no", "yes"], "inside bowl_1,cabinet_2": ["no", "no"], "inside bowl_2,cabinet_1": ["no", "yes"], "inside bowl_2,cabinet_2": ["no", "no"], "inside piece_of_cloth_1,cabinet_1": ["no", "yes"], "inside piece_of_cloth_1,cabinet_2": ["no", "no"], "nextto bowl_1,bowl_2": ["yes", "yes"], "nextto bowl_1,cabinet_1": ["yes", "yes"], "nextto bowl_1,cabinet_2": ["yes", "no"], "nextto bowl_1,piece_of_cloth_1": ["no", "no"], "nextto bowl_1,sink_1": ["no", "no"], "nextto bowl_2,bowl_1": ["yes", "yes"], "nextto bowl_2,cabinet_1": ["yes", "yes"], "nextto bowl_2,cabinet_2": ["yes", "no"], "nextto bowl_2,piece_of_cloth_1": ["no", "no"], "nextto bowl_2,sink_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_1": ["yes", "no"], "nextto piece_of_cloth_1,bowl_2": ["no", "no"], "nextto piece_of_cloth_1,cabinet_1": ["no", "yes"], "nextto piece_of_cloth_1,cabinet_2": ["yes", "no"], "nextto piece_of_cloth_1,sink_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6595744680851063, "yes_accuracy": 0.5625, "yes_correct": 9, "yes_total": 16, "no_accuracy": 0.7096774193548387, "no_correct": 22, "no_total": 31, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.6666666666666666, "yes_correct": 4, "yes_total": 6, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.6428571428571429, "no_correct": 9, "no_total": 14}, "inside": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 3, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.6, "no_correct": 6, "no_total": 10}}}, "step": 3, "actions": ["grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable bowl_2": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable cabinet_2": ["no", "yes"], "reachable piece_of_cloth_1": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "holding bowl_1": ["yes", "yes"], "holding bowl_2": ["yes", "no"], "holding piece_of_cloth_1": ["yes", "no"], "open cabinet_1": ["yes", "yes"], "open cabinet_2": ["no", "no"], "ontop bowl_1,bowl_2": ["yes", "no"], "ontop bowl_1,cabinet_1": ["no", "no"], "ontop bowl_1,cabinet_2": ["no", "no"], "ontop bowl_1,piece_of_cloth_1": ["no", "no"], "ontop bowl_1,sink_1": ["no", "no"], "ontop bowl_2,bowl_1": ["yes", "no"], "ontop bowl_2,cabinet_1": ["yes", "no"], "ontop bowl_2,cabinet_2": ["yes", "no"], "ontop bowl_2,piece_of_cloth_1": ["yes", "no"], "ontop bowl_2,sink_1": ["yes", "no"], "ontop piece_of_cloth_1,bowl_1": ["yes", "no"], "ontop piece_of_cloth_1,bowl_2": ["yes", "no"], "ontop piece_of_cloth_1,cabinet_1": ["no", "no"], "ontop piece_of_cloth_1,cabinet_2": ["no", "no"], "ontop piece_of_cloth_1,sink_1": ["no", "no"], "inside bowl_1,cabinet_1": ["no", "no"], "inside bowl_1,cabinet_2": ["no", "no"], "inside bowl_2,cabinet_1": ["no", "yes"], "inside bowl_2,cabinet_2": ["no", "no"], "inside piece_of_cloth_1,cabinet_1": ["no", "yes"], "inside piece_of_cloth_1,cabinet_2": ["no", "no"], "nextto bowl_1,bowl_2": ["no", "no"], "nextto bowl_1,cabinet_1": ["yes", "no"], "nextto bowl_1,cabinet_2": ["no", "no"], "nextto bowl_1,piece_of_cloth_1": ["no", "no"], "nextto bowl_1,sink_1": ["no", "no"], "nextto bowl_2,bowl_1": ["yes", "no"], "nextto bowl_2,cabinet_1": ["no", "yes"], "nextto bowl_2,cabinet_2": ["yes", "no"], "nextto bowl_2,piece_of_cloth_1": ["yes", "no"], "nextto bowl_2,sink_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_2": ["yes", "no"], "nextto piece_of_cloth_1,cabinet_1": ["no", "yes"], "nextto piece_of_cloth_1,cabinet_2": ["no", "no"], "nextto piece_of_cloth_1,sink_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.5319148936170213, "yes_accuracy": 0.5, "yes_correct": 6, "yes_total": 12, "no_accuracy": 0.5428571428571428, "no_correct": 19, "no_total": 35, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.6666666666666666, "yes_correct": 4, "yes_total": 6, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.3333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.4666666666666667, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.4666666666666667, "no_correct": 7, "no_total": 15}, "inside": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.4666666666666667, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.5384615384615384, "no_correct": 7, "no_total": 13}}}, "step": 4, "actions": ["place-on(bowl_1, sink_1)"]}], "remaining_actions": []}, "data/planning/igibson/simple/sorting_books_simple.pddl_Ihlen_0_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(hardback_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable hardback_1": ["yes", 4.193704574145113e-13, 7.834872074036214e-13, "The agent is a robotic arm. The hardback_1 is a book on a table. The robotic arm is positioned above the table and appears to be able to reach the book. Therefore, the answer is \"Yes\".", true, "Question: Is the hardback_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The hardback_1 is a book on a table. The robotic arm is positioned above the table and appears to be able to reach the book. Therefore, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable table_1": ["yes", 4.752021801231188e-13, 7.834760401212448e-13, "The image shows a robotic arm (the agent) and a table labeled \"table_1\". I need to determine if the arm can reach the table. The arm is extended towards the table. The distance between the arm's gripper and the table appears to be small, and the arm's orientation seems to be directed towards the table. Therefore, the table is within reach of the agent.", false, "Question: Is the table_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a table labeled \"table_1\". I need to determine if the arm can reach the table. The arm is extended towards the table. The distance between the arm's gripper and the table appears to be small, and the arm's orientation seems to be directed towards the table. Therefore, the table is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable shelf_1": ["yes", 1.1399393798697255e-12, 1.2917205282833577e-12, "The image shows a robotic arm (the agent) and a shelf labeled \"shelf_1\". I need to determine if the arm can reach the shelf. The arm is extended towards the shelf. The distance between the arm's gripper and the shelf appears to be small, and the arm's orientation seems to be directed towards the shelf. Therefore, it is likely that the shelf is within the arm's reach.", false, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a shelf labeled \"shelf_1\". I need to determine if the arm can reach the shelf. The arm is extended towards the shelf. The distance between the arm's gripper and the shelf appears to be small, and the arm's orientation seems to be directed towards the shelf. Therefore, it is likely that the shelf is within the arm's reach.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable shelf_1": ["yes", "no"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["yes", "no"], "holding book_2": ["yes", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,shelf_1": ["yes", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["yes", "no"], "ontop book_2,table_1": ["yes", "yes"], "ontop book_2,shelf_1": ["no", "no"], "nextto hardback_1,table_1": ["yes", "no"], "nextto hardback_1,shelf_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["yes", "no"], "nextto book_2,table_1": ["yes", "no"], "nextto book_2,shelf_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.5555555555555556, "yes_accuracy": 1.0, "yes_correct": 5, "yes_total": 5, "no_accuracy": 0.38461538461538464, "no_correct": 5, "no_total": 13, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "ontop": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.5, "no_correct": 2, "no_total": 4}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 3, "no_total": 6}}}, "step": 1, "actions": []}], "remaining_actions": []}, "data/planning/igibson/simple/sorting_books_simple.pddl_Ihlen_0_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(hardback_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable hardback_1": ["yes", 5.384790920451299e-13, 1.4637379849857801e-12, "The agent is a robotic arm. The hardback_1 is a book on the floor. The robotic arm is extended towards the book. The distance between the arm and the book appears to be within the arm's reach. Therefore, the hardback_1 is in reach of the agent.", true, "Question: Is the hardback_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The hardback_1 is a book on the floor. The robotic arm is extended towards the book. The distance between the arm and the book appears to be within the arm's reach. Therefore, the hardback_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable table_1": ["yes", 8.877856674631424e-13, 1.6586020751274688e-12, "The image shows a robotic arm (the agent) and a table labeled \"table_1\". I need to determine if the arm can reach the table. The arm is extended towards the table. The table is within the visual field of the arm and appears to be close enough for the arm to grasp it. Therefore, the table is in reach of the agent.", false, "Question: Is the table_1 in reach of the agent?\n<explanation>\nThe image shows a robotic arm (the agent) and a table labeled \"table_1\". I need to determine if the arm can reach the table. The arm is extended towards the table. The table is within the visual field of the arm and appears to be close enough for the arm to grasp it. Therefore, the table is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable shelf_1": ["yes", 1.8793866202876375e-12, 3.098584973673657e-12, "The image shows a robotic arm (the agent) and a shelf labeled \"shelf_1\". I need to determine if the arm can reach the shelf. The arm is extended towards the shelf. The shelf is within the visual field of the arm and appears to be close enough for the arm to grasp it. Therefore, the shelf is in reach of the agent.", false, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a shelf labeled \"shelf_1\". I need to determine if the arm can reach the shelf. The arm is extended towards the shelf. The shelf is within the visual field of the arm and appears to be close enough for the arm to grasp it. Therefore, the shelf is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "place-on(hardback_1, shelf_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding hardback_1": ["yes", 2.0206393849808713e-11, 2.9400128165324446e-11, "The image shows a robotic arm. The robotic arm appears to be holding a rectangular object. The object is labeled as \"hardback_1\" in the environment. Therefore, the agent is holding the hardback_1.", true, "Question: Is the agent holding the hardback_1\n<explanation>\nThe image shows a robotic arm. The robotic arm appears to be holding a rectangular object. The object is labeled as \"hardback_1\" in the environment. Therefore, the agent is holding the hardback_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable shelf_1": ["yes", 1.8793866202876375e-12, 3.098584973673657e-12, "The image shows a robotic arm (the agent) and a shelf labeled \"shelf_1\". I need to determine if the arm can reach the shelf. The arm is extended towards the shelf. The shelf is within the visual field of the arm and appears to be close enough for the arm to grasp it. Therefore, the shelf is in reach of the agent.", true, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a shelf labeled \"shelf_1\". I need to determine if the arm can reach the shelf. The arm is extended towards the shelf. The shelf is within the visual field of the arm and appears to be close enough for the arm to grasp it. Therefore, the shelf is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "place-on(hardback_1, shelf_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding hardback_1": ["yes", 2.0206393849808713e-11, 2.9400128165324446e-11, "The image shows a robotic arm. The robotic arm appears to be holding a rectangular object. The object is labeled as \"hardback_1\" in the environment. Therefore, the agent is holding the hardback_1.", true, "Question: Is the agent holding the hardback_1\n<explanation>\nThe image shows a robotic arm. The robotic arm appears to be holding a rectangular object. The object is labeled as \"hardback_1\" in the environment. Therefore, the agent is holding the hardback_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable shelf_1": ["yes", 1.8793866202876375e-12, 3.098584973673657e-12, "The image shows a robotic arm (the agent) and a shelf labeled \"shelf_1\". I need to determine if the arm can reach the shelf. The arm is extended towards the shelf. The shelf is within the visual field of the arm and appears to be close enough for the arm to grasp it. Therefore, the shelf is in reach of the agent.", true, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a shelf labeled \"shelf_1\". I need to determine if the arm can reach the shelf. The arm is extended towards the shelf. The shelf is within the visual field of the arm and appears to be close enough for the arm to grasp it. Therefore, the shelf is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable shelf_1": ["yes", "no"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["yes", "no"], "holding book_2": ["yes", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,shelf_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["yes", "yes"], "ontop book_2,shelf_1": ["yes", "no"], "nextto hardback_1,table_1": ["yes", "no"], "nextto hardback_1,shelf_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "no"], "nextto book_2,table_1": ["yes", "no"], "nextto book_2,shelf_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6111111111111112, "yes_accuracy": 1.0, "yes_correct": 5, "yes_total": 5, "no_accuracy": 0.46153846153846156, "no_correct": 6, "no_total": 13, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "ontop": {"accuracy": 0.8333333333333334, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 3, "no_total": 6}}}, "step": 1, "actions": ["place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable shelf_1": ["yes", "no"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["yes", "no"], "holding book_2": ["yes", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,shelf_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["yes", "yes"], "ontop book_2,shelf_1": ["yes", "no"], "nextto hardback_1,table_1": ["yes", "no"], "nextto hardback_1,shelf_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "no"], "nextto book_2,table_1": ["yes", "no"], "nextto book_2,shelf_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6111111111111112, "yes_accuracy": 1.0, "yes_correct": 5, "yes_total": 5, "no_accuracy": 0.46153846153846156, "no_correct": 6, "no_total": 13, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "ontop": {"accuracy": 0.8333333333333334, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 3, "no_total": 6}}}, "step": 2, "actions": ["place-on(hardback_1, shelf_1)"]}], "remaining_actions": []}, "data/planning/igibson/simple/sorting_books_simple.pddl_Pomaria_1_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(hardback_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable hardback_1": ["no", 3.0987077053595824e-12, 1.7831831497505668e-11, "The agent is the robotic arm. The hardback_1 is the book labeled \"book\" in the image. The robotic arm is far away from the book. Therefore, the book is not in reach of the agent.", false, "Question: Is the hardback_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The hardback_1 is the book labeled \"book\" in the image. The robotic arm is far away from the book. Therefore, the book is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable table_1": ["no", 1.463723131416017e-12, 8.423145861358172e-12, "The agent is the robotic arm. The table_1 is the table in the foreground of the image. The robotic arm appears to be far away from the table_1. Therefore, the table_1 is not in reach of the agent.", true, "Question: Is the table_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The table_1 is the table in the foreground of the image. The robotic arm appears to be far away from the table_1. Therefore, the table_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(hardback_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable hardback_1": ["no", 3.0987077053595824e-12, 1.7831831497505668e-11, "The agent is the robotic arm. The hardback_1 is the book labeled \"book\" in the image. The robotic arm is far away from the book. Therefore, the book is not in reach of the agent.", true, "Question: Is the hardback_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm. The hardback_1 is the book labeled \"book\" in the image. The robotic arm is far away from the book. Therefore, the book is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable hardback_1": ["yes", 7.834682880757116e-13, 3.5112609434589936e-12, "The agent is the robotic arm visible in the image. The object \"hardback_1\" is labeled in red. The robotic arm is positioned such that it appears to be holding an object. The hardback_1 is on a table, and the robotic arm is close to the table. Therefore, the hardback_1 is in reach of the agent.", true, "Question: Is the hardback_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm visible in the image. The object \"hardback_1\" is labeled in red. The robotic arm is positioned such that it appears to be holding an object. The hardback_1 is on a table, and the robotic arm is close to the table. Therefore, the hardback_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable table_1": ["yes", 4.752055411498535e-13, 1.8794742238231743e-12, "The agent is the robotic arm visible in the image. The table_1 is the brown table in the middle of the image. The robotic arm appears to be positioned such that it could reach the table_1.", false, "Question: Is the table_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm visible in the image. The table_1 is the brown table in the middle of the image. The robotic arm appears to be positioned such that it could reach the table_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(shelf_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable shelf_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable shelf_1": ["yes", 2.1296154943672985e-12, 5.788894537339662e-12, "The agent is a robotic arm. The shelf_1 is the wooden shelf in the image. The robotic arm is positioned above the shelf. Therefore, the shelf is in reach of the agent.", true, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The shelf_1 is the wooden shelf in the image. The robotic arm is positioned above the shelf. Therefore, the shelf is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable hardback_1": {"before": true, "after": false}, "reachable table_1": {"before": true, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable hardback_1": ["no", "yes"], "reachable table_1": ["no", "yes"], "reachable book_1": ["no", "no"], "reachable book_2": ["no", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["yes", "no"], "holding book_2": ["yes", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["yes", "yes"], "ontop book_2,book_1": ["yes", "no"], "nextto hardback_1,table_1": ["yes", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["yes", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["yes", "yes"], "nextto book_2,table_1": ["yes", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.68, "yes_accuracy": 0.5714285714285714, "yes_correct": 4, "yes_total": 7, "no_accuracy": 0.7222222222222222, "no_correct": 13, "no_total": 18, "predicates": {"reachable": {"accuracy": 0.25, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 3, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.3333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3}, "ontop": {"accuracy": 0.8888888888888888, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}, "nextto": {"accuracy": 0.7777777777777778, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}}}, "step": 1, "actions": ["navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "no"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["yes", "no"], "holding book_1": ["no", "no"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["yes", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["yes", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["yes", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["yes", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["yes", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["yes", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.72, "yes_accuracy": 0.8571428571428571, "yes_correct": 6, "yes_total": 7, "no_accuracy": 0.6666666666666666, "no_correct": 12, "no_total": 18, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "ontop": {"accuracy": 0.8888888888888888, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}, "nextto": {"accuracy": 0.5555555555555556, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.5714285714285714, "no_correct": 4, "no_total": 7}}}, "step": 2, "actions": ["navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}], "remaining_actions": []}, "data/planning/igibson/simple/sorting_books_simple.pddl_Pomaria_1_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(hardback_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable hardback_1": ["yes", 6.913872686170608e-13, 2.734489501152182e-12, "The agent is the robotic arm in the image. The hardback_1 is the book labeled \"book_1\". The robotic arm is positioned such that it appears to be reaching towards the book labeled \"book_1\". Therefore, the hardback_1 is in reach of the agent.", true, "Question: Is the hardback_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm in the image. The hardback_1 is the book labeled \"book_1\". The robotic arm is positioned such that it appears to be reaching towards the book labeled \"book_1\". Therefore, the hardback_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable table_1": ["yes", 7.83399549657976e-13, 2.413040253723686e-12, "The agent is the robotic arm in the image. The table_1 is the small, light-colored table in the foreground. The robotic arm appears to be positioned such that it could easily reach the table_1.", false, "Question: Is the table_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm in the image. The table_1 is the small, light-colored table in the foreground. The robotic arm appears to be positioned such that it could easily reach the table_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(shelf_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable shelf_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable shelf_1": ["yes", 2.129578197812565e-12, 6.559562788777118e-12, "The agent is a robotic arm. The shelf_1 is the table in the image. The robotic arm is positioned above the table. Therefore, the shelf_1 is in reach of the agent.", true, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The shelf_1 is the table in the image. The robotic arm is positioned above the table. Therefore, the shelf_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable hardback_1": {"before": true, "after": false}, "reachable table_1": {"before": true, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["no", "no"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["yes", "no"], "holding book_1": ["no", "no"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,book_1": ["yes", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["yes", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["yes", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["yes", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.84, "yes_accuracy": 0.8571428571428571, "yes_correct": 6, "yes_total": 7, "no_accuracy": 0.8333333333333334, "no_correct": 15, "no_total": 18, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "ontop": {"accuracy": 0.8888888888888888, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}, "nextto": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}}}, "step": 1, "actions": ["navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}], "remaining_actions": []}, "data/planning/igibson/simple/sorting_books_simple.pddl_Rs_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(hardback_1)", "action_correct": true, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable hardback_1": ["yes", 3.2660752899947576e-13, 1.0060218717106162e-12, "The robotic arm (agent) is positioned in the upper right corner of the image. The object labeled \"hardback_1\" is located on the floor in the lower right corner of the image. Given the distance and the position of the arm, it appears that the object is within the arm's reach.", true, "Question: Is the hardback_1 in reach of the agent\n<explanation>\nThe robotic arm (agent) is positioned in the upper right corner of the image. The object labeled \"hardback_1\" is located on the floor in the lower right corner of the image. Given the distance and the position of the arm, it appears that the object is within the arm's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable table_1": ["no", 4.193722192430416e-13, 1.291757282737005e-12, "The agent is the robotic arm in the image. The table_1 is labeled in the image and is located in the middle of the room. The robotic arm is positioned in the upper right corner of the image. The distance between the robotic arm and the table_1 appears to be too far for the arm to reach the table.", true, "Question: Is the table_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm in the image. The table_1 is labeled in the image and is located in the middle of the room. The robotic arm is positioned in the upper right corner of the image. The distance between the robotic arm and the table_1 appears to be too far for the arm to reach the table.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable shelf_1": ["no", 1.139939163029291e-12, 3.5112596424163867e-12, "The agent is the robotic arm in the image. The shelf_1 is located on the right side of the image. The robotic arm is positioned on the left side of the image. The distance between the robotic arm and the shelf_1 appears to be too far for the arm to reach.", true, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe agent is the robotic arm in the image. The shelf_1 is located on the right side of the image. The robotic arm is positioned on the left side of the image. The distance between the robotic arm and the shelf_1 appears to be too far for the arm to reach.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(hardback_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable hardback_1": ["yes", 3.2660752899947576e-13, 1.0060218717106162e-12, "The robotic arm (agent) is positioned in the upper right corner of the image. The object labeled \"hardback_1\" is located on the floor in the lower right corner of the image. Given the distance and the position of the arm, it appears that the object is within the arm's reach.", true, "Question: Is the hardback_1 in reach of the agent\n<explanation>\nThe robotic arm (agent) is positioned in the upper right corner of the image. The object labeled \"hardback_1\" is located on the floor in the lower right corner of the image. Given the distance and the position of the arm, it appears that the object is within the arm's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"holding hardback_1": ["yes", 1.0815106622763526e-11, 1.2255120529491847e-11, "The image shows a robotic arm (the agent). The object labeled \"hardback_1\" is directly grasped by the robotic arm. Therefore, the agent is holding the hardback_1.", true, "Question: Is the agent holding the hardback_1\n<explanation>\nThe image shows a robotic arm (the agent). The object labeled \"hardback_1\" is directly grasped by the robotic arm. Therefore, the agent is holding the hardback_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop hardback_1,table_1": ["no", 1.0770882449828711e-11, 4.259966684960759e-11, "First, I will identify the objects \"hardback_1\" and \"table_1\" in the image. \"hardback_1\" is the book being held by the robotic arm. \"table_1\" is the table in the room. The robotic arm is holding the book, and the book is not on the table. Therefore, the answer is \"No\".", true, "Question: Is the hardback_1 on top of the table_1\n<explanation>\nFirst, I will identify the objects \"hardback_1\" and \"table_1\" in the image. \"hardback_1\" is the book being held by the robotic arm. \"table_1\" is the table in the room. The robotic arm is holding the book, and the book is not on the table. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop hardback_1,shelf_1": ["no", 3.968892055283835e-12, 2.015569655622329e-11, "First, I will locate the hardback_1 and shelf_1 in the image. The hardback_1 is being held by the robotic arm. The shelf_1 is the tall, white structure on the right side of the image. The hardback_1 is not on top of the shelf_1, it is being held by the robotic arm. Therefore, the answer is \"No\".", true, "Question: Is the hardback_1 on top of the shelf_1\n<explanation>\nFirst, I will locate the hardback_1 and shelf_1 in the image. The hardback_1 is being held by the robotic arm. The shelf_1 is the tall, white structure on the right side of the image. The hardback_1 is not on top of the shelf_1, it is being held by the robotic arm. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto hardback_1,table_1": ["no", 1.991417100666304e-11, 3.7204569286464206e-11, "First, I need to identify the locations of \"hardback_1\" and \"table_1\" in the image. \"hardback_1\" is the object being held by the robotic arm. \"table_1\" is the table on the left side of the image. The robotic arm is positioned to the right of the table. Therefore, \"hardback_1\" is not next to \"table_1\".", true, "Question: Is the hardback_1 next to the table_1?\n<explanation>\nFirst, I need to identify the locations of \"hardback_1\" and \"table_1\" in the image. \"hardback_1\" is the object being held by the robotic arm. \"table_1\" is the table on the left side of the image. The robotic arm is positioned to the right of the table. Therefore, \"hardback_1\" is not next to \"table_1\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto hardback_1,shelf_1": ["no", 5.087666832964688e-12, 9.505013096045012e-12, "I need to determine if the object labeled \"hardback_1\" is located next to the object labeled \"shelf_1\" in the image. Looking at the image, \"hardback_1\" is being held by the robotic arm and is not near the shelf. Therefore, the answer is \"No\".", true, "Question: Is the hardback_1 next to the shelf_1?\n<explanation>\nI need to determine if the object labeled \"hardback_1\" is located next to the object labeled \"shelf_1\" in the image. Looking at the image, \"hardback_1\" is being held by the robotic arm and is not near the shelf. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"ontop hardback_1,hardback_1": {"before": null, "after": false}, "nextto hardback_1,hardback_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(shelf_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {"reachable shelf_1": ["no", 8.876403301619207e-13, 2.7341245587009233e-12, "The agent is a robotic arm. I need to determine if the shelf_1 is within the arm's reach. Looking at the image, the shelf_1 is located on the right side of the image, and the robotic arm is on the left side. The distance between the arm and the shelf appears to be too far for the arm to reach.", true, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. I need to determine if the shelf_1 is within the arm's reach. Looking at the image, the shelf_1 is located on the right side of the image, and the robotic arm is on the left side. The distance between the arm and the shelf appears to be too far for the arm to reach.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable shelf_1": ["yes", 2.129575595727351e-12, 6.559554982521476e-12, "The image shows a robotic arm holding a book. The shelf_1 is visible in the background. The robotic arm is holding the book and appears to be positioned near the shelf. It seems that the robotic arm can reach the shelf.", true, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a book. The shelf_1 is visible in the background. The robotic arm is holding the book and appears to be positioned near the shelf. It seems that the robotic arm can reach the shelf.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable hardback_1": ["yes", 1.2917203114429232e-12, 3.9787791117351645e-12, "The image shows a robotic arm holding a book. The book is labeled \"hardback_1\". The robotic arm is positioned close to the book. Therefore, the hardback_1 is in reach of the agent.", false, "Question: Is the hardback_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a book. The book is labeled \"hardback_1\". The robotic arm is positioned close to the book. Therefore, the hardback_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-on(hardback_1, shelf_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding hardback_1": ["yes", 2.594485563889304e-11, 2.939937182588892e-11, "The image shows a robotic arm holding an object. The object appears to be a book. The object is labeled as \"hardback_1\". Therefore, the agent is holding the hardback_1.", true, "Question: Is the agent holding the hardback_1\n<explanation>\nThe image shows a robotic arm holding an object. The object appears to be a book. The object is labeled as \"hardback_1\". Therefore, the agent is holding the hardback_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable shelf_1": ["yes", 2.129575595727351e-12, 6.559554982521476e-12, "The image shows a robotic arm holding a book. The shelf_1 is visible in the background. The robotic arm is holding the book and appears to be positioned near the shelf. It seems that the robotic arm can reach the shelf.", true, "Question: Is the shelf_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a book. The shelf_1 is visible in the background. The robotic arm is holding the book and appears to be positioned near the shelf. It seems that the robotic arm can reach the shelf.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"ontop hardback_1,shelf_1": ["yes", 5.788613945817422e-12, 7.432727176792664e-12, "The image shows a robotic arm holding a book. The book is resting on the top shelf of a wooden shelf unit. The book is labeled \"hardback_1\" and the shelf unit is labeled \"shelf_1\". Therefore, the hardback_1 is on top of the shelf_1.", true, "Question: Is the hardback_1 on top of the shelf_1\n<explanation>\nThe image shows a robotic arm holding a book. The book is resting on the top shelf of a wooden shelf unit. The book is labeled \"hardback_1\" and the shelf unit is labeled \"shelf_1\". Therefore, the hardback_1 is on top of the shelf_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "holding hardback_1": ["yes", 1.3887687874691856e-11, 1.3887687874691856e-11, "The image shows a robotic arm. The robotic arm is holding a brown object. The brown object appears to be a book. The book is labeled \"hardback_1\". Therefore, the agent is holding the hardback_1.", false, "Question: Is the agent holding the hardback_1\n<explanation>\nThe image shows a robotic arm. The robotic arm is holding a brown object. The brown object appears to be a book. The book is labeled \"hardback_1\". Therefore, the agent is holding the hardback_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "executed but failed"}], "replans": [{"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable shelf_1": ["yes", "yes"], "holding hardback_1": ["yes", "yes"], "ontop hardback_1,shelf_1": ["no", "no"], "nextto hardback_1,shelf_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 3, "actions": ["place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable shelf_1": ["yes", "yes"], "holding hardback_1": ["yes", "no"], "ontop hardback_1,shelf_1": ["yes", "no"], "nextto hardback_1,shelf_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.4, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}}}, "step": 4, "actions": []}], "remaining_actions": []}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Merom_1_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(door_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable door_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable door_1": ["yes", 2.1295675726312746e-12, 4.508294345478836e-12, "The image shows a robotic arm extending towards a door. The arm appears to be close to the door, and the hand is positioned near the doorknob. Therefore, the door is within reach of the agent.", true, "Question: Is the door_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The arm appears to be close to the door, and the hand is positioned near the doorknob. Therefore, the door is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable door_2": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(door_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable door_1": ["yes", 2.1295675726312746e-12, 4.508294345478836e-12, "The image shows a robotic arm extending towards a door. The arm appears to be close to the door, and the hand is positioned near the door handle. Therefore, the door is within reach of the agent.", true, "Question: Is the door_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The arm appears to be close to the door, and the hand is positioned near the door handle. Therefore, the door is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_1": ["yes", 2.1297332387232304e-12, 1.4637426470551218e-12, "The image shows a door. The door is slightly ajar, meaning it is not fully closed. Therefore, the door is open.", true, "Question: Is the door_1 open\n<explanation>\nThe image shows a door. The door is slightly ajar, meaning it is not fully closed. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open door_1": ["no", 1.9809823811715865e-13, 1.8795034972818314e-12, "The image shows a robotic arm holding a doorknob. The door itself is visible, and it appears to be closed. The robotic arm is positioned as if it is about to open the door. Therefore, the door is not open.", true, "Question: Is the door_1 open\n<explanation>\nThe image shows a robotic arm holding a doorknob. The door itself is visible, and it appears to be closed. The robotic arm is positioned as if it is about to open the door. Therefore, the door is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "navigate-to(door_2)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable door_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable door_2": ["yes", 1.4636896295688873e-12, 3.5112089017547143e-12, "The image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.", true, "Question: Is the door_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable door_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "close-container(door_2)", "action_correct": false, "action_state_correct": true, "preconditions_results": {"reachable door_2": ["yes", 1.4636896295688873e-12, 3.5112089017547143e-12, "The image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.", true, "Question: Is the door_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_2": ["yes", 4.752106911101728e-13, 7.834900263292699e-13, "The image shows a robotic arm near a door. The door appears to be slightly ajar, meaning it is not fully closed. Therefore, the door is open.", true, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm near a door. The door appears to be slightly ajar, meaning it is not fully closed. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open door_2": ["yes", 4.1937037609934835e-13, 3.7009306209923043e-13, "The image shows a robotic arm interacting with a door. The door is visibly ajar, with a gap between the door and the doorframe. This indicates that the door is open.", false, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm interacting with a door. The door is visibly ajar, with a gap between the door and the doorframe. This indicates that the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "executed but failed"}, {"action": "close-container(door_2)", "action_correct": true, "action_state_correct": false, "preconditions_results": {"reachable door_2": ["yes", 1.29170231368686e-12, 3.5112110701590593e-12, "The image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.", true, "Question: Is the door_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_2": ["yes", 4.1937037609934835e-13, 3.7009306209923043e-13, "The image shows a robotic arm interacting with a door. The door is visibly ajar, with a gap between the door and the doorframe. This indicates that the door is open.", true, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm interacting with a door. The door is visibly ajar, with a gap between the door and the doorframe. This indicates that the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open door_2": ["no", 6.101832906134363e-13, 1.2917579332583085e-12, "The image shows a robotic arm near a door. The door appears to be closed, as there is no visible gap between the door and the door frame. Therefore, the door is not open.", true, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm near a door. The door appears to be closed, as there is no visible gap between the door and the door frame. Therefore, the door is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "executed but failed"}], "replans": [{"enum_results": {"reachable door_2": ["yes", "yes"], "holding door_2": ["yes", "no"], "open door_2": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 4, "actions": ["close-container(door_2)"]}], "remaining_actions": []}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Merom_1_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(door_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable door_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable door_1": ["yes", 2.4131215688866225e-12, 5.108578490786719e-12, "The image shows a robotic arm extending towards a door. The arm's gripper is positioned close to the door. Therefore, the door is within reach of the agent.", true, "Question: Is the door_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The arm's gripper is positioned close to the door. Therefore, the door is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable door_2": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(door_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable door_1": ["yes", 2.4131215688866225e-12, 5.108578490786719e-12, "The image shows a robotic arm extending towards a door. The arm's gripper is close to the door. Therefore, the door is within reach of the agent.", true, "Question: Is the door_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The arm's gripper is close to the door. Therefore, the door is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_1": ["yes", 2.4133204115650564e-12, 5.108999594910513e-12, "The image shows a door. The door is not fully open, but it is slightly ajar. Therefore, the door is open.", true, "Question: Is the door_1 open\n<explanation>\nThe image shows a door. The door is not fully open, but it is slightly ajar. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open door_1": ["no", 2.2447527777552656e-13, 2.734668394510642e-12, "The image shows a robotic arm interacting with a door. The door appears to be closed, as there is no visible gap or opening. Therefore, the door is not open.", true, "Question: Is the door_1 open\n<explanation>\nThe image shows a robotic arm interacting with a door. The door appears to be closed, as there is no visible gap or opening. Therefore, the door is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "navigate-to(door_2)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable door_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable door_2": ["yes", 1.658512736868456e-12, 3.5110712080788087e-12, "The image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.", true, "Question: Is the door_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable door_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "close-container(door_2)", "action_correct": false, "action_state_correct": true, "preconditions_results": {"reachable door_2": ["yes", 1.658512736868456e-12, 3.5110712080788087e-12, "The image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.", true, "Question: Is the door_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_2": ["yes", 2.8823002470000636e-13, 4.193722192430416e-13, "The image shows a robotic arm near a door. The door is slightly ajar, indicating that it is not fully closed. Therefore, the door is open.", true, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm near a door. The door is slightly ajar, indicating that it is not fully closed. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open door_2": ["yes", 3.7009731759275744e-13, 3.7009731759275744e-13, "The image shows a door. The door is partially open, with a gap visible between the door and the door frame. Therefore, the door is open.", false, "Question: Is the door_2 open\n<explanation>\nThe image shows a door. The door is partially open, with a gap visible between the door and the door frame. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "executed but failed"}, {"action": "close-container(door_2)", "action_correct": false, "action_state_correct": true, "preconditions_results": {"reachable door_2": ["yes", 7.834760401212448e-13, 2.1297085189136977e-12, "The image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.", true, "Question: Is the door_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_2": ["yes", 3.7009731759275744e-13, 3.7009731759275744e-13, "The image shows a door. The door is partially open, with a gap visible between the door and the doorframe. Therefore, the door is open.", true, "Question: Is the door_2 open\n<explanation>\nThe image shows a door. The door is partially open, with a gap visible between the door and the doorframe. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open door_2": ["yes", 1.006010053906936e-12, 1.139958787088613e-12, "The image shows a robotic arm near a door. The door is clearly open, as there is a visible gap between the door and the wall. Therefore, the door is open.", false, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm near a door. The door is clearly open, as there is a visible gap between the door and the wall. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "executed but failed"}, {"action": "close-container(door_2)", "action_correct": false, "action_state_correct": true, "preconditions_results": {"reachable door_2": ["yes", 5.107996491060529e-12, 1.7828660422991582e-11, "The image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.", true, "Question: Is the door_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_2": ["yes", 1.006010053906936e-12, 1.139958787088613e-12, "The image shows a robotic arm near a door. The door is clearly open, as there is a visible gap between the door and the wall. Therefore, the door is open.", true, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm near a door. The door is clearly open, as there is a visible gap between the door and the wall. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open door_2": ["yes", 1.139958787088613e-12, 1.6586303728041707e-12, "The image shows a robotic arm near a door. The door appears to be slightly ajar, meaning it is not fully closed. Therefore, the door is open.", false, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm near a door. The door appears to be slightly ajar, meaning it is not fully closed. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "executed but failed"}, {"action": "close-container(door_2)", "action_correct": true, "action_state_correct": false, "preconditions_results": {"reachable door_2": ["yes", 3.5106900025949628e-12, 1.0813687618960177e-11, "The image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.", true, "Question: Is the door_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The door is labeled as door_2. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_2": ["yes", 1.139958787088613e-12, 1.6586303728041707e-12, "The image shows a robotic arm near a door. The door appears to be slightly ajar, meaning it is not fully closed. Therefore, the door is open.", true, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm near a door. The door appears to be slightly ajar, meaning it is not fully closed. Therefore, the door is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open door_2": ["no", 1.2015220632669021e-13, 4.1937240897842176e-13, "The image shows a robotic arm near a door. The door appears to be closed, as there is no visible gap between the door and the door frame. Therefore, the door is not open.", true, "Question: Is the door_2 open\n<explanation>\nThe image shows a robotic arm near a door. The door appears to be closed, as there is no visible gap between the door and the door frame. Therefore, the door is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "executed but failed"}], "replans": [{"enum_results": {"reachable door_2": ["yes", "yes"], "holding door_2": ["yes", "no"], "open door_2": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 4, "actions": ["close-container(door_2)"]}, {"enum_results": {"reachable door_2": ["yes", "yes"], "holding door_2": ["no", "no"], "open door_2": ["yes", "yes"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 5, "actions": ["close-container(door_2)"]}, {"enum_results": {"reachable door_2": ["yes", "yes"], "holding door_2": ["no", "no"], "open door_2": ["yes", "yes"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 6, "actions": ["close-container(door_2)"]}], "remaining_actions": []}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Pomaria_0_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(door_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable door_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable door_1": ["yes", 2.129749284915383e-12, 6.560089711032946e-12, "The image shows a robotic arm extending towards a door. The arm's end effector is positioned close to a circular hole in the door. Given the proximity of the arm to the door, it can be inferred that the door is within reach of the agent.", true, "Question: Is the door_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The arm's end effector is positioned close to a circular hole in the door. Given the proximity of the arm to the door, it can be inferred that the door is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable door_2": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(door_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable door_1": ["yes", 2.129749284915383e-12, 6.560089711032946e-12, "The image shows a robotic arm extending towards a door. The arm's end effector is positioned close to a circular opening in the door. Given the proximity of the arm to the door, it can be inferred that the door is within reach of the agent.", true, "Question: Is the door_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The arm's end effector is positioned close to a circular opening in the door. Given the proximity of the arm to the door, it can be inferred that the door is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_1": ["no", 1.6586721145878114e-12, 1.2256019983614141e-11, "The image shows a robotic arm interacting with a door. The door appears to be closed, as there is no visible gap or opening. The robotic arm is positioned against the door.", false, "Question: Is the door_1 open\n<explanation>\nThe image shows a robotic arm interacting with a door. The door appears to be closed, as there is no visible gap or opening. The robotic arm is positioned against the door.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}], "replans": [{"enum_results": {"reachable door_1": ["yes", "yes"], "open door_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 2, "actions": ["navigate-to(door_2)", "close-container(door_2)"]}], "remaining_actions": ["close-container(door_2)"]}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Pomaria_0_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(door_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable door_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable door_1": ["yes", 1.0059923814115246e-12, 4.508545013021115e-12, "The image shows a robotic arm extending towards a door. The arm's gripper is positioned close to the door. The door appears to be within the arm's range of motion. Therefore, the door is in reach of the agent.", true, "Question: Is the door_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The arm's gripper is positioned close to the door. The door appears to be within the arm's range of motion. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable door_2": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(door_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable door_1": ["yes", 1.0059923814115246e-12, 4.508545013021115e-12, "The image shows a robotic arm extending towards a door. The arm's gripper is positioned close to the door. The door appears to be within the arm's range of motion. Therefore, the door is in reach of the agent.", true, "Question: Is the door_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a door. The arm's gripper is positioned close to the door. The door appears to be within the arm's range of motion. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open door_1": ["no", 2.543645090564983e-13, 2.4133431798106786e-12, "The image shows a robotic arm positioned against a wooden door. The door appears to be closed, as there is no visible gap or opening. Therefore, the door is not open.", false, "Question: Is the door_1 open\n<explanation>\nThe image shows a robotic arm positioned against a wooden door. The door appears to be closed, as there is no visible gap or opening. Therefore, the door is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}], "replans": [{"enum_results": {"reachable door_1": ["yes", "yes"], "open door_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 2, "actions": ["navigate-to(door_2)", "close-container(door_2)"]}], "remaining_actions": ["close-container(door_2)"]}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Wainscott_1_int_0": {"all_correct": true, "goal_reached": false, "action_results": [{"action": "navigate-to(door_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable door_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable door_1": ["yes", 3.97856530706675e-12, 1.3886557702347258e-11, "The image shows a robotic arm (the agent) extending towards a door. The door is labeled as door_1. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.", true, "Question: Is the door_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) extending towards a door. The door is labeled as door_1. The arm appears to be close enough to the door to potentially interact with it. Therefore, the door is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable door_2": {"before": false, "after": false}}}, "action_info": "success"}], "replans": [], "remaining_actions": ["navigate-to(door_2)", "close-container(door_2)"]}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Merom_1_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["no", 6.913722524169719e-13, 3.511077930132278e-12, "The image shows a robotic arm holding a white object. The window is located behind the arm. The arm is positioned such that it is not directly in front of the window. The arm is holding an object, and it appears to be reaching towards something else. However, based on the image, the window is not within the immediate reach of the robotic arm.", false, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a white object. The window is located behind the arm. The arm is positioned such that it is not directly in front of the window. The arm is holding an object, and it appears to be reaching towards something else. However, based on the image, the window is not within the immediate reach of the robotic arm.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["no", 6.913722524169719e-13, 3.511077930132278e-12, "The image shows a robotic arm holding a white object. The window is located behind the arm. The arm is positioned such that it is not directly in front of the window. The arm is holding an object, and it appears to be reaching towards something else. However, based on the image, the window is not within the immediate reach of the robotic arm.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a white object. The window is located behind the arm. The arm is positioned such that it is not directly in front of the window. The arm is holding an object, and it appears to be reaching towards something else. However, based on the image, the window is not within the immediate reach of the robotic arm.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable window_1": ["yes", 3.5104076763492476e-12, 9.542277558394208e-12, "The image shows a robotic arm extending towards a window. The window is clearly visible and appears to be within the arm's reach. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is clearly visible and appears to be within the arm's reach. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["yes", 3.5104076763492476e-12, 9.542277558394208e-12, "The image shows a robotic arm extending towards a window. The window is clearly visible and appears to be within the arm's reach. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is clearly visible and appears to be within the arm's reach. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["yes", 1.0060052834173772e-12, 2.413281380286847e-12, "The image shows a window with multiple panes. The window appears to be fully open, as the panes are separated and the view beyond is visible.", true, "Question: Is the window_1 open\n<explanation>\nThe image shows a window with multiple panes. The window appears to be fully open, as the panes are separated and the view beyond is visible.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open window_1": ["yes", 1.139899481229778e-12, 1.6585439618910236e-12, "The image shows a window. The window appears to be open, as there is a gap between the window panels and the curtains are visible behind the window.", false, "Question: Is the window_1 open\n<explanation>\nThe image shows a window. The window appears to be open, as there is a gap between the window panels and the curtains are visible behind the window.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["yes", 8.40660267092952e-12, 1.3860145670063773e-11, "The image shows a robotic arm extending towards a window. The arm appears to be close to the window. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The arm appears to be close to the window. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["yes", 1.139899481229778e-12, 1.6585439618910236e-12, "The image shows a window. The window appears to be open, as there is a gap between the window panels and the curtains are visible behind the window.", true, "Question: Is the window_1 open\n<explanation>\nThe image shows a window. The window appears to be open, as there is a gap between the window panels and the curtains are visible behind the window.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable window_1": ["no", "yes"], "holding window_1": ["no", "no"], "open window_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 1, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_1": ["yes", "yes"], "holding window_1": ["no", "no"], "open window_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}}}, "step": 3, "actions": ["close-container(window_1)", "navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}], "remaining_actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Merom_1_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["no", 3.5098345670808717e-12, 9.54071977671278e-12, "The image shows a robotic arm extending towards a window. The window is a significant distance away from the arm. The arm appears to be reaching, but it is not close enough to be considered within reach.", false, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is a significant distance away from the arm. The arm appears to be reaching, but it is not close enough to be considered within reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["no", 3.5098345670808717e-12, 9.54071977671278e-12, "The image shows a robotic arm extending towards a window. The window is a significant distance away from the arm. The arm appears to be reaching, but it is not close enough to be considered within reach.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is a significant distance away from the arm. The arm appears to be reaching, but it is not close enough to be considered within reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable window_1": ["yes", 6.913530620385189e-13, 3.97846209101993e-12, "The image shows a robotic arm (the agent) extending towards a window. The arm appears to be close to the window frame. Therefore, it is reasonable to assume the window is within reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) extending towards a window. The arm appears to be close to the window frame. Therefore, it is reasonable to assume the window is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["yes", 6.913530620385189e-13, 3.97846209101993e-12, "The image shows a robotic arm (the agent) extending towards a window. The arm appears to be close to the window frame. Therefore, it is reasonable to assume the window is within the agent's reach.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) extending towards a window. The arm appears to be close to the window frame. Therefore, it is reasonable to assume the window is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["no", 1.463752730135326e-12, 5.108999594910513e-12, "The image shows a window with multiple panes. The window appears to be closed, as the panes are all aligned and there is no visible gap between them.", false, "Question: Is the window_1 open\n<explanation>\nThe image shows a window with multiple panes. The window appears to be closed, as the panes are all aligned and there is no visible gap between them.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_2)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["yes", 8.87790763213353e-13, 2.129699411615449e-12, "The image shows a robotic arm extending towards a window. The robotic arm appears to be close enough to the window to potentially interact with it. Therefore, the window is in reach of the agent.", true, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The robotic arm appears to be close enough to the window to potentially interact with it. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_1": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_2": ["yes", 8.87790763213353e-13, 2.129699411615449e-12, "The image shows a robotic arm (the agent) and a window labeled \"window_2\". The robotic arm is extended towards the window. Based on the position of the arm and the window in the image, it appears that the arm is close enough to the window to reach it.", true, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a window labeled \"window_2\". The robotic arm is extended towards the window. Based on the position of the arm and the window in the image, it appears that the arm is close enough to the window to reach it.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_2": ["no", 2.882327623104919e-13, 1.139982747956625e-12, "The image shows a window labeled \"window_2\". The window appears to be closed, as the slats are all aligned vertically. Therefore, the window is not open.", false, "Question: Is the window_2 open\n<explanation>\nThe image shows a window labeled \"window_2\". The window appears to be closed, as the slats are all aligned vertically. Therefore, the window is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 7.833943996976567e-13, 2.129486691149207e-12, "The image shows a robotic arm extending towards a window. The robotic arm appears to be close to the window frame. Therefore, the window is within reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The robotic arm appears to be close to the window frame. Therefore, the window is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["yes", 7.833943996976567e-13, 2.129486691149207e-12, "The image shows a robotic arm extending towards a window. The robotic arm appears to be close to the window frame. Therefore, the window is within reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The robotic arm appears to be close to the window frame. Therefore, the window is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["no", 1.7482144746595873e-13, 8.878165672250582e-13, "The image shows a window with multiple panes. The window appears to be closed, as the panes are all intact and aligned. There is no visible gap or indication that the window is open.", false, "Question: Is the window_1 open\n<explanation>\nThe image shows a window with multiple panes. The window appears to be closed, as the panes are all intact and aligned. There is no visible gap or indication that the window is open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_2)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["yes", 1.0059854425176207e-12, 2.7345521680377516e-12, "The image shows a robotic arm (the agent) and a window labeled \"window_2\". The robotic arm is extended towards the window. Based on the position of the arm and the window in the image, it appears that the arm is close enough to the window to reach it.", true, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a window labeled \"window_2\". The robotic arm is extended towards the window. Based on the position of the arm and the window in the image, it appears that the arm is close enough to the window to reach it.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_1": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_2": ["yes", 1.0059854425176207e-12, 2.7345521680377516e-12, "The image shows a robotic arm (the agent) and a window labeled \"window_2\". The robotic arm is extended towards the window. Based on the position of the arm and the window in the image, it appears that the arm is close enough to the window to reach it.", true, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) and a window labeled \"window_2\". The robotic arm is extended towards the window. Based on the position of the arm and the window in the image, it appears that the arm is close enough to the window to reach it.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_2": ["no", 4.752102032191952e-13, 1.4637503448905465e-12, "The image shows a robotic arm holding an object. In the background, there is a window labeled \"window_2\". The window appears to be closed, as the slats are all aligned vertically.", false, "Question: Is the window_2 open\n<explanation>\nThe image shows a robotic arm holding an object. In the background, there is a window labeled \"window_2\". The window appears to be closed, as the slats are all aligned vertically.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 1.291610264922416e-12, 3.5109608362976497e-12, "The image shows a robotic arm extending towards a window. The arm appears to be close to the window frame. Therefore, the window is within reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The arm appears to be close to the window frame. Therefore, the window is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable window_1": ["no", "yes"], "holding window_1": ["yes", "no"], "open window_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 1, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_1": ["yes", "yes"], "holding window_1": ["yes", "no"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 3, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["yes", "yes"], "holding window_2": ["yes", "no"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 5, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_1": ["yes", "yes"], "holding window_1": ["yes", "no"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 7, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["yes", "yes"], "holding window_2": ["yes", "no"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 9, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}], "remaining_actions": ["close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Rs_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 6.101569445006449e-13, 2.129657127730722e-12, "The image shows a robotic arm. The window_1 is located above the robotic arm. The robotic arm is extended towards the window_1. Therefore, the window_1 is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The window_1 is located above the robotic arm. The robotic arm is extended towards the window_1. Therefore, the window_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["yes", 6.101569445006449e-13, 2.129657127730722e-12, "The image shows a robotic arm. The window_1 is located above the robotic arm. The robotic arm is extended towards the window_1. Therefore, the window_1 is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The window_1 is located above the robotic arm. The robotic arm is extended towards the window_1. Therefore, the window_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["no", 1.7482224706506094e-13, 8.87820632983205e-13, "The image shows a robotic arm and a window. The window appears to be closed, as the slats are all aligned vertically. Therefore, the window is not open.", false, "Question: Is the window_1 open\n<explanation>\nThe image shows a robotic arm and a window. The window appears to be closed, as the slats are all aligned vertically. Therefore, the window is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["no", 4.751910670508508e-13, 1.6585797405627156e-12, "The agent is a robotic arm. The window_2 is located far away from the robotic arm. The robotic arm is holding a cup. Therefore, the window_2 is not in reach of the agent.", false, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The window_2 is located far away from the robotic arm. The robotic arm is holding a cup. Therefore, the window_2 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_1": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 3.2660148457236415e-13, 1.0060032234332494e-12, "The image shows a robotic arm. The window_1 is located on the left side of the image. The robotic arm is positioned in the center of the image. The robotic arm appears to be extended towards the left. Based on the position of the robotic arm and the window_1, it seems that the robotic arm is within reach of the window_1.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The window_1 is located on the left side of the image. The robotic arm is positioned in the center of the image. The robotic arm appears to be extended towards the left. Based on the position of the robotic arm and the window_1, it seems that the robotic arm is within reach of the window_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["no", 3.2660148457236415e-13, 1.0060032234332494e-12, "The image shows a robotic arm. The window is located on the left side of the image. The robotic arm is positioned on the right side of the image. The robotic arm is pointing towards the empty space in front of it. The window is far away from the robotic arm. Therefore, the window is not in reach of the agent.", false, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The window is located on the left side of the image. The robotic arm is positioned on the right side of the image. The robotic arm is pointing towards the empty space in front of it. The window is far away from the robotic arm. Therefore, the window is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "open window_1": ["no", 2.882327623104919e-13, 8.878194403608153e-13, "The image shows a robotic arm and a window. The window has a wooden structure with horizontal bars. The window appears to be closed, as the bars are aligned and there is no visible gap indicating it is open.", false, "Question: Is the window_1 open\n<explanation>\nThe image shows a robotic arm and a window. The window has a wooden structure with horizontal bars. The window appears to be closed, as the bars are aligned and there is no visible gap indicating it is open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["no", 2.543514986304285e-13, 1.139924309459528e-12, "The agent is a robotic arm holding a bowl. The window_2 is located far away from the agent. The agent is holding an object, so it cannot reach the window. Therefore, the answer is \"No\".", false, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a bowl. The window_2 is located far away from the agent. The agent is holding an object, so it cannot reach the window. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_1": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["no", 7.834755522302672e-13, 3.978816841970767e-12, "The image shows a robotic arm. The window is located behind the arm. The arm is pointing downwards. Therefore, the window is not in reach of the agent.", false, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The window is located behind the arm. The arm is pointing downwards. Therefore, the window is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["no", 1.980916515889608e-13, 8.877851795721647e-13, "The agent is a robotic arm. The window_2 is located far away from the robotic arm. The robotic arm is holding a bowl. Therefore, the window_2 is not in reach of the agent.", false, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The window_2 is located far away from the robotic arm. The robotic arm is holding a bowl. Therefore, the window_2 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_1": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["no", 7.834667701926701e-13, 3.978772172841261e-12, "The image shows a robotic arm. The window is located on the left side of the image. The robotic arm is positioned towards the right side of the image. The robotic arm is not close enough to the window to reach it. Therefore, the answer is \"No\".", false, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The window is located on the left side of the image. The robotic arm is positioned towards the right side of the image. The robotic arm is not close enough to the window to reach it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["no", 2.2446739020472173e-13, 1.1399393798697255e-12, "The agent is a robotic arm. The window_2 is located far away from the robotic arm. The robotic arm is holding a bowl. Therefore, the window_2 is not in reach of the agent.", false, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The window_2 is located far away from the robotic arm. The robotic arm is holding a bowl. Therefore, the window_2 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_1": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable window_1": ["yes", "yes"], "holding window_1": ["no", "no"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 2, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["no", "yes"], "holding window_2": ["no", "no"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 3, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_1": ["no", "yes"], "holding window_1": ["no", "no"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 5, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["no", "yes"], "holding window_2": ["no", "no"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 6, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_1": ["no", "yes"], "holding window_1": ["no", "no"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 7, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["no", "yes"], "holding window_2": ["no", "no"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 8, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_1": ["no", "yes"], "holding window_1": ["no", "no"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 9, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["no", "yes"], "holding window_2": ["no", "no"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 10, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}], "remaining_actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Rs_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 6.101569445006449e-13, 2.129657127730722e-12, "The image shows a robotic arm. The window_1 is located above the robotic arm. The robotic arm is extended towards the window_1. Therefore, the window_1 is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The window_1 is located above the robotic arm. The robotic arm is extended towards the window_1. Therefore, the window_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["yes", 6.101569445006449e-13, 2.129657127730722e-12, "The image shows a robotic arm. The window_1 is located above the robotic arm. The robotic arm is extended towards the window_1. Therefore, the window_1 is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The window_1 is located above the robotic arm. The robotic arm is extended towards the window_1. Therefore, the window_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["no", 1.7482224706506094e-13, 8.87820632983205e-13, "The image shows a robotic arm and a window. The window appears to be closed, as the slats are all aligned vertically. Therefore, the window is not open.", false, "Question: Is the window_1 open\n<explanation>\nThe image shows a robotic arm and a window. The window appears to be closed, as the slats are all aligned vertically. Therefore, the window is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["no", 2.8822685340865184e-13, 1.2917431881087627e-12, "The image shows a robotic arm holding a white bowl. The window_2 is located far away from the robotic arm. The robotic arm is holding an object, and it is not close enough to reach the window_2. Therefore, the window_2 is not in reach of the agent.", false, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a white bowl. The window_2 is located far away from the robotic arm. The robotic arm is holding an object, and it is not close enough to reach the window_2. Therefore, the window_2 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_1": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 4.752021259130101e-13, 2.1297083020732632e-12, "The image shows a robotic arm extending towards a window. The window is labeled as \"window_1\". The arm appears to be close enough to the window to potentially interact with it. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is labeled as \"window_1\". The arm appears to be close enough to the window to potentially interact with it. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["yes", 4.752021259130101e-13, 2.1297083020732632e-12, "The image shows a robotic arm extending towards a window. The window is located on a wooden structure. The robotic arm appears to be close enough to the window to potentially interact with it. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is located on a wooden structure. The robotic arm appears to be close enough to the window to potentially interact with it. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["no", 2.8823314178125226e-13, 1.1399842658396664e-12, "The image shows a robotic arm and a window. The window appears to be closed, as the slats are all aligned vertically. Therefore, the window is not open.", false, "Question: Is the window_1 open\n<explanation>\nThe image shows a robotic arm and a window. The window appears to be closed, as the slats are all aligned vertically. Therefore, the window is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["no", 2.543472973470101e-13, 1.0059629995326502e-12, "The agent is a robotic arm holding a bowl. The window_2 is located far away from the agent. The agent is holding an object, so it cannot reach the window. Therefore, the answer is \"No\".", false, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a bowl. The window_2 is located far away from the agent. The agent is holding an object, so it cannot reach the window. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_1": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 2.2447266213778544e-13, 1.2917508859441873e-12, "The image shows a robotic arm extending towards a window. The window is a wooden structure with multiple slats. The arm appears to be close to the window. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is a wooden structure with multiple slats. The arm appears to be close to the window. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["yes", 2.2447266213778544e-13, 1.2917508859441873e-12, "The image shows a robotic arm extending towards a window. The window is a wooden structure with multiple slats. The arm appears to be close to the window. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is a wooden structure with multiple slats. The arm appears to be close to the window. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["no", 1.5428049191922727e-13, 7.835010309813206e-13, "The image shows a robotic arm and a wooden structure that appears to be a window. The window has multiple slats, and they are all closed. Therefore, the window is not open.", false, "Question: Is the window_1 open\n<explanation>\nThe image shows a robotic arm and a wooden structure that appears to be a window. The window has multiple slats, and they are all closed. Therefore, the window is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["no", 2.882269618288691e-13, 1.1399597628705682e-12, "The agent is a robotic arm holding a cup. The window_2 is located far away from the agent. The agent is holding an object, so it cannot reach the window. Therefore, the answer is \"No\".", false, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a cup. The window_2 is located far away from the agent. The agent is holding an object, so it cannot reach the window. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_1": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 4.752056495700707e-13, 2.73461960541288e-12, "The image shows a robotic arm. The window is located on the left side of the image. The robotic arm is positioned in the center of the image. The robotic arm appears to be able to reach the window.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The window is located on the left side of the image. The robotic arm is positioned in the center of the image. The robotic arm appears to be able to reach the window.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable window_1": ["yes", "yes"], "holding window_1": ["no", "no"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 2, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["no", "yes"], "holding window_2": ["no", "no"], "open window_2": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 3, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_1": ["yes", "yes"], "holding window_1": ["no", "no"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 5, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["no", "yes"], "holding window_2": ["no", "no"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 6, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_1": ["yes", "yes"], "holding window_1": ["no", "no"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 8, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["no", "yes"], "holding window_2": ["no", "no"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 9, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}], "remaining_actions": ["close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Wainscott_0_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 7.83399549657976e-13, 2.7343327255180405e-12, "The image shows a robotic arm extending towards a window. The window is located on the wall, and the arm appears to be close enough to potentially interact with the window. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is located on the wall, and the arm appears to be close enough to potentially interact with the window. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_1": ["yes", 7.83399549657976e-13, 2.7343327255180405e-12, "The image shows a robotic arm extending towards a window. The window is located on a wall, and the arm appears to be close enough to potentially interact with the window. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The window is located on a wall, and the arm appears to be close enough to potentially interact with the window. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["no", 4.751995238277962e-13, 2.1296965926898004e-12, "The image shows a window with a dark brown frame. The window appears to be closed, as the slats are aligned vertically and not spread apart.", false, "Question: Is the window_1 open\n<explanation>\nThe image shows a window with a dark brown frame. The window appears to be closed, as the slats are aligned vertically and not spread apart.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_2)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["yes", 2.882216763432782e-13, 1.2917198777620542e-12, "The image shows a robotic arm extending towards the right. The window_2 is located on the right side of the image. The robotic arm appears to be close to the window. Therefore, the window_2 is in reach of the agent.", true, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards the right. The window_2 is located on the right side of the image. The robotic arm appears to be close to the window. Therefore, the window_2 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_1": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_2": ["yes", 2.882216763432782e-13, 1.2917198777620542e-12, "The image shows a robotic arm extending towards the right. The window_2 is located on the right side of the image. The robotic arm appears to be close to the window. Therefore, the window_2 is in reach of the agent.", true, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards the right. The window_2 is located on the right side of the image. The robotic arm appears to be close to the window. Therefore, the window_2 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_2": ["no", 8.877692960103378e-13, 1.879407436969349e-12, "The image shows a window labeled \"window_2\". The window appears to be closed, as the panes are all visible and there is no indication of it being open.", false, "Question: Is the window_2 open\n<explanation>\nThe image shows a window labeled \"window_2\". The window appears to be closed, as the panes are all visible and there is no indication of it being open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_1": ["yes", 6.101313031192657e-13, 2.1295675726312746e-12, "The image shows a robotic arm extending towards a window. The robotic arm appears to be close enough to the window to potentially interact with it. Therefore, the window is in reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The robotic arm appears to be close enough to the window to potentially interact with it. Therefore, the window is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_2": {"before": true, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable window_1": ["yes", 6.101313031192657e-13, 2.1295675726312746e-12, "The image shows a robotic arm extending towards a window. The arm appears to be close to the window frame. Therefore, the window is within reach of the agent.", true, "Question: Is the window_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a window. The arm appears to be close to the window frame. Therefore, the window is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open window_1": ["yes", 7.834850932093851e-13, 2.1297332387232304e-12, "The image shows a window with a lattice-like structure. The window appears to be partially open, as there is a gap between the window and the wall. Therefore, the window is open.", true, "Question: Is the window_1 open\n<explanation>\nThe image shows a window with a lattice-like structure. The window appears to be partially open, as there is a gap between the window and the wall. Therefore, the window is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"open window_1": ["no", 6.914129099984401e-13, 7.433388973798749e-12, "The image shows a window with bars. The window appears to be closed, as the bars are in place and there is no visible opening.", true, "Question: Is the window_1 open\n<explanation>\nThe image shows a window with bars. The window appears to be closed, as the bars are in place and there is no visible opening.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "navigate-to(window_3)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_3": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_3": ["no", 1.2916455014930217e-12, 4.508286105542325e-12, "The image shows a robotic arm holding a cylindrical object. The window_3 is located on the left side of the image. The robotic arm is positioned to the right of the window. Based on the image, the robotic arm is not close enough to the window to reach it.", false, "Question: Is the window_3 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a cylindrical object. The window_3 is located on the left side of the image. The robotic arm is positioned to the right of the window. Based on the image, the robotic arm is not close enough to the window to reach it.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable window_1": {"before": true, "after": false}, "reachable window_2": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(window_2)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_2": ["yes", 6.101651302270472e-13, 2.4132497215834103e-12, "The image shows a robotic arm extending towards the right. The window_2 is located on the right side of the image. The robotic arm appears to be close to the window. Therefore, the window_2 is in reach of the agent.", true, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards the right. The window_2 is located on the right side of the image. The robotic arm appears to be close to the window. Therefore, the window_2 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_1": {"before": false, "after": false}, "reachable window_3": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(window_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable window_2": ["no", 6.101651302270472e-13, 2.4132497215834103e-12, "The image shows a robotic arm. The question asks if the window_2 is in reach of the agent. The robotic arm is positioned to the right of the window. The distance between the arm and the window appears to be too far for the arm to reach the window.", false, "Question: Is the window_2 in reach of the agent\n<explanation>\nThe image shows a robotic arm. The question asks if the window_2 is in reach of the agent. The robotic arm is positioned to the right of the window. The distance between the arm and the window appears to be too far for the arm to reach the window.\n</explanation>\n<answer>\nNo\n</answer>", false], "open window_2": ["no", 1.139935693582339e-12, 2.129680329657213e-12, "The image shows a window labeled \"window_2\". The window appears to be closed, as the panes are all visible and there is no indication of it being open.", false, "Question: Is the window_2 open\n<explanation>\nThe image shows a window labeled \"window_2\". The window appears to be closed, as the panes are all visible and there is no indication of it being open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(window_3)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable window_3": [true, false, false], "all_correct": true}, "effects_results": {"reachable window_3": ["yes", 8.877357399530994e-13, 2.734418377489667e-12, "The image shows a robotic arm holding a blue cylindrical object. The window_3 is a wooden structure with multiple panes. The robotic arm is positioned to the right of the window_3. It appears that the arm is close enough to the window to potentially reach it.", true, "Question: Is the window_3 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a blue cylindrical object. The window_3 is a wooden structure with multiple panes. The robotic arm is positioned to the right of the window_3. It appears that the arm is close enough to the window to potentially reach it.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable window_1": {"before": false, "after": false}, "reachable window_2": {"before": false, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable window_1": ["yes", "yes"], "open window_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 2, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["yes", "yes"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 4, "actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_3": ["no", "yes"], "reachable sofa_1": ["no", "yes"], "open window_3": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 7, "actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"]}, {"enum_results": {"reachable window_2": ["no", "yes"], "open window_2": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 9, "actions": ["navigate-to(window_3)", "close-container(window_3)"]}], "remaining_actions": ["close-container(window_3)"]}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Beechwood_0_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 2.1295701747164886e-12, 1.3886542089835974e-11, "The agent is a robotic arm. The cabinet_1 is on the left side of the image. The robotic arm is in the middle of the image. The distance between the robotic arm and the cabinet_1 seems too far for the robotic arm to reach.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is on the left side of the image. The robotic arm is in the middle of the image. The distance between the robotic arm and the cabinet_1 seems too far for the robotic arm to reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 9.543015683233236e-12, 3.330839770665506e-11, "The agent is a robotic arm holding a pitcher and an apple. The cabinet_1 is the set of wooden cabinets in the background. The robotic arm is positioned in front of a counter with an apple and a pitcher on it. The cabinets are behind the counter. The robotic arm is not close enough to the cabinets to reach them.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a pitcher and an apple. The cabinet_1 is the set of wooden cabinets in the background. The robotic arm is positioned in front of a counter with an apple and a pitcher on it. The cabinets are behind the counter. The robotic arm is not close enough to the cabinets to reach them.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 9.543015683233236e-12, 3.330839770665506e-11, "The agent is a robotic arm holding a pitcher and an apple. The cabinet_1 is the set of wooden cabinets in the background. The robotic arm is positioned in front of a counter with an apple and a pitcher on it. The cabinets are behind the counter. The robotic arm is not close enough to the cabinets to reach them.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a pitcher and an apple. The cabinet_1 is the set of wooden cabinets in the background. The robotic arm is positioned in front of a counter with an apple and a pitcher on it. The cabinets are behind the counter. The robotic arm is not close enough to the cabinets to reach them.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 1.6586181213196216e-12, 5.789146072243678e-12, "The agent is a robotic arm holding an object. The cabinet_1 is located above the counter. The robotic arm is currently holding an object and is positioned near the counter. The arm's reach appears to be limited to the area around the counter. The cabinet is significantly higher than the arm's current position. Therefore, the cabinet_1 is not in reach of the agent.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding an object. The cabinet_1 is located above the counter. The robotic arm is currently holding an object and is positioned near the counter. The arm's reach appears to be limited to the area around the counter. The cabinet is significantly higher than the arm's current position. Therefore, the cabinet_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": true, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 1.6586181213196216e-12, 5.789146072243678e-12, "The agent is a robotic arm holding an object. The cabinet_1 is located above the counter. The robotic arm is currently holding an object and is positioned near the counter. The arm's reach appears to be limited to the area around the counter. The cabinet is significantly higher than the arm's current position. Therefore, the cabinet_1 is not in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding an object. The cabinet_1 is located above the counter. The robotic arm is currently holding an object and is positioned near the counter. The arm's reach appears to be limited to the area around the counter. The cabinet is significantly higher than the arm's current position. Therefore, the cabinet_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 7.432493856485145e-12, 1.78296266639677e-11, "The image shows a robotic arm holding an object. The cabinet_1 is located on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The arm is holding an object, and it appears to be close to the cabinet. Therefore, the cabinet_1 is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding an object. The cabinet_1 is located on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The arm is holding an object, and it appears to be close to the cabinet. Therefore, the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 7.432493856485145e-12, 1.78296266639677e-11, "The image shows a robotic arm holding an object. The cabinet_1 is located on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The arm is holding an object, and it appears to be close to the cabinet. Therefore, the cabinet_1 is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding an object. The cabinet_1 is located on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The arm is holding an object, and it appears to be close to the cabinet. Therefore, the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 1.0815300044431098e-11, 1.7831415163871434e-11, "The image shows a kitchen environment with cabinets. I need to determine if cabinet_1 is open. Looking at the image, the cabinet doors are closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen environment with cabinets. I need to determine if cabinet_1 is open. Looking at the image, the cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["no", 4.508688561388752e-12, 5.1090134726983205e-12, "The image shows a kitchen environment with a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The cabinet door is closed. Therefore, the cabinet_1 is not open.", false, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen environment with a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The cabinet door is closed. Therefore, the cabinet_1 is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable snack_food_1": ["yes", 1.879487234249244e-12, 3.5113446438667095e-12, "The image shows a robotic arm holding an object. The object appears to be a snack_food_1. The arm is positioned near a counter. Therefore, the snack_food_1 is in reach of the agent.", true, "Question: Is the snack_food_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding an object. The object appears to be a snack_food_1. The arm is positioned near a counter. Therefore, the snack_food_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable carton_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable carton_1": ["no", 4.5084786598481585e-12, 2.5944503490027415e-11, "The image shows a first-person view from the agent's perspective. The agent appears to be holding a black object. In the scene, there is a carton labeled \"carton_1\" visible in the distance. Given the perspective and the distance, it seems unlikely that the carton is within the agent's immediate reach.", false, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a first-person view from the agent's perspective. The agent appears to be holding a black object. In the scene, there is a carton labeled \"carton_1\" visible in the distance. Given the perspective and the distance, it seems unlikely that the carton is within the agent's immediate reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable cabinet_1": {"before": true, "after": false}, "reachable snack_food_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(snack_food_1)", "action_correct": true, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable carton_1": ["no", 5.789191608734923e-12, 3.331449352494964e-11, "The image shows a robotic arm, which represents the agent. I need to determine if the carton_1 is within the arm's reach. The carton_1 is located in the distance, and the robotic arm is positioned in the foreground. Based on the visual perspective, the carton_1 appears to be beyond the arm's immediate reach.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm, which represents the agent. I need to determine if the carton_1 is within the arm's reach. The carton_1 is located in the distance, and the robotic arm is positioned in the foreground. Based on the visual perspective, the carton_1 appears to be beyond the arm's immediate reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {"reachable snack_food_1": {"before": false, "after": true}, "reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "executed but failed"}], "replans": [{"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "reachable apple_1": ["no", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7241379310344828, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.75, "no_correct": 18, "no_total": 24, "predicates": {"reachable": {"accuracy": 0.6, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.25, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.25, "no_correct": 2, "no_total": 8}}}, "step": 1, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 10, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}}}, "step": 2, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "yes"], "holding countertop_1": ["yes", "no"], "holding snack_food_1": ["yes", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop snack_food_1,countertop_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["no", "no"], "ontop snack_food_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside snack_food_1,cabinet_1": ["no", "yes"], "nextto countertop_1,snack_food_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto snack_food_1,countertop_1": ["yes", "no"], "nextto snack_food_1,cabinet_1": ["yes", "yes"], "nextto snack_food_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.5238095238095238, "yes_accuracy": 0.7142857142857143, "yes_correct": 5, "yes_total": 7, "no_accuracy": 0.42857142857142855, "no_correct": 6, "no_total": 14, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "ontop": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 4, "no_total": 6}, "inside": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.3333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.2, "no_correct": 1, "no_total": 5}}}, "step": 4, "actions": ["navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open door_1": ["yes", "no"], "holding door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.625, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.8333333333333334, "no_correct": 5, "no_total": 6, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 5, "actions": ["navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}], "remaining_actions": ["navigate-to(carton_1)", "place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Beechwood_0_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 2.1295701747164886e-12, 1.3886542089835974e-11, "The agent is a robotic arm. The cabinet_1 is on the left side of the image. The robotic arm is in the middle of the image. The distance between the robotic arm and the cabinet_1 seems too far for the robotic arm to reach.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is on the left side of the image. The robotic arm is in the middle of the image. The distance between the robotic arm and the cabinet_1 seems too far for the robotic arm to reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 8.4211760828512e-12, 2.0201351008664048e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 8.4211760828512e-12, 2.0201351008664048e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 1.87922377312133e-12, 6.559136480482897e-12, "The agent is a robotic arm holding a yellow object and an apple. The cabinet_1 is the wooden structure with a grid pattern on the door, located in the background. The robotic arm is positioned in front of a counter with a drawer. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a yellow object and an apple. The cabinet_1 is the wooden structure with a grid pattern on the door, located in the background. The robotic arm is positioned in front of a counter with a drawer. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 1.87922377312133e-12, 6.559136480482897e-12, "The agent is a robotic arm holding a yellow object and an apple. The cabinet_1 is the wooden structure with a grid pattern on the door, located in the background. The robotic arm is positioned in front of a counter with a drawer. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a yellow object and an apple. The cabinet_1 is the wooden structure with a grid pattern on the door, located in the background. The robotic arm is positioned in front of a counter with a drawer. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 6.55935939244956e-12, 1.7830186979650442e-11, "The agent is a robotic arm. The cabinet_1 is the wooden structure in the background. The robotic arm is holding a yellow object and a red object. The robotic arm is not close to the cabinet_1. Therefore, the cabinet_1 is not in reach of the agent.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the wooden structure in the background. The robotic arm is holding a yellow object and a red object. The robotic arm is not close to the cabinet_1. Therefore, the cabinet_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 6.55935939244956e-12, 1.7830186979650442e-11, "The agent is a robotic arm. The cabinet_1 is the wooden structure in the background. The robotic arm is holding a yellow object and a red object. The robotic arm is not close to the cabinet_1. Therefore, the cabinet_1 is not in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the wooden structure in the background. The robotic arm is holding a yellow object and a red object. The robotic arm is not close to the cabinet_1. Therefore, the cabinet_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 4.507791275670803e-12, 1.3884974767175429e-11, "The agent is a robotic arm holding a teapot. The cabinet_1 is on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach the cabinet.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a teapot. The cabinet_1 is on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 4.507791275670803e-12, 1.3884974767175429e-11, "The agent is a robotic arm holding a teapot. The cabinet_1 is on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach the cabinet.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a teapot. The cabinet_1 is on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 3.510855018165615e-12, 9.543493599550867e-12, "The image shows a robotic arm extending towards a countertop. The cabinet_1 is located above the countertop. The robotic arm is holding an apple. The arm is close to the cabinet, but it is not clear if it can reach the cabinet. However, given the position of the arm and the apple, it seems that the arm is not reaching for the cabinet.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a countertop. The cabinet_1 is located above the countertop. The robotic arm is holding an apple. The arm is close to the cabinet, but it is not clear if it can reach the cabinet. However, given the position of the arm and the apple, it seems that the arm is not reaching for the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 3.510855018165615e-12, 9.543493599550867e-12, "The image shows a robotic arm extending towards a cabinet. The cabinet is labeled as \"cabinet_1\". The arm appears to be close enough to the cabinet to potentially interact with it. Therefore, the cabinet is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm extending towards a cabinet. The cabinet is labeled as \"cabinet_1\". The arm appears to be close enough to the cabinet to potentially interact with it. Therefore, the cabinet is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 5.789064973921176e-12, 9.544554382956427e-12, "The image shows a kitchen environment with cabinets. The cabinet labeled \"cabinet_1\" is the one on the left side of the image. The doors of this cabinet are closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen environment with cabinets. The cabinet labeled \"cabinet_1\" is the one on the left side of the image. The doors of this cabinet are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["no", 6.560081904777304e-12, 1.0815745868364424e-11, "The image shows a robotic arm holding an object in front of a cabinet. The cabinet doors appear to be closed. Therefore, the cabinet is not open.", false, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a robotic arm holding an object in front of a cabinet. The cabinet doors appear to be closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable snack_food_1": ["yes", 2.413276176116419e-12, 3.511296071609382e-12, "The image shows a robotic arm holding a black object. There is a red object and a yellow object on the counter. The question asks if the snack_food_1 is in reach of the agent. snack_food_1 is the red object. The robotic arm is holding the black object, and the red object is on the counter in front of the arm. Therefore, the snack_food_1 is in reach of the agent.", true, "Question: Is the snack_food_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a black object. There is a red object and a yellow object on the counter. The question asks if the snack_food_1 is in reach of the agent. snack_food_1 is the red object. The robotic arm is holding the black object, and the red object is on the counter in front of the arm. Therefore, the snack_food_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable carton_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable carton_1": ["yes", 3.098765168074724e-12, 1.3887702619841402e-11, "The image shows a robotic arm, which represents the agent. The carton_1 is a brown box located in the background. The robotic arm appears to be extended towards the background. Based on the image, the carton_1 appears to be within the arm's reach.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm, which represents the agent. The carton_1 is a brown box located in the background. The robotic arm appears to be extended towards the background. Based on the image, the carton_1 appears to be within the arm's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable cabinet_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": true, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7586206896551724, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.75, "no_correct": 18, "no_total": 24, "predicates": {"reachable": {"accuracy": 0.8, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.25, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.25, "no_correct": 2, "no_total": 8}}}, "step": 1, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 10, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}}}, "step": 2, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6190476190476191, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.5625, "no_correct": 9, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.8333333333333334, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.8, "no_correct": 4, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 6}}}, "step": 3, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6551724137931034, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 15, "no_total": 24, "predicates": {"reachable": {"accuracy": 0.8, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.125, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.125, "no_correct": 1, "no_total": 8}}}, "step": 4, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 1.0, "yes_correct": 5, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 10, "no_total": 16, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}}}, "step": 5, "actions": ["open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "yes"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "holding snack_food_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,snack_food_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "ontop snack_food_1,countertop_1": ["no", "no"], "ontop snack_food_1,apple_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["no", "yes"], "ontop snack_food_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside snack_food_1,cabinet_1": ["no", "yes"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,snack_food_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,snack_food_1": ["no", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,juice_1": ["no", "yes"], "nextto snack_food_1,countertop_1": ["yes", "no"], "nextto snack_food_1,apple_1": ["no", "no"], "nextto snack_food_1,cabinet_1": ["yes", "yes"], "nextto snack_food_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6388888888888888, "yes_accuracy": 0.5454545454545454, "yes_correct": 6, "yes_total": 11, "no_accuracy": 0.68, "no_correct": 17, "no_total": 25, "predicates": {"reachable": {"accuracy": 0.8, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.3333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3}, "ontop": {"accuracy": 0.9166666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 10, "no_total": 10}, "inside": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.4166666666666667, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.4, "no_correct": 4, "no_total": 10}}}, "step": 6, "actions": ["navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}], "remaining_actions": []}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Beechwood_0_int_21": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 2.1295701747164886e-12, 1.3886542089835974e-11, "The agent is a robotic arm. The cabinet_1 is on the left side of the image. The robotic arm is in the middle of the image. The distance between the robotic arm and the cabinet_1 seems too far for the robotic arm to reach.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is on the left side of the image. The robotic arm is in the middle of the image. The distance between the robotic arm and the cabinet_1 seems too far for the robotic arm to reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 5.7873384903817104e-12, 1.7826257830977355e-11, "The agent is a robotic arm holding a teapot and an apple. The cabinet_1 is on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach the cabinet.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a teapot and an apple. The cabinet_1 is on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 5.7873384903817104e-12, 1.7826257830977355e-11, "The agent is a robotic arm holding a teapot and an apple. The cabinet_1 is on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach the cabinet.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm holding a teapot and an apple. The cabinet_1 is on the left side of the image. The robotic arm is positioned to the right of the cabinet_1. The distance between the robotic arm and the cabinet_1 appears to be too far for the arm to reach the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 5.788131692691101e-12, 1.782870032163153e-11, "The image shows a robotic arm holding an object. The cabinet is located above the counter. The robotic arm is positioned such that it is not directly above the cabinet. Therefore, the cabinet is not in reach of the agent.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding an object. The cabinet is located above the counter. The robotic arm is positioned such that it is not directly above the cabinet. Therefore, the cabinet is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 5.788131692691101e-12, 1.782870032163153e-11, "The image shows a robotic arm holding an object. The cabinet is located above the counter. The robotic arm is positioned such that it is not directly above the cabinet. Therefore, the cabinet is not in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding an object. The cabinet is located above the counter. The robotic arm is positioned such that it is not directly above the cabinet. Therefore, the cabinet is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 7.431089597831342e-12, 1.7826257830977355e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 7.431089597831342e-12, 1.7826257830977355e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 9.541671272539354e-12, 2.2889280748561447e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": true, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 9.541671272539354e-12, 2.2889280748561447e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding a teapot and an apple. The robotic arm is close to the counter. The cabinet is further away than the counter. The robotic arm is not close enough to the cabinet to reach it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 3.978720998498719e-12, 1.0815285299281552e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 3.978720998498719e-12, 1.0815285299281552e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is currently holding an object and is positioned in front of the counter. The cabinet is behind the counter. The robotic arm's reach appears to be limited to the counter area. Therefore, the cabinet is not in reach of the agent.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is currently holding an object and is positioned in front of the counter. The cabinet is behind the counter. The robotic arm's reach appears to be limited to the counter area. Therefore, the cabinet is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "open cabinet_1": ["no", 8.42320744404157e-12, 2.0206223846908067e-11, "The image shows a kitchen environment with cabinets. I need to determine if cabinet_1 is open. Looking at the image, the cabinet doors are closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen environment with cabinets. I need to determine if cabinet_1 is open. Looking at the image, the cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 3.978720998498719e-12, 1.0815285299281552e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 3.978720998498719e-12, 1.0815285299281552e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 3.978720998498719e-12, 1.0815285299281552e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 3.978720998498719e-12, 1.0815285299281552e-11, "The agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.", false, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. The cabinet_1 is the cabinet on the left side of the image. The robotic arm is holding an object and is positioned in front of the counter. The cabinet is above the counter. The robotic arm appears to be able to reach the cabinet.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}], "replans": [{"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6551724137931034, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 15, "no_total": 24, "predicates": {"reachable": {"accuracy": 0.8, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.125, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.125, "no_correct": 1, "no_total": 8}}}, "step": 1, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 10, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}}}, "step": 2, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7586206896551724, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.75, "no_correct": 18, "no_total": 24, "predicates": {"reachable": {"accuracy": 0.8, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.25, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.25, "no_correct": 2, "no_total": 8}}}, "step": 3, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7241379310344828, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": 0.7083333333333334, "no_correct": 17, "no_total": 24, "predicates": {"reachable": {"accuracy": 0.8, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.125, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.125, "no_correct": 1, "no_total": 8}}}, "step": 4, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6190476190476191, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 10, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}}}, "step": 6, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6190476190476191, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 10, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}}}, "step": 7, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6190476190476191, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 10, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}}}, "step": 8, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6190476190476191, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 10, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}}}, "step": 9, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6190476190476191, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.625, "no_correct": 10, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}}}, "step": 10, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}], "remaining_actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Wainscott_0_int_0": {"all_correct": false, "goal_reached": true, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable cabinet_1": ["no", 3.09830351478968e-12, 1.2254027653701982e-11, "The agent is a robotic arm. I need to determine if the cabinet_1 is within the arm's reach. Looking at the image, the cabinet_1 is located across the room, and the robotic arm is positioned near a refrigerator. The distance between the arm and the cabinet_1 appears to be too far for the arm to reach it.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. I need to determine if the cabinet_1 is within the arm's reach. Looking at the image, the cabinet_1 is located across the room, and the robotic arm is positioned near a refrigerator. The distance between the arm and the cabinet_1 appears to be too far for the arm to reach it.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 8.422018291098787e-12, 2.2893419798775128e-11, "The image shows a robotic arm (the agent) extending towards a countertop. The countertop has a brown object on it. Behind the countertop, there is a cabinet. The robotic arm appears to be close enough to the countertop to reach it, and the cabinet is behind the countertop. Therefore, the cabinet is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) extending towards a countertop. The countertop has a brown object on it. Behind the countertop, there is a cabinet. The robotic arm appears to be close enough to the countertop to reach it, and the cabinet is behind the countertop. Therefore, the cabinet is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {"reachable cabinet_1": ["yes", 8.422018291098787e-12, 2.2893419798775128e-11, "The image shows a robotic arm (the agent) extending towards a countertop. The countertop has a brown object on it. Behind the countertop, there is a cabinet. The robotic arm appears to be close enough to the countertop to reach it, and the cabinet is behind the countertop. Therefore, the cabinet is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) extending towards a countertop. The countertop has a brown object on it. Behind the countertop, there is a cabinet. The robotic arm appears to be close enough to the countertop to reach it, and the cabinet is behind the countertop. Therefore, the cabinet is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 1.0814603552955493e-11, 1.3886226370163346e-11, "The image shows a kitchen scene with a robotic arm holding an object. The arm is positioned near a countertop and a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen scene with a robotic arm holding an object. The arm is positioned near a countertop and a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["no", 8.42227156072628e-12, 1.0814410131287922e-11, "The image shows a kitchen environment with a robotic arm holding an object. The arm is positioned near a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.", false, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen environment with a robotic arm holding an object. The arm is positioned near a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable snack_food_1": {"before": false, "after": true}}}, "action_info": "executed but failed"}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 4.5079647480184004e-12, 1.573434264823259e-11, "The image shows a robotic arm holding an object. The arm is positioned near a countertop and a cabinet. The cabinet is labeled as cabinet_1. The arm appears to be close enough to the cabinet to potentially reach it.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding an object. The arm is positioned near a countertop and a cabinet. The cabinet is labeled as cabinet_1. The arm appears to be close enough to the cabinet to potentially reach it.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 8.42227156072628e-12, 1.0814410131287922e-11, "The image shows a kitchen environment with a robotic arm holding an object. The arm is positioned near a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen environment with a robotic arm holding an object. The arm is positioned near a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["no", 4.508609197789726e-12, 5.789168623648866e-12, "The image shows a robotic arm holding a white plate. The arm is positioned near a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.", false, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a robotic arm holding a white plate. The arm is positioned near a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable snack_food_1": ["yes", 1.2917579332583085e-12, 1.8794965583879275e-12, "The image shows a robotic arm holding a white plate. Below the arm, on a wooden surface, is a brown object labeled \"snack_food_1\". The arm is positioned directly above the snack_food_1. Therefore, the snack_food_1 is within reach of the agent.", true, "Question: Is the snack_food_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a white plate. Below the arm, on a wooden surface, is a brown object labeled \"snack_food_1\". The arm is positioned directly above the snack_food_1. Therefore, the snack_food_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(snack_food_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable snack_food_1": ["yes", 1.2917579332583085e-12, 1.8794965583879275e-12, "The image shows a robotic arm holding a white plate. Below the arm, on a wooden surface, is a brown object labeled \"snack_food_1\". The arm is positioned directly above the snack_food_1. Therefore, the snack_food_1 is within reach of the agent.", true, "Question: Is the snack_food_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a white plate. Below the arm, on a wooden surface, is a brown object labeled \"snack_food_1\". The arm is positioned directly above the snack_food_1. Therefore, the snack_food_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"holding snack_food_1": ["yes", 3.331390718841476e-11, 2.020590812723544e-11, "The image shows a robotic arm holding a yellow object. The object appears to be a snack. The object is labeled as snack_food_1. Therefore, the agent is holding the snack_food_1.", true, "Question: Is the agent holding the snack_food_1\n<explanation>\nThe image shows a robotic arm holding a yellow object. The object appears to be a snack. The object is labeled as snack_food_1. Therefore, the agent is holding the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop snack_food_1,cabinet_1": ["no", 8.420597552571962e-12, 2.2889556569594127e-11, "The image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The arm is positioned in front of a cabinet, labeled as cabinet_1. The snack_food_1 is being held by the robotic arm and is not on top of the cabinet.", true, "Question: Is the snack_food_1 on top of the cabinet_1\n<explanation>\nThe image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The arm is positioned in front of a cabinet, labeled as cabinet_1. The snack_food_1 is being held by the robotic arm and is not on top of the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto snack_food_1,cabinet_1": ["no", 5.786787281997219e-12, 1.7824559536694373e-11, "The image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The robotic arm is positioned in front of a cabinet, labeled as cabinet_1. The snack_food_1 is being held by the robotic arm, and is not directly next to the cabinet. Therefore, the answer is \"No\".", true, "Question: Is the snack_food_1 next to the cabinet_1\n<explanation>\nThe image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The robotic arm is positioned in front of a cabinet, labeled as cabinet_1. The snack_food_1 is being held by the robotic arm, and is not directly next to the cabinet. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "inside snack_food_1,cabinet_1": ["no", 5.108578490786719e-12, 2.0204820455616e-11, "The image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The arm is positioned in front of a cabinet, labeled as cabinet_1. However, the snack_food_1 is not inside the cabinet; it is being held by the robotic arm in front of it. Therefore, the answer is \"No\".", true, "Question: Is the snack_food_1 inside the cabinet_1\n<explanation>\nThe image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The arm is positioned in front of a cabinet, labeled as cabinet_1. However, the snack_food_1 is not inside the cabinet; it is being held by the robotic arm in front of it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"ontop snack_food_1,carton_1": {"before": false, "after": false}, "ontop snack_food_1,snack_food_1": {"before": null, "after": false}, "nextto snack_food_1,carton_1": {"before": false, "after": false}, "nextto snack_food_1,snack_food_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable carton_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable carton_1": ["yes", 1.2917627037478674e-12, 4.508695066601787e-12, "The image shows a robotic arm (the agent) holding a yellow pillow. There is a carton labeled \"carton_1\" on a table in the background. The robotic arm is holding the pillow, and it appears to be positioned such that it could potentially reach the carton if it released the pillow. Therefore, the carton is in reach of the agent.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) holding a yellow pillow. There is a carton labeled \"carton_1\" on a table in the background. The robotic arm is holding the pillow, and it appears to be positioned such that it could potentially reach the carton if it released the pillow. Therefore, the carton is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable snack_food_1": ["yes", 5.384822904415387e-13, 1.006017426481709e-12, "The image shows a robotic arm (the agent) holding a yellow object. There is also a bowl of snack_food_1 on a table in the background. The robotic arm appears to be close enough to the table to reach the snack_food_1.", false, "Question: Is the snack_food_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) holding a yellow object. There is also a bowl of snack_food_1 on a table in the background. The robotic arm appears to be close enough to the table to reach the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable cabinet_1": ["yes", "yes"], "open cabinet_1": ["no", "no"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 2, "actions": ["open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable snack_food_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "open cabinet_1": ["no", "yes"], "holding snack_food_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["no", "yes"], "inside snack_food_1,cabinet_1": ["no", "yes"], "nextto snack_food_1,cabinet_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.2857142857142857, "yes_accuracy": 0.16666666666666666, "yes_correct": 1, "yes_total": 6, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "inside": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 3, "actions": ["grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "reachable snack_food_1": ["yes", "yes"], "open carton_1": ["no", "yes"], "open electric_refrigerator_1": ["no", "no"], "holding snack_food_1": ["yes", "yes"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "nextto snack_food_1,carton_1": ["no", "no"], "nextto snack_food_1,electric_refrigerator_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.875, "no_correct": 7, "no_total": 8, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}}}, "step": 5, "actions": ["place-next-to(snack_food_1, snack_food_1)", "open-container(carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"]}], "remaining_actions": ["open-container(carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"]}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Wainscott_0_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable cabinet_1": ["no", 3.09830351478968e-12, 1.2254027653701982e-11, "The agent is a robotic arm. I need to determine if the cabinet_1 is within the arm's reach. Looking at the image, the cabinet_1 is located across the room, and the robotic arm is positioned near a refrigerator. The distance between the arm and the cabinet_1 appears to be too far for the arm to reach it.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe agent is a robotic arm. I need to determine if the cabinet_1 is within the arm's reach. Looking at the image, the cabinet_1 is located across the room, and the robotic arm is positioned near a refrigerator. The distance between the arm and the cabinet_1 appears to be too far for the arm to reach it.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 8.421121439061707e-12, 2.2890979042844428e-11, "The image shows a robotic arm (the agent) extending towards a countertop. The countertop has a wooden cutting board and a knife on it. Behind the countertop are cabinets. The arm is positioned such that it could potentially reach the cabinets. Therefore, the cabinet_1 is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) extending towards a countertop. The countertop has a wooden cutting board and a knife on it. Behind the countertop are cabinets. The arm is positioned such that it could potentially reach the cabinets. Therefore, the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable carton_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 8.421121439061707e-12, 2.2890979042844428e-11, "The image shows a robotic arm (the agent) extending towards a countertop. The countertop has a wooden cutting board and a knife on it. Behind the countertop are cabinets. The arm is positioned such that it could potentially reach the cabinets. Therefore, the cabinet_1 is in reach of the agent.", true, "Question: Is the cabinet_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm (the agent) extending towards a countertop. The countertop has a wooden cutting board and a knife on it. Behind the countertop are cabinets. The arm is positioned such that it could potentially reach the cabinets. Therefore, the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 1.3884934001173743e-11, 2.289238416885997e-11, "The image shows a kitchen scene with a robotic arm holding an object. The arm is positioned near a countertop and a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.", true, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a kitchen scene with a robotic arm holding an object. The arm is positioned near a countertop and a cabinet. The cabinet doors are closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["no", 6.559988229709601e-12, 1.2255669569471994e-11, "The image shows a cabinet. The cabinet doors are visible and appear to be closed. Therefore, the cabinet is not open.", false, "Question: Is the cabinet_1 open\n<explanation>\nThe image shows a cabinet. The cabinet doors are visible and appear to be closed. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable snack_food_1": ["yes", 3.511296071609382e-12, 5.789148674328892e-12, "The image shows a robotic arm holding a white plate. Below the arm, on a counter, is a brown object labeled \"snack_food_1\". The arm is positioned directly above the snack_food_1. Therefore, the snack_food_1 is within reach of the agent.", true, "Question: Is the snack_food_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a white plate. Below the arm, on a counter, is a brown object labeled \"snack_food_1\". The arm is positioned directly above the snack_food_1. Therefore, the snack_food_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(snack_food_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable snack_food_1": ["yes", 3.511296071609382e-12, 5.789148674328892e-12, "The image shows a robotic arm holding a white plate. Below the arm, on a counter, is a brown object labeled \"snack_food_1\". The arm is positioned directly above the snack_food_1. Therefore, the snack_food_1 is within reach of the agent.", true, "Question: Is the snack_food_1 in reach of the agent\n<explanation>\nThe image shows a robotic arm holding a white plate. Below the arm, on a counter, is a brown object labeled \"snack_food_1\". The arm is positioned directly above the snack_food_1. Therefore, the snack_food_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"holding snack_food_1": ["yes", 4.847074477898339e-11, 2.0205613224244523e-11, "The image shows a robotic arm holding a yellow object. The object appears to be a snack. The object is labeled as snack_food_1. Therefore, the agent is holding the snack_food_1.", true, "Question: Is the agent holding the snack_food_1\n<explanation>\nThe image shows a robotic arm holding a yellow object. The object appears to be a snack. The object is labeled as snack_food_1. Therefore, the agent is holding the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop snack_food_1,cabinet_1": ["no", 7.432890240799406e-12, 1.7830577292432537e-11, "The image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The robotic arm is positioned below a cabinet, labeled as cabinet_1. The snack_food_1 is being held by the robotic arm and is not resting on top of the cabinet. Therefore, the answer is \"No\".", true, "Question: Is the snack_food_1 on top of the cabinet_1\n<explanation>\nThe image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The robotic arm is positioned below a cabinet, labeled as cabinet_1. The snack_food_1 is being held by the robotic arm and is not resting on top of the cabinet. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto snack_food_1,cabinet_1": ["no", 5.788741014312038e-12, 1.2254764043817534e-11, "The image shows a robotic arm holding a yellow object, which is likely snack_food_1. Below the arm, there is a table with a brown object on it. To the right of the table, there is a cabinet. The robotic arm is holding the snack_food_1 above the table, and the cabinet is to the right of the table. Therefore, the snack_food_1 is not next to the cabinet.", true, "Question: Is the snack_food_1 next to the cabinet_1\n<explanation>\nThe image shows a robotic arm holding a yellow object, which is likely snack_food_1. Below the arm, there is a table with a brown object on it. To the right of the table, there is a cabinet. The robotic arm is holding the snack_food_1 above the table, and the cabinet is to the right of the table. Therefore, the snack_food_1 is not next to the cabinet.\n</explanation>\n<answer>\nNo\n</answer>", true], "inside snack_food_1,cabinet_1": ["no", 7.433388973798749e-12, 1.3887399910594844e-11, "The image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The robotic arm is positioned in front of a cabinet, labeled as cabinet_1. The snack_food_1 is being held by the robotic arm and is not inside the cabinet. Therefore, the answer is \"No\".", true, "Question: Is the snack_food_1 inside the cabinet_1\n<explanation>\nThe image shows a robotic arm holding a yellow object, which is labeled as snack_food_1. The robotic arm is positioned in front of a cabinet, labeled as cabinet_1. The snack_food_1 is being held by the robotic arm and is not inside the cabinet. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"ontop snack_food_1,carton_1": {"before": false, "after": false}, "ontop snack_food_1,snack_food_1": {"before": null, "after": false}, "nextto snack_food_1,carton_1": {"before": false, "after": false}, "nextto snack_food_1,snack_food_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable carton_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable carton_1": ["yes", 3.098748905042137e-12, 9.544818928286514e-12, "The image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable snack_food_1": ["yes", 1.8794414809175652e-12, 5.108852143415055e-12, "The image shows a first-person view from the agent's perspective. I can see a snack_food_1 object on the counter in the foreground. Since the agent is looking directly at the snack_food_1, it is likely within the agent's reach.", false, "Question: Is the snack_food_1 in reach of the agent\n<explanation>\nThe image shows a first-person view from the agent's perspective. I can see a snack_food_1 object on the counter in the foreground. Since the agent is looking directly at the snack_food_1, it is likely within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-inside(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["yes", 2.2896500667668462e-11, 7.991663580897423e-11, "The image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.", true, "Question: Is the agent holding the snack_food_1\n<explanation>\nThe image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 3.098748905042137e-12, 9.544818928286514e-12, "The image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 3.5113585216545173e-12, 1.0815745868364424e-11, "The image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.", false, "Question: Is the carton_1 open\n<explanation>\nThe image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-inside(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["yes", 2.2896500667668462e-11, 7.991663580897423e-11, "The image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.", true, "Question: Is the agent holding the snack_food_1\n<explanation>\nThe image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 3.098748905042137e-12, 9.544818928286514e-12, "The image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 3.5113585216545173e-12, 1.0815745868364424e-11, "The image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.", false, "Question: Is the carton_1 open\n<explanation>\nThe image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-inside(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["yes", 2.2896500667668462e-11, 7.991663580897423e-11, "The image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.", true, "Question: Is the agent holding the snack_food_1\n<explanation>\nThe image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 3.098748905042137e-12, 9.544818928286514e-12, "The image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 3.5113585216545173e-12, 1.0815745868364424e-11, "The image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.", false, "Question: Is the carton_1 open\n<explanation>\nThe image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-inside(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["yes", 2.2896500667668462e-11, 7.991663580897423e-11, "The image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.", true, "Question: Is the agent holding the snack_food_1\n<explanation>\nThe image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 3.098748905042137e-12, 9.544818928286514e-12, "The image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 3.5113585216545173e-12, 1.0815745868364424e-11, "The image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.", false, "Question: Is the carton_1 open\n<explanation>\nThe image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-inside(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["yes", 2.2896500667668462e-11, 7.991663580897423e-11, "The image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.", true, "Question: Is the agent holding the snack_food_1\n<explanation>\nThe image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 3.098748905042137e-12, 9.544818928286514e-12, "The image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 3.5113585216545173e-12, 1.0815745868364424e-11, "The image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.", false, "Question: Is the carton_1 open\n<explanation>\nThe image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-inside(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["yes", 2.2896500667668462e-11, 7.991663580897423e-11, "The image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.", true, "Question: Is the agent holding the snack_food_1\n<explanation>\nThe image shows a first-person view from the robotic arm (the agent). There is a snack_food_1 object visible on the counter in front of the agent. The agent's arm is positioned near the snack_food_1, but it is not clear if the agent is holding the snack_food_1. However, given the perspective, it is likely that the agent is holding the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 3.098748905042137e-12, 9.544818928286514e-12, "The image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.", true, "Question: Is the carton_1 in reach of the agent\n<explanation>\nThe image shows a first-person view from the agent's perspective. The carton_1 is visible in the lower-left corner of the image. Given the agent's perspective and the position of the carton_1, it appears to be within the agent's immediate reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 3.5113585216545173e-12, 1.0815745868364424e-11, "The image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.", false, "Question: Is the carton_1 open\n<explanation>\nThe image shows a kitchen scene. There is a carton visible on the counter. I need to determine if the carton is open. Visually inspecting the carton, it appears to be closed.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}], "replans": [{"enum_results": {"reachable snack_food_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "open cabinet_1": ["no", "yes"], "holding snack_food_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["no", "no"], "inside snack_food_1,cabinet_1": ["no", "yes"], "nextto snack_food_1,cabinet_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.42857142857142855, "yes_accuracy": 0.2, "yes_correct": 1, "yes_total": 5, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 2, "actions": ["grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable snack_food_1": ["yes", "yes"], "open carton_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "holding snack_food_1": ["yes", "yes"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 4, "actions": ["place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable snack_food_1": ["yes", "yes"], "open carton_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "holding snack_food_1": ["yes", "yes"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 5, "actions": ["place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable snack_food_1": ["yes", "yes"], "open carton_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "holding snack_food_1": ["yes", "yes"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 6, "actions": ["place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable snack_food_1": ["yes", "yes"], "open carton_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "holding snack_food_1": ["yes", "yes"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 7, "actions": ["place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable snack_food_1": ["yes", "yes"], "open carton_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "holding snack_food_1": ["yes", "yes"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 8, "actions": ["place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable snack_food_1": ["yes", "yes"], "open carton_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "holding snack_food_1": ["yes", "yes"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 9, "actions": ["place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable snack_food_1": ["yes", "yes"], "open carton_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "holding snack_food_1": ["yes", "yes"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 10, "actions": ["place-inside(snack_food_1, carton_1)"]}], "remaining_actions": ["place-inside(snack_food_1, carton_1)"]}, "problem_stats": {"data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Benevolence_1_int_0": {"action_correct": 1, "action_total": 6, "remaining_actions": ["place-on(bowl_1, sink_1)"], "action_accuracy": 0.16666666666666666, "failed": false}, "data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Benevolence_1_int_20": {"action_correct": 2, "action_total": 8, "remaining_actions": [], "action_accuracy": 0.25, "failed": false}, "data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Benevolence_1_int_21": {"action_correct": 1, "action_total": 6, "remaining_actions": ["navigate-to(sink_1)", "place-on(bowl_1, sink_1)"], "action_accuracy": 0.16666666666666666, "failed": false}, "data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Rs_int_0": {"action_correct": 3, "action_total": 7, "remaining_actions": ["navigate-to(sink_1)", "place-on(bowl_1, sink_1)"], "action_accuracy": 0.42857142857142855, "failed": false}, "data/planning/igibson/simple/cleaning_out_drawers_simple.pddl_Rs_int_20": {"action_correct": 2, "action_total": 5, "remaining_actions": [], "action_accuracy": 0.4, "failed": false}, "data/planning/igibson/simple/sorting_books_simple.pddl_Ihlen_0_int_0": {"action_correct": 0, "action_total": 1, "remaining_actions": [], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/simple/sorting_books_simple.pddl_Ihlen_0_int_20": {"action_correct": 0, "action_total": 3, "remaining_actions": [], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/simple/sorting_books_simple.pddl_Pomaria_1_int_0": {"action_correct": 1, "action_total": 3, "remaining_actions": [], "action_accuracy": 0.3333333333333333, "failed": false}, "data/planning/igibson/simple/sorting_books_simple.pddl_Pomaria_1_int_20": {"action_correct": 2, "action_total": 2, "remaining_actions": [], "action_accuracy": 1.0, "failed": false}, "data/planning/igibson/simple/sorting_books_simple.pddl_Rs_int_0": {"action_correct": 2, "action_total": 4, "remaining_actions": [], "action_accuracy": 0.5, "failed": false}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Merom_1_int_0": {"action_correct": 4, "action_total": 5, "remaining_actions": [], "action_accuracy": 0.8, "failed": false}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Merom_1_int_20": {"action_correct": 6, "action_total": 7, "remaining_actions": [], "action_accuracy": 0.8571428571428571, "failed": false}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Pomaria_0_int_0": {"action_correct": 1, "action_total": 3, "remaining_actions": ["close-container(door_2)"], "action_accuracy": 0.3333333333333333, "failed": false}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Pomaria_0_int_20": {"action_correct": 1, "action_total": 3, "remaining_actions": ["close-container(door_2)"], "action_accuracy": 0.3333333333333333, "failed": false}, "data/planning/igibson/simple/locking_every_door_simple.pddl_Wainscott_1_int_0": {"action_correct": 1, "action_total": 3, "remaining_actions": ["navigate-to(door_2)", "close-container(door_2)"], "action_accuracy": 0.3333333333333333, "failed": false}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Merom_1_int_0": {"action_correct": 0, "action_total": 8, "remaining_actions": ["navigate-to(window_2)", "close-container(window_2)", "navigate-to(window_3)", "close-container(window_3)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Merom_1_int_20": {"action_correct": 4, "action_total": 13, "remaining_actions": ["close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"], "action_accuracy": 0.3076923076923077, "failed": false}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Rs_int_0": {"action_correct": 2, "action_total": 14, "remaining_actions": ["navigate-to(window_1)", "close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"], "action_accuracy": 0.14285714285714285, "failed": false}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Rs_int_20": {"action_correct": 4, "action_total": 13, "remaining_actions": ["close-container(window_1)", "navigate-to(window_3)", "close-container(window_3)"], "action_accuracy": 0.3076923076923077, "failed": false}, "data/planning/igibson/simple/locking_every_window_simple.pddl_Wainscott_0_int_0": {"action_correct": 6, "action_total": 11, "remaining_actions": ["close-container(window_3)"], "action_accuracy": 0.5454545454545454, "failed": false}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Beechwood_0_int_0": {"action_correct": 0, "action_total": 13, "remaining_actions": ["navigate-to(carton_1)", "place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Beechwood_0_int_20": {"action_correct": 1, "action_total": 7, "remaining_actions": [], "action_accuracy": 0.14285714285714285, "failed": false}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Beechwood_0_int_21": {"action_correct": 0, "action_total": 15, "remaining_actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Wainscott_0_int_0": {"action_correct": 4, "action_total": 8, "remaining_actions": ["open-container(carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"], "action_accuracy": 0.5, "failed": false}, "data/planning/igibson/simple/packing_food_for_work_simple.pddl_Wainscott_0_int_20": {"action_correct": 3, "action_total": 11, "remaining_actions": ["place-inside(snack_food_1, carton_1)"], "action_accuracy": 0.2727272727272727, "failed": false}}, "predicate_stats": {"reachable": {"accuracy": 0.7066666666666667, "yes_accuracy": 0.7412935323383084, "yes_correct": 149, "yes_total": 201, "no_accuracy": 0.4166666666666667, "no_correct": 10, "no_total": 24, "correct": 159, "total": 225}, "open": {"accuracy": 0.5769230769230769, "yes_accuracy": 0.3877551020408163, "yes_correct": 19, "yes_total": 49, "no_accuracy": 0.7454545454545455, "no_correct": 41, "no_total": 55, "correct": 60, "total": 104}, "holding": {"accuracy": 0.6422018348623854, "yes_accuracy": 0.8, "yes_correct": 12, "yes_total": 15, "no_accuracy": 0.6170212765957447, "no_correct": 58, "no_total": 94, "correct": 70, "total": 109}, "ontop": {"accuracy": 0.8326996197718631, "yes_accuracy": 0.7575757575757576, "yes_correct": 25, "yes_total": 33, "no_accuracy": 0.8434782608695652, "no_correct": 194, "no_total": 230, "correct": 219, "total": 263}, "inside": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 16, "no_accuracy": 1.0, "no_correct": 80, "no_total": 80, "correct": 80, "total": 96}, "nextto": {"accuracy": 0.3650190114068441, "yes_accuracy": 0.5555555555555556, "yes_correct": 15, "yes_total": 27, "no_accuracy": 0.3432203389830508, "no_correct": 81, "no_total": 236, "correct": 96, "total": 263}}, "predicate_accuracy": 0.6452830188679245, "macro_predicate_accuracy": 0.6594739238273616, "action_accuracy": 0.2849162011173184, "task_accuracy": 0.12, "fail_ratio": 0.0, "metadata": {"model_name": "google/gemma-3-12b-it", "prompt_path": "data/prompts/benchmark/igibson/prompt_cot.md", "problems_dir": "data/planning/igibson/simple", "seed": 1, "replan": true, "fail_probability": 0.0, "enumerate_initial_state": false, "job_id": "7181222_6"}}