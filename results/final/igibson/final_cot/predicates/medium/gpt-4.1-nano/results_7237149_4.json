{"data/planning/igibson/medium/sorting_books_medium.pddl_Pomaria_1_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable book_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable book_1": ["no", 0.9999999999999711, 2.888069156746728e-14, "The image shows a robotic arm (agent) in an environment with objects. The book_1 is on the floor, and the robotic arm is positioned near the wall and furniture, but it is not clear if the arm is close enough to reach the book. Since the arm is extended towards the wall and the book is on the floor at some distance, it is unlikely that the book is within immediate reach of the robotic arm.", false, "<explanation>\nThe image shows a robotic arm (agent) in an environment with objects. The book_1 is on the floor, and the robotic arm is positioned near the wall and furniture, but it is not clear if the arm is close enough to reach the book. Since the arm is extended towards the wall and the book is on the floor at some distance, it is unlikely that the book is within immediate reach of the robotic arm.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable hardback_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}, "reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 1.5547648377459882e-09, 0.9999999984452351, "The image shows a robotic arm in a virtual household environment. There is a book on the floor, labeled as \"book_1.\" The arm appears to be extended towards the book, indicating that it is within reach. Since the arm is close to the book and seems to be able to grasp it, the book is likely in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. There is a book on the floor, labeled as \"book_1.\" The arm appears to be extended towards the book, indicating that it is within reach. Since the arm is close to the book and seems to be able to grasp it, the book is likely in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"holding book_1": ["no", 0.9999988074746416, 1.1925253583126916e-06, "The image shows a robotic arm holding a book, but the book is not labeled as \"book_1.\" Since the question specifically asks if the agent is holding \"book_1,\" and there is no indication that the book being held is named \"book_1,\" I cannot confirm that the agent is holding that specific book.", false, "<explanation>\nThe image shows a robotic arm holding a book, but the book is not labeled as \"book_1.\" Since the question specifically asks if the agent is holding \"book_1,\" and there is no indication that the book being held is named \"book_1,\" I cannot confirm that the agent is holding that specific book.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop book_1,hardback_1": {"before": false, "after": false}, "ontop book_1,table_1": {"before": false, "after": false}, "ontop book_1,shelf_1": {"before": false, "after": false}, "ontop book_1,book_1": {"before": null, "after": false}, "nextto book_1,hardback_1": {"before": false, "after": false}, "nextto book_1,table_1": {"before": false, "after": false}, "nextto book_1,shelf_1": {"before": false, "after": false}, "nextto book_1,book_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(hardback_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable hardback_1": ["no", 0.9999999999999983, 1.6341566732185268e-15, "The image shows a virtual household with a robotic arm (agent) and several objects, including a book labeled \"book_1\" on a table. The \"hardback_1\" is also visible on the same table, positioned behind \"book_1.\" The robotic arm appears to be extended towards the \"book_1,\" which is closer to the agent, but \"hardback_1\" is further back on the table and not directly in front of the robotic arm. Based on the perspective, \"hardback_1\" does not seem to be within immediate reach of the agent.", false, "<explanation>\nThe image shows a virtual household with a robotic arm (agent) and several objects, including a book labeled \"book_1\" on a table. The \"hardback_1\" is also visible on the same table, positioned behind \"book_1.\" The robotic arm appears to be extended towards the \"book_1,\" which is closer to the agent, but \"hardback_1\" is further back on the table and not directly in front of the robotic arm. Based on the perspective, \"hardback_1\" does not seem to be within immediate reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable table_1": ["yes", 2.2297139998152266e-22, 1.0, "The image shows a virtual household with a robotic arm (agent) and several objects, including a table labeled \"table_1.\" The table is positioned in the room with other furniture, and the robotic arm is extended towards the objects above. Since the robotic arm is capable of reaching objects within the room, and the table \"table_1\" is located in the same room and appears to be within a reasonable distance from the robotic arm, it is likely within reach. However, the exact distance and the arm's reach are not explicitly shown, but based on typical virtual household setups, the table is accessible to the agent.", false, "<explanation>\nThe image shows a virtual household with a robotic arm (agent) and several objects, including a table labeled \"table_1.\" The table is positioned in the room with other furniture, and the robotic arm is extended towards the objects above. Since the robotic arm is capable of reaching objects within the room, and the table \"table_1\" is located in the same room and appears to be within a reasonable distance from the robotic arm, it is likely within reach. However, the exact distance and the arm's reach are not explicitly shown, but based on typical virtual household setups, the table is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable book_1": ["yes", 2.0960781362235348e-13, 0.9999999999997904, "The image shows a virtual household with a robotic arm as the agent. There are two books labeled \"book_1\" and \"book_2\" on a small table. \"book_1\" is positioned on the table, and the robotic arm is extended towards the books. The arm appears to be close to \"book_1,\" suggesting it is within reach. Since the arm is designed to interact with objects and is shown near \"book_1,\" it is reasonable to conclude that \"book_1\" is within reach of the agent.", false, "<explanation>\nThe image shows a virtual household with a robotic arm as the agent. There are two books labeled \"book_1\" and \"book_2\" on a small table. \"book_1\" is positioned on the table, and the robotic arm is extended towards the books. The arm appears to be close to \"book_1,\" suggesting it is within reach. Since the arm is designed to interact with objects and is shown near \"book_1,\" it is reasonable to conclude that \"book_1\" is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 2.492858178986758e-13, 0.9999999999997508, "The image shows a virtual household with objects including two books labeled \"book_1\" and \"book_2\". The robotic arm (agent) is visible, and the book_1 is placed on a small table. The book_1 appears to be relatively close to the robotic arm, which is positioned above the scene. Given the typical reach of a robotic arm in such a simulation, and the proximity of the book to the arm's position, it is likely that the book_1 is within reach of the agent.", true, "<explanation>\nThe image shows a virtual household with objects including two books labeled \"book_1\" and \"book_2\". The robotic arm (agent) is visible, and the book_1 is placed on a small table. The book_1 appears to be relatively close to the robotic arm, which is positioned above the scene. Given the typical reach of a robotic arm in such a simulation, and the proximity of the book to the arm's position, it is likely that the book_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding hardback_1": ["no", 0.9999999999998516, 1.4844790253889297e-13, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a book, but it is not labeled as \"hardback_1\" or any specific book in the image. The only labeled books are \"book\" and \"book_2\" on the table, and neither of these is being held by the robotic arm. Therefore, based on the visual information, the agent is not holding the \"hardback_1.\"", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a book, but it is not labeled as \"hardback_1\" or any specific book in the image. The only labeled books are \"book\" and \"book_2\" on the table, and neither of these is being held by the robotic arm. Therefore, based on the visual information, the agent is not holding the \"hardback_1.\"\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 3.080655374509401e-13, 0.9999999999996919, "The image shows a virtual household with objects including two books labeled \"book_1\" and \"book_2.\" The robotic arm (agent) is positioned above the books, and the book_1 is on a table closer to the arm's current position. Given the perspective, the book_1 appears to be within a reachable distance for the robotic arm, which is capable of interacting with objects in the environment. Therefore, the book_1 is in reach of the agent.", true, "<explanation>\nThe image shows a virtual household with objects including two books labeled \"book_1\" and \"book_2.\" The robotic arm (agent) is positioned above the books, and the book_1 is on a table closer to the arm's current position. Given the perspective, the book_1 appears to be within a reachable distance for the robotic arm, which is capable of interacting with objects in the environment. Therefore, the book_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding hardback_1": ["no", 0.9999999999999999, 7.38277097427216e-17, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a book, but it is not clear if it is specifically the \"hardback_1\" because the object being held is not labeled or clearly distinguishable as that specific book. The \"book_1\" and \"book_2\" are on the table, but the arm is not holding either of these. Therefore, based on the visual information, the agent is not holding \"hardback_1\".", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a book, but it is not clear if it is specifically the \"hardback_1\" because the object being held is not labeled or clearly distinguishable as that specific book. The \"book_1\" and \"book_2\" are on the table, but the arm is not holding either of these. Therefore, based on the visual information, the agent is not holding \"hardback_1\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable book_1": ["yes", "yes"], "holding book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 1, "actions": ["grasp(book_1)", "navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable book_1": ["yes", "yes"], "holding book_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 2, "actions": ["navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["no", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["yes", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["yes", "no"], "ontop book_2,hardback_1": ["yes", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "yes"], "nextto book_1,hardback_1": ["yes", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["yes", "yes"], "nextto book_2,table_1": ["yes", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.64, "yes_accuracy": 0.5555555555555556, "yes_correct": 5, "yes_total": 9, "no_accuracy": 0.6875, "no_correct": 11, "no_total": 16, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.4444444444444444, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.5714285714285714, "no_correct": 4, "no_total": 7}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}}}, "step": 3, "actions": ["grasp(book_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["no", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["yes", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["yes", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8, "yes_accuracy": 0.5555555555555556, "yes_correct": 5, "yes_total": 9, "no_accuracy": 0.9375, "no_correct": 15, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}, "nextto": {"accuracy": 0.8888888888888888, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}}}, "step": 4, "actions": ["grasp(book_1)", "navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}], "remaining_actions": ["navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, "data/planning/igibson/medium/sorting_books_medium.pddl_Pomaria_1_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(book_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable book_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable book_1": ["yes", 1.7852011409357433e-19, 1.0, "The image shows a robotic arm in a virtual household environment. The book_1 is located on the floor, and the robotic arm is extended towards the wall, near the ceiling, with its gripper open. The book_1 appears to be on the ground, relatively close to the robotic arm, but it is not directly in front of or underneath the arm. Given the position of the arm and the book, it seems that the book_1 is within a reachable distance for the robotic arm, assuming it can extend or move slightly. Therefore, the book_1 is likely in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The book_1 is located on the floor, and the robotic arm is extended towards the wall, near the ceiling, with its gripper open. The book_1 appears to be on the ground, relatively close to the robotic arm, but it is not directly in front of or underneath the arm. Given the position of the arm and the book, it seems that the book_1 is within a reachable distance for the robotic arm, assuming it can extend or move slightly. Therefore, the book_1 is likely in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable hardback_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}, "reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(book_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable book_1": ["yes", 2.162706224400445e-14, 0.9999999999999784, "The image shows a robotic arm in a virtual household environment. The book_1 is located on the floor, and the robotic arm is positioned near the wall, with its gripper extended downward. The book_1 appears to be on the ground, relatively close to the robotic arm, which is capable of reaching objects on the floor. Given the proximity and the arm's position, it is likely that the book_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The book_1 is located on the floor, and the robotic arm is positioned near the wall, with its gripper extended downward. The book_1 appears to be on the ground, relatively close to the robotic arm, which is capable of reaching objects on the floor. Given the proximity and the arm's position, it is likely that the book_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"holding book_1": ["yes", 1.6194610612979301e-12, 0.9999999999983805, "The image shows a robotic arm holding a book, which appears to be a book with a white cover and some images or text on it. Since the question asks if the agent is holding \"book_1,\" and the object in the robotic arm looks like a book, it is reasonable to conclude that the agent is indeed holding a book. The specific label \"book_1\" is not visible, but based on the description, the object being held is a book, which matches the question.", true, "<explanation>\nThe image shows a robotic arm holding a book, which appears to be a book with a white cover and some images or text on it. Since the question asks if the agent is holding \"book_1,\" and the object in the robotic arm looks like a book, it is reasonable to conclude that the agent is indeed holding a book. The specific label \"book_1\" is not visible, but based on the description, the object being held is a book, which matches the question.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"ontop book_1,hardback_1": {"before": false, "after": false}, "ontop book_1,table_1": {"before": false, "after": false}, "ontop book_1,shelf_1": {"before": false, "after": false}, "ontop book_1,book_1": {"before": null, "after": false}, "nextto book_1,hardback_1": {"before": false, "after": false}, "nextto book_1,table_1": {"before": false, "after": false}, "nextto book_1,shelf_1": {"before": false, "after": false}, "nextto book_1,book_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(hardback_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable hardback_1": ["no", 1.0, 3.942839622466351e-21, "The image shows a virtual household with a robotic arm (agent) and various objects, including a book labeled \"book_1\" on a table. The \"hardback_1\" is not explicitly visible in the image, but based on the description, it appears to be a different book or object. Since the question asks if \"hardback_1\" is within reach of the agent, I need to determine if it is close enough for the robotic arm to grasp. The \"book_1\" is on the table, and the \"hardback_1\" is not shown in the image, so I cannot confirm its position. Without visual evidence of \"hardback_1\" being near the agent, I must conclude that it is not in reach.", false, "<explanation>\nThe image shows a virtual household with a robotic arm (agent) and various objects, including a book labeled \"book_1\" on a table. The \"hardback_1\" is not explicitly visible in the image, but based on the description, it appears to be a different book or object. Since the question asks if \"hardback_1\" is within reach of the agent, I need to determine if it is close enough for the robotic arm to grasp. The \"book_1\" is on the table, and the \"hardback_1\" is not shown in the image, so I cannot confirm its position. Without visual evidence of \"hardback_1\" being near the agent, I must conclude that it is not in reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable table_1": ["yes", 5.825088263909829e-17, 0.9999999999999999, "The image shows a virtual household with a robotic arm (agent) and several objects, including a table labeled \"table_1.\" The table is positioned in the room with other furniture, and the robotic arm is extending towards the objects above. Based on the perspective, the table appears to be within a reasonable distance for the robotic arm to reach, considering typical interaction ranges in such virtual environments. There are no visible obstructions blocking access to the table, and it is located relatively close to the area where the robotic arm is operating.", false, "<explanation>\nThe image shows a virtual household with a robotic arm (agent) and several objects, including a table labeled \"table_1.\" The table is positioned in the room with other furniture, and the robotic arm is extending towards the objects above. Based on the perspective, the table appears to be within a reasonable distance for the robotic arm to reach, considering typical interaction ranges in such virtual environments. There are no visible obstructions blocking access to the table, and it is located relatively close to the area where the robotic arm is operating.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable book_1": ["yes", 4.940855279634035e-10, 0.9999999995059144, "The image shows a virtual household with a robotic arm (agent) and several objects, including a book labeled \"book_1\" on a small table. The book \"book_1\" appears to be positioned on the table, which is relatively close to the robotic arm. Given the typical reach of a robotic arm in such a simulation, and the proximity of the book to the arm's position, it is reasonable to conclude that the book \"book_1\" is within reach of the agent.", false, "<explanation>\nThe image shows a virtual household with a robotic arm (agent) and several objects, including a book labeled \"book_1\" on a small table. The book \"book_1\" appears to be positioned on the table, which is relatively close to the robotic arm. Given the typical reach of a robotic arm in such a simulation, and the proximity of the book to the arm's position, it is reasonable to conclude that the book \"book_1\" is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 1.47547601460619e-11, 0.9999999999852452, "The image shows a virtual environment with a robotic arm (agent) and two books labeled \"book_1\" and \"book_2.\" The book labeled \"book_1\" is placed on a small table, and the robotic arm is positioned above the table, holding a large object. The book \"book_1\" appears to be within the reach of the robotic arm, as it is on the same table and close to the arm's position.", true, "<explanation>\nThe image shows a virtual environment with a robotic arm (agent) and two books labeled \"book_1\" and \"book_2.\" The book labeled \"book_1\" is placed on a small table, and the robotic arm is positioned above the table, holding a large object. The book \"book_1\" appears to be within the reach of the robotic arm, as it is on the same table and close to the arm's position.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding hardback_1": ["no", 0.9999999967419109, 3.258089152994624e-09, "The image shows a robotic arm (agent) in a virtual household environment. The arm is positioned above a table with a book labeled \"book_2\" and is not holding any object. The book labeled \"hardback_1\" is on the table, not in the robotic arm's grasp. Therefore, the agent is not holding \"hardback_1\".", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm is positioned above a table with a book labeled \"book_2\" and is not holding any object. The book labeled \"hardback_1\" is on the table, not in the robotic arm's grasp. Therefore, the agent is not holding \"hardback_1\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 2.136332220872178e-12, 0.9999999999978637, "The image shows a virtual household with a robotic arm (agent) and several objects, including two books labeled \"book_1\" and \"book_2.\" The book labeled \"book_1\" is placed on a small table, and the robotic arm is positioned above the table, holding a large object. The book_1 appears to be within the reach of the robotic arm, as it is on the same table and close to the arm's position.", true, "<explanation>\nThe image shows a virtual household with a robotic arm (agent) and several objects, including two books labeled \"book_1\" and \"book_2.\" The book labeled \"book_1\" is placed on a small table, and the robotic arm is positioned above the table, holding a large object. The book_1 appears to be within the reach of the robotic arm, as it is on the same table and close to the arm's position.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding hardback_1": ["no", 0.9999999967153772, 3.2846227610767134e-09, "The image shows a robotic arm (agent) in a virtual household environment. The arm is positioned above a table with a book labeled \"book_2\" and is not holding any object. The book labeled \"book_1\" is on the table, not in the robotic arm's grasp. Therefore, the agent is not holding \"hardback_1\" or any other object.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm is positioned above a table with a book labeled \"book_2\" and is not holding any object. The book labeled \"book_1\" is on the table, not in the robotic arm's grasp. Therefore, the agent is not holding \"hardback_1\" or any other object.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["no", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["yes", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["yes", "yes"], "nextto book_2,table_1": ["yes", "no"], "nextto book_2,book_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.72, "yes_accuracy": 0.5555555555555556, "yes_correct": 5, "yes_total": 9, "no_accuracy": 0.8125, "no_correct": 13, "no_total": 16, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}}}, "step": 3, "actions": ["grasp(book_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["no", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["no", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["yes", "no"], "ontop book_1,book_2": ["yes", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["yes", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.68, "yes_accuracy": 0.4444444444444444, "yes_correct": 4, "yes_total": 9, "no_accuracy": 0.8125, "no_correct": 13, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}}}, "step": 4, "actions": ["grasp(book_1)", "navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}], "remaining_actions": ["navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, "data/planning/igibson/medium/sorting_books_medium.pddl_Pomaria_1_int_21": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(book_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable book_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable book_1": ["yes", 4.9770744903950326e-08, 0.9999999502292551, "The image shows a robotic arm in a virtual household environment. There is a book labeled \"book_1\" on the floor. The arm appears to be extended towards the book, and the book is close to the arm's position. Given the proximity of the book to the robotic arm, it is likely within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. There is a book labeled \"book_1\" on the floor. The arm appears to be extended towards the book, and the book is close to the arm's position. Given the proximity of the book to the robotic arm, it is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable hardback_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}, "reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 6.347459530966041e-08, 0.9999999365254046, "The image shows a robotic arm in a virtual household environment. There is a book labeled \"book_1\" on the floor. The arm appears to be extended towards the book, and the book is close to the arm's position. Given the proximity of the book to the robotic arm, it is likely within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. There is a book labeled \"book_1\" on the floor. The arm appears to be extended towards the book, and the book is close to the arm's position. Given the proximity of the book to the robotic arm, it is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"holding book_1": ["no", 0.9999983960024754, 1.6039975246103789e-06, "The image shows a robotic arm holding a book, but the book is not labeled as \"book_1.\" Since the question specifically asks if the agent is holding \"book_1,\" and there is no indication that the book being held is \"book_1,\" I cannot confirm that the agent is holding that specific book.", false, "<explanation>\nThe image shows a robotic arm holding a book, but the book is not labeled as \"book_1.\" Since the question specifically asks if the agent is holding \"book_1,\" and there is no indication that the book being held is \"book_1,\" I cannot confirm that the agent is holding that specific book.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop book_1,hardback_1": {"before": false, "after": false}, "ontop book_1,table_1": {"before": false, "after": false}, "ontop book_1,shelf_1": {"before": false, "after": false}, "ontop book_1,book_1": {"before": null, "after": false}, "nextto book_1,hardback_1": {"before": false, "after": false}, "nextto book_1,table_1": {"before": false, "after": false}, "nextto book_1,shelf_1": {"before": false, "after": false}, "nextto book_1,book_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 7.11677132165103e-10, 0.9999999992883228, "The image shows a robotic arm holding a book, which appears to be close to the agent. Since the arm is extended and holding the book, it suggests that the book is within the reach of the agent. There are no visible obstacles blocking the arm's extension, and the book is being held by the robotic arm, indicating it is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm holding a book, which appears to be close to the agent. Since the arm is extended and holding the book, it suggests that the book is within the reach of the agent. There are no visible obstacles blocking the arm's extension, and the book is being held by the robotic arm, indicating it is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding hardback_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable book_1": ["yes", "yes"], "holding book_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 2, "actions": ["grasp(book_1)", "navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}], "remaining_actions": ["navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, "data/planning/igibson/medium/sorting_books_medium.pddl_Pomaria_1_int_23": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(book_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable book_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable book_1": ["yes", 1.0025165560045653e-07, 0.9999998997483444, "The image shows a robotic arm (agent) in a virtual household environment. The book_1 is visible on the floor, relatively close to the robotic arm. Given the perspective, the book appears to be within a reachable distance for the robotic arm to pick up or interact with it.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The book_1 is visible on the floor, relatively close to the robotic arm. Given the perspective, the book appears to be within a reachable distance for the robotic arm to pick up or interact with it.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable hardback_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}, "reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(book_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable book_1": ["yes", 6.863243846248531e-08, 0.9999999313675615, "The image shows a robotic arm (agent) in a virtual household environment. The book_1 is visible on the floor, relatively close to the robotic arm. Given the perspective, the book appears to be within a reachable distance for the robotic arm to pick up or interact with it.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The book_1 is visible on the floor, relatively close to the robotic arm. Given the perspective, the book appears to be within a reachable distance for the robotic arm to pick up or interact with it.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"holding book_1": ["yes", 6.715530855277162e-09, 0.9999999932844691, "In the image, the robotic arm appears to be holding a book or a similar object. The object is white with some visible text or images on it, and it is being held in a way consistent with grasping. Therefore, the agent is indeed holding the book.", true, "<explanation>\nIn the image, the robotic arm appears to be holding a book or a similar object. The object is white with some visible text or images on it, and it is being held in a way consistent with grasping. Therefore, the agent is indeed holding the book.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"ontop book_1,hardback_1": {"before": false, "after": false}, "ontop book_1,table_1": {"before": false, "after": false}, "ontop book_1,shelf_1": {"before": false, "after": false}, "ontop book_1,book_1": {"before": null, "after": false}, "nextto book_1,hardback_1": {"before": false, "after": false}, "nextto book_1,table_1": {"before": false, "after": false}, "nextto book_1,shelf_1": {"before": false, "after": false}, "nextto book_1,book_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(hardback_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable hardback_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable hardback_1": ["no", 1.0, 1.2698842607458178e-23, "The image shows a room with several objects, including a table with a book labeled \"book_1\" and another book labeled \"book_2.\" The robotic arm (agent) is positioned near the top of the image, holding a large sheet of paper or a similar object. The \"book_1\" is on the table, and the \"book_2\" is standing upright on the table. The arm appears to be reaching towards the large sheet, but there is no clear indication that it is reaching for \"book_1.\" Given the position of the arm and the objects, \"book_1\" is on the table and within the room, but it is not explicitly shown to be within the arm's reach at this moment.", false, "<explanation>\nThe image shows a room with several objects, including a table with a book labeled \"book_1\" and another book labeled \"book_2.\" The robotic arm (agent) is positioned near the top of the image, holding a large sheet of paper or a similar object. The \"book_1\" is on the table, and the \"book_2\" is standing upright on the table. The arm appears to be reaching towards the large sheet, but there is no clear indication that it is reaching for \"book_1.\" Given the position of the arm and the objects, \"book_1\" is on the table and within the room, but it is not explicitly shown to be within the arm's reach at this moment.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable table_1": ["yes", 2.8510268544671244e-09, 0.9999999971489731, "The image shows a room with a table labeled \"table_1\" near the center. The robotic arm (agent) is positioned above the table, holding a book. Since the arm is directly over the table and appears to be interacting with objects on it, it suggests that the table is within the reach of the agent. Therefore, the table_1 is in reach of the agent.", false, "<explanation>\nThe image shows a room with a table labeled \"table_1\" near the center. The robotic arm (agent) is positioned above the table, holding a book. Since the arm is directly over the table and appears to be interacting with objects on it, it suggests that the table is within the reach of the agent. Therefore, the table_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable book_1": ["yes", 6.406136717502769e-17, 0.9999999999999999, "The image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table, and the robotic arm (agent) is holding a book above the table. The \"book_1\" appears to be on the same table as \"book_2,\" which is closer to the robotic arm. Since the robotic arm is holding a book and is positioned above the table, it is likely within reach of \"book_1\" on the table, especially considering typical interaction ranges in such environments. Therefore, \"book_1\" is within reach of the agent.", false, "<explanation>\nThe image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table, and the robotic arm (agent) is holding a book above the table. The \"book_1\" appears to be on the same table as \"book_2,\" which is closer to the robotic arm. Since the robotic arm is holding a book and is positioned above the table, it is likely within reach of \"book_1\" on the table, especially considering typical interaction ranges in such environments. Therefore, \"book_1\" is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable shelf_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 3.2598276031834845e-15, 0.9999999999999968, "The image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table near the center of the room, and the robotic arm (agent) is holding a white object above the table. The \"book_1\" appears to be positioned on the same table as the agent's current focus. Given the typical reach of a robotic arm in such a simulation, and the proximity of \"book_1\" to the agent's current position, it is likely within reach.", true, "<explanation>\nThe image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table near the center of the room, and the robotic arm (agent) is holding a white object above the table. The \"book_1\" appears to be positioned on the same table as the agent's current focus. Given the typical reach of a robotic arm in such a simulation, and the proximity of \"book_1\" to the agent's current position, it is likely within reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding hardback_1": ["no", 0.9999999830606974, 1.6939302586397694e-08, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a rolled-up poster or paper, not a book. The hardback_1 is on the table, and there is no indication that the robotic arm is holding it. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a rolled-up poster or paper, not a book. The hardback_1 is on the table, and there is no indication that the robotic arm is holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "grasp(hardback_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable hardback_1": ["yes", 9.063678480856e-12, 0.9999999999909364, "The image shows a virtual household with a robotic arm (agent) and various objects, including a book labeled \"book_1\" on a table. The book \"book_1\" appears to be positioned on a table that is relatively close to the robotic arm. Given the perspective, the book seems to be within a reachable distance for the robotic arm, which is capable of interacting with objects in the environment. Therefore, it is reasonable to conclude that \"book_1\" is within reach of the agent.", true, "<explanation>\nThe image shows a virtual household with a robotic arm (agent) and various objects, including a book labeled \"book_1\" on a table. The book \"book_1\" appears to be positioned on a table that is relatively close to the robotic arm. Given the perspective, the book seems to be within a reachable distance for the robotic arm, which is capable of interacting with objects in the environment. Therefore, it is reasonable to conclude that \"book_1\" is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding book_1": ["no", 0.9999999997668195, 2.3318042690846935e-10, "The image shows a robotic arm in a virtual household environment. The arm appears to be holding a white object, but it is not clear if this object is a book. The book_1 is on the table, and the arm is not directly interacting with it. Therefore, the agent is not holding book_1.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The arm appears to be holding a white object, but it is not clear if this object is a book. The book_1 is on the table, and the arm is not directly interacting with it. Therefore, the agent is not holding book_1.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["no", 0.9999999999999981, 1.866863480650176e-15, "The image shows a virtual household with objects and furniture. The book_1 is placed on a table, and the robotic arm (agent) is positioned near the ceiling, holding a large object. The book_1 appears to be on the table, which is at a lower level than the robotic arm's current position. Since the robotic arm is holding an object and is not shown reaching towards the book_1, it is unlikely that the book_1 is within immediate reach of the agent at this moment.", false, "<explanation>\nThe image shows a virtual household with objects and furniture. The book_1 is placed on a table, and the robotic arm (agent) is positioned near the ceiling, holding a large object. The book_1 appears to be on the table, which is at a lower level than the robotic arm's current position. Since the robotic arm is holding an object and is not shown reaching towards the book_1, it is unlikely that the book_1 is within immediate reach of the agent at this moment.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding hardback_1": ["no", 0.9999999663175536, 3.3682446381932556e-08, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a rolled-up poster or paper, not a book. The hardback_1 is on the table, not being held by the robotic arm. Therefore, the agent is not holding hardback_1.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a rolled-up poster or paper, not a book. The hardback_1 is on the table, not being held by the robotic arm. Therefore, the agent is not holding hardback_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(hardback_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable hardback_1": ["yes", 1.5332392400808955e-11, 0.9999999999846676, "The image shows a virtual household with a robotic arm (agent) and various objects, including a book labeled \"book_1\" on a table. The book \"book_1\" appears to be positioned on a table that is relatively close to the robotic arm. Given the perspective, the book seems to be within a reachable distance for the robotic arm, which is capable of interacting with objects in the environment. Therefore, it is reasonable to conclude that \"book_1\" is within reach of the agent.", true, "<explanation>\nThe image shows a virtual household with a robotic arm (agent) and various objects, including a book labeled \"book_1\" on a table. The book \"book_1\" appears to be positioned on a table that is relatively close to the robotic arm. Given the perspective, the book seems to be within a reachable distance for the robotic arm, which is capable of interacting with objects in the environment. Therefore, it is reasonable to conclude that \"book_1\" is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding book_1": ["no", 0.9999999999636883, 3.6311726698388025e-11, "The image shows a robotic arm in a virtual household environment. The arm appears to be holding a white object, but it is not clear if this object is a book. The book_1 is on the table, and the robotic arm is positioned above it, but there is no clear indication that the arm is grasping or holding book_1. Therefore, based on the visual evidence, the agent is not holding book_1.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The arm appears to be holding a white object, but it is not clear if this object is a book. The book_1 is on the table, and the robotic arm is positioned above it, but there is no clear indication that the arm is grasping or holding book_1. Therefore, based on the visual evidence, the agent is not holding book_1.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "navigate-to(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 2.9239248190512854e-15, 0.9999999999999971, "The image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table near the center of the room, and the robotic arm (agent) is holding a book above the table. The \"book_1\" appears to be positioned on the same table, close to the robotic arm's current position. Given the proximity of the \"book_1\" to the robotic arm and the fact that the arm is holding a book above the table, it is reasonable to conclude that \"book_1\" is within reach of the agent.", false, "<explanation>\nThe image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table near the center of the room, and the robotic arm (agent) is holding a book above the table. The \"book_1\" appears to be positioned on the same table, close to the robotic arm's current position. Given the proximity of the \"book_1\" to the robotic arm and the fact that the arm is holding a book above the table, it is reasonable to conclude that \"book_1\" is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["no", 0.9999999999999658, 3.420720741097639e-14, "The image shows a virtual household with objects and furniture. The book_1 is placed on a table, and the robotic arm (agent) is positioned above the table, holding a white object. The book_1 appears to be close to the edge of the table, but it is not clearly within the reach of the robotic arm based on the current perspective. Since the arm is holding an object and is positioned above the table, it might be able to reach the book_1 if extended, but from this image alone, it is not certain that the book_1 is within immediate reach.", false, "<explanation>\nThe image shows a virtual household with objects and furniture. The book_1 is placed on a table, and the robotic arm (agent) is positioned above the table, holding a white object. The book_1 appears to be close to the edge of the table, but it is not clearly within the reach of the robotic arm based on the current perspective. Since the arm is holding an object and is positioned above the table, it might be able to reach the book_1 if extended, but from this image alone, it is not certain that the book_1 is within immediate reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding hardback_1": ["no", 0.9999999563335474, 4.366645252634957e-08, "The image shows a robotic arm (agent) in a virtual household environment. The arm is holding a white object, which appears to be a rolled-up poster or paper, not a book. The hardback_1 is located on the table, and the agent is not holding it. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm is holding a white object, which appears to be a rolled-up poster or paper, not a book. The hardback_1 is located on the table, and the agent is not holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 1.2985519583089735e-15, 0.9999999999999987, "The image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table, and the robotic arm (agent) is holding a white object above the table. The \"book_1\" appears to be positioned on the table, which is relatively close to the robotic arm's position. Given the typical reach of a robotic arm in such a virtual environment, and the proximity of \"book_1\" to the table's edge, it is likely within reach of the agent.", false, "<explanation>\nThe image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table, and the robotic arm (agent) is holding a white object above the table. The \"book_1\" appears to be positioned on the table, which is relatively close to the robotic arm's position. Given the typical reach of a robotic arm in such a virtual environment, and the proximity of \"book_1\" to the table's edge, it is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 8.806968458560656e-12, 0.999999999991193, "The image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The robotic arm (agent) is positioned above the books, and \"book_1\" is on a table near the arm. Since the arm is directly above \"book_1\" and appears to be able to grasp objects within its reach, it is likely that \"book_1\" is within the agent's reach.", true, "<explanation>\nThe image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The robotic arm (agent) is positioned above the books, and \"book_1\" is on a table near the arm. Since the arm is directly above \"book_1\" and appears to be able to grasp objects within its reach, it is likely that \"book_1\" is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding hardback_1": ["no", 0.9999999082417083, 9.175829174958992e-08, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a rolled-up poster or paper, not a book. The hardback_1 is on the table, not being held by the agent. Therefore, the agent is not holding hardback_1.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding a white object, which looks like a rolled-up poster or paper, not a book. The hardback_1 is on the table, not being held by the agent. Therefore, the agent is not holding hardback_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "grasp(book_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable book_1": ["yes", 2.7364098545398557e-16, 0.9999999999999998, "The image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table, and the robotic arm (agent) is holding a white object, possibly a book or a paper, but it is not clear if it is \"book_1.\" The \"book_1\" appears to be on the table, which is relatively close to the robotic arm. Given the typical reach of a robotic arm in such a simulation, and the proximity of \"book_1\" to the table, it is likely within reach of the agent.", true, "<explanation>\nThe image shows a room with several objects, including two books labeled \"book_1\" and \"book_2.\" The \"book_1\" is placed on a table, and the robotic arm (agent) is holding a white object, possibly a book or a paper, but it is not clear if it is \"book_1.\" The \"book_1\" appears to be on the table, which is relatively close to the robotic arm. Given the typical reach of a robotic arm in such a simulation, and the proximity of \"book_1\" to the table, it is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding hardback_1": ["no", 0.9999985411569181, 1.4588430819330028e-06, "In the image, the robotic arm (agent) is holding a white object, which appears to be a rolled-up poster or paper, not a book. The hardback_1 is located on the table, and the agent is not holding it. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the robotic arm (agent) is holding a white object, which appears to be a rolled-up poster or paper, not a book. The hardback_1 is located on the table, and the agent is not holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["yes", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["yes", "yes"], "nextto book_1,hardback_1": ["yes", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["yes", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.76, "yes_accuracy": 0.6666666666666666, "yes_correct": 6, "yes_total": 9, "no_accuracy": 0.8125, "no_correct": 13, "no_total": 16, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}}}, "step": 3, "actions": ["grasp(book_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["no", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["no", "yes"], "ontop hardback_1,book_1": ["yes", "no"], "ontop hardback_1,book_2": ["yes", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["yes", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["yes", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.68, "yes_accuracy": 0.4444444444444444, "yes_correct": 4, "yes_total": 9, "no_accuracy": 0.8125, "no_correct": 13, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.4444444444444444, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.5714285714285714, "no_correct": 4, "no_total": 7}, "nextto": {"accuracy": 0.8888888888888888, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}}}, "step": 4, "actions": ["grasp(hardback_1)", "navigate-to(book_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)", "navigate-to(book_1)", "grasp(book_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["no", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["no", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["yes", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["yes", "no"], "nextto hardback_1,book_2": ["yes", "yes"], "nextto book_1,hardback_1": ["yes", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.68, "yes_accuracy": 0.4444444444444444, "yes_correct": 4, "yes_total": 9, "no_accuracy": 0.8125, "no_correct": 13, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}}}, "step": 5, "actions": ["grasp(book_1)", "navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["no", "yes"], "reachable book_1": ["no", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,book_1": ["yes", "no"], "ontop hardback_1,book_2": ["yes", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["yes", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["yes", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.68, "yes_accuracy": 0.4444444444444444, "yes_correct": 4, "yes_total": 9, "no_accuracy": 0.8125, "no_correct": 13, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.5555555555555556, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.5714285714285714, "no_correct": 4, "no_total": 7}, "nextto": {"accuracy": 0.8888888888888888, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}}}, "step": 6, "actions": ["grasp(hardback_1)", "navigate-to(book_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)", "navigate-to(book_1)", "grasp(book_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["no", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["no", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,book_1": ["yes", "no"], "ontop hardback_1,book_2": ["yes", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["yes", "no"], "nextto hardback_1,book_2": ["no", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.64, "yes_accuracy": 0.3333333333333333, "yes_correct": 3, "yes_total": 9, "no_accuracy": 0.8125, "no_correct": 13, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}}}, "step": 7, "actions": ["navigate-to(book_1)", "grasp(book_1)", "navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["no", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["yes", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.76, "yes_accuracy": 0.4444444444444444, "yes_correct": 4, "yes_total": 9, "no_accuracy": 0.9375, "no_correct": 15, "no_total": 16, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}}}, "step": 8, "actions": ["grasp(book_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["no", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["yes", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["no", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["yes", "no"], "ontop book_1,hardback_1": ["yes", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["yes", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["yes", "yes"], "nextto book_2,table_1": ["yes", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6, "yes_accuracy": 0.4444444444444444, "yes_correct": 4, "yes_total": 9, "no_accuracy": 0.6875, "no_correct": 11, "no_total": 16, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.5555555555555556, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}}}, "step": 9, "actions": ["navigate-to(book_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)", "navigate-to(book_1)", "grasp(book_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,book_1": ["yes", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["yes", "no"], "nextto hardback_1,book_2": ["yes", "yes"], "nextto book_1,hardback_1": ["yes", "no"], "nextto book_1,table_1": ["yes", "no"], "nextto book_1,book_2": ["yes", "no"], "nextto book_2,hardback_1": ["no", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.68, "yes_accuracy": 0.6666666666666666, "yes_correct": 6, "yes_total": 9, "no_accuracy": 0.6875, "no_correct": 11, "no_total": 16, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.8571428571428571, "no_correct": 6, "no_total": 7}, "nextto": {"accuracy": 0.4444444444444444, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.42857142857142855, "no_correct": 3, "no_total": 7}}}, "step": 10, "actions": ["grasp(book_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, {"enum_results": {"reachable hardback_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable book_1": ["yes", "yes"], "reachable book_2": ["yes", "yes"], "holding hardback_1": ["no", "no"], "holding book_1": ["no", "yes"], "holding book_2": ["no", "no"], "ontop hardback_1,table_1": ["yes", "yes"], "ontop hardback_1,book_1": ["no", "no"], "ontop hardback_1,book_2": ["no", "no"], "ontop book_1,hardback_1": ["no", "no"], "ontop book_1,table_1": ["no", "no"], "ontop book_1,book_2": ["no", "no"], "ontop book_2,hardback_1": ["no", "no"], "ontop book_2,table_1": ["no", "yes"], "ontop book_2,book_1": ["no", "no"], "nextto hardback_1,table_1": ["no", "no"], "nextto hardback_1,book_1": ["no", "no"], "nextto hardback_1,book_2": ["no", "yes"], "nextto book_1,hardback_1": ["no", "no"], "nextto book_1,table_1": ["no", "no"], "nextto book_1,book_2": ["no", "no"], "nextto book_2,hardback_1": ["yes", "yes"], "nextto book_2,table_1": ["no", "no"], "nextto book_2,book_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.88, "yes_accuracy": 0.6666666666666666, "yes_correct": 6, "yes_total": 9, "no_accuracy": 1.0, "no_correct": 16, "no_total": 16, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.8888888888888888, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "nextto": {"accuracy": 0.8888888888888888, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}}}, "step": 11, "actions": ["grasp(book_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}], "remaining_actions": ["navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"]}, "data/planning/igibson/medium/cleaning_out_drawers_medium.pddl_Benevolence_1_int_21": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable cabinet_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable cabinet_1": ["no", 0.9999999999998032, 1.9680215651343523e-13, "The image shows a robotic arm (agent) reaching towards an object on a kitchen counter. The cabinet_1 is located below the counter, and the robotic arm is extended towards the counter surface, not the cabinet below. Since the arm is reaching towards the counter surface and not the lower cabinet, it suggests that the cabinet_1 is not within the reach of the agent in this moment.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object on a kitchen counter. The cabinet_1 is located below the counter, and the robotic arm is extended towards the counter surface, not the cabinet below. Since the arm is reaching towards the counter surface and not the lower cabinet, it suggests that the cabinet_1 is not within the reach of the agent in this moment.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}, "reachable cabinet_2": {"before": true, "after": false}, "reachable spoon_1": {"before": false, "after": false}, "reachable sink_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 0.9999999999985386, 1.4613388699475536e-12, "The image shows a robotic arm (agent) reaching towards an object on a kitchen counter. The cabinet_1 is located below the counter, and the robotic arm is extended towards the counter surface, not the cabinet below. Since the arm is reaching towards the counter surface and not the lower cabinet, it suggests that the cabinet_1 is not within the immediate reach of the robotic arm in this position.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object on a kitchen counter. The cabinet_1 is located below the counter, and the robotic arm is extended towards the counter surface, not the cabinet below. Since the arm is reaching towards the counter surface and not the lower cabinet, it suggests that the cabinet_1 is not within the immediate reach of the robotic arm in this position.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 1.8417499114202972e-16, 0.9999999999999998, "The image shows a robotic arm (agent) reaching towards an object on the countertop. The cabinet_1 is located directly below the object the robotic arm is reaching for, and it appears to be within the same plane as the arm's reach. Given the perspective, the cabinet_1 is close enough to be accessible by the robotic arm, especially since the arm is extended towards the object on the countertop, which is near the cabinet. Therefore, the cabinet_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object on the countertop. The cabinet_1 is located directly below the object the robotic arm is reaching for, and it appears to be within the same plane as the arm's reach. Given the perspective, the cabinet_1 is close enough to be accessible by the robotic arm, especially since the arm is extended towards the object on the countertop, which is near the cabinet. Therefore, the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_2": ["yes", 1.715770952089295e-15, 0.9999999999999983, "The image shows a robotic arm (agent) reaching towards an object on the countertop. The cabinet_2 is located directly below the object the robotic arm is reaching for, and it appears to be within the same plane as the arm's reach. Since the cabinet_2 is on the lower part of the counter and the arm is extended towards the object above, it is likely that the cabinet_2 is within the reach of the agent, especially considering typical reach distances in such environments.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object on the countertop. The cabinet_2 is located directly below the object the robotic arm is reaching for, and it appears to be within the same plane as the arm's reach. Since the cabinet_2 is on the lower part of the counter and the arm is extended towards the object above, it is likely that the cabinet_2 is within the reach of the agent, especially considering typical reach distances in such environments.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}, "reachable spoon_1": {"before": false, "after": false}, "reachable sink_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(cabinet_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable cabinet_1": ["yes", 2.6963001213233265e-13, 0.9999999999997303, "The image shows a robotic arm (agent) reaching towards an object on the countertop. The cabinet_1 is located directly below the object the robotic arm is reaching for, and it appears to be within the same horizontal plane. Given the position of the robotic arm and the proximity of cabinet_1, it is likely that the cabinet_1 is within reach of the agent, especially considering the arm's extension towards the object on the countertop.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object on the countertop. The cabinet_1 is located directly below the object the robotic arm is reaching for, and it appears to be within the same horizontal plane. Given the position of the robotic arm and the proximity of cabinet_1, it is likely that the cabinet_1 is within reach of the agent, especially considering the arm's extension towards the object on the countertop.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 0.9999999998025203, 1.9747966443687928e-10, "The image shows a kitchen or similar environment with a robotic arm and cabinets. The cabinet labeled \"cabinet_1\" is visible in the image. The cabinet doors are closed, as there are no visible gaps or handles indicating that it is open. The cabinet doors appear to be shut.", true, "<explanation>\nThe image shows a kitchen or similar environment with a robotic arm and cabinets. The cabinet labeled \"cabinet_1\" is visible in the image. The cabinet doors are closed, as there are no visible gaps or handles indicating that it is open. The cabinet doors appear to be shut.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding bowl_1": [true, false, false], "holding spoon_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["yes", 5.658347455523184e-12, 0.9999999999943416, "The image shows a kitchen or similar environment with a robotic arm and various objects. The cabinet labeled \"cabinet_2\" is clearly visible, and the cabinet labeled \"cabinet_1\" is located below it. The cabinet \"cabinet_1\" appears to have its door slightly ajar, revealing the inside. Since the door is not fully closed and is visibly open, the cabinet \"cabinet_1\" is open.", true, "<explanation>\nThe image shows a kitchen or similar environment with a robotic arm and various objects. The cabinet labeled \"cabinet_2\" is clearly visible, and the cabinet labeled \"cabinet_1\" is located below it. The cabinet \"cabinet_1\" appears to have its door slightly ajar, revealing the inside. Since the door is not fully closed and is visibly open, the cabinet \"cabinet_1\" is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable bowl_1": ["yes", 1.4533140494547094e-10, 0.9999999998546686, "The image shows a robotic arm (agent) positioned behind a counter, with a bowl labeled \"bowl_1\" located on the counter in front of it. The bowl appears to be within the area directly in front of the robotic arm, which suggests it is likely within reach. Since the robotic arm is capable of reaching objects on the counter, and the bowl is placed on the counter close to the arm, it is reasonable to conclude that the bowl_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned behind a counter, with a bowl labeled \"bowl_1\" located on the counter in front of it. The bowl appears to be within the area directly in front of the robotic arm, which suggests it is likely within reach. Since the robotic arm is capable of reaching objects on the counter, and the bowl is placed on the counter close to the arm, it is reasonable to conclude that the bowl_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "open-container(cabinet_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_2": ["yes", 1.5059471877095095e-13, 0.9999999999998495, "The image shows a robotic arm (agent) positioned behind a counter, with a cabinet labeled \"cabinet_2\" located in front of it. The cabinet is on the same level as the counter, and the robotic arm appears to be close to the cabinet. Given the typical reach of a robotic arm in such a virtual household environment, and considering the cabinet's position relative to the arm, it is likely within the arm's reach. Therefore, the cabinet_2 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned behind a counter, with a cabinet labeled \"cabinet_2\" located in front of it. The cabinet is on the same level as the counter, and the robotic arm appears to be close to the cabinet. Given the typical reach of a robotic arm in such a virtual household environment, and considering the cabinet's position relative to the arm, it is likely within the arm's reach. Therefore, the cabinet_2 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_2": ["no", 0.9999999999840743, 1.5925701033867298e-11, "The image shows a kitchen or similar environment with a robotic arm and various objects. The cabinet labeled \"cabinet_2\" is visible in the image. The cabinet doors are clearly visible, and they appear to be closed, as there are no gaps or indications that they are open. The handles are also aligned as if the doors are shut. Therefore, the cabinet_2 is not open.", true, "<explanation>\nThe image shows a kitchen or similar environment with a robotic arm and various objects. The cabinet labeled \"cabinet_2\" is visible in the image. The cabinet doors are clearly visible, and they appear to be closed, as there are no gaps or indications that they are open. The handles are also aligned as if the doors are shut. Therefore, the cabinet_2 is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "holding bowl_1": ["no", 0.9999611532413829, 3.884675861705176e-05, "In the image, the robotic arm (agent) is visible, but it is not holding any object. The bowl_1 is located on the counter, and there is no indication that the robotic arm is grasping or holding it. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the robotic arm (agent) is visible, but it is not holding any object. The bowl_1 is located on the counter, and there is no indication that the robotic arm is grasping or holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding spoon_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_2": ["no", 0.9999999999968051, 3.194905244932053e-12, "The image shows a kitchen scene with a robotic arm and various objects. The cabinet_2 is located in the middle of the image, below the countertop. The cabinet doors are visible, and they appear to be closed, as there are no gaps or indications that the doors are open. The handles are also aligned, which typically suggests the doors are shut. Therefore, the cabinet_2 is not open.", false, "<explanation>\nThe image shows a kitchen scene with a robotic arm and various objects. The cabinet_2 is located in the middle of the image, below the countertop. The cabinet doors are visible, and they appear to be closed, as there are no gaps or indications that the doors are open. The handles are also aligned, which typically suggests the doors are shut. Therefore, the cabinet_2 is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable spoon_1": ["no", 0.9999999999999958, 4.174577895110355e-15, "The image shows a robotic arm (agent) in a virtual household environment. The red outlines indicate objects, including \"spoon_1,\" which is located inside a drawer labeled \"cabinet_2.\" The drawer is partially open, and \"spoon_1\" appears to be inside it. The robotic arm is positioned behind the counter, and the spoon is inside the cabinet, which is below the counter surface. Since the spoon is inside the cabinet and the cabinet is closed, the spoon is not directly accessible or in reach of the robotic arm at this moment.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The red outlines indicate objects, including \"spoon_1,\" which is located inside a drawer labeled \"cabinet_2.\" The drawer is partially open, and \"spoon_1\" appears to be inside it. The robotic arm is positioned behind the counter, and the spoon is inside the cabinet, which is below the counter surface. Since the spoon is inside the cabinet and the cabinet is closed, the spoon is not directly accessible or in reach of the robotic arm at this moment.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 5.811900430425173e-11, 0.999999999941881, "The image shows a robotic arm (agent) positioned behind a counter, with a bowl labeled \"bowl_1\" placed on the counter in front of it. The bowl appears to be within the area directly in front of the robotic arm, which suggests it is within reach. Since the robotic arm is capable of reaching objects on the counter, and the bowl is located on the counter close to the arm, it is reasonable to conclude that the bowl_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned behind a counter, with a bowl labeled \"bowl_1\" placed on the counter in front of it. The bowl appears to be within the area directly in front of the robotic arm, which suggests it is within reach. Since the robotic arm is capable of reaching objects on the counter, and the bowl is located on the counter close to the arm, it is reasonable to conclude that the bowl_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding spoon_1": ["no", 0.9999999316830204, 6.831697960200934e-08, "The image shows a robotic arm in a household environment, but there is no visible indication that the robotic arm is holding any object, including spoon_1. The arm appears to be empty, and there is no clear grasp or hold on spoon_1 in the image. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm in a household environment, but there is no visible indication that the robotic arm is holding any object, including spoon_1. The arm appears to be empty, and there is no clear grasp or hold on spoon_1 in the image. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"holding bowl_1": ["no", 0.9999991740104683, 8.259895316482677e-07, "In the image, the robotic arm (agent) is visible, but there is no indication that it is holding any object. The bowl_1 is placed on the table, and the arm appears to be positioned above the table without grasping anything. Therefore, the agent is not holding the bowl_1.", false, "<explanation>\nIn the image, the robotic arm (agent) is visible, but there is no indication that it is holding any object. The bowl_1 is placed on the table, and the arm appears to be positioned above the table without grasping anything. Therefore, the agent is not holding the bowl_1.\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop bowl_1,cabinet_1": ["no", 0.9999971087053113, 2.8912946886165053e-06, "In the image, the bowl_1 is placed on the table, which is in front of the cabinet_1. The cabinet_1 is below the bowl_1, and there is no indication that the bowl_1 is on top of the cabinet_1. Instead, it appears to be on the table in front of the cabinet. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the bowl_1 is placed on the table, which is in front of the cabinet_1. The cabinet_1 is below the bowl_1, and there is no indication that the bowl_1 is on top of the cabinet_1. Instead, it appears to be on the table in front of the cabinet. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop bowl_1,cabinet_2": ["no", 0.9998604506657567, 0.00013954933424336694, "In the image, the bowl_1 is placed on the table, not on the cabinet_2. The cabinet_2 is located below the bowl_1, and there is no indication that the bowl_1 is on top of the cabinet_2. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the bowl_1 is placed on the table, not on the cabinet_2. The cabinet_2 is located below the bowl_1, and there is no indication that the bowl_1 is on top of the cabinet_2. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop bowl_1,spoon_1": ["no", 0.9999997802570812, 2.197429187195518e-07, "In the image, the bowl_1 is placed on the table, and the spoon_1 is also on the table, but they are not positioned in a way that indicates the bowl_1 is on top of the spoon_1. The bowl_1 appears to be separate from the spoon_1, which is located to the left of the bowl_1. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the bowl_1 is placed on the table, and the spoon_1 is also on the table, but they are not positioned in a way that indicates the bowl_1 is on top of the spoon_1. The bowl_1 appears to be separate from the spoon_1, which is located to the left of the bowl_1. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto bowl_1,cabinet_1": ["no", 0.999999999999976, 2.3968480154225668e-14, "The image shows a kitchen scene with various objects labeled. The bowl_1 is placed on the countertop, and the cabinet_1 is located below the countertop. The bowl_1 appears to be positioned directly on the surface of the countertop, not next to the cabinet_1, which is below the countertop. Since the question asks if bowl_1 is next to cabinet_1, and considering their positions, they are not adjacent or directly next to each other; the bowl_1 is on the countertop, while the cabinet_1 is below it.", true, "<explanation>\nThe image shows a kitchen scene with various objects labeled. The bowl_1 is placed on the countertop, and the cabinet_1 is located below the countertop. The bowl_1 appears to be positioned directly on the surface of the countertop, not next to the cabinet_1, which is below the countertop. Since the question asks if bowl_1 is next to cabinet_1, and considering their positions, they are not adjacent or directly next to each other; the bowl_1 is on the countertop, while the cabinet_1 is below it.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto bowl_1,cabinet_2": ["no", 0.9999999999999588, 4.1156151289079736e-14, "The image shows a kitchen scene with various objects labeled. The bowl_1 is placed on the countertop, and the cabinet_2 is located directly below the bowl_1, on the same surface. Since the question asks if bowl_1 is next to cabinet_2, I need to determine if they are adjacent or very close to each other. Given that the bowl_1 is on the countertop and the cabinet_2 is below the countertop, they are not directly next to each other but are vertically aligned. Typically, \"next to\" implies horizontal proximity, not vertical. Therefore, bowl_1 is not next to cabinet_2.", true, "<explanation>\nThe image shows a kitchen scene with various objects labeled. The bowl_1 is placed on the countertop, and the cabinet_2 is located directly below the bowl_1, on the same surface. Since the question asks if bowl_1 is next to cabinet_2, I need to determine if they are adjacent or very close to each other. Given that the bowl_1 is on the countertop and the cabinet_2 is below the countertop, they are not directly next to each other but are vertically aligned. Typically, \"next to\" implies horizontal proximity, not vertical. Therefore, bowl_1 is not next to cabinet_2.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto bowl_1,spoon_1": ["no", 0.9999999186854672, 8.131453273976539e-08, "In the image, bowl_1 is positioned on the table, and spoon_1 is also on the table, but they are not directly next to each other. Bowl_1 is placed more towards the center of the table, while spoon_1 is located on the left side, near the drawers. Therefore, bowl_1 is not next to spoon_1.", true, "<explanation>\nIn the image, bowl_1 is positioned on the table, and spoon_1 is also on the table, but they are not directly next to each other. Bowl_1 is placed more towards the center of the table, while spoon_1 is located on the left side, near the drawers. Therefore, bowl_1 is not next to spoon_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "inside bowl_1,cabinet_1": ["no", 0.9999969671222567, 3.032877743335672e-06, "In the image, the bowl_1 is placed on the countertop, not inside the cabinet_1. The cabinet_1 is located below the countertop, and the bowl_1 is clearly visible on the surface above the cabinet. Therefore, the bowl_1 is not inside the cabinet_1.", true, "<explanation>\nIn the image, the bowl_1 is placed on the countertop, not inside the cabinet_1. The cabinet_1 is located below the countertop, and the bowl_1 is clearly visible on the surface above the cabinet. Therefore, the bowl_1 is not inside the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop bowl_1,bowl_1": {"before": null, "after": false}, "ontop bowl_1,sink_1": {"before": false, "after": false}, "nextto bowl_1,bowl_1": {"before": null, "after": false}, "nextto bowl_1,sink_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(bowl_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable bowl_1": ["yes", 4.9689570666659516e-11, 0.9999999999503104, "The image shows a kitchen scene with a robotic arm (agent) and various objects, including a bowl labeled \"bowl_1.\" The bowl_1 is placed on the countertop, and the robotic arm is positioned above the counter, seemingly close to the bowl. Given the typical reach of a robotic arm in such a simulation, and the proximity of the arm to the bowl, it appears that the bowl_1 is within the arm's reach.", true, "<explanation>\nThe image shows a kitchen scene with a robotic arm (agent) and various objects, including a bowl labeled \"bowl_1.\" The bowl_1 is placed on the countertop, and the robotic arm is positioned above the counter, seemingly close to the bowl. Given the typical reach of a robotic arm in such a simulation, and the proximity of the arm to the bowl, it appears that the bowl_1 is within the arm's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding spoon_1": ["no", 0.9999996385775091, 3.6142249094817365e-07, "In the image, the robotic arm (agent) is visible, but it is not holding or interacting with any objects. The objects on the table include a bowl, a magazine, and other items, but there is no indication that the robotic arm is grasping or holding spoon_1. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the robotic arm (agent) is visible, but it is not holding or interacting with any objects. The objects on the table include a bowl, a magazine, and other items, but there is no indication that the robotic arm is grasping or holding spoon_1. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable cabinet_1": ["no", "yes"], "open cabinet_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 1, "actions": ["navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(bowl_1)", "navigate-to(cabinet_2)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)", "navigate-to(cabinet_2)", "open-container(cabinet_2)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open cabinet_2": ["no", "no"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}}}, "step": 2, "actions": ["open-container(cabinet_1)", "open-container(cabinet_2)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable bowl_2": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable spoon_1": ["yes", "yes"], "reachable spoon_2": ["no", "yes"], "reachable piece_of_cloth_1": ["yes", "yes"], "holding bowl_1": ["no", "no"], "holding bowl_2": ["no", "no"], "holding spoon_1": ["no", "no"], "holding spoon_2": ["no", "no"], "holding piece_of_cloth_1": ["no", "no"], "open cabinet_1": ["yes", "yes"], "open cabinet_2": ["yes", "yes"], "ontop bowl_1,bowl_2": ["no", "no"], "ontop bowl_1,cabinet_1": ["no", "no"], "ontop bowl_1,cabinet_2": ["no", "no"], "ontop bowl_1,spoon_1": ["no", "no"], "ontop bowl_1,spoon_2": ["no", "no"], "ontop bowl_1,piece_of_cloth_1": ["no", "yes"], "ontop bowl_2,bowl_1": ["no", "no"], "ontop bowl_2,cabinet_1": ["no", "no"], "ontop bowl_2,cabinet_2": ["no", "no"], "ontop bowl_2,spoon_1": ["no", "no"], "ontop bowl_2,spoon_2": ["no", "no"], "ontop bowl_2,piece_of_cloth_1": ["no", "no"], "ontop spoon_1,bowl_1": ["no", "no"], "ontop spoon_1,bowl_2": ["no", "no"], "ontop spoon_1,cabinet_1": ["no", "no"], "ontop spoon_1,cabinet_2": ["no", "yes"], "ontop spoon_1,spoon_2": ["no", "no"], "ontop spoon_1,piece_of_cloth_1": ["no", "no"], "ontop spoon_2,bowl_1": ["no", "no"], "ontop spoon_2,bowl_2": ["no", "no"], "ontop spoon_2,cabinet_1": ["no", "no"], "ontop spoon_2,cabinet_2": ["no", "no"], "ontop spoon_2,spoon_1": ["yes", "no"], "ontop spoon_2,piece_of_cloth_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_2": ["no", "no"], "ontop piece_of_cloth_1,cabinet_1": ["no", "no"], "ontop piece_of_cloth_1,cabinet_2": ["no", "no"], "ontop piece_of_cloth_1,spoon_1": ["no", "no"], "ontop piece_of_cloth_1,spoon_2": ["no", "no"], "inside bowl_1,cabinet_1": ["yes", "yes"], "inside bowl_1,cabinet_2": ["yes", "no"], "inside bowl_2,cabinet_1": ["yes", "yes"], "inside bowl_2,cabinet_2": ["no", "no"], "inside spoon_1,cabinet_1": ["no", "no"], "inside spoon_1,cabinet_2": ["yes", "yes"], "inside spoon_2,cabinet_1": ["yes", "no"], "inside spoon_2,cabinet_2": ["no", "yes"], "inside piece_of_cloth_1,cabinet_1": ["no", "yes"], "inside piece_of_cloth_1,cabinet_2": ["no", "no"], "nextto bowl_1,bowl_2": ["yes", "no"], "nextto bowl_1,cabinet_1": ["no", "yes"], "nextto bowl_1,cabinet_2": ["no", "no"], "nextto bowl_1,spoon_1": ["no", "no"], "nextto bowl_1,spoon_2": ["no", "no"], "nextto bowl_1,piece_of_cloth_1": ["yes", "no"], "nextto bowl_2,bowl_1": ["no", "no"], "nextto bowl_2,cabinet_1": ["yes", "yes"], "nextto bowl_2,cabinet_2": ["no", "no"], "nextto bowl_2,spoon_1": ["no", "no"], "nextto bowl_2,spoon_2": ["no", "no"], "nextto bowl_2,piece_of_cloth_1": ["yes", "yes"], "nextto spoon_1,bowl_1": ["no", "no"], "nextto spoon_1,bowl_2": ["no", "no"], "nextto spoon_1,cabinet_1": ["no", "no"], "nextto spoon_1,cabinet_2": ["no", "yes"], "nextto spoon_1,spoon_2": ["no", "no"], "nextto spoon_1,piece_of_cloth_1": ["no", "no"], "nextto spoon_2,bowl_1": ["no", "no"], "nextto spoon_2,bowl_2": ["no", "no"], "nextto spoon_2,cabinet_1": ["no", "no"], "nextto spoon_2,cabinet_2": ["no", "yes"], "nextto spoon_2,spoon_1": ["no", "no"], "nextto spoon_2,piece_of_cloth_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_2": ["yes", "yes"], "nextto piece_of_cloth_1,cabinet_1": ["no", "yes"], "nextto piece_of_cloth_1,cabinet_2": ["yes", "no"], "nextto piece_of_cloth_1,spoon_1": ["no", "no"], "nextto piece_of_cloth_1,spoon_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8214285714285714, "yes_accuracy": 0.6086956521739131, "yes_correct": 14, "yes_total": 23, "no_accuracy": 0.9016393442622951, "no_correct": 55, "no_total": 61, "predicates": {"reachable": {"accuracy": 0.8571428571428571, "yes_accuracy": 0.8571428571428571, "yes_correct": 6, "yes_total": 7, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.9, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.9642857142857143, "no_correct": 27, "no_total": 28}, "inside": {"accuracy": 0.6, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.6, "no_correct": 3, "no_total": 5}, "nextto": {"accuracy": 0.7666666666666667, "yes_accuracy": 0.42857142857142855, "yes_correct": 3, "yes_total": 7, "no_accuracy": 0.8695652173913043, "no_correct": 20, "no_total": 23}}}, "step": 4, "actions": ["grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, {"enum_results": {"reachable bowl_1": ["yes", "yes"], "reachable bowl_2": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["no", "yes"], "reachable spoon_1": ["no", "yes"], "reachable spoon_2": ["yes", "yes"], "reachable piece_of_cloth_1": ["yes", "yes"], "holding bowl_1": ["no", "yes"], "holding bowl_2": ["no", "no"], "holding spoon_1": ["no", "no"], "holding spoon_2": ["no", "no"], "holding piece_of_cloth_1": ["no", "no"], "open cabinet_1": ["yes", "yes"], "open cabinet_2": ["yes", "yes"], "ontop bowl_1,bowl_2": ["yes", "no"], "ontop bowl_1,cabinet_1": ["no", "no"], "ontop bowl_1,cabinet_2": ["no", "no"], "ontop bowl_1,spoon_1": ["no", "no"], "ontop bowl_1,spoon_2": ["no", "no"], "ontop bowl_1,piece_of_cloth_1": ["no", "no"], "ontop bowl_2,bowl_1": ["no", "no"], "ontop bowl_2,cabinet_1": ["no", "no"], "ontop bowl_2,cabinet_2": ["no", "no"], "ontop bowl_2,spoon_1": ["no", "no"], "ontop bowl_2,spoon_2": ["no", "no"], "ontop bowl_2,piece_of_cloth_1": ["no", "no"], "ontop spoon_1,bowl_1": ["no", "no"], "ontop spoon_1,bowl_2": ["no", "no"], "ontop spoon_1,cabinet_1": ["no", "no"], "ontop spoon_1,cabinet_2": ["no", "yes"], "ontop spoon_1,spoon_2": ["no", "no"], "ontop spoon_1,piece_of_cloth_1": ["no", "no"], "ontop spoon_2,bowl_1": ["no", "no"], "ontop spoon_2,bowl_2": ["no", "no"], "ontop spoon_2,cabinet_1": ["no", "no"], "ontop spoon_2,cabinet_2": ["no", "no"], "ontop spoon_2,spoon_1": ["no", "no"], "ontop spoon_2,piece_of_cloth_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_1": ["no", "no"], "ontop piece_of_cloth_1,bowl_2": ["no", "no"], "ontop piece_of_cloth_1,cabinet_1": ["no", "no"], "ontop piece_of_cloth_1,cabinet_2": ["yes", "no"], "ontop piece_of_cloth_1,spoon_1": ["no", "no"], "ontop piece_of_cloth_1,spoon_2": ["no", "no"], "inside bowl_1,cabinet_1": ["no", "no"], "inside bowl_1,cabinet_2": ["no", "no"], "inside bowl_2,cabinet_1": ["no", "yes"], "inside bowl_2,cabinet_2": ["no", "no"], "inside spoon_1,cabinet_1": ["no", "no"], "inside spoon_1,cabinet_2": ["no", "yes"], "inside spoon_2,cabinet_1": ["yes", "no"], "inside spoon_2,cabinet_2": ["yes", "yes"], "inside piece_of_cloth_1,cabinet_1": ["no", "yes"], "inside piece_of_cloth_1,cabinet_2": ["no", "no"], "nextto bowl_1,bowl_2": ["no", "no"], "nextto bowl_1,cabinet_1": ["no", "no"], "nextto bowl_1,cabinet_2": ["no", "no"], "nextto bowl_1,spoon_1": ["no", "no"], "nextto bowl_1,spoon_2": ["no", "no"], "nextto bowl_1,piece_of_cloth_1": ["no", "no"], "nextto bowl_2,bowl_1": ["yes", "no"], "nextto bowl_2,cabinet_1": ["no", "yes"], "nextto bowl_2,cabinet_2": ["yes", "no"], "nextto bowl_2,spoon_1": ["no", "no"], "nextto bowl_2,spoon_2": ["no", "no"], "nextto bowl_2,piece_of_cloth_1": ["no", "yes"], "nextto spoon_1,bowl_1": ["no", "no"], "nextto spoon_1,bowl_2": ["no", "no"], "nextto spoon_1,cabinet_1": ["no", "no"], "nextto spoon_1,cabinet_2": ["no", "yes"], "nextto spoon_1,spoon_2": ["no", "no"], "nextto spoon_1,piece_of_cloth_1": ["no", "no"], "nextto spoon_2,bowl_1": ["no", "no"], "nextto spoon_2,bowl_2": ["no", "no"], "nextto spoon_2,cabinet_1": ["no", "no"], "nextto spoon_2,cabinet_2": ["yes", "yes"], "nextto spoon_2,spoon_1": ["no", "no"], "nextto spoon_2,piece_of_cloth_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_1": ["no", "no"], "nextto piece_of_cloth_1,bowl_2": ["no", "yes"], "nextto piece_of_cloth_1,cabinet_1": ["no", "yes"], "nextto piece_of_cloth_1,cabinet_2": ["no", "no"], "nextto piece_of_cloth_1,spoon_1": ["no", "no"], "nextto piece_of_cloth_1,spoon_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7976190476190477, "yes_accuracy": 0.42857142857142855, "yes_correct": 9, "yes_total": 21, "no_accuracy": 0.9206349206349206, "no_correct": 58, "no_total": 63, "predicates": {"reachable": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.7142857142857143, "yes_correct": 5, "yes_total": 7, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.8, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.9, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.9310344827586207, "no_correct": 27, "no_total": 29}, "inside": {"accuracy": 0.6, "yes_accuracy": 0.25, "yes_correct": 1, "yes_total": 4, "no_accuracy": 0.8333333333333334, "no_correct": 5, "no_total": 6}, "nextto": {"accuracy": 0.7666666666666667, "yes_accuracy": 0.16666666666666666, "yes_correct": 1, "yes_total": 6, "no_accuracy": 0.9166666666666666, "no_correct": 22, "no_total": 24}}}, "step": 5, "actions": ["grasp(bowl_1)", "navigate-to(spoon_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}], "remaining_actions": ["navigate-to(spoon_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, "data/planning/igibson/medium/cleaning_out_drawers_medium.pddl_Rs_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable cabinet_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable cabinet_1": ["yes", 5.47370696044299e-13, 0.9999999999994527, "The image shows a robotic arm (agent) extending towards the area near the cabinet_1. The cabinet_1 is positioned above and slightly to the right of the robotic arm. Given the arm's extension and the proximity of the cabinet_1, it appears to be within reach of the agent. The arm's position suggests it can interact with objects on or inside the cabinet_1.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards the area near the cabinet_1. The cabinet_1 is positioned above and slightly to the right of the robotic arm. Given the arm's extension and the proximity of the cabinet_1, it appears to be within reach of the agent. The arm's position suggests it can interact with objects on or inside the cabinet_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_2": ["yes", 3.371800819279705e-09, 0.9999999966281992, "The image shows a robotic arm (agent) extending towards the area near cabinet_2. The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is positioned right next to cabinet_2, it suggests that the cabinet is accessible to the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the area near cabinet_2. The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is positioned right next to cabinet_2, it suggests that the cabinet is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sink_1": ["yes", 1.4494010576669998e-14, 0.9999999999999855, "The image shows a robotic arm (agent) positioned near a cabinet and a countertop with a sink. The sink is labeled as \"sink_1\" and is located on the right side of the image, integrated into the countertop. The robotic arm appears to be close to the sink, with its end effector near the edge of the countertop, suggesting it can potentially reach the sink. Given the proximity and typical reach of such robotic arms in virtual household simulators, it is reasonable to conclude that the sink_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) positioned near a cabinet and a countertop with a sink. The sink is labeled as \"sink_1\" and is located on the right side of the image, integrated into the countertop. The robotic arm appears to be close to the sink, with its end effector near the edge of the countertop, suggesting it can potentially reach the sink. Given the proximity and typical reach of such robotic arms in virtual household simulators, it is reasonable to conclude that the sink_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable bowl_1": {"before": false, "after": false}, "reachable spoon_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "close-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 0.9999999999999999, 6.55964808985495e-17, "The image shows a robotic arm (agent) extending towards the area near cabinet_2, which is on a wooden surface. Cabinet_1 is located above and behind the robotic arm, on a higher level, and appears to be a separate object in the environment. Given the position and the perspective, cabinet_1 is not within the immediate reach of the robotic arm, which is extending towards cabinet_2. Therefore, cabinet_1 is not in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the area near cabinet_2, which is on a wooden surface. Cabinet_1 is located above and behind the robotic arm, on a higher level, and appears to be a separate object in the environment. Given the position and the perspective, cabinet_1 is not within the immediate reach of the robotic arm, which is extending towards cabinet_2. Therefore, cabinet_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "open cabinet_1": ["no", 0.999999994989425, 5.010574940479987e-09, "The image shows a robotic arm near a cabinet labeled \"cabinet_1.\" The cabinet appears to have a closed door, as there are no visible gaps or open spaces indicating that it is open. The cabinet's door looks flush with the rest of the cabinet, suggesting it is closed.", false, "<explanation>\nThe image shows a robotic arm near a cabinet labeled \"cabinet_1.\" The cabinet appears to have a closed door, as there are no visible gaps or open spaces indicating that it is open. The cabinet's door looks flush with the rest of the cabinet, suggesting it is closed.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 0.9999999999995903, 4.0968718837966436e-13, "The image shows a robotic arm (agent) extending towards the area near cabinet_2, which is on a wooden surface. Cabinet_1 is located above and behind the robotic arm, attached to the wall. Given the position of the robotic arm and the cabinet, it appears that cabinet_1 is not within the reach of the robotic arm, as it is positioned higher and further away from the arm's current location.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the area near cabinet_2, which is on a wooden surface. Cabinet_1 is located above and behind the robotic arm, attached to the wall. Given the position of the robotic arm and the cabinet, it appears that cabinet_1 is not within the reach of the robotic arm, as it is positioned higher and further away from the arm's current location.\n</explanation>\n<answer>\nNo\n</answer>", false], "open cabinet_1": ["no", 0.999999996004941, 3.9950589655222875e-09, "The image shows a robotic arm near a cabinet labeled \"cabinet_1.\" The cabinet appears to have a closed door, as there are no visible gaps or open spaces indicating that it is open. The cabinet's door looks flush with the rest of the cabinet, suggesting it is closed.", true, "<explanation>\nThe image shows a robotic arm near a cabinet labeled \"cabinet_1.\" The cabinet appears to have a closed door, as there are no visible gaps or open spaces indicating that it is open. The cabinet's door looks flush with the rest of the cabinet, suggesting it is closed.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding bowl_1": [true, false, false], "holding spoon_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 1.6793423084961963e-09, 0.9999999983206577, "The image shows a robotic arm (agent) extending towards the area near cabinet_1. The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards or near cabinet_1, it suggests that the cabinet is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards the area near cabinet_1. The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards or near cabinet_1, it suggests that the cabinet is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["yes", 9.013352788947042e-10, 0.9999999990986648, "The image shows a robotic arm near two cabinets labeled \"cabinet_1\" and \"cabinet_2.\" The cabinet_1 appears to have its doors open, as the interior is visible and the doors are not aligned with the closed position. The cabinet_2, on the other hand, appears to be closed. Therefore, based on the visual evidence, cabinet_1 is open.", false, "<explanation>\nThe image shows a robotic arm near two cabinets labeled \"cabinet_1\" and \"cabinet_2.\" The cabinet_1 appears to have its doors open, as the interior is visible and the doors are not aligned with the closed position. The cabinet_2, on the other hand, appears to be closed. Therefore, based on the visual evidence, cabinet_1 is open.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding bowl_1": [true, false, false], "holding spoon_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "close-container(cabinet_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_2": ["yes", 2.0510777522116043e-09, 0.9999999979489222, "The image shows a robotic arm (agent) extending towards the area near cabinet_2. The cabinet_2 is positioned on a countertop, and the robotic arm appears to be close to or reaching towards it. Given the proximity and the extension of the robotic arm, it is reasonable to conclude that the cabinet_2 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards the area near cabinet_2. The cabinet_2 is positioned on a countertop, and the robotic arm appears to be close to or reaching towards it. Given the proximity and the extension of the robotic arm, it is reasonable to conclude that the cabinet_2 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_2": ["yes", 1.2730263942939742e-07, 0.9999998726973606, "The image shows a robotic arm near a cabinet labeled \"cabinet_2.\" The cabinet appears to have a visible gap between the door and the frame, indicating that it is open. Since the question asks if the cabinet_2 is open, and the visual evidence suggests it is, the answer is \"Yes.\"", true, "<explanation>\nThe image shows a robotic arm near a cabinet labeled \"cabinet_2.\" The cabinet appears to have a visible gap between the door and the frame, indicating that it is open. Since the question asks if the cabinet_2 is open, and the visual evidence suggests it is, the answer is \"Yes.\"\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "close-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 0.9999999999999999, 1.565038929383593e-16, "The image shows a robotic arm (agent) extending towards the area near cabinet_2, which is on a wooden surface. Cabinet_1 is located above and behind the robotic arm, on a higher level, and appears to be a wall-mounted or ceiling-mounted cabinet. Given the position and the typical height of such cabinets, it is unlikely that cabinet_1 is within the reach of the robotic arm, which is positioned at a lower level near the other objects.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the area near cabinet_2, which is on a wooden surface. Cabinet_1 is located above and behind the robotic arm, on a higher level, and appears to be a wall-mounted or ceiling-mounted cabinet. Given the position and the typical height of such cabinets, it is unlikely that cabinet_1 is within the reach of the robotic arm, which is positioned at a lower level near the other objects.\n</explanation>\n<answer>\nNo\n</answer>", false], "open cabinet_1": ["no", 0.9999997613448504, 2.3865514961800225e-07, "The image shows a robotic arm near a set of cabinets labeled \"cabinet_1\" and \"cabinet_2.\" The cabinet_1 appears to have its doors closed, as there are no visible gaps or open spaces indicating that it is open. The cabinet doors are aligned and seem to be shut.", false, "<explanation>\nThe image shows a robotic arm near a set of cabinets labeled \"cabinet_1\" and \"cabinet_2.\" The cabinet_1 appears to have its doors closed, as there are no visible gaps or open spaces indicating that it is open. The cabinet doors are aligned and seem to be shut.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "close-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 0.9999999999999996, 4.92184638624295e-16, "The image shows a robotic arm (agent) extending towards the area near cabinet_2, which is on a wooden surface. Cabinet_1 is positioned above and behind the robotic arm, with its label indicating it is a separate object. The arm appears to be reaching towards the lower cabinet (cabinet_2), not cabinet_1. Since cabinet_1 is located higher and further away from the arm's current position, it does not seem to be within the arm's reach in this image.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the area near cabinet_2, which is on a wooden surface. Cabinet_1 is positioned above and behind the robotic arm, with its label indicating it is a separate object. The arm appears to be reaching towards the lower cabinet (cabinet_2), not cabinet_1. Since cabinet_1 is located higher and further away from the arm's current position, it does not seem to be within the arm's reach in this image.\n</explanation>\n<answer>\nNo\n</answer>", false], "open cabinet_1": ["yes", 1.3691246739823182e-08, 0.9999999863087533, "The image shows a robotic arm near two cabinets labeled \"cabinet_1\" and \"cabinet_2.\" The cabinet_1 appears to have its doors open, as the interior is visible and the doors are not aligned with the closed position. The cabinet_2, on the other hand, appears to be closed. Therefore, the cabinet_1 is open.", true, "<explanation>\nThe image shows a robotic arm near two cabinets labeled \"cabinet_1\" and \"cabinet_2.\" The cabinet_1 appears to have its doors open, as the interior is visible and the doors are not aligned with the closed position. The cabinet_2, on the other hand, appears to be closed. Therefore, the cabinet_1 is open.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "close-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 4.911833252124673e-13, 0.9999999999995088, "The image shows a robotic arm (agent) extending towards the area near the cabinet_1. The cabinet_1 is positioned above and slightly to the right of the robotic arm. Given the arm's extension and the proximity of the cabinet_1, it appears to be within reach of the agent. The arm's position suggests it can interact with objects on or inside the cabinet_1.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards the area near the cabinet_1. The cabinet_1 is positioned above and slightly to the right of the robotic arm. Given the arm's extension and the proximity of the cabinet_1, it appears to be within reach of the agent. The arm's position suggests it can interact with objects on or inside the cabinet_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["yes", 6.869531679693596e-10, 0.9999999993130468, "The image shows a robotic arm near two cabinets labeled \"cabinet_1\" and \"cabinet_2.\" The cabinet_1 appears to have its doors open, as the interior is visible and the doors are not aligned with the closed position. The cabinet_2 appears closed, with its doors aligned and not open. Therefore, the cabinet_1 is open.", true, "<explanation>\nThe image shows a robotic arm near two cabinets labeled \"cabinet_1\" and \"cabinet_2.\" The cabinet_1 appears to have its doors open, as the interior is visible and the doors are not aligned with the closed position. The cabinet_2 appears closed, with its doors aligned and not open. Therefore, the cabinet_1 is open.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "open cabinet_1": ["yes", "no"], "open cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 1, "actions": ["close-container(cabinet_1)", "open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.8, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}}}, "step": 2, "actions": ["open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.8, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}}}, "step": 3, "actions": ["open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["no", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "open cabinet_1": ["yes", "no"], "open cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.4, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 4, "actions": ["close-container(cabinet_2)", "open-container(cabinet_2)", "grasp(spoon_1)", "place-on(spoon_1, sink_1)", "navigate-to(bowl_1)", "grasp(bowl_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "open cabinet_1": ["yes", "no"], "open cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 5, "actions": ["close-container(cabinet_1)", "open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "open cabinet_1": ["yes", "no"], "open cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 6, "actions": ["close-container(cabinet_1)", "open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "yes"], "reachable cabinet_2": ["yes", "yes"], "reachable sink_1": ["yes", "yes"], "open cabinet_1": ["yes", "no"], "open cabinet_2": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 7, "actions": ["close-container(cabinet_1)", "open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}], "remaining_actions": ["open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"]}, "data/planning/igibson/medium/packing_food_for_work_medium.pddl_Beechwood_0_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 1.718511479725875e-16, 0.9999999999999998, "The image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be within the same room and relatively close to the robotic arm. However, without specific distance markers or a clear indication of the arm's reach, it is difficult to determine definitively if the cabinet_1 is within reach of the agent. Based on typical room layouts and the positioning shown, it is likely that the cabinet_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be within the same room and relatively close to the robotic arm. However, without specific distance markers or a clear indication of the arm's reach, it is difficult to determine definitively if the cabinet_1 is within reach of the agent. Based on typical room layouts and the positioning shown, it is likely that the cabinet_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 1.493140761613246e-13, 0.9999999999998507, "The image shows a robotic arm (agent) in a household environment. The carton_1 is located on the left side of the image, on a shelf or counter. The robotic arm appears to be positioned further back in the room, near the center. Given the perspective, the carton_1 seems to be within the reach of the robotic arm, as it is on a shelf or counter that is not too far from the arm's position. Therefore, the carton_1 is likely within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a household environment. The carton_1 is located on the left side of the image, on a shelf or counter. The robotic arm appears to be positioned further back in the room, near the center. Given the perspective, the carton_1 seems to be within the reach of the robotic arm, as it is on a shelf or counter that is not too far from the arm's position. Therefore, the carton_1 is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "open carton_1": ["no", 0.999999999681509, 3.184909950773324e-10, "The image shows a virtual household with various objects and furniture, including a robotic arm. The question asks if the carton_1 is open. However, there is no visible carton labeled as \"carton_1\" in the image, nor is there any clear indication of an open or closed carton. Since the image does not provide any evidence of a carton_1 being open, the answer is \"No\".", true, "<explanation>\nThe image shows a virtual household with various objects and furniture, including a robotic arm. The question asks if the carton_1 is open. However, there is no visible carton labeled as \"carton_1\" in the image, nor is there any clear indication of an open or closed carton. Since the image does not provide any evidence of a carton_1 being open, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "open-container(cabinet_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable cabinet_1": ["yes", 1.313497448327678e-09, 0.9999999986865026, "The image shows a robotic arm (agent) in a household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be relatively close to the robotic arm, and the arm seems to be within a reachable distance to interact with objects on or inside the cabinet_1.", true, "<explanation>\nThe image shows a robotic arm (agent) in a household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be relatively close to the robotic arm, and the arm seems to be within a reachable distance to interact with objects on or inside the cabinet_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 0.9999870413337284, 1.2958666271571593e-05, "In the image, the cabinet_1 is the black-colored cabinet on the left side. The doors of this cabinet appear to be closed, as there are no visible gaps or open spaces indicating that it is open. Therefore, the cabinet_1 is not open.", true, "<explanation>\nIn the image, the cabinet_1 is the black-colored cabinet on the left side. The doors of this cabinet appear to be closed, as there are no visible gaps or open spaces indicating that it is open. Therefore, the cabinet_1 is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["yes", 2.097430300511978e-05, 0.9999790256969949, "In the image, the cabinet_1 appears to be partially open, as the door is not fully closed and is visibly ajar. This indicates that the cabinet_1 is open.", true, "<explanation>\nIn the image, the cabinet_1 appears to be partially open, as the door is not fully closed and is visibly ajar. This indicates that the cabinet_1 is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable snack_food_1": ["yes", 1.9339620549302573e-13, 0.9999999999998066, "The image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or shelf on the left side of the image, which appears to be within the reach of the robotic arm, considering the arm's position and the proximity of the snack to the arm's current location. Since the arm is capable of reaching objects within its environment, and the snack_food_1 is close to the arm's position, it is reasonable to conclude that the snack_food_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or shelf on the left side of the image, which appears to be within the reach of the robotic arm, considering the arm's position and the proximity of the snack to the arm's current location. Since the arm is capable of reaching objects within its environment, and the snack_food_1 is close to the arm's position, it is reasonable to conclude that the snack_food_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 4.147050811132499e-14, 0.9999999999999585, "The image shows a robotic arm in a virtual household environment. The arm appears to be positioned near a desk or table, with a carton labeled \"carton_1\" visible on a small table or shelf to the left side of the image. The carton is relatively close to the robotic arm, which is extended towards the area where the carton is located. Given the proximity and the typical reach of a robotic arm in such environments, it is reasonable to conclude that the carton_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The arm appears to be positioned near a desk or table, with a carton labeled \"carton_1\" visible on a small table or shelf to the left side of the image. The carton is relatively close to the robotic arm, which is extended towards the area where the carton is located. Given the proximity and the typical reach of a robotic arm in such environments, it is reasonable to conclude that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "open carton_1": ["yes", 5.652230201352145e-07, 0.9999994347769798, "The image shows a room with various objects, including a robot arm and a carton labeled \"carton_1\" on a shelf. The carton appears to be slightly ajar, with the top flaps not fully closed, indicating that it is open.", false, "<explanation>\nThe image shows a room with various objects, including a robot arm and a carton labeled \"carton_1\" on a shelf. The carton appears to be slightly ajar, with the top flaps not fully closed, indicating that it is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding snack_food_1": ["no", 0.9999961127782285, 3.887221771417229e-06, "The image shows a robotic arm in a virtual household environment. However, there is no clear indication that the robotic arm is holding any object, including snack_food_1. The arm appears to be extended but not grasping or holding anything specific. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. However, there is no clear indication that the robotic arm is holding any object, including snack_food_1. The arm appears to be extended but not grasping or holding anything specific. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(snack_food_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable snack_food_1": ["yes", 1.2918651029981916e-11, 0.9999999999870813, "The image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or shelf on the left side of the image, which is relatively close to the robotic arm. Given the perspective, the snack_food_1 appears to be within the reach of the robotic arm, as it is not far from the arm's position and is on a surface that the arm could potentially extend to or grasp from.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or shelf on the left side of the image, which is relatively close to the robotic arm. Given the perspective, the snack_food_1 appears to be within the reach of the robotic arm, as it is not far from the arm's position and is on a surface that the arm could potentially extend to or grasp from.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "all_correct": true}, "effects_results": {"holding snack_food_1": ["yes", 0.0001215915100706661, 0.9998784084899294, "The image shows a robotic arm, which is the agent, holding a yellow object that appears to be a snack food. Since the object is being held by the robotic arm, the agent is indeed holding the snack_food_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding a yellow object that appears to be a snack food. Since the object is being held by the robotic arm, the agent is indeed holding the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop snack_food_1,carton_1": ["no", 0.9999999999771828, 2.2817207914065197e-11, "The image shows a robotic arm holding a yellow object, which appears to be a snack food, near a carton. The snack_food_1 is positioned on a small table or surface, and the carton_1 is on a shelf or rack. The snack_food_1 is not on top of the carton_1; instead, it is placed on a different surface, separate from the carton. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm holding a yellow object, which appears to be a snack food, near a carton. The snack_food_1 is positioned on a small table or surface, and the carton_1 is on a shelf or rack. The snack_food_1 is not on top of the carton_1; instead, it is placed on a different surface, separate from the carton. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop snack_food_1,cabinet_1": ["no", 0.9999999973142173, 2.685782676481018e-09, "The image shows a robotic arm holding a yellow object, which is identified as snack_food_1, and it is positioned near a cabinet_1. The snack_food_1 appears to be placed on a small table or surface in front of the cabinet, not on top of the cabinet itself. Since the question asks if snack_food_1 is on top of the cabinet_1, and based on the visual evidence, it is not on top of the cabinet but rather in front of it.", true, "<explanation>\nThe image shows a robotic arm holding a yellow object, which is identified as snack_food_1, and it is positioned near a cabinet_1. The snack_food_1 appears to be placed on a small table or surface in front of the cabinet, not on top of the cabinet itself. Since the question asks if snack_food_1 is on top of the cabinet_1, and based on the visual evidence, it is not on top of the cabinet but rather in front of it.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto snack_food_1,carton_1": ["yes", 1.1161198967180519e-13, 0.9999999999998884, "The image shows a robotic arm holding a yellow object, which appears to be a snack food, and it is positioned near a brown box labeled \"carton_1.\" The snack food is placed on a small table or surface, and the carton_1 is located directly behind it, on the same surface. Since the snack food is very close to the carton_1 and appears to be adjacent to it, the answer is \"Yes.\"", false, "<explanation>\nThe image shows a robotic arm holding a yellow object, which appears to be a snack food, and it is positioned near a brown box labeled \"carton_1.\" The snack food is placed on a small table or surface, and the carton_1 is located directly behind it, on the same surface. Since the snack food is very close to the carton_1 and appears to be adjacent to it, the answer is \"Yes.\"\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto snack_food_1,cabinet_1": ["no", 0.9999999995505909, 4.494090280150501e-10, "The image shows a robotic arm holding a yellow object, which appears to be a snack food, and it is positioned near a cabinet. The snack_food_1 is the yellow object, and the cabinet_1 is the black shelving unit. The snack_food_1 is placed on a small table or surface in front of the cabinet, not directly next to or touching the cabinet. Therefore, the snack_food_1 is not next to the cabinet_1.", true, "<explanation>\nThe image shows a robotic arm holding a yellow object, which appears to be a snack food, and it is positioned near a cabinet. The snack_food_1 is the yellow object, and the cabinet_1 is the black shelving unit. The snack_food_1 is placed on a small table or surface in front of the cabinet, not directly next to or touching the cabinet. Therefore, the snack_food_1 is not next to the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "inside snack_food_1,cabinet_1": ["no", 0.9999999905501783, 9.44982170538646e-09, "The image shows a robotic arm holding a yellow object, which appears to be a snack food, near a cabinet. The cabinet has open shelves, but the snack_food_1 is not visible inside the cabinet. It is instead positioned outside, near the cabinet, on a small table or surface. Therefore, the snack_food_1 is not inside the cabinet_1.", true, "<explanation>\nThe image shows a robotic arm holding a yellow object, which appears to be a snack food, near a cabinet. The cabinet has open shelves, but the snack_food_1 is not visible inside the cabinet. It is instead positioned outside, near the cabinet, on a small table or surface. Therefore, the snack_food_1 is not inside the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop snack_food_1,electric_refrigerator_1": {"before": false, "after": false}, "ontop snack_food_1,sandwich_1": {"before": false, "after": false}, "ontop snack_food_1,snack_food_1": {"before": null, "after": false}, "nextto snack_food_1,electric_refrigerator_1": {"before": false, "after": false}, "nextto snack_food_1,sandwich_1": {"before": false, "after": false}, "nextto snack_food_1,snack_food_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["no", 0.9999999999557952, 4.4204780698765184e-11, "The image shows a robotic arm (agent) reaching towards an object, which appears to be a yellow pillow or cushion. The object labeled \"carton_1\" is not visible in the image, and based on the description, the agent is reaching towards a different object. Since \"carton_1\" is not shown in the image, it cannot be determined if it is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object, which appears to be a yellow pillow or cushion. The object labeled \"carton_1\" is not visible in the image, and based on the description, the agent is reaching towards a different object. Since \"carton_1\" is not shown in the image, it cannot be determined if it is within reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable carton_1": ["no", 0.9999999968079919, 3.1920081329589294e-09, "The image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, not a carton. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and there is no evidence of a carton_1 in the image, the answer is \"No\".", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, not a carton. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and there is no evidence of a carton_1 in the image, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable snack_food_1": ["yes", 8.045991678316508e-08, 0.9999999195400833, "The image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a snack food. The snack_food_1 is positioned very close to the robotic arm, within the arm's reach, and the arm is actively extending towards it. Therefore, the snack_food_1 is indeed within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a snack food. The snack_food_1 is positioned very close to the robotic arm, within the arm's reach, and the arm is actively extending towards it. Therefore, the snack_food_1 is indeed within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable electric_refrigerator_1": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}, "reachable sandwich_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["no", 0.9999999992302476, 7.697523358045378e-10, "The image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, not a carton. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if carton_1 is in reach of the agent, and there is no evidence of carton_1 in the image, I conclude that the carton_1 is not in reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, not a carton. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if carton_1 is in reach of the agent, and there is no evidence of carton_1 in the image, I conclude that the carton_1 is not in reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable carton_1": ["no", 0.9999999999997866, 2.1336903205074544e-13, "The image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, on top of a black box. The carton_1 is not explicitly visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and there is no evidence of the carton_1 in the image, I will assume it is not within reach based on the current view.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, on top of a black box. The carton_1 is not explicitly visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and there is no evidence of the carton_1 in the image, I will assume it is not within reach based on the current view.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable snack_food_1": ["yes", 7.522759387374488e-09, 0.9999999924772406, "The image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a snack food. The snack_food_1 is positioned very close to the robotic arm, within the arm's reach, and the arm is actively extending towards it. Based on this, it is reasonable to conclude that the snack_food_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a snack food. The snack_food_1 is positioned very close to the robotic arm, within the arm's reach, and the arm is actively extending towards it. Based on this, it is reasonable to conclude that the snack_food_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable electric_refrigerator_1": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}, "reachable sandwich_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["no", 0.9999999999976845, 2.315446059128733e-12, "The image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a banana, on top of a black box. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if carton_1 is in reach of the agent, and the carton_1 is not shown, the most logical conclusion is that it is not in reach based on the provided image.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a banana, on top of a black box. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if carton_1 is in reach of the agent, and the carton_1 is not shown, the most logical conclusion is that it is not in reach based on the provided image.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable carton_1": ["yes", 7.278573013424896e-15, 0.9999999999999927, "The image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, and a black box or container. The black box or container is labeled \"carton_1\" in the question. The carton_1 is positioned very close to the robotic arm, within the arm's reach, as the arm is extending directly towards it. Therefore, it is reasonable to conclude that the carton_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, and a black box or container. The black box or container is labeled \"carton_1\" in the question. The carton_1 is positioned very close to the robotic arm, within the arm's reach, as the arm is extending directly towards it. Therefore, it is reasonable to conclude that the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable snack_food_1": ["yes", 3.5677672111015486e-10, 0.9999999996432233, "The image shows a robotic arm (agent) reaching towards an object that appears to be a snack food. The snack food is positioned very close to the robotic arm, within what looks like a reachable distance. Since the arm is extended towards the snack food, it suggests that the snack food is indeed within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object that appears to be a snack food. The snack food is positioned very close to the robotic arm, within what looks like a reachable distance. Since the arm is extended towards the snack food, it suggests that the snack food is indeed within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable electric_refrigerator_1": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}, "reachable sandwich_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["no", 0.9999999984565691, 1.5434308960251562e-09, "The image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, not a carton. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and there is no evidence of a carton_1 in the image, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow or cushion, not a carton. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and there is no evidence of a carton_1 in the image, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable carton_1": ["yes", 6.151613577498642e-10, 0.9999999993848386, "The image shows a robotic arm (agent) reaching towards a yellow pillow and a gray object, which appears to be a carton labeled \"carton_1.\" The carton_1 is positioned on a surface close to the robotic arm, and the arm is extended towards it. Given the proximity and the arm's position, it seems that the carton_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow pillow and a gray object, which appears to be a carton labeled \"carton_1.\" The carton_1 is positioned on a surface close to the robotic arm, and the arm is extended towards it. Given the proximity and the arm's position, it seems that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable snack_food_1": ["yes", 3.951002003462327e-09, 0.999999996048998, "The image shows a robotic arm (agent) reaching towards an object, which appears to be a yellow snack food on a gray block. The snack_food_1 is positioned very close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Therefore, the snack_food_1 is indeed within the agent's reach.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object, which appears to be a yellow snack food on a gray block. The snack_food_1 is positioned very close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Therefore, the snack_food_1 is indeed within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable electric_refrigerator_1": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}, "reachable sandwich_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 8.47327261624424e-11, 0.9999999999152672, "The image shows a robotic arm (agent) reaching towards a yellow pillow and a gray box, which appears to be a carton. The carton_1 is located directly in front of the robotic arm, within the same surface area, and the arm is extended towards it. Given the position and the arm's extension, it seems that the carton_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow pillow and a gray box, which appears to be a carton. The carton_1 is located directly in front of the robotic arm, within the same surface area, and the arm is extended towards it. Given the position and the arm's extension, it seems that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 0.999999902093544, 9.790645610452347e-08, "The image shows a robotic arm holding a yellow object over a carton. The carton appears to be closed, with no visible opening or flaps that are lifted or separated. Since there are no signs of the carton being open, the answer is that the carton_1 is not open.", true, "<explanation>\nThe image shows a robotic arm holding a yellow object over a carton. The carton appears to be closed, with no visible opening or flaps that are lifted or separated. Since there are no signs of the carton being open, the answer is that the carton_1 is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding snack_food_1": ["yes", 4.503709059589864e-06, 0.9999954962909404, "The image shows a robotic arm, which is the agent, holding an object that appears to be a yellow snack food. Since the question asks if the agent is holding \"snack_food_1,\" and the object in the robotic arm looks like a snack food, it is reasonable to conclude that the agent is indeed holding snack_food_1.", false, "<explanation>\nThe image shows a robotic arm, which is the agent, holding an object that appears to be a yellow snack food. Since the question asks if the agent is holding \"snack_food_1,\" and the object in the robotic arm looks like a snack food, it is reasonable to conclude that the agent is indeed holding snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-next-to(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["yes", 2.3590622123736204e-06, 0.9999976409377876, "The image shows a robotic arm, which is the agent, holding an object that appears to be a yellow snack food. Since the question asks if the agent is holding \"snack_food_1,\" and the object in the robotic arm looks like a snack food, it is reasonable to conclude that the agent is indeed holding snack_food_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding an object that appears to be a yellow snack food. Since the question asks if the agent is holding \"snack_food_1,\" and the object in the robotic arm looks like a snack food, it is reasonable to conclude that the agent is indeed holding snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["no", 0.999999999999913, 8.70859687157105e-14, "The image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow, and a black box or container. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and the carton_1 is not shown in the image, the most logical conclusion is that it is not in reach, or at least not visible or accessible in this view.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow object, which appears to be a pillow, and a black box or container. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and the carton_1 is not shown in the image, the most logical conclusion is that it is not in reach, or at least not visible or accessible in this view.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-next-to(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["no", 0.9999999996542769, 3.4572312582481496e-10, "The image shows a robotic arm, which is the agent, reaching towards a yellow object that appears to be a snack food. The arm is positioned over the object, but it is not clear if the arm is actually grasping or holding the snack food. Since the arm's gripper is not visibly closed around the object, it cannot be confirmed that the agent is holding the snack food.", false, "<explanation>\nThe image shows a robotic arm, which is the agent, reaching towards a yellow object that appears to be a snack food. The arm is positioned over the object, but it is not clear if the arm is actually grasping or holding the snack food. Since the arm's gripper is not visibly closed around the object, it cannot be confirmed that the agent is holding the snack food.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable carton_1": ["yes", 2.072469493809015e-09, 0.9999999979275305, "The image shows a robotic arm (agent) reaching towards a yellow pillow and a black box, which appears to be a carton. The carton_1 is positioned on a surface close to the robotic arm, and the arm is extended towards it. Given the proximity and the arm's position, it seems that the carton_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow pillow and a black box, which appears to be a carton. The carton_1 is positioned on a surface close to the robotic arm, and the arm is extended towards it. Given the proximity and the arm's position, it seems that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 6.86982951159945e-10, 0.9999999993130171, "The image shows a robotic arm (agent) reaching towards a yellow pillow and a gray object, which appears to be a carton labeled \"carton_1.\" The carton_1 is positioned on a surface close to the robotic arm, and the arm is extended towards it. Given the proximity and the arm's position, it seems that the carton_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a yellow pillow and a gray object, which appears to be a carton labeled \"carton_1.\" The carton_1 is positioned on a surface close to the robotic arm, and the arm is extended towards it. Given the proximity and the arm's position, it seems that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-next-to(snack_food_1, carton_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"holding snack_food_1": ["yes", 3.9433933942042926e-07, 0.9999996056606606, "The image shows a robotic arm, which is the agent, positioned over a yellow object that appears to be a snack food. The arm's gripper is around the object, indicating that it is holding it. Since the object is identified as snack_food_1, the agent is indeed holding snack_food_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, positioned over a yellow object that appears to be a snack food. The arm's gripper is around the object, indicating that it is holding it. Since the object is identified as snack_food_1, the agent is indeed holding snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 9.963222406071822e-10, 0.9999999990036778, "The image shows a robotic arm (agent) reaching towards an object, which appears to be a carton labeled \"carton_1.\" The carton is positioned on a surface close to the robotic arm, and the arm is extended towards it, indicating that it is within the arm's reach. Since the arm is actively reaching towards the carton, it suggests that the carton is indeed within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object, which appears to be a carton labeled \"carton_1.\" The carton is positioned on a surface close to the robotic arm, and the arm is extended towards it, indicating that it is within the arm's reach. Since the arm is actively reaching towards the carton, it suggests that the carton is indeed within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"updated_non_visible_preds": {"nextto snack_food_1,carton_1": {"before": true, "after": true}, "holding snack_food_1": {"before": true, "after": false}}}, "action_info": "executed but failed"}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 1.1690973681418684e-12, 0.9999999999988309, "The image shows a robotic arm (agent) in a virtual household environment. The arm is extended forward, and there is a carton (carton_1) in front of it. The carton appears to be within the arm's reach, as the arm is positioned directly in front of it and seems capable of grasping or interacting with it. Based on the perspective and proximity, the carton_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm is extended forward, and there is a carton (carton_1) in front of it. The carton appears to be within the arm's reach, as the arm is positioned directly in front of it and seems capable of grasping or interacting with it. Based on the perspective and proximity, the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["yes", 1.1515437694125446e-05, 0.9999884845623058, "The image shows a carton_1 that appears to be open, as the top flaps are not visible and the interior of the carton is exposed. This suggests that the carton_1 is open.", false, "<explanation>\nThe image shows a carton_1 that appears to be open, as the top flaps are not visible and the interior of the carton is exposed. This suggests that the carton_1 is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(snack_food_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable snack_food_1": ["yes", 2.496037261817395e-08, 0.9999999750396273, "The image shows a robotic arm (agent) in a kitchen environment. The snack_food_1 is located on the countertop to the right of the robotic arm. The arm appears to be close to the snack_food_1, and given the typical reach of a robotic arm in such a setting, it is likely within reach. Therefore, the snack_food_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a kitchen environment. The snack_food_1 is located on the countertop to the right of the robotic arm. The arm appears to be close to the snack_food_1, and given the typical reach of a robotic arm in such a setting, it is likely within reach. Therefore, the snack_food_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["no", 1.0, 8.493693806082337e-18, "The image shows a robotic arm (agent) reaching towards a countertop with a red object on it. The electric refrigerator is located to the left of the robotic arm, near the corner of the kitchen. The refrigerator appears to be positioned behind the robotic arm and the countertop, and there is no clear indication that the refrigerator is within the reach of the robotic arm based on the current perspective. The arm is extended towards the countertop, but the refrigerator is further away and not directly accessible from the arm's current position.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a countertop with a red object on it. The electric refrigerator is located to the left of the robotic arm, near the corner of the kitchen. The refrigerator appears to be positioned behind the robotic arm and the countertop, and there is no clear indication that the refrigerator is within the reach of the robotic arm based on the current perspective. The arm is extended towards the countertop, but the refrigerator is further away and not directly accessible from the arm's current position.\n</explanation>\n<answer>\nNo\n</answer>", true], "reachable cabinet_1": ["yes", 1.6852799630182018e-15, 0.9999999999999983, "The image shows a robotic arm (agent) near a kitchen counter with cabinets. The cabinet_1 is located on the right side of the image, above the counter. The robotic arm appears to be positioned very close to the cabinet_1, and given the perspective, it seems to be within reach of the cabinet. Since the arm is extended towards the cabinet and is close enough to interact with objects on the counter or cabinet, it is reasonable to conclude that the cabinet_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) near a kitchen counter with cabinets. The cabinet_1 is located on the right side of the image, above the counter. The robotic arm appears to be positioned very close to the cabinet_1, and given the perspective, it seems to be within reach of the cabinet. Since the arm is extended towards the cabinet and is close enough to interact with objects on the counter or cabinet, it is reasonable to conclude that the cabinet_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable carton_1": {"before": true, "after": false}, "reachable sandwich_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(snack_food_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable snack_food_1": ["yes", 4.043236188915066e-08, 0.9999999595676381, "The image shows a robotic arm (agent) in a kitchen environment. The snack_food_1 is located on the countertop to the right of the robotic arm. The arm appears to be close to the snack_food_1, and given the typical reach of a robotic arm in such a setting, it is likely within reach. Therefore, the snack_food_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a kitchen environment. The snack_food_1 is located on the countertop to the right of the robotic arm. The arm appears to be close to the snack_food_1, and given the typical reach of a robotic arm in such a setting, it is likely within reach. Therefore, the snack_food_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "all_correct": true}, "effects_results": {"holding snack_food_1": ["yes", 1.498213474758431e-07, 0.9999998501786526, "The image shows a robotic arm, which is the agent, holding a yellowish-green object that appears to be a snack food. Since the question asks if the agent is holding \"snack_food_1,\" and the object in the image resembles a snack food, it is reasonable to conclude that the agent is indeed holding snack_food_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding a yellowish-green object that appears to be a snack food. Since the question asks if the agent is holding \"snack_food_1,\" and the object in the image resembles a snack food, it is reasonable to conclude that the agent is indeed holding snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop snack_food_1,electric_refrigerator_1": ["no", 0.9999999981248903, 1.8751097250547268e-09, "The image shows a kitchen scene with a robotic arm holding a yellow object, which appears to be a snack food. The snack_food_1 is located on the countertop, to the right of the electric refrigerator. The electric refrigerator is positioned against the wall, and the snack_food_1 is not on top of it but rather beside it on the counter. Therefore, the snack_food_1 is not on top of the electric refrigerator.", true, "<explanation>\nThe image shows a kitchen scene with a robotic arm holding a yellow object, which appears to be a snack food. The snack_food_1 is located on the countertop, to the right of the electric refrigerator. The electric refrigerator is positioned against the wall, and the snack_food_1 is not on top of it but rather beside it on the counter. Therefore, the snack_food_1 is not on top of the electric refrigerator.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop snack_food_1,cabinet_1": ["no", 0.9999999988942677, 1.1057322385162612e-09, "The image shows a kitchen scene with a robotic arm holding a yellowish-green object, which appears to be a snack food. The snack_food_1 is located on the countertop, not on top of the cabinet_1. The cabinet_1 is positioned above the countertop, and the snack_food_1 is placed on the surface of the countertop, not on the top of the cabinet. Therefore, the snack_food_1 is not on top of the cabinet_1.", true, "<explanation>\nThe image shows a kitchen scene with a robotic arm holding a yellowish-green object, which appears to be a snack food. The snack_food_1 is located on the countertop, not on top of the cabinet_1. The cabinet_1 is positioned above the countertop, and the snack_food_1 is placed on the surface of the countertop, not on the top of the cabinet. Therefore, the snack_food_1 is not on top of the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto snack_food_1,electric_refrigerator_1": ["yes", 2.5944610275423125e-14, 0.999999999999974, "The image shows a kitchen scene with a robotic arm holding a green object. There is an electric refrigerator on the left side of the image, and a small red object on the counter to the right of the refrigerator. The snack_food_1 is not explicitly visible in the image, but based on the description, the snack_food_1 is likely the small red object on the counter. Since the red object is next to the refrigerator, it can be inferred that the snack_food_1 is indeed next to the electric refrigerator.", false, "<explanation>\nThe image shows a kitchen scene with a robotic arm holding a green object. There is an electric refrigerator on the left side of the image, and a small red object on the counter to the right of the refrigerator. The snack_food_1 is not explicitly visible in the image, but based on the description, the snack_food_1 is likely the small red object on the counter. Since the red object is next to the refrigerator, it can be inferred that the snack_food_1 is indeed next to the electric refrigerator.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto snack_food_1,cabinet_1": ["yes", 3.2529702124777966e-07, 0.9999996747029788, "In the image, there is a red object on the countertop near the cabinet. Based on the context, this object appears to be a snack food, and it is positioned next to the cabinet. Therefore, the snack_food_1 is next to the cabinet_1.", false, "<explanation>\nIn the image, there is a red object on the countertop near the cabinet. Based on the context, this object appears to be a snack food, and it is positioned next to the cabinet. Therefore, the snack_food_1 is next to the cabinet_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop snack_food_1,carton_1": {"before": false, "after": false}, "ontop snack_food_1,sandwich_1": {"before": false, "after": false}, "ontop snack_food_1,snack_food_1": {"before": null, "after": false}, "nextto snack_food_1,carton_1": {"before": true, "after": false}, "nextto snack_food_1,sandwich_1": {"before": false, "after": false}, "nextto snack_food_1,snack_food_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable carton_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable carton_1": ["yes", 9.887763944691096e-11, 0.9999999999011223, "The image shows a robotic arm in a virtual household environment. The carton_1 is located in front of the robotic arm, and it appears to be within the arm's reach based on its position relative to the arm's grasping area. Since the arm is extended towards the carton and there are no visible obstructions, it is reasonable to conclude that the carton_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The carton_1 is located in front of the robotic arm, and it appears to be within the arm's reach based on its position relative to the arm's grasping area. Since the arm is extended towards the carton and there are no visible obstructions, it is reasonable to conclude that the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable snack_food_1": ["yes", 2.0280545782658717e-12, 0.999999999997972, "The image shows a robotic arm (agent) in a virtual household environment. The snack_food_1 is located on a table in the background, and the arm appears to be positioned in the foreground, facing towards the snack_food_1. Given the perspective, the snack_food_1 seems to be within the reach of the robotic arm, as it is on the same table and not too far away from the arm's position.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The snack_food_1 is located on a table in the background, and the arm appears to be positioned in the foreground, facing towards the snack_food_1. Given the perspective, the snack_food_1 seems to be within the reach of the robotic arm, as it is on the same table and not too far away from the arm's position.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable electric_refrigerator_1": {"before": true, "after": false}, "reachable cabinet_1": {"before": true, "after": false}, "reachable sandwich_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-inside(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["yes", 8.780375919463128e-14, 0.9999999999999122, "The image shows a robotic arm, which is the agent, holding a yellowish snack food item. The question asks if the agent is holding \"snack_food_1.\" Since the object in the agent's grasp appears to be a snack food, it is likely that this is the snack_food_1. There are no other snack foods visible in the image, and the object being held matches the description of a snack food. Therefore, the answer is \"Yes.\"", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding a yellowish snack food item. The question asks if the agent is holding \"snack_food_1.\" Since the object in the agent's grasp appears to be a snack food, it is likely that this is the snack_food_1. There are no other snack foods visible in the image, and the object being held matches the description of a snack food. Therefore, the answer is \"Yes.\"\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 8.228194976739363e-10, 0.9999999991771805, "The image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located in front of the agent, and the arm appears to be extended towards it. Given the perspective, the carton_1 seems to be within the reach of the robotic arm, as it is directly in front of it and not obstructed by other objects.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located in front of the agent, and the arm appears to be extended towards it. Given the perspective, the carton_1 seems to be within the reach of the robotic arm, as it is directly in front of it and not obstructed by other objects.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["yes", 3.620050706148775e-08, 0.999999963799493, "The image shows a carton_1 that appears to be open, as the top flaps are lifted and visible. The perspective from the robotic arm's point of view suggests that the carton is not closed. Therefore, the carton_1 is open.", true, "<explanation>\nThe image shows a carton_1 that appears to be open, as the top flaps are lifted and visible. The perspective from the robotic arm's point of view suggests that the carton is not closed. Therefore, the carton_1 is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"inside snack_food_1,carton_1": ["yes", 3.6603209572218087e-06, 0.9999963396790428, "The image shows a carton with an object inside it. The object appears to be a small, yellow item, which matches the description of snack_food_1. Since the snack_food_1 is located within the carton_1 in the image, the answer is \"Yes\".", true, "<explanation>\nThe image shows a carton with an object inside it. The object appears to be a small, yellow item, which matches the description of snack_food_1. Since the snack_food_1 is located within the carton_1 in the image, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", true], "holding snack_food_1": ["yes", 2.526918625546424e-09, 0.9999999974730813, "The image shows a robotic arm in a virtual household environment, and it appears to be holding an object. The object looks like a small yellow item, which matches the description of a snack_food_1. Since the question asks if the agent is holding snack_food_1, and the object in the robotic arm appears to be a yellow snack, it is reasonable to conclude that the agent is indeed holding snack_food_1.", false, "<explanation>\nThe image shows a robotic arm in a virtual household environment, and it appears to be holding an object. The object looks like a small yellow item, which matches the description of a snack_food_1. Since the question asks if the agent is holding snack_food_1, and the object in the robotic arm appears to be a yellow snack, it is reasonable to conclude that the agent is indeed holding snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "place-next-to(snack_food_1, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding snack_food_1": ["yes", 1.6423695437137221e-06, 0.9999983576304563, "The image shows a robotic arm, which is the agent, holding a yellow object that appears to be a snack food. Since the question asks if the agent is holding \"snack_food_1,\" and the object in the robot's grasp looks like a snack food, it is reasonable to conclude that the agent is indeed holding snack_food_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding a yellow object that appears to be a snack food. Since the question asks if the agent is holding \"snack_food_1,\" and the object in the robot's grasp looks like a snack food, it is reasonable to conclude that the agent is indeed holding snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable carton_1": ["yes", 3.332589962539652e-11, 0.9999999999666741, "The image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located in the center of the image, inside a box that the agent appears to be holding or about to hold. Since the carton_1 is within the box that the robotic arm is interacting with, it is likely within reach of the agent. Therefore, the carton_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located in the center of the image, inside a box that the agent appears to be holding or about to hold. Since the carton_1 is within the box that the robotic arm is interacting with, it is likely within reach of the agent. Therefore, the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable carton_1": ["yes", "no"], "reachable countertop_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["no", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open cabinet_1": ["no", "no"], "open door_1": ["yes", "no"], "holding countertop_1": ["no", "no"], "holding door_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop countertop_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,countertop_1": ["no", "no"], "ontop door_1,cabinet_1": ["yes", "no"], "ontop door_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "inside door_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["no", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto countertop_1,door_1": ["yes", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,countertop_1": ["no", "no"], "nextto door_1,cabinet_1": ["yes", "no"], "nextto door_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6451612903225806, "yes_accuracy": 0.25, "yes_correct": 1, "yes_total": 4, "no_accuracy": 0.7037037037037037, "no_correct": 19, "no_total": 27, "predicates": {"reachable": {"accuracy": 0.4, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 6, "no_total": 8}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8}}}, "step": 1, "actions": ["open-container(carton_1)", "navigate-to(cabinet_1)", "open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "no"], "reachable countertop_1": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["no", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open cabinet_1": ["no", "no"], "open door_1": ["yes", "no"], "holding countertop_1": ["no", "no"], "holding door_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop countertop_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,countertop_1": ["no", "no"], "ontop door_1,cabinet_1": ["no", "no"], "ontop door_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "inside door_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["no", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto countertop_1,door_1": ["yes", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,countertop_1": ["no", "no"], "nextto door_1,cabinet_1": ["yes", "no"], "nextto door_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7096774193548387, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.7407407407407407, "no_correct": 20, "no_total": 27, "predicates": {"reachable": {"accuracy": 0.6, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.875, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.875, "no_correct": 7, "no_total": 8}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8}}}, "step": 2, "actions": ["open-container(cabinet_1)", "open-container(carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "no"], "reachable countertop_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["yes", "yes"], "reachable door_1": ["yes", "no"], "open carton_1": ["yes", "yes"], "open cabinet_1": ["yes", "yes"], "open door_1": ["yes", "no"], "holding countertop_1": ["no", "no"], "holding snack_food_1": ["no", "no"], "holding door_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop countertop_1,door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,countertop_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["yes", "no"], "ontop snack_food_1,juice_1": ["no", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,countertop_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "ontop door_1,cabinet_1": ["no", "no"], "ontop door_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,door_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,cabinet_1": ["yes", "yes"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "inside door_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["no", "no"], "nextto countertop_1,snack_food_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["no", "no"], "nextto countertop_1,juice_1": ["no", "no"], "nextto countertop_1,door_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,countertop_1": ["yes", "no"], "nextto snack_food_1,cabinet_1": ["yes", "yes"], "nextto snack_food_1,juice_1": ["yes", "no"], "nextto snack_food_1,door_1": ["yes", "no"], "nextto door_1,carton_1": ["yes", "no"], "nextto door_1,countertop_1": ["yes", "no"], "nextto door_1,snack_food_1": ["yes", "no"], "nextto door_1,cabinet_1": ["yes", "no"], "nextto door_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.68, "yes_accuracy": 0.875, "yes_correct": 7, "yes_total": 8, "no_accuracy": 0.6428571428571429, "no_correct": 27, "no_total": 42, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.8666666666666667, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.8666666666666667, "no_correct": 13, "no_total": 15}, "inside": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "nextto": {"accuracy": 0.3333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.2857142857142857, "no_correct": 4, "no_total": 14}}}, "step": 4, "actions": ["grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "no"], "reachable countertop_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable juice_1": ["no", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open cabinet_1": ["yes", "yes"], "open door_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding snack_food_1": ["yes", "yes"], "holding door_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop countertop_1,door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,countertop_1": ["yes", "no"], "ontop snack_food_1,cabinet_1": ["no", "no"], "ontop snack_food_1,juice_1": ["no", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,countertop_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "ontop door_1,cabinet_1": ["no", "no"], "ontop door_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,door_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,cabinet_1": ["no", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "inside door_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["yes", "no"], "nextto countertop_1,snack_food_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto countertop_1,door_1": ["yes", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,countertop_1": ["yes", "no"], "nextto snack_food_1,cabinet_1": ["yes", "no"], "nextto snack_food_1,juice_1": ["yes", "no"], "nextto snack_food_1,door_1": ["yes", "no"], "nextto door_1,carton_1": ["yes", "no"], "nextto door_1,countertop_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"], "nextto door_1,cabinet_1": ["yes", "no"], "nextto door_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.66, "yes_accuracy": 0.5714285714285714, "yes_correct": 4, "yes_total": 7, "no_accuracy": 0.6744186046511628, "no_correct": 29, "no_total": 43, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.9333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.9333333333333333, "no_correct": 14, "no_total": 15}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 8, "no_total": 8}, "nextto": {"accuracy": 0.13333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.13333333333333333, "no_correct": 2, "no_total": 15}}}, "step": 5, "actions": ["navigate-to(carton_1)", "place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(snack_food_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["yes", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["no", "yes"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["yes", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7222222222222222, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.7857142857142857, "no_correct": 11, "no_total": 14, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}}}, "step": 6, "actions": ["navigate-to(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["yes", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["yes", "yes"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}}}, "step": 7, "actions": ["navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["yes", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["no", "yes"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["yes", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7222222222222222, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.7857142857142857, "no_correct": 11, "no_total": 14, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}}}, "step": 8, "actions": ["navigate-to(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["no", "yes"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["yes", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7222222222222222, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.7857142857142857, "no_correct": 11, "no_total": 14, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}}}, "step": 9, "actions": ["open-container(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["yes", "yes"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}}}, "step": 10, "actions": ["place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["yes", "yes"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}}}, "step": 11, "actions": ["place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["yes", "yes"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}}}, "step": 12, "actions": ["navigate-to(carton_1)", "place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(snack_food_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["yes", "yes"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8333333333333334, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}}}, "step": 13, "actions": ["place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable door_1": ["yes", "no"], "open carton_1": ["yes", "yes"], "open door_1": ["yes", "no"], "holding door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.6666666666666666, "no_correct": 4, "no_total": 6, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 15, "actions": ["navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "reachable apple_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "yes"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "holding snack_food_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,snack_food_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "ontop snack_food_1,countertop_1": ["yes", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "ontop snack_food_1,apple_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["no", "no"], "ontop snack_food_1,juice_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,cabinet_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,snack_food_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["yes", "no"], "nextto apple_1,snack_food_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["yes", "yes"], "nextto snack_food_1,countertop_1": ["yes", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"], "nextto snack_food_1,apple_1": ["yes", "no"], "nextto snack_food_1,cabinet_1": ["yes", "no"], "nextto snack_food_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6595744680851063, "yes_accuracy": 0.875, "yes_correct": 7, "yes_total": 8, "no_accuracy": 0.6153846153846154, "no_correct": 24, "no_total": 39, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 5, "yes_total": 5, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.8666666666666667, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "nextto": {"accuracy": 0.13333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.07142857142857142, "no_correct": 1, "no_total": 14}}}, "step": 16, "actions": ["grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable apple_1": ["yes", "yes"], "reachable snack_food_1": ["no", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["no", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "yes"], "holding countertop_1": ["no", "no"], "holding apple_1": ["yes", "no"], "holding snack_food_1": ["yes", "yes"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,snack_food_1": ["no", "no"], "ontop apple_1,cabinet_1": ["yes", "no"], "ontop apple_1,juice_1": ["no", "no"], "ontop snack_food_1,countertop_1": ["no", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "ontop snack_food_1,apple_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["no", "no"], "ontop snack_food_1,juice_1": ["yes", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["yes", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["no", "no"], "inside snack_food_1,cabinet_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,snack_food_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["yes", "no"], "nextto apple_1,snack_food_1": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "yes"], "nextto snack_food_1,countertop_1": ["yes", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"], "nextto snack_food_1,apple_1": ["yes", "no"], "nextto snack_food_1,cabinet_1": ["yes", "no"], "nextto snack_food_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.46808510638297873, "yes_accuracy": 0.5555555555555556, "yes_correct": 5, "yes_total": 9, "no_accuracy": 0.4473684210526316, "no_correct": 17, "no_total": 38, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.7333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.7142857142857143, "no_correct": 10, "no_total": 14}, "inside": {"accuracy": 0.8333333333333334, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.8333333333333334, "no_correct": 5, "no_total": 6}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 14}}}, "step": 17, "actions": ["navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["yes", "yes"], "open door_1": ["yes", "no"], "holding snack_food_1": ["yes", "yes"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["yes", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["no", "no"], "nextto snack_food_1,door_1": ["yes", "no"], "nextto door_1,carton_1": ["yes", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7777777777777778, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.7142857142857143, "no_correct": 10, "no_total": 14, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 2, "no_total": 4}}}, "step": 18, "actions": ["place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable door_1": ["yes", "no"], "open carton_1": ["no", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["yes", "no"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["no", "yes"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["yes", "yes"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "yes"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.6666666666666666, "yes_correct": 4, "yes_total": 6, "no_accuracy": 0.8333333333333334, "no_correct": 10, "no_total": 12, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.75, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "inside": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}}}, "step": 19, "actions": ["place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "yes"], "reachable snack_food_1": ["no", "yes"], "reachable door_1": ["yes", "no"], "open carton_1": ["no", "yes"], "open door_1": ["no", "no"], "holding snack_food_1": ["no", "no"], "holding door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["no", "yes"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "inside snack_food_1,carton_1": ["yes", "yes"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "yes"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,snack_food_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.5, "yes_correct": 3, "yes_total": 6, "no_accuracy": 0.9166666666666666, "no_correct": 11, "no_total": 12, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.75, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "inside": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}}}, "step": 20, "actions": ["open-container(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}], "remaining_actions": ["open-container(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, "data/planning/igibson/medium/packing_food_for_work_medium.pddl_Beechwood_0_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 6.793035439952e-10, 0.9999999993206965, "The image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be relatively close to the robotic arm, and the arm seems to be within a reachable distance to interact with objects on or inside the cabinet. Therefore, it is reasonable to conclude that the cabinet_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be relatively close to the robotic arm, and the arm seems to be within a reachable distance to interact with objects on or inside the cabinet. Therefore, it is reasonable to conclude that the cabinet_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["no", 0.999999999888484, 1.1151596338107634e-10, "The image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be within the same room but not directly adjacent to the robotic arm. The arm does not seem to be close enough to reach the cabinet_1 without moving closer.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be within the same room but not directly adjacent to the robotic arm. The arm does not seem to be close enough to reach the cabinet_1 without moving closer.\n</explanation>\n<answer>\nNo\n</answer>", false], "open cabinet_1": ["yes", 3.859766648907126e-06, 0.999996140233351, "In the image, the cabinet_1 is located on the left side. The doors of the cabinet_1 are visibly open, revealing the interior shelves. Therefore, the cabinet_1 is open.", false, "<explanation>\nIn the image, the cabinet_1 is located on the left side. The doors of the cabinet_1 are visibly open, revealing the interior shelves. Therefore, the cabinet_1 is open.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 2.4427830350599405e-10, 0.9999999997557217, "The image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be quite close to the agent, and the arm seems to be within a reachable distance to interact with objects on or inside the cabinet. Therefore, it is reasonable to conclude that the cabinet_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, and the robotic arm is positioned further back in the room, near the center. Given the perspective, the cabinet_1 appears to be quite close to the agent, and the arm seems to be within a reachable distance to interact with objects on or inside the cabinet. Therefore, it is reasonable to conclude that the cabinet_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open cabinet_1": ["no", 0.9999260987139008, 7.390128609914788e-05, "In the image, the cabinet_1 is visible on the left side. The doors of the cabinet_1 appear to be closed, as there are no visible gaps or open spaces indicating that it is open. Therefore, the cabinet_1 is not open.", true, "<explanation>\nIn the image, the cabinet_1 is visible on the left side. The doors of the cabinet_1 appear to be closed, as there are no visible gaps or open spaces indicating that it is open. Therefore, the cabinet_1 is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"open cabinet_1": ["yes", 3.0614273157233874e-05, 0.9999693857268428, "In the image, the cabinet labeled \"cabinet_1\" is visibly open, with its door swung outward, revealing the interior. This indicates that the cabinet is not closed.", true, "<explanation>\nIn the image, the cabinet labeled \"cabinet_1\" is visibly open, with its door swung outward, revealing the interior. This indicates that the cabinet is not closed.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable snack_food_1": ["no", 0.9999999999979033, 2.0966968183864995e-12, "The image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or cabinet on the left side of the image, near the open door. The robotic arm appears to be positioned further back in the room, near the center. Since the snack_food_1 is on a surface close to the left side and the robotic arm is further away, it is unlikely that the snack_food_1 is within reach of the agent at this moment.", false, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or cabinet on the left side of the image, near the open door. The robotic arm appears to be positioned further back in the room, near the center. Since the snack_food_1 is on a surface close to the left side and the robotic arm is further away, it is unlikely that the snack_food_1 is within reach of the agent at this moment.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "navigate-to(snack_food_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable snack_food_1": ["no", 0.9999999999993293, 6.706695432107356e-13, "The image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or cabinet on the left side of the image, near the open door. The robotic arm appears to be positioned further back in the room, near the center. Since the snack_food_1 is on a surface close to the left side and the robotic arm is further back, it is unlikely that the snack_food_1 is within reach of the agent at this moment.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or cabinet on the left side of the image, near the open door. The robotic arm appears to be positioned further back in the room, near the center. Since the snack_food_1 is on a surface close to the left side and the robotic arm is further back, it is unlikely that the snack_food_1 is within reach of the agent at this moment.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable snack_food_1": ["no", 0.9999999999973697, 2.630296554406468e-12, "The image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or cabinet on the left side of the image, near the open door. The robotic arm appears to be positioned further back in the room, near the center. Since the snack_food_1 is on a small table close to the left side and the robotic arm is further back, it is unlikely that the snack_food_1 is within reach of the agent at this moment.", false, "<explanation>\nThe image shows a robotic arm in a virtual household environment. The snack_food_1 is located on a small table or cabinet on the left side of the image, near the open door. The robotic arm appears to be positioned further back in the room, near the center. Since the snack_food_1 is on a small table close to the left side and the robotic arm is further back, it is unlikely that the snack_food_1 is within reach of the agent at this moment.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable carton_1": ["yes", 2.878281095319254e-13, 0.9999999999997121, "The image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on a shelf to the left side of the image, while the robotic arm is positioned further back in the room, near the center. Given the perspective, the carton_1 appears to be within a reachable distance from the robotic arm, as it is on a shelf that is not too high and the arm is relatively close to that area. Therefore, it is reasonable to conclude that the carton_1 is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on a shelf to the left side of the image, while the robotic arm is positioned further back in the room, near the center. Given the perspective, the carton_1 appears to be within a reachable distance from the robotic arm, as it is on a shelf that is not too high and the arm is relatively close to that area. Therefore, it is reasonable to conclude that the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable cabinet_1": ["yes", 3.2722617760075484e-10, 0.9999999996727739, "The image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, with its door slightly open. The robotic arm appears to be positioned further back in the room, near the center. Given the perspective, the cabinet_1 is quite close to the robotic arm, and the arm seems to be within a reachable distance to interact with objects on or inside the cabinet. Therefore, it is reasonable to conclude that the cabinet_1 is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The cabinet_1 is located on the left side of the image, with its door slightly open. The robotic arm appears to be positioned further back in the room, near the center. Given the perspective, the cabinet_1 is quite close to the robotic arm, and the arm seems to be within a reachable distance to interact with objects on or inside the cabinet. Therefore, it is reasonable to conclude that the cabinet_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable electric_refrigerator_1": {"before": false, "after": false}, "reachable sandwich_1": {"before": false, "after": false}}}, "action_info": "executed but failed"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 1.9482959473057593e-11, 0.999999999980517, "The image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on a shelf on the left side of the image, while the robotic arm is positioned further back in the room, near the center. Given the perspective, the carton_1 appears to be within a reasonable reach of the robotic arm, which is capable of extending and grasping objects. Therefore, it is likely that the carton_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on a shelf on the left side of the image, while the robotic arm is positioned further back in the room, near the center. Given the perspective, the carton_1 appears to be within a reasonable reach of the robotic arm, which is capable of extending and grasping objects. Therefore, it is likely that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(carton_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable carton_1": ["no", 0.9999999999975063, 2.4936539559902855e-12, "The image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on a shelf on the left side of the image, and the robotic arm is positioned further back in the room, near a desk and some objects. The distance between the robotic arm and the carton_1 appears to be significant, and the arm does not seem to be extended towards the shelf where the carton_1 is located. Based on this, the carton_1 does not seem to be within the immediate reach of the robotic arm.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on a shelf on the left side of the image, and the robotic arm is positioned further back in the room, near a desk and some objects. The distance between the robotic arm and the carton_1 appears to be significant, and the arm does not seem to be extended towards the shelf where the carton_1 is located. Based on this, the carton_1 does not seem to be within the immediate reach of the robotic arm.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable carton_1": ["yes", 1.253224560950903e-09, 0.9999999987467755, "The image shows a robotic arm (agent) with its gripper holding a carton. The carton_1 is located directly in front of the robotic arm, within the arm's reach. Since the arm is already holding the carton, it indicates that the carton is indeed within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) with its gripper holding a carton. The carton_1 is located directly in front of the robotic arm, within the arm's reach. Since the arm is already holding the carton, it indicates that the carton is indeed within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable electric_refrigerator_1": {"before": false, "after": false}, "reachable cabinet_1": {"before": true, "after": false}, "reachable sandwich_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable electric_refrigerator_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 4.094221835131677e-07, 0.9999995905778165, "The image shows a robotic arm reaching towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable carton_1": {"before": true, "after": false}, "reachable cabinet_1": {"before": false, "after": false}, "reachable sandwich_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 1.4452875312183096e-07, 0.9999998554712469, "The image shows a robotic arm reaching towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 8.202924179398488e-08, 0.9999999179707582, "The image shows a robotic arm holding a door, which appears to be part of an appliance. The door is positioned at an angle that suggests it is open, revealing the interior of the appliance. Since the question asks if the electric refrigerator is open, and the door is visibly ajar, it indicates that the refrigerator is indeed open.", false, "<explanation>\nThe image shows a robotic arm holding a door, which appears to be part of an appliance. The door is positioned at an angle that suggests it is open, revealing the interior of the appliance. Since the question asks if the electric refrigerator is open, and the door is visibly ajar, it indicates that the refrigerator is indeed open.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(sandwich_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable sandwich_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 4.127130415921716e-09, 0.9999999958728696, "The image shows a robotic arm extending towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is reaching towards it, indicating that it is within the arm's reach. Since the arm is already extended towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", false, "<explanation>\nThe image shows a robotic arm extending towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is reaching towards it, indicating that it is within the arm's reach. Since the arm is already extended towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable sandwich_1": {"before": false, "after": true}, "reachable carton_1": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}, "reachable snack_food_1": {"before": false, "after": false}}}, "action_info": "executed but failed"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 2.8524656551767065e-11, 0.9999999999714754, "The image shows a robotic arm extending towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against the wall, and the robotic arm is very close to it, with the hand or end effector near the front of the refrigerator. Given the proximity and the extension of the robotic arm, it is reasonable to conclude that the refrigerator is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm extending towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against the wall, and the robotic arm is very close to it, with the hand or end effector near the front of the refrigerator. Given the proximity and the extension of the robotic arm, it is reasonable to conclude that the refrigerator is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["no", 0.999999077898817, 9.221011829635979e-07, "The image shows a robotic arm near an object that appears to be a refrigerator. The refrigerator door is visible, and it is closed. There are no signs of the door being open, such as a gap or an open door handle. Therefore, the refrigerator is not open.", true, "<explanation>\nThe image shows a robotic arm near an object that appears to be a refrigerator. The refrigerator door is visible, and it is closed. There are no signs of the door being open, such as a gap or an open door handle. Therefore, the refrigerator is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"open electric_refrigerator_1": ["yes", 1.2093754218676348e-05, 0.9999879062457814, "The image shows an open refrigerator with visible shelves and items inside. Since the door is clearly swung open, the refrigerator is in an open state.", true, "<explanation>\nThe image shows an open refrigerator with visible shelves and items inside. Since the door is clearly swung open, the refrigerator is in an open state.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sandwich_1": ["yes", 4.254643089737294e-12, 0.9999999999957454, "The image shows a robotic arm (agent) positioned very close to a shelf with objects on it. The sandwich_1 is located on the middle shelf, which appears to be within the reach of the robotic arm, given its proximity and the typical reach of such an arm in a household simulator. Since the arm is extended towards the shelf and the sandwich_1 is on the same shelf, it is likely within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned very close to a shelf with objects on it. The sandwich_1 is located on the middle shelf, which appears to be within the reach of the robotic arm, given its proximity and the typical reach of such an arm in a household simulator. Since the arm is extended towards the shelf and the sandwich_1 is on the same shelf, it is likely within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(sandwich_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable sandwich_1": ["yes", 2.073207706176618e-09, 0.9999999979267923, "The image shows a robotic arm (agent) positioned very close to the sandwich_1, which is on a shelf. The arm appears to be extended towards the sandwich, indicating that it is within reach. Since the arm is close enough to interact with the sandwich, it suggests that the sandwich_1 is indeed within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned very close to the sandwich_1, which is on a shelf. The arm appears to be extended towards the sandwich, indicating that it is within reach. Since the arm is close enough to interact with the sandwich, it suggests that the sandwich_1 is indeed within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": {"holding sandwich_1": ["no", 0.9999950499826746, 4.950017325348924e-06, "The image shows a robotic arm, which is the agent, but it is not holding a sandwich. Instead, it appears to be holding a different object, possibly a container or a similar item. There is no visible sandwich in the robotic arm's grasp. Therefore, the answer is \"No\".", false, "<explanation>\nThe image shows a robotic arm, which is the agent, but it is not holding a sandwich. Instead, it appears to be holding a different object, possibly a container or a similar item. There is no visible sandwich in the robotic arm's grasp. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop sandwich_1,carton_1": ["no", 0.9999962255745093, 3.7744254907471616e-06, "The image shows a robotic arm holding a sandwich, and there is a carton nearby. To determine if the sandwich_1 is on top of the carton_1, I need to see if the sandwich is placed directly on the carton. In the image, the sandwich appears to be held by the robotic arm and is not resting on the carton. Therefore, the sandwich_1 is not on top of the carton_1.", true, "<explanation>\nThe image shows a robotic arm holding a sandwich, and there is a carton nearby. To determine if the sandwich_1 is on top of the carton_1, I need to see if the sandwich is placed directly on the carton. In the image, the sandwich appears to be held by the robotic arm and is not resting on the carton. Therefore, the sandwich_1 is not on top of the carton_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop sandwich_1,electric_refrigerator_1": ["no", 0.9999998340590701, 1.6594092983925758e-07, "The image shows a robotic arm holding a sandwich, and there is an electric refrigerator in the scene. To determine if the sandwich is on top of the refrigerator, I need to see if the sandwich is placed directly on the surface of the refrigerator. In the image, the sandwich is being held by the robotic arm and is not resting on the refrigerator. Therefore, the sandwich is not on top of the refrigerator.", true, "<explanation>\nThe image shows a robotic arm holding a sandwich, and there is an electric refrigerator in the scene. To determine if the sandwich is on top of the refrigerator, I need to see if the sandwich is placed directly on the surface of the refrigerator. In the image, the sandwich is being held by the robotic arm and is not resting on the refrigerator. Therefore, the sandwich is not on top of the refrigerator.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop sandwich_1,cabinet_1": ["no", 0.9999999985191583, 1.4808416388236912e-09, "The image shows a robotic arm holding a sandwich, with a cabinet in the background. The sandwich_1 is located on the counter, not on top of the cabinet_1. The cabinet appears to be above the counter, and the sandwich is not positioned on it. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm holding a sandwich, with a cabinet in the background. The sandwich_1 is located on the counter, not on top of the cabinet_1. The cabinet appears to be above the counter, and the sandwich is not positioned on it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop sandwich_1,snack_food_1": ["no", 0.9999993074821436, 6.925178563602078e-07, "The image shows a robotic arm holding a sandwich_1, and there is a snack_food_1 nearby on the surface. However, the snack_food_1 is not directly underneath or on top of the sandwich_1; it is located to the side. Therefore, the sandwich_1 is not on top of the snack_food_1.", true, "<explanation>\nThe image shows a robotic arm holding a sandwich_1, and there is a snack_food_1 nearby on the surface. However, the snack_food_1 is not directly underneath or on top of the sandwich_1; it is located to the side. Therefore, the sandwich_1 is not on top of the snack_food_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto sandwich_1,carton_1": ["yes", 1.532629645123291e-08, 0.9999999846737035, "The image shows a robotic arm holding a sandwich_1, and there is a carton_1 nearby on the surface. The sandwich_1 appears to be placed very close to the carton_1, possibly next to it. Since the question asks if the sandwich_1 is next to the carton_1, and based on their proximity in the image, the answer is yes.", false, "<explanation>\nThe image shows a robotic arm holding a sandwich_1, and there is a carton_1 nearby on the surface. The sandwich_1 appears to be placed very close to the carton_1, possibly next to it. Since the question asks if the sandwich_1 is next to the carton_1, and based on their proximity in the image, the answer is yes.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto sandwich_1,electric_refrigerator_1": ["yes", 1.491389477277057e-14, 0.9999999999999851, "The image shows a robotic arm holding a sandwich, with an electric refrigerator nearby. The sandwich_1 appears to be placed on a surface close to the refrigerator, but it is not clearly positioned directly next to it. Since the question asks if the sandwich_1 is next to the electric_refrigerator_1, and based on the visible proximity, it seems to be close but not necessarily directly adjacent. However, given the context and typical interpretation of \"next to,\" it is reasonable to conclude that the sandwich is indeed next to the refrigerator.", false, "<explanation>\nThe image shows a robotic arm holding a sandwich, with an electric refrigerator nearby. The sandwich_1 appears to be placed on a surface close to the refrigerator, but it is not clearly positioned directly next to it. Since the question asks if the sandwich_1 is next to the electric_refrigerator_1, and based on the visible proximity, it seems to be close but not necessarily directly adjacent. However, given the context and typical interpretation of \"next to,\" it is reasonable to conclude that the sandwich is indeed next to the refrigerator.\n</explanation>\n<answer>\nYes\n</answer>", true], "nextto sandwich_1,cabinet_1": ["no", 0.9999999965832334, 3.4167666597394315e-09, "The image shows a robotic arm holding a sandwich_1, and there is a cabinet_1 in the background. The sandwich_1 appears to be placed on a surface near the cabinet_1, but it is not directly next to or touching the cabinet_1. Based on the perspective, the sandwich_1 is close but not immediately adjacent to the cabinet_1. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm holding a sandwich_1, and there is a cabinet_1 in the background. The sandwich_1 appears to be placed on a surface near the cabinet_1, but it is not directly next to or touching the cabinet_1. Based on the perspective, the sandwich_1 is close but not immediately adjacent to the cabinet_1. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto sandwich_1,snack_food_1": ["yes", 5.150413541615459e-10, 0.9999999994849587, "In the image, the sandwich_1 is located on the counter, and the snack_food_1 is also on the counter but farther away from the sandwich_1. The sandwich_1 appears to be close to the edge of the counter, while the snack_food_1 is positioned more towards the middle. Based on their positions, the sandwich_1 is next to the snack_food_1.", false, "<explanation>\nIn the image, the sandwich_1 is located on the counter, and the snack_food_1 is also on the counter but farther away from the sandwich_1. The sandwich_1 appears to be close to the edge of the counter, while the snack_food_1 is positioned more towards the middle. Based on their positions, the sandwich_1 is next to the snack_food_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "inside sandwich_1,electric_refrigerator_1": ["no", 0.9999904253642368, 9.574635763222077e-06, "The image shows a robotic arm holding a sandwich, and there is an electric refrigerator nearby. However, the sandwich is not inside the refrigerator; it appears to be outside or on top of the refrigerator. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm holding a sandwich, and there is an electric refrigerator nearby. However, the sandwich is not inside the refrigerator; it appears to be outside or on top of the refrigerator. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop sandwich_1,sandwich_1": {"before": null, "after": false}, "nextto sandwich_1,sandwich_1": {"before": null, "after": false}}}, "action_info": "success"}, {"action": "grasp(sandwich_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable sandwich_1": ["yes", 4.682071631536587e-09, 0.9999999953179284, "The image shows a robotic arm (agent) and a sandwich_1 placed on a surface. The sandwich_1 appears to be close to the robotic arm, which suggests it is within reach. Since the robotic arm is positioned directly next to the sandwich, it is likely that the sandwich is within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) and a sandwich_1 placed on a surface. The sandwich_1 appears to be close to the robotic arm, which suggests it is within reach. Since the robotic arm is positioned directly next to the sandwich, it is likely that the sandwich is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding snack_food_1": ["no", 0.9999999999986997, 1.3002949592769268e-12, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but the object is not clearly identifiable as snack_food_1. The object in the robotic arm looks like a cylindrical container or similar item, not specifically a snack_food_1. Since the question asks if the agent is holding snack_food_1, and based on the visual evidence, it does not appear to be holding that specific item.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but the object is not clearly identifiable as snack_food_1. The object in the robotic arm looks like a cylindrical container or similar item, not specifically a snack_food_1. Since the question asks if the agent is holding snack_food_1, and based on the visual evidence, it does not appear to be holding that specific item.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable carton_1": ["no", "no"], "reachable countertop_1": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["yes", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["no", "yes"], "open cabinet_1": ["no", "no"], "open door_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding door_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop countertop_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,countertop_1": ["no", "no"], "ontop door_1,cabinet_1": ["yes", "no"], "ontop door_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "inside door_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["no", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto countertop_1,door_1": ["yes", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,countertop_1": ["no", "no"], "nextto door_1,cabinet_1": ["yes", "no"], "nextto door_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7741935483870968, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.7777777777777778, "no_correct": 21, "no_total": 27, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 6, "no_total": 8}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8}}}, "step": 1, "actions": ["open-container(cabinet_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-next-to(snack_food_1, carton_1)", "open-container(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(snack_food_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "no"], "reachable countertop_1": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["yes", "yes"], "reachable door_1": ["yes", "no"], "open carton_1": ["no", "yes"], "open cabinet_1": ["no", "no"], "open door_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding door_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop countertop_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,countertop_1": ["no", "no"], "ontop door_1,cabinet_1": ["no", "no"], "ontop door_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "inside door_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["no", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto countertop_1,door_1": ["yes", "no"], "nextto door_1,carton_1": ["no", "no"], "nextto door_1,countertop_1": ["no", "no"], "nextto door_1,cabinet_1": ["yes", "no"], "nextto door_1,juice_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7096774193548387, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.7037037037037037, "no_correct": 19, "no_total": 27, "predicates": {"reachable": {"accuracy": 0.6, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 6, "no_total": 8}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 5, "no_total": 5}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8}}}, "step": 2, "actions": ["open-container(cabinet_1)", "open-container(carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "no"], "reachable countertop_1": ["yes", "yes"], "reachable snack_food_1": ["no", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["no", "yes"], "reachable door_1": ["yes", "no"], "open carton_1": ["yes", "yes"], "open cabinet_1": ["yes", "yes"], "open door_1": ["yes", "no"], "holding countertop_1": ["no", "no"], "holding snack_food_1": ["no", "no"], "holding door_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop countertop_1,door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,countertop_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["no", "no"], "ontop snack_food_1,juice_1": ["no", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,countertop_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "ontop door_1,cabinet_1": ["no", "no"], "ontop door_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,door_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,cabinet_1": ["yes", "yes"], "inside snack_food_1,door_1": ["no", "no"], "inside door_1,carton_1": ["no", "no"], "inside door_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["no", "no"], "nextto countertop_1,snack_food_1": ["no", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto countertop_1,door_1": ["yes", "no"], "nextto snack_food_1,carton_1": ["no", "no"], "nextto snack_food_1,countertop_1": ["yes", "no"], "nextto snack_food_1,cabinet_1": ["yes", "yes"], "nextto snack_food_1,juice_1": ["no", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["yes", "no"], "nextto door_1,countertop_1": ["yes", "no"], "nextto door_1,snack_food_1": ["yes", "no"], "nextto door_1,cabinet_1": ["yes", "no"], "nextto door_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.72, "yes_accuracy": 0.75, "yes_correct": 6, "yes_total": 8, "no_accuracy": 0.7142857142857143, "no_correct": 30, "no_total": 42, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.9333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.9333333333333333, "no_correct": 14, "no_total": 15}, "inside": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "nextto": {"accuracy": 0.4, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.35714285714285715, "no_correct": 5, "no_total": 14}}}, "step": 3, "actions": ["navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "no"], "reachable countertop_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["no", "yes"], "reachable door_1": ["yes", "no"], "open carton_1": ["yes", "yes"], "open cabinet_1": ["yes", "yes"], "open door_1": ["yes", "no"], "holding countertop_1": ["no", "no"], "holding snack_food_1": ["no", "no"], "holding door_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop countertop_1,door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,countertop_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["no", "no"], "ontop snack_food_1,juice_1": ["no", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,countertop_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "ontop door_1,cabinet_1": ["no", "no"], "ontop door_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,door_1": ["no", "no"], "inside snack_food_1,carton_1": ["yes", "no"], "inside snack_food_1,cabinet_1": ["yes", "yes"], "inside snack_food_1,door_1": ["yes", "no"], "inside door_1,carton_1": ["no", "no"], "inside door_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["no", "no"], "nextto countertop_1,snack_food_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["no", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto countertop_1,door_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,countertop_1": ["yes", "no"], "nextto snack_food_1,cabinet_1": ["yes", "yes"], "nextto snack_food_1,juice_1": ["no", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["yes", "no"], "nextto door_1,countertop_1": ["yes", "no"], "nextto door_1,snack_food_1": ["yes", "no"], "nextto door_1,cabinet_1": ["yes", "no"], "nextto door_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.72, "yes_accuracy": 0.875, "yes_correct": 7, "yes_total": 8, "no_accuracy": 0.6904761904761905, "no_correct": 29, "no_total": 42, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 15, "no_total": 15}, "inside": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}, "nextto": {"accuracy": 0.4, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.35714285714285715, "no_correct": 5, "no_total": 14}}}, "step": 4, "actions": ["navigate-to(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "no"], "reachable countertop_1": ["yes", "yes"], "reachable snack_food_1": ["no", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable juice_1": ["no", "yes"], "reachable door_1": ["no", "no"], "open carton_1": ["yes", "yes"], "open cabinet_1": ["yes", "yes"], "open door_1": ["yes", "no"], "holding countertop_1": ["no", "no"], "holding snack_food_1": ["no", "no"], "holding door_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop countertop_1,door_1": ["no", "no"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,countertop_1": ["yes", "no"], "ontop snack_food_1,cabinet_1": ["no", "no"], "ontop snack_food_1,juice_1": ["no", "no"], "ontop snack_food_1,door_1": ["no", "no"], "ontop door_1,carton_1": ["no", "no"], "ontop door_1,countertop_1": ["no", "no"], "ontop door_1,snack_food_1": ["no", "no"], "ontop door_1,cabinet_1": ["no", "no"], "ontop door_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,door_1": ["no", "no"], "inside snack_food_1,carton_1": ["yes", "no"], "inside snack_food_1,cabinet_1": ["yes", "yes"], "inside snack_food_1,door_1": ["yes", "no"], "inside door_1,carton_1": ["no", "no"], "inside door_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["no", "no"], "nextto countertop_1,snack_food_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["no", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto countertop_1,door_1": ["no", "no"], "nextto snack_food_1,carton_1": ["yes", "no"], "nextto snack_food_1,countertop_1": ["yes", "no"], "nextto snack_food_1,cabinet_1": ["yes", "yes"], "nextto snack_food_1,juice_1": ["no", "no"], "nextto snack_food_1,door_1": ["no", "no"], "nextto door_1,carton_1": ["yes", "no"], "nextto door_1,countertop_1": ["yes", "no"], "nextto door_1,snack_food_1": ["yes", "no"], "nextto door_1,cabinet_1": ["yes", "no"], "nextto door_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7, "yes_accuracy": 0.75, "yes_correct": 6, "yes_total": 8, "no_accuracy": 0.6904761904761905, "no_correct": 29, "no_total": 42, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.9333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.9333333333333333, "no_correct": 14, "no_total": 15}, "inside": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.7142857142857143, "no_correct": 5, "no_total": 7}, "nextto": {"accuracy": 0.4, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.35714285714285715, "no_correct": 5, "no_total": 14}}}, "step": 5, "actions": ["navigate-to(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, {"enum_results": {"reachable electric_refrigerator_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}}}, "step": 8, "actions": ["navigate-to(sandwich_1)", "grasp(sandwich_1)", "navigate-to(snack_food_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable electric_refrigerator_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 9, "actions": ["open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(snack_food_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "no"], "reachable countertop_1": ["yes", "no"], "reachable sandwich_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "yes"], "reachable snack_food_1": ["yes", "no"], "reachable cabinet_1": ["yes", "no"], "reachable juice_1": ["yes", "no"], "open carton_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "yes"], "open cabinet_1": ["yes", "yes"], "holding countertop_1": ["no", "no"], "holding sandwich_1": ["no", "yes"], "holding snack_food_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,sandwich_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["yes", "no"], "ontop countertop_1,snack_food_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop sandwich_1,carton_1": ["no", "no"], "ontop sandwich_1,countertop_1": ["yes", "no"], "ontop sandwich_1,electric_refrigerator_1": ["no", "no"], "ontop sandwich_1,snack_food_1": ["no", "no"], "ontop sandwich_1,cabinet_1": ["no", "no"], "ontop sandwich_1,juice_1": ["no", "no"], "ontop snack_food_1,carton_1": ["no", "no"], "ontop snack_food_1,countertop_1": ["no", "no"], "ontop snack_food_1,sandwich_1": ["no", "no"], "ontop snack_food_1,electric_refrigerator_1": ["no", "no"], "ontop snack_food_1,cabinet_1": ["yes", "no"], "ontop snack_food_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside sandwich_1,carton_1": ["no", "no"], "inside sandwich_1,electric_refrigerator_1": ["no", "no"], "inside sandwich_1,cabinet_1": ["no", "no"], "inside snack_food_1,carton_1": ["no", "no"], "inside snack_food_1,electric_refrigerator_1": ["yes", "no"], "inside snack_food_1,cabinet_1": ["no", "yes"], "nextto countertop_1,carton_1": ["yes", "no"], "nextto countertop_1,sandwich_1": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,snack_food_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto sandwich_1,carton_1": ["no", "no"], "nextto sandwich_1,countertop_1": ["yes", "no"], "nextto sandwich_1,electric_refrigerator_1": ["no", "yes"], "nextto sandwich_1,snack_food_1": ["no", "no"], "nextto sandwich_1,cabinet_1": ["yes", "no"], "nextto sandwich_1,juice_1": ["no", "no"], "nextto snack_food_1,carton_1": ["no", "no"], "nextto snack_food_1,countertop_1": ["no", "no"], "nextto snack_food_1,sandwich_1": ["no", "no"], "nextto snack_food_1,electric_refrigerator_1": ["yes", "no"], "nextto snack_food_1,cabinet_1": ["no", "yes"], "nextto snack_food_1,juice_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.5689655172413793, "yes_accuracy": 0.4444444444444444, "yes_correct": 4, "yes_total": 9, "no_accuracy": 0.5918367346938775, "no_correct": 29, "no_total": 49, "predicates": {"reachable": {"accuracy": 0.2857142857142857, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 5}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.7777777777777778, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.7777777777777778, "no_correct": 14, "no_total": 18}, "inside": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.875, "no_correct": 7, "no_total": 8}, "nextto": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.375, "no_correct": 6, "no_total": 16}}}, "step": 11, "actions": ["grasp(sandwich_1)", "place-inside(sandwich_1, carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"]}], "remaining_actions": ["place-inside(sandwich_1, carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"]}, "data/planning/igibson/medium/packing_food_for_work_medium.pddl_Wainscott_0_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 1.228046313529307e-06, 0.9999987719536865, "The image shows a robotic arm (agent) extending towards a cabinet labeled \"cabinet_1.\" The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards the cabinet, it suggests that the cabinet is accessible to the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards a cabinet labeled \"cabinet_1.\" The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards the cabinet, it suggests that the cabinet is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 1.930693479206407e-08, 0.9999999806930652, "The image shows a robotic arm (agent) extending towards the right side of the scene. The cabinet_1 is located on the right side of the image, close to the robotic arm. Given the position and the extension of the robotic arm, it appears that the cabinet_1 is within reach of the agent. Therefore, the answer is \"Yes\".", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards the right side of the scene. The cabinet_1 is located on the right side of the image, close to the robotic arm. Given the position and the extension of the robotic arm, it appears that the cabinet_1 is within reach of the agent. Therefore, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", false], "open cabinet_1": ["no", 0.9999999181069579, 8.189304214780023e-08, "The image shows a kitchen with a robotic arm and various objects. The cabinet labeled \"cabinet_1\" is visible on the right side of the image. It appears to be closed, as the doors are flush and there are no visible gaps or open spaces indicating that it is open. Therefore, the cabinet_1 is not open.", true, "<explanation>\nThe image shows a kitchen with a robotic arm and various objects. The cabinet labeled \"cabinet_1\" is visible on the right side of the image. It appears to be closed, as the doors are flush and there are no visible gaps or open spaces indicating that it is open. Therefore, the cabinet_1 is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 1.6834886610564894e-06, 0.999998316511339, "The image shows a robotic arm (agent) extending towards a cabinet labeled \"cabinet_1.\" The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards the cabinet, it suggests that the cabinet is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards a cabinet labeled \"cabinet_1.\" The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards the cabinet, it suggests that the cabinet is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "open cabinet_1": ["no", 0.9999840443923913, 1.5955607608647534e-05, "In the image, the cabinet labeled as \"cabinet_1\" appears to be closed. There are no visible gaps or open doors indicating that it is open. The cabinet door is flush with the rest of the cabinet, suggesting it is shut.", true, "<explanation>\nIn the image, the cabinet labeled as \"cabinet_1\" appears to be closed. There are no visible gaps or open doors indicating that it is open. The cabinet door is flush with the rest of the cabinet, suggesting it is shut.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable carton_1": ["yes", "no"], "reachable countertop_1": ["no", "no"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable apple_1": ["yes", "no"], "reachable cabinet_1": ["yes", "no"], "reachable juice_1": ["no", "no"], "open carton_1": ["no", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,juice_1": ["no", "no"], "ontop apple_1,carton_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,carton_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,carton_1": ["no", "no"], "nextto apple_1,countertop_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,juice_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.7567567567567568, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.7941176470588235, "no_correct": 27, "no_total": 34, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.3333333333333333, "no_correct": 2, "no_total": 6}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 9, "no_total": 9}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "nextto": {"accuracy": 0.6, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.6666666666666666, "no_correct": 6, "no_total": 9}}}, "step": 1, "actions": ["open-container(cabinet_1)", "open-container(carton_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "place-inside(sandwich_1, carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["no", "no"], "reachable countertop_1": ["no", "no"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable apple_1": ["no", "no"], "reachable cabinet_1": ["yes", "no"], "reachable juice_1": ["no", "no"], "open carton_1": ["no", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop apple_1,carton_1": ["yes", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,carton_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,carton_1": ["no", "no"], "nextto apple_1,countertop_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,juice_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6756756756756757, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 3, "no_accuracy": 0.7352941176470589, "no_correct": 25, "no_total": 34, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 4, "no_total": 6}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.6, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.6666666666666666, "no_correct": 6, "no_total": 9}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "nextto": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5555555555555556, "no_correct": 5, "no_total": 9}}}, "step": 2, "actions": ["open-container(cabinet_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-next-to(sandwich_1, carton_1)", "open-container(carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(sandwich_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(sandwich_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}], "remaining_actions": ["open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-next-to(sandwich_1, carton_1)", "open-container(carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(sandwich_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(sandwich_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"]}, "data/planning/igibson/medium/packing_food_for_work_medium.pddl_Wainscott_0_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 2.1537235933307885e-07, 0.9999997846276407, "The image shows a robotic arm (agent) extending towards the right side of the scene. The cabinet_1 is located on the right side of the image, close to the robotic arm. Given the position of the robotic arm and the proximity of the cabinet, it appears that the cabinet_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the right side of the scene. The cabinet_1 is located on the right side of the image, close to the robotic arm. Given the position of the robotic arm and the proximity of the cabinet, it appears that the cabinet_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["no", 0.9999999999999793, 2.0607987675936227e-14, "The image shows a robotic arm (agent) extending towards the right side of the scene. The carton_1 is located on a small cart or table near the center of the image, slightly to the left. The robotic arm appears to be reaching towards the right wall, not directly towards the cart or table where the carton_1 is placed. Based on the position of the arm and the carton, the carton_1 does not seem to be within the reach of the robotic arm in this scene.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the right side of the scene. The carton_1 is located on a small cart or table near the center of the image, slightly to the left. The robotic arm appears to be reaching towards the right wall, not directly towards the cart or table where the carton_1 is placed. Based on the position of the arm and the carton, the carton_1 does not seem to be within the reach of the robotic arm in this scene.\n</explanation>\n<answer>\nNo\n</answer>", true], "open carton_1": ["no", 0.9999999967981088, 3.2018912054923738e-09, "The image shows a kitchen with various objects, including a robotic arm holding a carton. To determine if the carton is open, I need to look for signs such as an open lid or flaps. The carton appears to be closed, with no visible signs of it being open, such as an open top or flaps. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a kitchen with various objects, including a robotic arm holding a carton. To determine if the carton is open, I need to look for signs such as an open lid or flaps. The carton appears to be closed, with no visible signs of it being open, such as an open top or flaps. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 9.482598631310091e-07, 0.9999990517401369, "The image shows a robotic arm (agent) extending towards a cabinet labeled \"cabinet_1.\" The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards the cabinet, it suggests that the cabinet is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards a cabinet labeled \"cabinet_1.\" The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards the cabinet, it suggests that the cabinet is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "open cabinet_1": ["no", 0.9999999948571062, 5.14289382227547e-09, "The image shows a kitchen with a robotic arm and various objects. The cabinet labeled \"cabinet_1\" is visible in the image. To determine if it is open, I need to look at the cabinet doors and see if they are ajar or closed. In the image, the cabinet door appears to be closed, with no visible gap or opening. Therefore, the cabinet is not open.", true, "<explanation>\nThe image shows a kitchen with a robotic arm and various objects. The cabinet labeled \"cabinet_1\" is visible in the image. To determine if it is open, I need to look at the cabinet doors and see if they are ajar or closed. In the image, the cabinet door appears to be closed, with no visible gap or opening. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "open-container(cabinet_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable cabinet_1": ["yes", 1.5793957731300165e-06, 0.9999984206042268, "The image shows a robotic arm (agent) extending towards a cabinet labeled \"cabinet_1.\" The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards the cabinet, it suggests that the cabinet is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards a cabinet labeled \"cabinet_1.\" The arm appears to be close to or touching the cabinet, indicating that it is within reach. Since the arm is actively reaching towards the cabinet, it suggests that the cabinet is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "open cabinet_1": ["no", 0.9999999946032042, 5.396795839752274e-09, "The image shows a kitchen with a robotic arm and various objects. The cabinet labeled \"cabinet_1\" is visible in the image. To determine if it is open, I need to look at the cabinet doors and see if they are ajar or closed. In the image, the cabinet door appears to be closed, with no visible gap or opening. Therefore, the cabinet is not open.", true, "<explanation>\nThe image shows a kitchen with a robotic arm and various objects. The cabinet labeled \"cabinet_1\" is visible in the image. To determine if it is open, I need to look at the cabinet doors and see if they are ajar or closed. In the image, the cabinet door appears to be closed, with no visible gap or opening. Therefore, the cabinet is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding sandwich_1": [true, false, false], "holding snack_food_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable carton_1": ["yes", "no"], "reachable countertop_1": ["no", "no"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable apple_1": ["yes", "no"], "reachable cabinet_1": ["yes", "no"], "reachable juice_1": ["no", "no"], "open carton_1": ["no", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["yes", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop apple_1,carton_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,carton_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,carton_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,juice_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6216216216216216, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 3, "no_accuracy": 0.6764705882352942, "no_correct": 23, "no_total": 34, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.3333333333333333, "no_correct": 2, "no_total": 6}, "open": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.7, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.7777777777777778, "no_correct": 7, "no_total": 9}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "nextto": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5555555555555556, "no_correct": 5, "no_total": 9}}}, "step": 1, "actions": ["open-container(carton_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "place-inside(sandwich_1, carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "no"], "reachable countertop_1": ["no", "no"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable apple_1": ["yes", "no"], "reachable cabinet_1": ["yes", "no"], "reachable juice_1": ["no", "no"], "open carton_1": ["no", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,carton_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop apple_1,carton_1": ["yes", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,carton_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,carton_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,juice_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.6486486486486487, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.6764705882352942, "no_correct": 23, "no_total": 34, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.3333333333333333, "no_correct": 2, "no_total": 6}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.6, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.6666666666666666, "no_correct": 6, "no_total": 9}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "nextto": {"accuracy": 0.6, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.5555555555555556, "no_correct": 5, "no_total": 9}}}, "step": 2, "actions": ["open-container(cabinet_1)", "open-container(carton_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "place-inside(sandwich_1, carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"]}, {"enum_results": {"reachable carton_1": ["yes", "no"], "reachable countertop_1": ["no", "no"], "reachable electric_refrigerator_1": ["yes", "no"], "reachable apple_1": ["yes", "no"], "reachable cabinet_1": ["yes", "no"], "reachable juice_1": ["no", "no"], "open carton_1": ["no", "yes"], "open electric_refrigerator_1": ["no", "no"], "open cabinet_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding apple_1": ["no", "no"], "ontop countertop_1,carton_1": ["yes", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,juice_1": ["yes", "no"], "ontop apple_1,carton_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,juice_1": ["no", "no"], "inside countertop_1,carton_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside apple_1,carton_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "nextto countertop_1,carton_1": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,juice_1": ["yes", "no"], "nextto apple_1,carton_1": ["no", "no"], "nextto apple_1,countertop_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,juice_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6486486486486487, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 3, "no_accuracy": 0.7058823529411765, "no_correct": 24, "no_total": 34, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.3333333333333333, "no_correct": 2, "no_total": 6}, "open": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.6, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.6666666666666666, "no_correct": 6, "no_total": 9}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "nextto": {"accuracy": 0.6, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.6666666666666666, "no_correct": 6, "no_total": 9}}}, "step": 3, "actions": ["open-container(cabinet_1)", "open-container(carton_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "place-inside(sandwich_1, carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"]}], "remaining_actions": ["open-container(carton_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "place-inside(sandwich_1, carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"]}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Benevolence_1_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(plaything_2)", "action_correct": true, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable plaything_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable plaything_2": ["yes", 1.0356766409014585e-12, 0.9999999999989643, "The image shows a robotic arm (agent) holding an object, with several objects labeled as \"plaything\" in red. The \"plaything_2\" is located on the floor, directly in front of the robotic arm. The arm appears to be extended towards the \"plaything_2,\" suggesting that it is within reach. Since the robotic arm is close to \"plaything_2\" and appears to be aiming at it, it is reasonable to conclude that \"plaything_2\" is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) holding an object, with several objects labeled as \"plaything\" in red. The \"plaything_2\" is located on the floor, directly in front of the robotic arm. The arm appears to be extended towards the \"plaything_2,\" suggesting that it is within reach. Since the robotic arm is close to \"plaything_2\" and appears to be aiming at it, it is reasonable to conclude that \"plaything_2\" is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["no", 0.9999999999339667, 6.603333723618017e-11, "The image shows a robotic arm (agent) holding a gun-like object, with several objects labeled as \"carton\" and \"plaything\" in the environment. The carton_1 is not visible in the image, only carton_2 is visible. Since carton_1 is not present in the image, I cannot determine if it is within reach of the agent. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm (agent) holding a gun-like object, with several objects labeled as \"carton\" and \"plaything\" in the environment. The carton_1 is not visible in the image, only carton_2 is visible. Since carton_1 is not present in the image, I cannot determine if it is within reach of the agent. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable table_1": ["no", 1.0, 4.244501459241047e-20, "The image shows a robotic arm (agent) holding an object, with several objects labeled as \"plaything\" and \"apartment.\" The table is not explicitly labeled in the image, but there is a table visible on the left side of the image with chairs around it. The robotic arm is positioned towards the right side of the image, holding an object, and appears to be quite close to the center of the room. The table on the left side is some distance away from the robotic arm's current position, and there is no clear indication that the robotic arm is within reach of the table. Based on the perspective and the position of the robotic arm, it does not seem to be close enough to reach the table without moving.", true, "<explanation>\nThe image shows a robotic arm (agent) holding an object, with several objects labeled as \"plaything\" and \"apartment.\" The table is not explicitly labeled in the image, but there is a table visible on the left side of the image with chairs around it. The robotic arm is positioned towards the right side of the image, holding an object, and appears to be quite close to the center of the room. The table on the left side is some distance away from the robotic arm's current position, and there is no clear indication that the robotic arm is within reach of the table. Based on the perspective and the position of the robotic arm, it does not seem to be close enough to reach the table without moving.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {"reachable plaything_1": {"before": false, "after": false}, "reachable plaything_3": {"before": false, "after": false}, "reachable plaything_4": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["yes", 5.75366633274106e-09, 0.9999999942463337, "The image shows a robotic arm (agent) holding an object, and there is a plaything labeled \"plaything_2\" on the floor. The plaything_2 appears to be relatively close to the robotic arm, within a distance that seems reachable given the arm\u2019s position and length. Since the robotic arm is extended towards the plaything_2, it suggests that the plaything_2 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) holding an object, and there is a plaything labeled \"plaything_2\" on the floor. The plaything_2 appears to be relatively close to the robotic arm, within a distance that seems reachable given the arm\u2019s position and length. Since the robotic arm is extended towards the plaything_2, it suggests that the plaything_2 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": {"holding plaything_2": ["yes", 0.00011000264780442059, 0.9998899973521955, "The image shows a robotic arm, which is the agent, holding an object labeled \"plaything_2.\" Since the arm is grasping this object, it indicates that the agent is indeed holding \"plaything_2.\"", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding an object labeled \"plaything_2.\" Since the arm is grasping this object, it indicates that the agent is indeed holding \"plaything_2.\"\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop plaything_2,carton_1": ["no", 0.9999281141715629, 7.188582843707166e-05, "In the image, the object labeled \"plaything_2\" is positioned below the object labeled \"carton_1.\" The \"plaything_2\" appears to be inside or underneath the \"carton_1,\" not on top of it. Therefore, the answer is \"No.\"", true, "<explanation>\nIn the image, the object labeled \"plaything_2\" is positioned below the object labeled \"carton_1.\" The \"plaything_2\" appears to be inside or underneath the \"carton_1,\" not on top of it. Therefore, the answer is \"No.\"\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop plaything_2,table_1": ["no", 0.9999999999164603, 8.353968119649871e-11, "The image shows a robotic arm holding a plaything labeled \"plaything_2\" near a table. The table is visible in the scene, with chairs around it. The plaything_2 appears to be hanging or being held close to the table, but it is not clearly on top of the table. It is more likely being held or suspended near the table rather than resting on it.", true, "<explanation>\nThe image shows a robotic arm holding a plaything labeled \"plaything_2\" near a table. The table is visible in the scene, with chairs around it. The plaything_2 appears to be hanging or being held close to the table, but it is not clearly on top of the table. It is more likely being held or suspended near the table rather than resting on it.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto plaything_2,carton_1": ["yes", 2.0673759952822468e-07, 0.9999997932624005, "The image shows a robotic arm holding a plaything labeled \"plaything_2\" and a carton labeled \"carton_1\" on the floor. The plaything_2 is positioned very close to the carton_1, with no significant space between them. Based on their proximity, the plaything_2 is next to the carton_1.", false, "<explanation>\nThe image shows a robotic arm holding a plaything labeled \"plaything_2\" and a carton labeled \"carton_1\" on the floor. The plaything_2 is positioned very close to the carton_1, with no significant space between them. Based on their proximity, the plaything_2 is next to the carton_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto plaything_2,table_1": ["no", 0.9999999998611391, 1.3886088231280722e-10, "The image shows a robotic arm holding a plaything labeled \"plaything_2.\" The table_1 is located on the left side of the image, with chairs around it. The plaything_2 appears to be hanging or positioned near the robotic arm, which is in the center of the image. It is not directly next to the table_1, as it is closer to the robotic arm and not adjacent to the table surface or chairs. Therefore, the plaything_2 is not next to the table_1.", true, "<explanation>\nThe image shows a robotic arm holding a plaything labeled \"plaything_2.\" The table_1 is located on the left side of the image, with chairs around it. The plaything_2 appears to be hanging or positioned near the robotic arm, which is in the center of the image. It is not directly next to the table_1, as it is closer to the robotic arm and not adjacent to the table surface or chairs. Therefore, the plaything_2 is not next to the table_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop plaything_2,plaything_1": {"before": false, "after": false}, "ontop plaything_2,plaything_2": {"before": null, "after": false}, "ontop plaything_2,plaything_3": {"before": false, "after": false}, "ontop plaything_2,plaything_4": {"before": false, "after": false}, "nextto plaything_2,plaything_1": {"before": false, "after": false}, "nextto plaything_2,plaything_2": {"before": null, "after": false}, "nextto plaything_2,plaything_3": {"before": false, "after": false}, "nextto plaything_2,plaything_4": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["yes", 1.0279715770015645e-08, 0.9999999897202843, "The image shows a robotic arm (agent) holding a plaything, labeled \"plaything_2,\" which is located very close to the arm. The plaything_2 appears to be within the reach of the robotic arm, as it is being held by the arm itself. Therefore, the plaything_2 is indeed in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) holding a plaything, labeled \"plaything_2,\" which is located very close to the arm. The plaything_2 appears to be within the reach of the robotic arm, as it is being held by the arm itself. Therefore, the plaything_2 is indeed in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable plaything_6": ["yes", "yes"], "reachable plaything_8": ["no", "no"], "reachable carton_1": ["yes", "yes"], "reachable carton_2": ["yes", "yes"], "reachable table_1": ["yes", "no"], "holding plaything_2": ["no", "yes"], "holding plaything_6": ["yes", "no"], "holding plaything_8": ["no", "no"], "open carton_1": ["yes", "yes"], "open carton_2": ["yes", "yes"], "ontop plaything_2,plaything_6": ["no", "no"], "ontop plaything_2,plaything_8": ["no", "no"], "ontop plaything_2,carton_1": ["no", "no"], "ontop plaything_2,carton_2": ["yes", "no"], "ontop plaything_2,table_1": ["no", "no"], "ontop plaything_6,plaything_2": ["no", "no"], "ontop plaything_6,plaything_8": ["no", "no"], "ontop plaything_6,carton_1": ["no", "no"], "ontop plaything_6,carton_2": ["no", "no"], "ontop plaything_6,table_1": ["no", "no"], "ontop plaything_8,plaything_2": ["no", "no"], "ontop plaything_8,plaything_6": ["no", "no"], "ontop plaything_8,carton_1": ["no", "no"], "ontop plaything_8,carton_2": ["no", "no"], "ontop plaything_8,table_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_2": ["yes", "no"], "inside plaything_6,carton_1": ["no", "no"], "inside plaything_6,carton_2": ["yes", "no"], "inside plaything_8,carton_1": ["no", "no"], "inside plaything_8,carton_2": ["yes", "no"], "nextto plaything_2,plaything_6": ["no", "no"], "nextto plaything_2,plaything_8": ["no", "no"], "nextto plaything_2,carton_1": ["yes", "no"], "nextto plaything_2,carton_2": ["yes", "no"], "nextto plaything_2,table_1": ["no", "no"], "nextto plaything_6,plaything_2": ["no", "no"], "nextto plaything_6,plaything_8": ["no", "no"], "nextto plaything_6,carton_1": ["no", "no"], "nextto plaything_6,carton_2": ["yes", "no"], "nextto plaything_6,table_1": ["yes", "no"], "nextto plaything_8,plaything_2": ["no", "no"], "nextto plaything_8,plaything_6": ["no", "no"], "nextto plaything_8,carton_1": ["yes", "no"], "nextto plaything_8,carton_2": ["no", "no"], "nextto plaything_8,table_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.723404255319149, "yes_accuracy": 0.75, "yes_correct": 6, "yes_total": 8, "no_accuracy": 0.717948717948718, "no_correct": 28, "no_total": 39, "predicates": {"reachable": {"accuracy": 0.8333333333333334, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "holding": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.9333333333333333, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.9333333333333333, "no_correct": 14, "no_total": 15}, "inside": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 3, "no_total": 6}, "nextto": {"accuracy": 0.6, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.6428571428571429, "no_correct": 9, "no_total": 14}}}, "step": 2, "actions": ["grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}], "remaining_actions": ["place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Benevolence_1_int_21": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable plaything_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable carton_1": ["no", 0.9999999999999741, 2.583529293681533e-14, "The image shows a robotic arm (agent) near a shelf with various objects. The carton_1 is labeled and located on the top left side of the image, above the table and chairs. The robotic arm appears to be positioned towards the right side of the image, near the shelf with toys and books. Given the spatial arrangement, the carton_1 is not within the immediate reach of the robotic arm, which is positioned further to the right and lower in the image. Therefore, the carton_1 is not in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) near a shelf with various objects. The carton_1 is labeled and located on the top left side of the image, above the table and chairs. The robotic arm appears to be positioned towards the right side of the image, near the shelf with toys and books. Given the spatial arrangement, the carton_1 is not within the immediate reach of the robotic arm, which is positioned further to the right and lower in the image. Therefore, the carton_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable table_1": ["yes", 2.0331220917282464e-09, 0.9999999979668779, "The image shows a robotic arm (agent) near a table labeled \"table_1.\" The arm appears to be positioned close to the table, with its end effector near the edge of the table. Given the proximity and the typical reach of a robotic arm in such a simulation, it is likely that the table_1 is within the agent's reach. Therefore, the answer is \"Yes.\"", false, "<explanation>\nThe image shows a robotic arm (agent) near a table labeled \"table_1.\" The arm appears to be positioned close to the table, with its end effector near the edge of the table. Given the proximity and the typical reach of a robotic arm in such a simulation, it is likely that the table_1 is within the agent's reach. Therefore, the answer is \"Yes.\"\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable plaything_2": {"before": false, "after": true}, "reachable plaything_1": {"before": false, "after": false}, "reachable plaything_3": {"before": false, "after": false}, "reachable plaything_4": {"before": false, "after": false}}}, "action_info": "executed but failed"}, {"action": "navigate-to(plaything_2)", "action_correct": true, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable plaything_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable plaything_2": ["yes", 1.468600517521709e-10, 0.9999999998531399, "The image shows a robotic arm (agent) in a virtual household environment. The plaything_2 is located on the floor, relatively close to the robotic arm. Given the perspective, the plaything_2 appears to be within a short distance from the robotic arm, suggesting it is likely within reach. Since the robotic arm can hold objects and the plaything_2 is nearby, it is reasonable to conclude that the plaything_2 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The plaything_2 is located on the floor, relatively close to the robotic arm. Given the perspective, the plaything_2 appears to be within a short distance from the robotic arm, suggesting it is likely within reach. Since the robotic arm can hold objects and the plaything_2 is nearby, it is reasonable to conclude that the plaything_2 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["no", 0.9999999999816908, 1.8309245090245666e-11, "The image shows a robotic arm (agent) in a virtual household environment. There are two objects labeled \"plaything_7\" and \"plaything_2\" on the floor, with \"plaything_2\" closer to the robot. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks specifically about \"carton_1\" and it is not present in the image, I conclude that the carton_1 is not in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. There are two objects labeled \"plaything_7\" and \"plaything_2\" on the floor, with \"plaything_2\" closer to the robot. The carton_1 is not visible in the image, so I cannot determine its position relative to the agent. Since the question asks specifically about \"carton_1\" and it is not present in the image, I conclude that the carton_1 is not in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {"reachable plaything_1": {"before": false, "after": false}, "reachable plaything_3": {"before": false, "after": false}, "reachable plaything_4": {"before": false, "after": false}, "reachable table_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["no", 0.9999955399367468, 4.460063253193917e-06, "The image shows a robotic arm (agent) near a desk with a computer. There are two objects labeled \"plaything_7\" and \"plaything_2\" on the floor, but no object labeled \"carton_1\" is visible in the image. Since \"carton_1\" is not present in the scene, it cannot be in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) near a desk with a computer. There are two objects labeled \"plaything_7\" and \"plaything_2\" on the floor, but no object labeled \"carton_1\" is visible in the image. Since \"carton_1\" is not present in the scene, it cannot be in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable carton_1": ["yes", 8.424232251086618e-21, 1.0, "The image shows a virtual household with a robotic arm (agent) and various objects, including a carton labeled \"carton_1.\" The carton is located near the right side of the image, close to the window and some furniture. The robotic arm appears to be positioned in the center of the room, with its hand extending towards the objects. Given the proximity of \"carton_1\" to the agent's position and the typical reach of a robotic arm in such a simulation, it is likely within reach. However, without precise measurements, it is difficult to confirm definitively. Based on the visual cues, the carton seems close enough to be reachable by the agent.", true, "<explanation>\nThe image shows a virtual household with a robotic arm (agent) and various objects, including a carton labeled \"carton_1.\" The carton is located near the right side of the image, close to the window and some furniture. The robotic arm appears to be positioned in the center of the room, with its hand extending towards the objects. Given the proximity of \"carton_1\" to the agent's position and the typical reach of a robotic arm in such a simulation, it is likely within reach. However, without precise measurements, it is difficult to confirm definitively. Based on the visual cues, the carton seems close enough to be reachable by the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable table_1": ["yes", 2.3346672419292697e-10, 0.9999999997665333, "The image shows a robotic arm (agent) in a virtual household environment. The table labeled \"table_1\" is visible in the scene. The arm appears to be positioned close to the table, and the red lines indicating the agent's reach extend toward the table. Given the proximity and the typical range of a robotic arm in such a simulation, it is likely that the table is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The table labeled \"table_1\" is visible in the scene. The arm appears to be positioned close to the table, and the red lines indicating the agent's reach extend toward the table. Given the proximity and the typical range of a robotic arm in such a simulation, it is likely that the table is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable plaything_1": {"before": false, "after": false}, "reachable plaything_2": {"before": true, "after": false}, "reachable plaything_3": {"before": false, "after": false}, "reachable plaything_4": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 1.9738404202259572e-12, 0.9999999999980261, "The image shows a virtual household with objects and furniture, including a robotic arm (agent). The object labeled \"carton_1\" is located near the right side of the image, close to the window and some furniture. The robotic arm appears to be positioned in the center of the room, with its reach extending outward. Given the proximity of \"carton_1\" to the agent's position and the typical reach of a robotic arm in such a simulation, it is likely that \"carton_1\" is within the agent's reach.", true, "<explanation>\nThe image shows a virtual household with objects and furniture, including a robotic arm (agent). The object labeled \"carton_1\" is located near the right side of the image, close to the window and some furniture. The robotic arm appears to be positioned in the center of the room, with its reach extending outward. Given the proximity of \"carton_1\" to the agent's position and the typical reach of a robotic arm in such a simulation, it is likely that \"carton_1\" is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 0.999999994948491, 5.051509007574564e-09, "The image shows a virtual household with various objects and furniture, including a robotic arm. The label \"carton_1\" is visible in the image, but there is no indication or visual evidence that the carton is open. Typically, an open carton would show its interior or flaps, but this is not visible in the image. Therefore, based on the available visual information, the carton appears to be closed.", true, "<explanation>\nThe image shows a virtual household with various objects and furniture, including a robotic arm. The label \"carton_1\" is visible in the image, but there is no indication or visual evidence that the carton is open. Typically, an open carton would show its interior or flaps, but this is not visible in the image. Therefore, based on the available visual information, the carton appears to be closed.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_2": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 1.0887013156172577e-11, 0.999999999989113, "The image shows a robotic arm (agent) in a virtual household environment. The red outline indicates the agent's current reach area, and the object labeled \"carton_1\" is visible within this area. Since \"carton_1\" is located inside the red boundary, it suggests that the object is within the agent's reach. Therefore, the carton_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The red outline indicates the agent's current reach area, and the object labeled \"carton_1\" is visible within this area. Since \"carton_1\" is located inside the red boundary, it suggests that the object is within the agent's reach. Therefore, the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 0.9999991674092215, 8.325907785273037e-07, "The image shows a virtual household with various objects and furniture. The object labeled \"carton_1\" is visible in the image, and it appears to be closed. There are no visible signs such as an open lid or flaps indicating that it is open. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a virtual household with various objects and furniture. The object labeled \"carton_1\" is visible in the image, and it appears to be closed. There are no visible signs such as an open lid or flaps indicating that it is open. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_2": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable plaything_6": ["yes", "yes"], "reachable plaything_7": ["yes", "no"], "reachable plaything_8": ["yes", "no"], "reachable carton_1": ["no", "yes"], "reachable carton_2": ["yes", "yes"], "reachable table_1": ["yes", "no"], "holding plaything_6": ["yes", "no"], "holding plaything_7": ["no", "no"], "holding plaything_8": ["no", "no"], "open carton_1": ["no", "yes"], "open carton_2": ["no", "yes"], "ontop plaything_6,plaything_7": ["no", "no"], "ontop plaything_6,plaything_8": ["no", "no"], "ontop plaything_6,carton_1": ["no", "no"], "ontop plaything_6,carton_2": ["no", "no"], "ontop plaything_6,table_1": ["no", "no"], "ontop plaything_7,plaything_6": ["no", "no"], "ontop plaything_7,plaything_8": ["no", "no"], "ontop plaything_7,carton_1": ["no", "no"], "ontop plaything_7,carton_2": ["no", "no"], "ontop plaything_7,table_1": ["no", "no"], "ontop plaything_8,plaything_6": ["no", "no"], "ontop plaything_8,plaything_7": ["no", "no"], "ontop plaything_8,carton_1": ["no", "no"], "ontop plaything_8,carton_2": ["no", "no"], "ontop plaything_8,table_1": ["no", "no"], "inside plaything_6,carton_1": ["no", "no"], "inside plaything_6,carton_2": ["no", "no"], "inside plaything_7,carton_1": ["no", "no"], "inside plaything_7,carton_2": ["no", "no"], "inside plaything_8,carton_1": ["no", "no"], "inside plaything_8,carton_2": ["no", "no"], "nextto plaything_6,plaything_7": ["no", "no"], "nextto plaything_6,plaything_8": ["no", "no"], "nextto plaything_6,carton_1": ["no", "no"], "nextto plaything_6,carton_2": ["no", "no"], "nextto plaything_6,table_1": ["no", "no"], "nextto plaything_7,plaything_6": ["no", "no"], "nextto plaything_7,plaything_8": ["no", "no"], "nextto plaything_7,carton_1": ["no", "no"], "nextto plaything_7,carton_2": ["no", "no"], "nextto plaything_7,table_1": ["no", "no"], "nextto plaything_8,plaything_6": ["no", "no"], "nextto plaything_8,plaything_7": ["no", "no"], "nextto plaything_8,carton_1": ["no", "no"], "nextto plaything_8,carton_2": ["no", "no"], "nextto plaything_8,table_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.8297872340425532, "yes_accuracy": 0.3333333333333333, "yes_correct": 2, "yes_total": 6, "no_accuracy": 0.9024390243902439, "no_correct": 37, "no_total": 41, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 3}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 15, "no_total": 15}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "nextto": {"accuracy": 0.9333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}}}, "step": 1, "actions": ["navigate-to(plaything_2)", "navigate-to(carton_1)", "open-container(carton_1)", "navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_5": ["yes", "no"], "reachable plaything_7": ["yes", "no"], "reachable carton_1": ["yes", "yes"], "reachable carton_2": ["yes", "no"], "reachable table_1": ["yes", "no"], "holding plaything_5": ["no", "no"], "holding plaything_7": ["no", "no"], "open carton_1": ["no", "yes"], "open carton_2": ["no", "yes"], "ontop plaything_5,plaything_7": ["no", "no"], "ontop plaything_5,carton_1": ["no", "no"], "ontop plaything_5,carton_2": ["no", "no"], "ontop plaything_5,table_1": ["no", "no"], "ontop plaything_7,plaything_5": ["no", "no"], "ontop plaything_7,carton_1": ["no", "no"], "ontop plaything_7,carton_2": ["no", "no"], "ontop plaything_7,table_1": ["no", "no"], "inside plaything_5,carton_1": ["no", "no"], "inside plaything_5,carton_2": ["no", "no"], "inside plaything_7,carton_1": ["yes", "no"], "inside plaything_7,carton_2": ["no", "no"], "nextto plaything_5,plaything_7": ["no", "no"], "nextto plaything_5,carton_1": ["yes", "no"], "nextto plaything_5,carton_2": ["no", "no"], "nextto plaything_5,table_1": ["yes", "no"], "nextto plaything_7,plaything_5": ["no", "no"], "nextto plaything_7,carton_1": ["no", "no"], "nextto plaything_7,carton_2": ["no", "no"], "nextto plaything_7,table_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6896551724137931, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.7307692307692307, "no_correct": 19, "no_total": 26, "predicates": {"reachable": {"accuracy": 0.2, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 4}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 8, "no_total": 8}, "inside": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 6, "no_total": 8}}}, "step": 3, "actions": ["open-container(carton_1)", "navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_5": ["yes", "no"], "reachable plaything_7": ["yes", "no"], "reachable carton_1": ["yes", "yes"], "reachable carton_2": ["no", "no"], "reachable table_1": ["yes", "no"], "holding plaything_5": ["no", "no"], "holding plaything_7": ["no", "no"], "open carton_1": ["no", "yes"], "open carton_2": ["no", "yes"], "ontop plaything_5,plaything_7": ["yes", "no"], "ontop plaything_5,carton_1": ["no", "no"], "ontop plaything_5,carton_2": ["no", "no"], "ontop plaything_5,table_1": ["no", "no"], "ontop plaything_7,plaything_5": ["no", "no"], "ontop plaything_7,carton_1": ["no", "no"], "ontop plaything_7,carton_2": ["no", "no"], "ontop plaything_7,table_1": ["no", "no"], "inside plaything_5,carton_1": ["no", "no"], "inside plaything_5,carton_2": ["no", "no"], "inside plaything_7,carton_1": ["no", "no"], "inside plaything_7,carton_2": ["yes", "no"], "nextto plaything_5,plaything_7": ["yes", "no"], "nextto plaything_5,carton_1": ["no", "no"], "nextto plaything_5,carton_2": ["no", "no"], "nextto plaything_5,table_1": ["yes", "no"], "nextto plaything_7,plaything_5": ["yes", "no"], "nextto plaything_7,carton_1": ["no", "no"], "nextto plaything_7,carton_2": ["no", "no"], "nextto plaything_7,table_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6206896551724138, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.6538461538461539, "no_correct": 17, "no_total": 26, "predicates": {"reachable": {"accuracy": 0.4, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.25, "no_correct": 1, "no_total": 4}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.875, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.875, "no_correct": 7, "no_total": 8}, "inside": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 4, "no_total": 8}}}, "step": 4, "actions": ["open-container(carton_1)", "navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}], "remaining_actions": ["navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Ihlen_0_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(plaything_2)", "action_correct": true, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable plaything_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable plaything_2": ["yes", 9.076497928361144e-16, 0.9999999999999991, "The image shows a robotic arm (agent) in a virtual household. The plaything_2 is a small object on the floor, near the center of the room. The robotic arm appears to be positioned to the right side of the room, with its gripper extended downward. The plaything_2 is located quite close to the robotic arm, within the same room and near the center. Given the proximity, it is likely within reach of the robotic arm, which can extend or move to grasp objects on the floor.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household. The plaything_2 is a small object on the floor, near the center of the room. The robotic arm appears to be positioned to the right side of the room, with its gripper extended downward. The plaything_2 is located quite close to the robotic arm, within the same room and near the center. Given the proximity, it is likely within reach of the robotic arm, which can extend or move to grasp objects on the floor.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["no", 0.9999999998993001, 1.0069989901490899e-10, "The image shows a robotic arm (agent) in a virtual household with various objects. The carton_1 is not explicitly visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and I cannot see the carton_1 in the current view, I must conclude that it is not in reach based on the available information.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household with various objects. The carton_1 is not explicitly visible in the image, so I cannot determine its position relative to the agent. Since the question asks if the carton_1 is in reach of the agent, and I cannot see the carton_1 in the current view, I must conclude that it is not in reach based on the available information.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {"reachable plaything_1": {"before": false, "after": false}, "reachable plaything_3": {"before": false, "after": false}, "reachable plaything_4": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["yes", 8.437199554052037e-13, 0.9999999999991562, "The image shows a robotic arm (agent) in a virtual household. The plaything_2 is a small object on the floor, near the center of the room. The robotic arm is positioned to the right side of the image, extending towards the center. Given the perspective, the plaything_2 appears to be within the reach of the robotic arm, as it is close to the arm's position and the arm seems capable of extending to that area.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household. The plaything_2 is a small object on the floor, near the center of the room. The robotic arm is positioned to the right side of the image, extending towards the center. Given the perspective, the plaything_2 appears to be within the reach of the robotic arm, as it is close to the arm's position and the arm seems capable of extending to that area.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": {"holding plaything_2": ["yes", 2.228443885777347e-07, 0.9999997771556114, "The image shows a robotic arm (agent) holding a blue object, which appears to be a plaything. The label \"plaything_2\" suggests a specific toy, and the object in the agent's hand matches the description of a plaything. Therefore, the agent is holding the plaything_2.", true, "<explanation>\nThe image shows a robotic arm (agent) holding a blue object, which appears to be a plaything. The label \"plaything_2\" suggests a specific toy, and the object in the agent's hand matches the description of a plaything. Therefore, the agent is holding the plaything_2.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop plaything_2,carton_1": ["no", 0.9999999437412388, 5.62587612016277e-08, "The image shows a robotic arm holding a blue object labeled \"plaything_2\" and a carton labeled \"carton_1\" on a table. The \"plaything_2\" appears to be in the robotic arm's grasp, and the carton_1 is on the table. Since the plaything_2 is being held by the robotic arm and not resting on the carton_1, it is not on top of the carton_1.", true, "<explanation>\nThe image shows a robotic arm holding a blue object labeled \"plaything_2\" and a carton labeled \"carton_1\" on a table. The \"plaything_2\" appears to be in the robotic arm's grasp, and the carton_1 is on the table. Since the plaything_2 is being held by the robotic arm and not resting on the carton_1, it is not on top of the carton_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto plaything_2,carton_1": ["yes", 6.770078129783889e-08, 0.9999999322992187, "The image shows a robotic arm holding a blue object, which is identified as plaything_2, and a carton_1 on the table. The plaything_2 is positioned very close to the carton_1, with no significant space between them, indicating that they are next to each other.", false, "<explanation>\nThe image shows a robotic arm holding a blue object, which is identified as plaything_2, and a carton_1 on the table. The plaything_2 is positioned very close to the carton_1, with no significant space between them, indicating that they are next to each other.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop plaything_2,plaything_1": {"before": false, "after": false}, "ontop plaything_2,plaything_2": {"before": null, "after": false}, "ontop plaything_2,plaything_3": {"before": false, "after": false}, "ontop plaything_2,plaything_4": {"before": false, "after": false}, "ontop plaything_2,table_1": {"before": false, "after": false}, "nextto plaything_2,plaything_1": {"before": false, "after": false}, "nextto plaything_2,plaything_2": {"before": null, "after": false}, "nextto plaything_2,plaything_3": {"before": false, "after": false}, "nextto plaything_2,plaything_4": {"before": false, "after": false}, "nextto plaything_2,table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-inside(plaything_2, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding plaything_2": ["yes", 1.7260899084507156e-07, 0.9999998273910091, "The image shows a robotic arm (agent) holding a blue object, which appears to be a plaything. The label \"plaything_2\" suggests a specific toy, and the object in the agent's hand matches this description. Therefore, the agent is holding the plaything_2.", true, "<explanation>\nThe image shows a robotic arm (agent) holding a blue object, which appears to be a plaything. The label \"plaything_2\" suggests a specific toy, and the object in the agent's hand matches this description. Therefore, the agent is holding the plaything_2.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 3.7956478676807795e-14, 0.999999999999962, "The image shows a robotic arm (agent) holding an object, with a lion in the room. The carton_1 is visible on the table, positioned near the lion. The robotic arm appears to be extended towards the table, and the carton_1 is within the area that the arm can reach, given its position and the typical reach of such robotic arms in simulated environments. Therefore, it is reasonable to conclude that the carton_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) holding an object, with a lion in the room. The carton_1 is visible on the table, positioned near the lion. The robotic arm appears to be extended towards the table, and the carton_1 is within the area that the arm can reach, given its position and the typical reach of such robotic arms in simulated environments. Therefore, it is reasonable to conclude that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 0.9999999998991209, 1.0087907494321549e-10, "The image shows a room with a robotic arm holding a blue object, and a lion standing near a set of black cartons. The cartons are closed, with no visible openings or flaps indicating they are open. Since the question asks if the carton_1 is open, and based on the visual evidence, the carton appears to be closed, the answer is \"No\".", false, "<explanation>\nThe image shows a room with a robotic arm holding a blue object, and a lion standing near a set of black cartons. The cartons are closed, with no visible openings or flaps indicating they are open. Since the question asks if the carton_1 is open, and based on the visual evidence, the carton appears to be closed, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-inside(plaything_2, carton_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {"holding plaything_2": ["yes", 6.393747077852869e-08, 0.9999999360625292, "The image shows a robotic arm (agent) holding a blue object, which appears to be a plaything. The label \"plaything_2\" suggests a specific object, and the object in the agent's grasp matches the description of a plaything. Therefore, the agent is holding the plaything_2.", true, "<explanation>\nThe image shows a robotic arm (agent) holding a blue object, which appears to be a plaything. The label \"plaything_2\" suggests a specific object, and the object in the agent's grasp matches the description of a plaything. Therefore, the agent is holding the plaything_2.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 4.96871500173177e-09, 0.999999995031285, "The image shows a robotic arm (agent) holding an object, and there is a carton labeled \"carton_1\" on the table. The carton appears to be close to the robotic arm, which is holding an object and is positioned near the carton. Given the proximity and the typical reach of a robotic arm in such a setting, it is reasonable to conclude that the carton_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) holding an object, and there is a carton labeled \"carton_1\" on the table. The carton appears to be close to the robotic arm, which is holding an object and is positioned near the carton. Given the proximity and the typical reach of a robotic arm in such a setting, it is reasonable to conclude that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["yes", 2.4684786737118607e-06, 0.9999975315213263, "The image shows a carton labeled \"carton_1\" on a table. The carton appears to be tilted and partially open, with the top flaps not fully closed. This suggests that the carton is open.", true, "<explanation>\nThe image shows a carton labeled \"carton_1\" on a table. The carton appears to be tilted and partially open, with the top flaps not fully closed. This suggests that the carton is open.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"inside plaything_2,carton_1": ["no", 0.9999999402061782, 5.97938218311893e-08, "The image shows a robotic arm, a dog, a carton, and a plaything. The plaything_2 is not visible in the image, and there is no indication that it is inside the carton_1. Since the plaything_2 is not shown or mentioned as being inside the carton, the answer is \"No\".", false, "<explanation>\nThe image shows a robotic arm, a dog, a carton, and a plaything. The plaything_2 is not visible in the image, and there is no indication that it is inside the carton_1. Since the plaything_2 is not shown or mentioned as being inside the carton, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "holding plaything_2": ["no", 0.9999999999988635, 1.1365420084680691e-12, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but it is not clear from the image whether this object is a plaything_2 or something else. There is a small dog in the room, but no other objects are clearly identified as plaything_2. Since the object in the robotic arm is not explicitly labeled or clearly identifiable as plaything_2, I cannot confirm that the agent is holding plaything_2.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but it is not clear from the image whether this object is a plaything_2 or something else. There is a small dog in the room, but no other objects are clearly identified as plaything_2. Since the object in the robotic arm is not explicitly labeled or clearly identifiable as plaything_2, I cannot confirm that the agent is holding plaything_2.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "executed but failed"}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 8.239082487700606e-13, 0.9999999999991761, "The image shows a robotic arm (agent) in a virtual household, with a carton labeled \"carton_1\" visible in the scene. The carton is located on a small table near the center of the room. The robotic arm is extended downward and appears to be reaching toward objects on the table. Given the proximity of the robotic arm to the table and the carton, it is likely within reach of the agent. Therefore, the carton_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household, with a carton labeled \"carton_1\" visible in the scene. The carton is located on a small table near the center of the room. The robotic arm is extended downward and appears to be reaching toward objects on the table. Given the proximity of the robotic arm to the table and the carton, it is likely within reach of the agent. Therefore, the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 0.9999999999574373, 4.2562733772477615e-11, "The image shows a robotic arm in a virtual household, but there is no visible carton_1 in the scene. Since the question asks if the carton_1 is open, I need to determine if such a carton is present and its state. However, based on the provided image, there is no carton_1 visible, and therefore, I cannot confirm whether it is open or closed. The absence of the carton_1 in the scene suggests that the answer is \"No.\"", true, "<explanation>\nThe image shows a robotic arm in a virtual household, but there is no visible carton_1 in the scene. Since the question asks if the carton_1 is open, I need to determine if such a carton is present and its state. However, based on the provided image, there is no carton_1 visible, and therefore, I cannot confirm whether it is open or closed. The absence of the carton_1 in the scene suggests that the answer is \"No.\"\n</explanation>\n<answer>\nNo\n</answer>", false], "holding plaything_2": ["no", 0.9999999994636671, 5.36332815933004e-10, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but it is not clear from the image whether the object is a plaything_2 or something else. There is no visible label or distinguishing feature that identifies the object as plaything_2. Therefore, based on the available information, I cannot confirm that the agent is holding plaything_2.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but it is not clear from the image whether the object is a plaything_2 or something else. There is no visible label or distinguishing feature that identifies the object as plaything_2. Therefore, based on the available information, I cannot confirm that the agent is holding plaything_2.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 2.2568834525843567e-11, 0.9999999999774312, "The image shows a robotic arm (agent) in a virtual household environment. The arm is extended downward, and there is a carton labeled \"carton_1\" on the floor near the arm. The carton appears to be within the reach of the robotic arm, as it is close to the arm's position and within the area where the arm can extend to grasp objects.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm is extended downward, and there is a carton labeled \"carton_1\" on the floor near the arm. The carton appears to be within the reach of the robotic arm, as it is close to the arm's position and within the area where the arm can extend to grasp objects.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 6.805549108283484e-12, 0.9999999999931944, "The image shows a robotic arm (agent) in a virtual household environment. The arm is extended downward, and there is a carton labeled \"carton_1\" on the floor near the arm. The carton appears to be within the reach of the robotic arm, as it is close to the arm's position and within the area where the arm can extend and grasp objects. Therefore, the carton_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm is extended downward, and there is a carton labeled \"carton_1\" on the floor near the arm. The carton appears to be within the reach of the robotic arm, as it is close to the arm's position and within the area where the arm can extend and grasp objects. Therefore, the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 0.9999999981845349, 1.815465133625184e-09, "The image shows a robotic arm in a virtual household with various objects. However, there is no visible carton labeled \"carton_1\" or any clear indication of an open or closed carton in the scene. Since the question specifically asks about \"carton_1\" and its state, and no such object is visible or identifiable as open or closed, I cannot determine its status based on the provided image.", true, "<explanation>\nThe image shows a robotic arm in a virtual household with various objects. However, there is no visible carton labeled \"carton_1\" or any clear indication of an open or closed carton in the scene. Since the question specifically asks about \"carton_1\" and its state, and no such object is visible or identifiable as open or closed, I cannot determine its status based on the provided image.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding plaything_2": ["no", 0.9999999999999923, 7.69026583501286e-15, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but it is not clear from the image whether the object is a plaything_2 or something else. There is a small dog in the scene, but no clear indication of the specific object being held by the robotic arm. Since the question asks specifically about \"plaything_2\" and there is no visible label or distinctive feature identifying the object as such, I cannot confirm that the agent is holding plaything_2.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but it is not clear from the image whether the object is a plaything_2 or something else. There is a small dog in the scene, but no clear indication of the specific object being held by the robotic arm. Since the question asks specifically about \"plaything_2\" and there is no visible label or distinctive feature identifying the object as such, I cannot confirm that the agent is holding plaything_2.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 1.040536224773258e-11, 0.9999999999895947, "The image shows a robotic arm (agent) in a virtual household with various objects. The carton_1 is located on a small table near the center of the room. The robotic arm is positioned above the table, reaching downward. Given the arm's position and the proximity of the carton_1 on the table, it appears to be within the reach of the robotic arm. Therefore, the carton_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household with various objects. The carton_1 is located on a small table near the center of the room. The robotic arm is positioned above the table, reaching downward. Given the arm's position and the proximity of the carton_1 on the table, it appears to be within the reach of the robotic arm. Therefore, the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["no", 0.9999999838882088, 1.611179128410682e-08, "The image shows a robotic arm in a virtual household with various objects. However, there is no visible carton_1 in the image, and therefore, I cannot determine whether it is open or closed. Since the question asks specifically about carton_1 and there is no evidence of it in the image, the answer must be \"No.\"", true, "<explanation>\nThe image shows a robotic arm in a virtual household with various objects. However, there is no visible carton_1 in the image, and therefore, I cannot determine whether it is open or closed. Since the question asks specifically about carton_1 and there is no evidence of it in the image, the answer must be \"No.\"\n</explanation>\n<answer>\nNo\n</answer>", false], "holding plaything_2": ["no", 0.9999999995404438, 4.595561217025258e-10, "The image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but it is not clear from the image whether the object is a plaything_2 or something else. There is no visible label or distinguishing feature that identifies the object as plaything_2. Therefore, based on the available information, I cannot confirm that the agent is holding plaything_2.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm appears to be holding an object, but it is not clear from the image whether the object is a plaything_2 or something else. There is no visible label or distinguishing feature that identifies the object as plaything_2. Therefore, based on the available information, I cannot confirm that the agent is holding plaything_2.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["yes", "yes"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.8571428571428571, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}}}, "step": 2, "actions": ["place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["yes", "yes"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 3, "actions": ["place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["no", "no"], "open carton_1": ["no", "yes"], "ontop plaything_2,carton_1": ["yes", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 4, "actions": ["open-container(carton_1)", "grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["no", "yes"], "holding plaything_2": ["no", "no"], "open carton_1": ["no", "yes"], "ontop plaything_2,carton_1": ["yes", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.42857142857142855, "yes_accuracy": 0.25, "yes_correct": 1, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 5, "actions": ["navigate-to(carton_1)", "open-container(carton_1)", "navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["no", "no"], "open carton_1": ["no", "yes"], "ontop plaything_2,carton_1": ["yes", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5714285714285714, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 6, "actions": ["open-container(carton_1)", "grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["no", "no"], "open carton_1": ["no", "yes"], "ontop plaything_2,carton_1": ["yes", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5714285714285714, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 7, "actions": ["open-container(carton_1)", "grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}], "remaining_actions": ["grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Ihlen_0_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(plaything_2)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable plaything_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable plaything_2": ["yes", 1.306315413985404e-13, 0.9999999999998693, "The image shows a robotic arm (agent) in a virtual household with various objects. The plaything_2 is not explicitly labeled in the image, but there is a small object on the floor near the center of the image, which could be the plaything_2. The robotic arm is positioned towards the right side of the image, reaching out with its gripper. The small object on the floor appears to be within the reach of the robotic arm, considering the arm's position and extension. Therefore, it is reasonable to conclude that the plaything_2 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household with various objects. The plaything_2 is not explicitly labeled in the image, but there is a small object on the floor near the center of the image, which could be the plaything_2. The robotic arm is positioned towards the right side of the image, reaching out with its gripper. The small object on the floor appears to be within the reach of the robotic arm, considering the arm's position and extension. Therefore, it is reasonable to conclude that the plaything_2 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 8.373805219211463e-16, 0.9999999999999991, "The image shows a robotic arm (agent) in a virtual household with various objects. The carton_1 is not explicitly labeled in the image, but there is a cardboard box or carton-like object on the left side of the image, near the sofa. The robotic arm is positioned towards the right side of the image, and the carton-like object appears to be on the left side, relatively close to the sofa. Given the perspective, it seems that the carton_1 is within a reasonable reach of the robotic arm, considering typical interaction distances in such environments.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household with various objects. The carton_1 is not explicitly labeled in the image, but there is a cardboard box or carton-like object on the left side of the image, near the sofa. The robotic arm is positioned towards the right side of the image, and the carton-like object appears to be on the left side, relatively close to the sofa. Given the perspective, it seems that the carton_1 is within a reasonable reach of the robotic arm, considering typical interaction distances in such environments.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable plaything_1": {"before": false, "after": false}, "reachable plaything_3": {"before": false, "after": false}, "reachable plaything_4": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["yes", 4.2170078952939383e-11, 0.99999999995783, "The image shows a robotic arm (agent) in a virtual household. The plaything_2 is a small object on the floor, near the center of the image, close to the small dog. The robotic arm appears to be extended towards the plaything_2, indicating that it is within reach. Since the arm is close to the object and seems to be reaching for it, the plaything_2 is likely within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household. The plaything_2 is a small object on the floor, near the center of the image, close to the small dog. The robotic arm appears to be extended towards the plaything_2, indicating that it is within reach. Since the arm is close to the object and seems to be reaching for it, the plaything_2 is likely within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": {"holding plaything_2": ["no", 0.9999999999124924, 8.750755478538272e-11, "The image shows a robotic arm (agent) holding a black object, but the object is not clearly identified as a plaything_2. The object appears to be a black item, but there is no explicit indication that it is a plaything_2. Since the question asks specifically if the agent is holding the plaything_2, and there is no clear evidence of that, the answer should be \"No\".", false, "<explanation>\nThe image shows a robotic arm (agent) holding a black object, but the object is not clearly identified as a plaything_2. The object appears to be a black item, but there is no explicit indication that it is a plaything_2. Since the question asks specifically if the agent is holding the plaything_2, and there is no clear evidence of that, the answer should be \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop plaything_2,carton_1": ["no", 0.9999999970737199, 2.926280139096549e-09, "The image shows a robotic arm holding a lion, with a carton labeled \"carton_1\" on the floor. The plaything_2 is not visible in the image, so I cannot determine its position relative to the carton_1. Since the question asks if the plaything_2 is on top of the carton_1, and there is no evidence of plaything_2 being present or placed on the carton, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm holding a lion, with a carton labeled \"carton_1\" on the floor. The plaything_2 is not visible in the image, so I cannot determine its position relative to the carton_1. Since the question asks if the plaything_2 is on top of the carton_1, and there is no evidence of plaything_2 being present or placed on the carton, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto plaything_2,carton_1": ["no", 1.0, 1.7902424322900692e-20, "The image shows a robotic arm holding a lion toy, with a carton and a plant in the background. The question asks if the \"plaything_2\" is next to the \"carton_1.\" Since the image does not explicitly label objects as \"plaything_2\" or \"carton_1,\" I need to infer based on the visual information. The lion toy could be considered a plaything, but its position relative to the carton is not clearly shown as being next to it. The carton is on the floor, and the lion toy is on top of the robotic arm, which is in front of the carton. Therefore, the plaything (lion toy) is not directly next to the carton.", true, "<explanation>\nThe image shows a robotic arm holding a lion toy, with a carton and a plant in the background. The question asks if the \"plaything_2\" is next to the \"carton_1.\" Since the image does not explicitly label objects as \"plaything_2\" or \"carton_1,\" I need to infer based on the visual information. The lion toy could be considered a plaything, but its position relative to the carton is not clearly shown as being next to it. The carton is on the floor, and the lion toy is on top of the robotic arm, which is in front of the carton. Therefore, the plaything (lion toy) is not directly next to the carton.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop plaything_2,plaything_1": {"before": false, "after": false}, "ontop plaything_2,plaything_2": {"before": null, "after": false}, "ontop plaything_2,plaything_3": {"before": false, "after": false}, "ontop plaything_2,plaything_4": {"before": false, "after": false}, "ontop plaything_2,table_1": {"before": false, "after": false}, "nextto plaything_2,plaything_1": {"before": false, "after": false}, "nextto plaything_2,plaything_2": {"before": null, "after": false}, "nextto plaything_2,plaything_3": {"before": false, "after": false}, "nextto plaything_2,plaything_4": {"before": false, "after": false}, "nextto plaything_2,table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["no", 0.999999999317164, 6.828360613458588e-10, "The image shows a robotic arm (agent) in a virtual household environment, with a lion present. The question asks if the \"plaything_2\" is within reach of the agent. However, the image does not show any object labeled \"plaything_2\" or any clear indication of its position relative to the robotic arm. Without visual evidence of \"plaything_2\" or its proximity to the agent, I cannot determine if it is within reach.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment, with a lion present. The question asks if the \"plaything_2\" is within reach of the agent. However, the image does not show any object labeled \"plaything_2\" or any clear indication of its position relative to the robotic arm. Without visual evidence of \"plaything_2\" or its proximity to the agent, I cannot determine if it is within reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["no", 0.9999999999999999, 6.006583389705746e-17, "The image shows a robotic arm (agent) in a virtual household environment. The agent is holding a black object, and there is a lion on the table. The question asks if the \"plaything_2\" is within reach of the agent. However, the image does not clearly show an object labeled \"plaything_2\" or its position relative to the agent. Since the only visible objects are the lion, the table, and some furniture, and no clear indication of \"plaything_2\" being nearby, I cannot confirm that it is within reach based on this image alone.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The agent is holding a black object, and there is a lion on the table. The question asks if the \"plaything_2\" is within reach of the agent. However, the image does not clearly show an object labeled \"plaything_2\" or its position relative to the agent. Since the only visible objects are the lion, the table, and some furniture, and no clear indication of \"plaything_2\" being nearby, I cannot confirm that it is within reach based on this image alone.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "place-inside(plaything_2, carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding plaything_2": ["no", 0.9999999994376987, 5.623013670107604e-10, "The image shows a robotic arm (agent) holding a black object, but the object is not clearly identified as a plaything_2. The object appears to be a black rectangular item, which does not resemble a typical plaything. Since there is no clear indication that the object is a plaything_2, the answer is \"No\".", false, "<explanation>\nThe image shows a robotic arm (agent) holding a black object, but the object is not clearly identified as a plaything_2. The object appears to be a black rectangular item, which does not resemble a typical plaything. Since there is no clear indication that the object is a plaything_2, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable carton_1": ["yes", 3.2570826394940895e-11, 0.9999999999674292, "The image shows a robotic arm (agent) holding a dog, with a carton labeled \"carton_1\" visible on the table in front of the arm. The carton appears to be within the arm's reach, as it is close to the robotic hand and on the same surface. Given the proximity, it is reasonable to conclude that the carton is within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) holding a dog, with a carton labeled \"carton_1\" visible on the table in front of the arm. The carton appears to be within the arm's reach, as it is close to the robotic hand and on the same surface. Given the proximity, it is reasonable to conclude that the carton is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open carton_1": ["yes", 5.96010515417551e-14, 0.9999999999999404, "The image shows a robotic arm holding a carton labeled \"carton_1\" in a room with furniture and a lion. The carton appears to be tilted, and the flaps are visible. The flaps are not clearly open or closed, but the way it is tilted suggests it might be open or at least partially open. Since the question asks if the carton is open, and based on the visible position of the flaps, it seems likely that the carton is open or at least not fully closed.", true, "<explanation>\nThe image shows a robotic arm holding a carton labeled \"carton_1\" in a room with furniture and a lion. The carton appears to be tilted, and the flaps are visible. The flaps are not clearly open or closed, but the way it is tilted suggests it might be open or at least partially open. Since the question asks if the carton is open, and based on the visible position of the flaps, it seems likely that the carton is open or at least not fully closed.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["no", 0.9999999993173648, 6.826352219184605e-10, "The image shows a robotic arm (agent) in a virtual household environment, with a lion present. The question asks if the \"plaything_2\" is within reach of the agent. However, the image does not show any object labeled \"plaything_2\" or any clear indication of its position relative to the robotic arm. Without visual evidence of \"plaything_2\" or its proximity to the agent, I cannot determine if it is within reach.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment, with a lion present. The question asks if the \"plaything_2\" is within reach of the agent. However, the image does not show any object labeled \"plaything_2\" or any clear indication of its position relative to the robotic arm. Without visual evidence of \"plaything_2\" or its proximity to the agent, I cannot determine if it is within reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable plaything_2": ["yes", 1.3458526618820994e-14, 0.9999999999999866, "The image shows a robotic arm (agent) reaching towards a lion statue. The lion statue is positioned on a surface, and the robotic arm appears to be extended towards it. Since the question asks if the \"plaything_2\" is in reach of the agent, and the agent's arm is extended towards the lion, it suggests that the lion is within the arm's reach. Therefore, the plaything_2 (the lion statue) is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a lion statue. The lion statue is positioned on a surface, and the robotic arm appears to be extended towards it. Since the question asks if the \"plaything_2\" is in reach of the agent, and the agent's arm is extended towards the lion, it suggests that the lion is within the arm's reach. Therefore, the plaything_2 (the lion statue) is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable carton_1": ["yes", 9.736384384458873e-12, 0.9999999999902636, "The image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on a surface in front of the robotic arm. The arm appears to be extended towards the carton, suggesting that it is within reach. Since the arm is close to the carton and seems to be able to grasp or interact with it, the carton_1 is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on a surface in front of the robotic arm. The arm appears to be extended towards the carton, suggesting that it is within reach. Since the arm is close to the carton and seems to be able to grasp or interact with it, the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable plaything_1": {"before": false, "after": false}, "reachable plaything_3": {"before": false, "after": false}, "reachable plaything_4": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["yes", 4.419987660829015e-14, 0.9999999999999558, "The image shows a robotic arm (agent) reaching towards a lion statue on a table. The question asks if the \"plaything_2\" is in reach of the agent. Since the image does not explicitly label any object as \"plaything_2,\" I will assume that the lion statue is the object in question. The lion statue is on the table, and the robotic arm is extended towards it, indicating that it is within reach. Therefore, the \"plaything_2\" (assuming it is the lion statue) is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a lion statue on a table. The question asks if the \"plaything_2\" is in reach of the agent. Since the image does not explicitly label any object as \"plaything_2,\" I will assume that the lion statue is the object in question. The lion statue is on the table, and the robotic arm is extended towards it, indicating that it is within reach. Therefore, the \"plaything_2\" (assuming it is the lion statue) is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["yes", 5.6504269324547505e-16, 0.9999999999999994, "The image shows a robotic arm (agent) reaching towards a lion statue on a table. The \"plaything_2\" is not explicitly visible in the image, but based on the context, it appears that the question is asking if the agent can reach the lion statue, which might be considered a plaything. Since the robotic arm is extended towards the lion, it indicates that the lion is within reach of the agent. Therefore, if \"plaything_2\" refers to the lion or a similar object on the table, it is within reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a lion statue on a table. The \"plaything_2\" is not explicitly visible in the image, but based on the context, it appears that the question is asking if the agent can reach the lion statue, which might be considered a plaything. Since the robotic arm is extended towards the lion, it indicates that the lion is within reach of the agent. Therefore, if \"plaything_2\" refers to the lion or a similar object on the table, it is within reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding plaything_1": [true, false, false], "holding plaything_3": [true, false, false], "holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "navigate-to(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable plaything_2": ["no", 0.9999999999836197, 1.638028850199537e-11, "The image shows a robotic arm (agent) reaching towards a lion statue on a table. The question asks if the \"plaything_2\" is in reach of the agent. Since the image does not explicitly show an object labeled \"plaything_2,\" I cannot determine its location or whether it is within reach based on the provided image. Therefore, I cannot confirm that \"plaything_2\" is in reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a lion statue on a table. The question asks if the \"plaything_2\" is in reach of the agent. Since the image does not explicitly show an object labeled \"plaything_2,\" I cannot determine its location or whether it is within reach based on the provided image. Therefore, I cannot confirm that \"plaything_2\" is in reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable plaything_2": ["yes", 1.1511780732684846e-11, 0.9999999999884882, "The image shows a robotic arm (agent) in a virtual household environment, with objects labeled as playthings. The plaything_2 is located near the center of the image, close to the robotic arm. Since the robotic arm appears to be extended towards the plaything_2 and it is within the red bounding box indicating the agent's reach, it suggests that the plaything_2 is within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment, with objects labeled as playthings. The plaything_2 is located near the center of the image, close to the robotic arm. Since the robotic arm appears to be extended towards the plaything_2 and it is within the red bounding box indicating the agent's reach, it suggests that the plaything_2 is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable plaything_1": ["yes", 1.3884705780649118e-11, 0.9999999999861153, "The image shows a robotic arm (agent) in a virtual household environment, with objects labeled as playthings. The plaything_1 is located on the surface of a piece of furniture, near the edge, and appears to be within the reach of the robotic arm. Since the arm is extended towards the plaything_1 and it is positioned close to the arm's current location, it is reasonable to conclude that the plaything_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment, with objects labeled as playthings. The plaything_1 is located on the surface of a piece of furniture, near the edge, and appears to be within the reach of the robotic arm. Since the arm is extended towards the plaything_1 and it is positioned close to the arm's current location, it is reasonable to conclude that the plaything_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable plaything_3": ["no", 0.9999999999996896, 3.103732301202087e-13, "The image shows a robotic arm (agent) holding a black object labeled \"plaything_2.\" The object labeled \"plaything_3\" is located on a surface near the lion figure, to the right of the arm. The red bounding box around \"plaything_3\" indicates its position, which appears to be outside the reach of the robotic arm, as the arm is holding \"plaything_2\" and is not extended towards \"plaything_3.\" Therefore, \"plaything_3\" is not within the reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) holding a black object labeled \"plaything_2.\" The object labeled \"plaything_3\" is located on a surface near the lion figure, to the right of the arm. The red bounding box around \"plaything_3\" indicates its position, which appears to be outside the reach of the robotic arm, as the arm is holding \"plaything_2\" and is not extended towards \"plaything_3.\" Therefore, \"plaything_3\" is not within the reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable carton_1": ["yes", 1.509313400806973e-11, 0.9999999999849069, "The image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on top of a piece of furniture, near the lion figure. The robotic arm appears to be positioned close to the carton_1, with the carton_1 within the red bounding box indicating the agent's reach or interaction zone. Given the proximity, it is reasonable to conclude that the carton_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The carton_1 is located on top of a piece of furniture, near the lion figure. The robotic arm appears to be positioned close to the carton_1, with the carton_1 within the red bounding box indicating the agent's reach or interaction zone. Given the proximity, it is reasonable to conclude that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable plaything_4": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 1.4825571550200782e-13, 0.9999999999998518, "The image shows a robotic arm (agent) holding an object, with a lion on top of a piece of furniture. The carton_1 is labeled and located on the surface of the furniture, near the edge. The robotic arm appears to be extended towards the carton_1, which is within the arm's reach based on its position and the arm's extension. Therefore, the carton_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) holding an object, with a lion on top of a piece of furniture. The carton_1 is labeled and located on the surface of the furniture, near the edge. The robotic arm appears to be extended towards the carton_1, which is within the arm's reach based on its position and the arm's extension. Therefore, the carton_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "open carton_1": ["no", 0.9999985919207119, 1.4080792880773184e-06, "The image shows a robotic arm holding a black object labeled \"carton_1.\" The carton appears to be closed, as there are no visible flaps or openings indicating that it is open. The shape and structure of the carton suggest it is a closed container.", true, "<explanation>\nThe image shows a robotic arm holding a black object labeled \"carton_1.\" The carton appears to be closed, as there are no visible flaps or openings indicating that it is open. The shape and structure of the carton suggest it is a closed container.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding plaything_1": ["no", 0.9999999999351754, 6.48245958627076e-11, "The image shows a robotic arm (agent) in a virtual household environment. There are objects labeled as \"plaything_2\" and \"plaything_3\" near the arm, but there is no indication that the arm is holding any object labeled \"plaything_1.\" The arm appears to be empty or holding something that is not labeled as \"plaything_1.\" Therefore, based on the provided image, the agent is not holding \"plaything_1.\"", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. There are objects labeled as \"plaything_2\" and \"plaything_3\" near the arm, but there is no indication that the arm is holding any object labeled \"plaything_1.\" The arm appears to be empty or holding something that is not labeled as \"plaything_1.\" Therefore, based on the provided image, the agent is not holding \"plaything_1.\"\n</explanation>\n<answer>\nNo\n</answer>", true], "holding plaything_2": ["no", 1.0, 2.8431810105768587e-19, "The image shows a robotic arm in a virtual household environment, with a lion on top of a piece of furniture. There are three objects labeled \"plaything_1,\" \"plaything_2,\" and \"plaything_3.\" The \"plaything_2\" is located near the robotic arm, but it is not clear from the image whether the robotic arm is holding \"plaything_2\" or not. The arm appears to be holding \"plaything_3,\" as it is closer to the hand and the object in the grasp. Since the question asks if the agent is holding \"plaything_2,\" and the visual evidence suggests it is not, the answer is \"No.\"", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment, with a lion on top of a piece of furniture. There are three objects labeled \"plaything_1,\" \"plaything_2,\" and \"plaything_3.\" The \"plaything_2\" is located near the robotic arm, but it is not clear from the image whether the robotic arm is holding \"plaything_2\" or not. The arm appears to be holding \"plaything_3,\" as it is closer to the hand and the object in the grasp. Since the question asks if the agent is holding \"plaything_2,\" and the visual evidence suggests it is not, the answer is \"No.\"\n</explanation>\n<answer>\nNo\n</answer>", false], "holding plaything_3": ["no", 0.9999999999867518, 1.324818363313397e-11, "The image shows a robotic arm (agent) in a virtual household environment. There are objects labeled as \"plaything_2,\" \"plaything_3,\" and \"plaything_4.\" The \"plaything_3\" is located near the robotic arm, but it is not clear from the image whether the robotic arm is holding \"plaything_3\" or not. The arm appears to be close to \"plaything_3,\" but there is no visible grasp or hold on it. Therefore, based on the visual evidence, the agent is not holding \"plaything_3.\"", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. There are objects labeled as \"plaything_2,\" \"plaything_3,\" and \"plaything_4.\" The \"plaything_3\" is located near the robotic arm, but it is not clear from the image whether the robotic arm is holding \"plaything_3\" or not. The arm appears to be close to \"plaything_3,\" but there is no visible grasp or hold on it. Therefore, based on the visual evidence, the agent is not holding \"plaything_3.\"\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 2.8212289734633696e-13, 0.9999999999997179, "The image shows a robotic arm (agent) in a virtual household environment, with various objects labeled. The carton_1 is located on the surface of a piece of furniture, near the lion figure. The robotic arm appears to be positioned close to the carton_1, with the arm extending towards it. Given the proximity and the typical reach of such a robotic arm in this environment, it is reasonable to conclude that the carton_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment, with various objects labeled. The carton_1 is located on the surface of a piece of furniture, near the lion figure. The robotic arm appears to be positioned close to the carton_1, with the arm extending towards it. Given the proximity and the typical reach of such a robotic arm in this environment, it is reasonable to conclude that the carton_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "open carton_1": ["no", 0.9999999999940098, 5.9902036795523915e-12, "The image shows a robotic arm holding a black object labeled \"plaything_2\" in front of a lion statue. There is a carton on the shelf below the lion, but the image does not clearly show the carton_1 itself or whether it is open or closed. Since the question asks specifically about carton_1 and there is no visible indication that it is open, I cannot confirm that it is open based on this image.", true, "<explanation>\nThe image shows a robotic arm holding a black object labeled \"plaything_2\" in front of a lion statue. There is a carton on the shelf below the lion, but the image does not clearly show the carton_1 itself or whether it is open or closed. Since the question asks specifically about carton_1 and there is no visible indication that it is open, I cannot confirm that it is open based on this image.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding plaything_1": ["no", 0.9999999659459015, 3.4054098557035885e-08, "The image shows a robotic arm in a virtual household environment, with objects labeled as \"plaything_2\" and \"plaything_3\" visible. The object labeled \"plaything_1\" is not present in the image. Since the question asks if the agent is holding \"plaything_1\" and that object is not visible or identified in the scene, the answer is no.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment, with objects labeled as \"plaything_2\" and \"plaything_3\" visible. The object labeled \"plaything_1\" is not present in the image. Since the question asks if the agent is holding \"plaything_1\" and that object is not visible or identified in the scene, the answer is no.\n</explanation>\n<answer>\nNo\n</answer>", true], "holding plaything_2": ["no", 0.9999999999966177, 3.382282338273753e-12, "The image shows a robotic arm in a virtual household environment, with objects labeled as \"plaything_2\" and \"plaything_3.\" The \"plaything_2\" is located near the robotic arm, but it is not clear from the image whether the robotic arm is actively holding or grasping \"plaything_2.\" The arm appears to be positioned close to the objects, but there is no definitive visual evidence that it is holding \"plaything_2.\" Therefore, based on the available information, the agent is not holding \"plaything_2.\"", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment, with objects labeled as \"plaything_2\" and \"plaything_3.\" The \"plaything_2\" is located near the robotic arm, but it is not clear from the image whether the robotic arm is actively holding or grasping \"plaything_2.\" The arm appears to be positioned close to the objects, but there is no definitive visual evidence that it is holding \"plaything_2.\" Therefore, based on the available information, the agent is not holding \"plaything_2.\"\n</explanation>\n<answer>\nNo\n</answer>", false], "holding plaything_3": ["yes", 7.615065820462019e-08, 0.9999999238493418, "The image shows a robotic arm (agent) with a red bounding box around a black object labeled \"plaything_3.\" The bounding box indicates that the agent is holding or interacting with this object. Since the label \"plaything_3\" is associated with the object in the agent's grasp, it suggests that the agent is indeed holding \"plaything_3.\"", false, "<explanation>\nThe image shows a robotic arm (agent) with a red bounding box around a black object labeled \"plaything_3.\" The bounding box indicates that the agent is holding or interacting with this object. Since the label \"plaything_3\" is associated with the object in the agent's grasp, it suggests that the agent is indeed holding \"plaything_3.\"\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "open-container(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable carton_1": ["yes", 1.9208868680370627e-12, 0.9999999999980791, "The image shows a robotic arm (agent) holding an object, with a lion on top of a piece of furniture. The carton_1 is visible on the surface of the furniture, near the lion. The carton_1 appears to be within the reach of the robotic arm, as it is close to the arm's position and within the area that the arm can extend to. Therefore, the carton_1 is likely in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) holding an object, with a lion on top of a piece of furniture. The carton_1 is visible on the surface of the furniture, near the lion. The carton_1 appears to be within the reach of the robotic arm, as it is close to the arm's position and within the area that the arm can extend to. Therefore, the carton_1 is likely in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "open carton_1": ["no", 0.9999999867722861, 1.3227713904574573e-08, "The image shows a robotic arm holding a black object labeled \"carton_1.\" The carton appears to be closed, as there are no visible signs of an open lid or flaps. The top of the carton is not visible, but based on the perspective and the way it is held, it looks like it is in a closed state.", true, "<explanation>\nThe image shows a robotic arm holding a black object labeled \"carton_1.\" The carton appears to be closed, as there are no visible signs of an open lid or flaps. The top of the carton is not visible, but based on the perspective and the way it is held, it looks like it is in a closed state.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding plaything_1": ["no", 0.9999999392404837, 6.075951635106755e-08, "The image shows a robotic arm in a virtual household environment, with objects labeled as \"plaything_2\" and \"plaything_3\" near the arm. The label \"plaything_1\" is not visible in the image, and there is no indication that the robotic arm is holding any object, including \"plaything_1.\" Therefore, based on the provided image, the agent is not holding \"plaything_1.\"", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment, with objects labeled as \"plaything_2\" and \"plaything_3\" near the arm. The label \"plaything_1\" is not visible in the image, and there is no indication that the robotic arm is holding any object, including \"plaything_1.\" Therefore, based on the provided image, the agent is not holding \"plaything_1.\"\n</explanation>\n<answer>\nNo\n</answer>", true], "holding plaything_2": ["no", 0.9999999999697967, 3.020323645723648e-11, "The image shows a robotic arm in a virtual household environment, with objects labeled as \"plaything_2\" and \"plaything_3.\" The \"plaything_2\" is located near the robotic arm, but it is not clear from the image whether the robotic arm is actively holding or grasping \"plaything_2.\" The arm appears to be close to \"plaything_2,\" but there is no definitive visual evidence that it is currently holding it.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment, with objects labeled as \"plaything_2\" and \"plaything_3.\" The \"plaything_2\" is located near the robotic arm, but it is not clear from the image whether the robotic arm is actively holding or grasping \"plaything_2.\" The arm appears to be close to \"plaything_2,\" but there is no definitive visual evidence that it is currently holding it.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding plaything_3": ["no", 0.999999998441972, 1.558028014302437e-09, "The image shows a robotic arm (agent) with a red bounding box around the object it is holding. The object inside the bounding box is labeled \"plaything_2,\" not \"plaything_3.\" The label \"plaything_3\" is associated with a different object outside the bounding box, near the lion. Therefore, the agent is not holding \"plaything_3.\"", true, "<explanation>\nThe image shows a robotic arm (agent) with a red bounding box around the object it is holding. The object inside the bounding box is labeled \"plaything_2,\" not \"plaything_3.\" The label \"plaything_3\" is associated with a different object outside the bounding box, near the lion. Therefore, the agent is not holding \"plaything_3.\"\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding plaything_4": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["no", "yes"], "holding plaything_2": ["no", "no"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 1, "actions": ["grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["no", "yes"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8571428571428571, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 2, "actions": ["grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["no", "yes"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8571428571428571, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 3, "actions": ["grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["no", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["yes", "yes"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8571428571428571, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 4, "actions": ["place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["no", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["no", "yes"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 5, "actions": ["navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["no", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["no", "yes"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["yes", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.5714285714285714, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 6, "actions": ["navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["no", "yes"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}}}, "step": 7, "actions": ["grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_2": ["no", "yes"], "reachable carton_1": ["yes", "yes"], "holding plaything_2": ["no", "yes"], "open carton_1": ["yes", "yes"], "ontop plaything_2,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "nextto plaything_2,carton_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.5714285714285714, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}}}, "step": 8, "actions": ["navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_1": ["yes", "yes"], "reachable plaything_2": ["yes", "yes"], "reachable plaything_3": ["yes", "yes"], "reachable carton_1": ["yes", "no"], "holding plaything_1": ["no", "no"], "holding plaything_2": ["no", "yes"], "holding plaything_3": ["no", "no"], "open carton_1": ["no", "yes"], "ontop plaything_1,plaything_2": ["no", "no"], "ontop plaything_1,plaything_3": ["no", "no"], "ontop plaything_1,carton_1": ["no", "no"], "ontop plaything_2,plaything_1": ["yes", "no"], "ontop plaything_2,plaything_3": ["no", "no"], "ontop plaything_2,carton_1": ["yes", "no"], "ontop plaything_3,plaything_1": ["no", "no"], "ontop plaything_3,plaything_2": ["yes", "no"], "ontop plaything_3,carton_1": ["no", "no"], "inside plaything_1,carton_1": ["yes", "no"], "inside plaything_2,carton_1": ["no", "no"], "inside plaything_3,carton_1": ["no", "no"], "nextto plaything_1,plaything_2": ["no", "no"], "nextto plaything_1,plaything_3": ["yes", "no"], "nextto plaything_1,carton_1": ["yes", "no"], "nextto plaything_2,plaything_1": ["yes", "no"], "nextto plaything_2,plaything_3": ["yes", "no"], "nextto plaything_2,carton_1": ["yes", "no"], "nextto plaything_3,plaything_1": ["no", "no"], "nextto plaything_3,plaything_2": ["no", "no"], "nextto plaything_3,carton_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.5862068965517241, "yes_accuracy": 0.6666666666666666, "yes_correct": 4, "yes_total": 6, "no_accuracy": 0.5652173913043478, "no_correct": 13, "no_total": 23, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 6, "no_total": 9}, "inside": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "nextto": {"accuracy": 0.4444444444444444, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.375, "no_correct": 3, "no_total": 8}}}, "step": 9, "actions": ["open-container(carton_1)", "grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_1": ["yes", "yes"], "reachable plaything_2": ["yes", "yes"], "reachable plaything_3": ["yes", "yes"], "reachable carton_1": ["yes", "no"], "holding plaything_1": ["no", "no"], "holding plaything_2": ["no", "yes"], "holding plaything_3": ["no", "no"], "open carton_1": ["no", "yes"], "ontop plaything_1,plaything_2": ["no", "no"], "ontop plaything_1,plaything_3": ["no", "no"], "ontop plaything_1,carton_1": ["no", "no"], "ontop plaything_2,plaything_1": ["yes", "no"], "ontop plaything_2,plaything_3": ["no", "no"], "ontop plaything_2,carton_1": ["no", "no"], "ontop plaything_3,plaything_1": ["no", "no"], "ontop plaything_3,plaything_2": ["no", "no"], "ontop plaything_3,carton_1": ["no", "no"], "inside plaything_1,carton_1": ["yes", "no"], "inside plaything_2,carton_1": ["no", "no"], "inside plaything_3,carton_1": ["no", "no"], "nextto plaything_1,plaything_2": ["no", "no"], "nextto plaything_1,plaything_3": ["yes", "no"], "nextto plaything_1,carton_1": ["yes", "no"], "nextto plaything_2,plaything_1": ["yes", "no"], "nextto plaything_2,plaything_3": ["yes", "no"], "nextto plaything_2,carton_1": ["yes", "no"], "nextto plaything_3,plaything_1": ["no", "no"], "nextto plaything_3,plaything_2": ["no", "no"], "nextto plaything_3,carton_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.6551724137931034, "yes_accuracy": 0.6666666666666666, "yes_correct": 4, "yes_total": 6, "no_accuracy": 0.6521739130434783, "no_correct": 15, "no_total": 23, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.8888888888888888, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.8888888888888888, "no_correct": 8, "no_total": 9}, "inside": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "nextto": {"accuracy": 0.4444444444444444, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.375, "no_correct": 3, "no_total": 8}}}, "step": 10, "actions": ["open-container(carton_1)", "grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_1": ["yes", "yes"], "reachable plaything_2": ["yes", "yes"], "reachable plaything_3": ["no", "yes"], "reachable carton_1": ["yes", "no"], "holding plaything_1": ["no", "no"], "holding plaything_2": ["no", "yes"], "holding plaything_3": ["no", "no"], "open carton_1": ["no", "yes"], "ontop plaything_1,plaything_2": ["no", "no"], "ontop plaything_1,plaything_3": ["no", "no"], "ontop plaything_1,carton_1": ["yes", "no"], "ontop plaything_2,plaything_1": ["no", "no"], "ontop plaything_2,plaything_3": ["no", "no"], "ontop plaything_2,carton_1": ["no", "no"], "ontop plaything_3,plaything_1": ["no", "no"], "ontop plaything_3,plaything_2": ["yes", "no"], "ontop plaything_3,carton_1": ["yes", "no"], "inside plaything_1,carton_1": ["no", "no"], "inside plaything_2,carton_1": ["no", "no"], "inside plaything_3,carton_1": ["no", "no"], "nextto plaything_1,plaything_2": ["yes", "no"], "nextto plaything_1,plaything_3": ["yes", "no"], "nextto plaything_1,carton_1": ["yes", "no"], "nextto plaything_2,plaything_1": ["yes", "no"], "nextto plaything_2,plaything_3": ["yes", "no"], "nextto plaything_2,carton_1": ["yes", "no"], "nextto plaything_3,plaything_1": ["no", "no"], "nextto plaything_3,plaything_2": ["no", "no"], "nextto plaything_3,carton_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.5517241379310345, "yes_accuracy": 0.5, "yes_correct": 3, "yes_total": 6, "no_accuracy": 0.5652173913043478, "no_correct": 13, "no_total": 23, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.6666666666666666, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.6666666666666666, "no_correct": 6, "no_total": 9}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "nextto": {"accuracy": 0.3333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.25, "no_correct": 2, "no_total": 8}}}, "step": 11, "actions": ["open-container(carton_1)", "grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}], "remaining_actions": ["grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"]}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Ihlen_1_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(plaything_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable plaything_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable plaything_2": ["yes", 1.3629273940663013e-08, 0.9999999863707261, "The image shows a robotic arm (agent) extending towards the plaything_2, which is located on the floor near the brown armchair. The robotic arm appears to be close enough to potentially reach the plaything_2, as it is within the arm's extension range. Therefore, it is reasonable to conclude that the plaything_2 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards the plaything_2, which is located on the floor near the brown armchair. The robotic arm appears to be close enough to potentially reach the plaything_2, as it is within the arm's extension range. Therefore, it is reasonable to conclude that the plaything_2 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable plaything_4": ["yes", 7.473215910807654e-08, 0.9999999252678409, "The image shows a robotic arm (agent) reaching towards a red object labeled \"plaything_4\" on the floor. The plaything_4 appears to be close to the robotic arm, within the arm's reach, as the arm is extended towards it. Therefore, the plaything_4 is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a red object labeled \"plaything_4\" on the floor. The plaything_4 appears to be close to the robotic arm, within the arm's reach, as the arm is extended towards it. Therefore, the plaything_4 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable plaything_1": {"before": false, "after": false}, "reachable plaything_3": {"before": false, "after": false}, "reachable carton_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(carton_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable carton_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable carton_1": ["yes", 3.984013034834957e-11, 0.9999999999601599, "The image shows a robotic arm (agent) in a virtual household environment. The arm is extended towards an object labeled \"carton_1\" which is located in front of the arm. Since the arm appears to be close to the carton and is reaching towards it, it suggests that the carton is within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm is extended towards an object labeled \"carton_1\" which is located in front of the arm. Since the arm appears to be close to the carton and is reaching towards it, it suggests that the carton is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable plaything_3": ["yes", 1.6924463176699236e-10, 0.9999999998307554, "The image shows a robotic arm (agent) in a virtual household environment. The arm is extended towards a red object labeled \"plaything_3\" which is located in front of the robot. The position of the arm and the proximity to the object suggest that the plaything_3 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The arm is extended towards a red object labeled \"plaything_3\" which is located in front of the robot. The position of the arm and the proximity to the object suggest that the plaything_3 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable plaything_4": ["yes", 2.5940586651104278e-08, 0.9999999740594133, "The image shows a robotic arm (agent) in a virtual household environment. The plaything_4 is marked with a red label and appears to be located near the robotic arm, which is extended towards it. Given the proximity and the position of the robotic arm, it seems that the plaything_4 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The plaything_4 is marked with a red label and appears to be located near the robotic arm, which is extended towards it. Given the proximity and the position of the robotic arm, it seems that the plaything_4 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable plaything_1": {"before": false, "after": false}, "reachable plaything_2": {"before": true, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-next-to(plaything_4, plaything_4)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding plaything_4": ["yes", 5.871806660841373e-10, 0.9999999994128194, "The image shows a robotic arm, which is the agent, reaching towards an object labeled \"plaything_4\" in the environment. The arm appears to be in close proximity to the object, suggesting that it is holding or about to hold it. Since the question asks if the agent is holding the plaything_4, and the arm is directly interacting with that object, the answer is likely \"Yes\".", true, "<explanation>\nThe image shows a robotic arm, which is the agent, reaching towards an object labeled \"plaything_4\" in the environment. The arm appears to be in close proximity to the object, suggesting that it is holding or about to hold it. Since the question asks if the agent is holding the plaything_4, and the arm is directly interacting with that object, the answer is likely \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable plaything_4": ["yes", 2.004208992525899e-10, 0.9999999997995791, "The image shows a robotic arm (agent) in a virtual household environment. The plaything_4 is visible in the image, located near the robotic arm. The arm appears to be close to the plaything_4, suggesting that it is within reach. Since the robotic arm is designed to interact with objects and is positioned near the plaything_4, it is reasonable to conclude that the plaything_4 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The plaything_4 is visible in the image, located near the robotic arm. The arm appears to be close to the plaything_4, suggesting that it is within reach. Since the robotic arm is designed to interact with objects and is positioned near the plaything_4, it is reasonable to conclude that the plaything_4 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "place-next-to(plaything_4, plaything_4)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding plaything_4": ["yes", 1.1665019718449454e-09, 0.999999998833498, "The image shows a robotic arm, which is the agent, reaching towards an object labeled \"plaything_4\" in the environment. The arm appears to be in close proximity to the object, suggesting that it is holding or about to hold it. Since the question asks if the agent is holding the plaything_4, and the arm is directly interacting with that object, the answer is \"Yes\".", true, "<explanation>\nThe image shows a robotic arm, which is the agent, reaching towards an object labeled \"plaything_4\" in the environment. The arm appears to be in close proximity to the object, suggesting that it is holding or about to hold it. Since the question asks if the agent is holding the plaything_4, and the arm is directly interacting with that object, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable plaything_4": ["yes", 2.4522941898500097e-08, 0.9999999754770581, "The image shows a robotic arm (agent) in a virtual household environment. The plaything_4 is marked with a red label and appears to be located near the robotic arm, which is extended towards it. Given the proximity and the position of the robotic arm, it seems that the plaything_4 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The plaything_4 is marked with a red label and appears to be located near the robotic arm, which is extended towards it. Given the proximity and the position of the robotic arm, it seems that the plaything_4 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable plaything_2": ["yes", "yes"], "reachable plaything_4": ["yes", "no"], "holding plaything_2": ["yes", "no"], "holding plaything_4": ["yes", "no"], "ontop plaything_2,plaything_4": ["no", "no"], "ontop plaything_4,plaything_2": ["no", "no"], "nextto plaything_2,plaything_4": ["no", "no"], "nextto plaything_4,plaything_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.625, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.5714285714285714, "no_correct": 4, "no_total": 7, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}}}, "step": 1, "actions": ["navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "place-inside(plaything_4, carton_1)"]}, {"enum_results": {"reachable plaything_3": ["yes", "no"], "reachable plaything_4": ["yes", "no"], "reachable carton_1": ["yes", "yes"], "holding plaything_3": ["no", "no"], "holding plaything_4": ["yes", "no"], "open carton_1": ["no", "yes"], "ontop plaything_3,plaything_4": ["no", "no"], "ontop plaything_3,carton_1": ["no", "no"], "ontop plaything_4,plaything_3": ["no", "no"], "ontop plaything_4,carton_1": ["no", "no"], "inside plaything_3,carton_1": ["no", "no"], "inside plaything_4,carton_1": ["no", "no"], "nextto plaything_3,plaything_4": ["yes", "no"], "nextto plaything_3,carton_1": ["no", "no"], "nextto plaything_4,plaything_3": ["no", "no"], "nextto plaything_4,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6875, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.7142857142857143, "no_correct": 10, "no_total": 14, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}}}, "step": 2, "actions": ["place-next-to(plaything_4, plaything_4)", "open-container(carton_1)", "grasp(plaything_4)", "place-inside(plaything_4, carton_1)", "navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)"]}, {"enum_results": {"reachable plaything_3": ["yes", "no"], "reachable plaything_4": ["yes", "no"], "reachable carton_1": ["yes", "yes"], "holding plaything_3": ["no", "no"], "holding plaything_4": ["yes", "no"], "open carton_1": ["no", "yes"], "ontop plaything_3,plaything_4": ["no", "no"], "ontop plaything_3,carton_1": ["yes", "no"], "ontop plaything_4,plaything_3": ["yes", "no"], "ontop plaything_4,carton_1": ["no", "no"], "inside plaything_3,carton_1": ["no", "no"], "inside plaything_4,carton_1": ["no", "no"], "nextto plaything_3,plaything_4": ["yes", "no"], "nextto plaything_3,carton_1": ["no", "no"], "nextto plaything_4,plaything_3": ["yes", "no"], "nextto plaything_4,carton_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.5, "no_correct": 7, "no_total": 14, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "holding": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 2, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 2, "no_total": 4}}}, "step": 3, "actions": ["place-next-to(plaything_4, plaything_4)", "open-container(carton_1)", "grasp(plaything_4)", "place-inside(plaything_4, carton_1)", "navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)"]}], "remaining_actions": ["open-container(carton_1)", "grasp(plaything_4)", "place-inside(plaything_4, carton_1)", "navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)"]}, "data/planning/igibson/medium/collect_misplaced_items_medium.pddl_Beechwood_0_int_23": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(gym_shoe_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable gym_shoe_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable gym_shoe_1": ["yes", 2.3371994196660067e-14, 0.9999999999999766, "The image shows a robotic arm (agent) reaching towards an object in a corner of a room. The object in question, gym_shoe_1, is not clearly visible in the image, but the arm is extended in a way that suggests it is reaching for an object near the wall. Since the question asks if gym_shoe_1 is in reach of the agent, and the arm appears to be extended towards the area where the shoe might be, it is reasonable to infer that the shoe is within reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object in a corner of a room. The object in question, gym_shoe_1, is not clearly visible in the image, but the arm is extended in a way that suggests it is reaching for an object near the wall. Since the question asks if gym_shoe_1 is in reach of the agent, and the arm appears to be extended towards the area where the shoe might be, it is reasonable to infer that the shoe is within reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable sock_1": {"before": false, "after": false}, "reachable sock_2": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}, "reachable table_2": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(gym_shoe_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable gym_shoe_1": ["yes", 2.7657720575777974e-11, 0.9999999999723422, "The image shows a robotic arm (agent) reaching towards an object in a corner of a room. The object in question, gym_shoe_1, is not clearly visible in the image, but based on the context, it is likely the object the robotic arm is reaching for. Since the arm is extended towards the corner and appears to be close to the object, it suggests that the gym_shoe_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object in a corner of a room. The object in question, gym_shoe_1, is not clearly visible in the image, but based on the context, it is likely the object the robotic arm is reaching for. Since the arm is extended towards the corner and appears to be close to the object, it suggests that the gym_shoe_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "holding sock_2": [true, false, false], "all_correct": true}, "effects_results": {"holding gym_shoe_1": ["yes", 7.027930903336828e-06, 0.9999929720690967, "The image shows a robotic arm holding a gym shoe, which appears to be labeled as \"gym_shoe_1.\" Since the arm is gripping the shoe and it is clearly visible in the hand of the robotic arm, the agent is indeed holding the gym_shoe_1.", true, "<explanation>\nThe image shows a robotic arm holding a gym shoe, which appears to be labeled as \"gym_shoe_1.\" Since the arm is gripping the shoe and it is clearly visible in the hand of the robotic arm, the agent is indeed holding the gym_shoe_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"ontop gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "ontop gym_shoe_1,sock_1": {"before": false, "after": false}, "ontop gym_shoe_1,sock_2": {"before": false, "after": false}, "ontop gym_shoe_1,table_1": {"before": false, "after": false}, "ontop gym_shoe_1,table_2": {"before": false, "after": false}, "ontop gym_shoe_1,cabinet_1": {"before": false, "after": false}, "nextto gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "nextto gym_shoe_1,sock_1": {"before": false, "after": false}, "nextto gym_shoe_1,sock_2": {"before": false, "after": false}, "nextto gym_shoe_1,table_1": {"before": false, "after": false}, "nextto gym_shoe_1,table_2": {"before": false, "after": false}, "nextto gym_shoe_1,cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(sock_2)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable sock_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable sock_2": ["yes", 4.032843010814619e-11, 0.9999999999596716, "The image shows a robotic arm (agent) reaching towards a pair of shoes, with a sock (sock_2) on the floor nearby. The sock_2 appears to be close to the robotic arm, which is extended towards the shoes. Given the proximity of the sock to the robotic arm's reach, it is likely within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a pair of shoes, with a sock (sock_2) on the floor nearby. The sock_2 appears to be close to the robotic arm, which is extended towards the shoes. Given the proximity of the sock to the robotic arm's reach, it is likely within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable gym_shoe_1": ["yes", 9.010176541094511e-06, 0.9999909898234589, "The image shows a robotic arm (agent) holding a gym shoe, specifically gym_shoe_1. Since the shoe is being held by the robotic arm, it is clearly within the agent's reach. Therefore, the gym_shoe_1 is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) holding a gym shoe, specifically gym_shoe_1. Since the shoe is being held by the robotic arm, it is clearly within the agent's reach. Therefore, the gym_shoe_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable table_1": ["yes", 5.230962156879229e-11, 0.9999999999476904, "The image shows a robotic arm (agent) reaching towards a shoe, with a small table nearby. The table is positioned close to the robotic arm, and the arm appears to be extending towards or over the table. Given the proximity and the arm's position, it is likely within reach of the table. Therefore, the table_1 is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a shoe, with a small table nearby. The table is positioned close to the robotic arm, and the arm appears to be extending towards or over the table. Given the proximity and the arm's position, it is likely within reach of the table. Therefore, the table_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable sock_1": {"before": false, "after": false}, "reachable table_2": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-next-to(gym_shoe_1, sock_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding gym_shoe_1": ["yes", 0.00046885076973719086, 0.9995311492302628, "The image shows a robotic arm (agent) holding a gym shoe. The shoe is clearly grasped by the robotic arm, indicating that the agent is indeed holding the gym_shoe_1.", true, "<explanation>\nThe image shows a robotic arm (agent) holding a gym shoe. The shoe is clearly grasped by the robotic arm, indicating that the agent is indeed holding the gym_shoe_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sock_2": ["yes", 7.159673189325558e-12, 0.9999999999928403, "The image shows a robotic arm (agent) reaching towards a pair of shoes, with a sock (sock_2) on the floor nearby. The sock_2 appears to be close to the robotic arm, which is extended towards the shoes. Given the proximity of the sock_2 to the robotic arm and the fact that the arm is reaching in that direction, it is reasonable to conclude that sock_2 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a pair of shoes, with a sock (sock_2) on the floor nearby. The sock_2 appears to be close to the robotic arm, which is extended towards the shoes. Given the proximity of the sock_2 to the robotic arm and the fact that the arm is reaching in that direction, it is reasonable to conclude that sock_2 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"nextto gym_shoe_1,sock_2": ["no", 0.9999999100576887, 8.994231121789413e-08, "In the image, the gym_shoe_1 is located on the table, and the sock_2 is also on the table, but they are not next to each other. The sock_2 is positioned closer to the edge of the table, while the gym_shoe_1 is more towards the center. Therefore, they are not next to each other.", false, "<explanation>\nIn the image, the gym_shoe_1 is located on the table, and the sock_2 is also on the table, but they are not next to each other. The sock_2 is positioned closer to the edge of the table, while the gym_shoe_1 is more towards the center. Therefore, they are not next to each other.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding gym_shoe_1": ["no", 0.9999983557255456, 1.6442744544122255e-06, "The image shows a robotic arm, which is the agent, but it is not holding any objects. Instead, there are some objects on the table, including what appears to be a gym shoe, but the arm is not grasping or holding it. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm, which is the agent, but it is not holding any objects. Instead, there are some objects on the table, including what appears to be a gym shoe, but the arm is not grasping or holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 5.617912861627794e-14, 0.9999999999999438, "The image shows a robotic arm (agent) in a household environment. The gym_shoe_1 is located on the table, near the wall, and appears to be within the vicinity of the robotic arm. Since the robotic arm is positioned close to the table and the shoe is on the table, it is likely within reach of the agent, assuming the arm can extend to that area.", true, "<explanation>\nThe image shows a robotic arm (agent) in a household environment. The gym_shoe_1 is located on the table, near the wall, and appears to be within the vicinity of the robotic arm. Since the robotic arm is positioned close to the table and the shoe is on the table, it is likely within reach of the agent, assuming the arm can extend to that area.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding sock_2": ["no", 0.9999919392457906, 8.06075420942368e-06, "The image shows a robotic arm, which is the agent, but it is not holding anything. There are some objects on the table, including what appears to be a sock, but the sock is not being held by the robotic arm. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm, which is the agent, but it is not holding anything. There are some objects on the table, including what appears to be a sock, but the sock is not being held by the robotic arm. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "all_correct": true}, "effects_results": {"holding gym_shoe_1": ["no", 0.9999999921599914, 7.840008632289497e-09, "The image shows a robotic arm, which is the agent, reaching towards a pair of shoes on a table. However, the arm is not gripping or holding the gym_shoe_1; it appears to be in the process of reaching or about to pick something up, but it is not currently holding the shoe.", false, "<explanation>\nThe image shows a robotic arm, which is the agent, reaching towards a pair of shoes on a table. However, the arm is not gripping or holding the gym_shoe_1; it appears to be in the process of reaching or about to pick something up, but it is not currently holding the shoe.\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop gym_shoe_1,sock_2": ["no", 0.9999997470847365, 2.529152634800029e-07, "In the image, the gym_shoe_1 is located on the table, while the sock_2 is on the floor. The gym_shoe_1 is not on top of the sock_2; instead, they are separated by some distance, with the shoe being elevated on the table and the sock lying on the floor. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the gym_shoe_1 is located on the table, while the sock_2 is on the floor. The gym_shoe_1 is not on top of the sock_2; instead, they are separated by some distance, with the shoe being elevated on the table and the sock lying on the floor. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop gym_shoe_1,table_1": ["no", 0.9999982336751174, 1.766324882596086e-06, "The image shows a robotic arm reaching towards a table with various objects on it. The gym_shoe_1 is visible on the table, but it is not on top of the table; it is on the floor near the table. Therefore, the gym_shoe_1 is not on top of the table_1.", true, "<explanation>\nThe image shows a robotic arm reaching towards a table with various objects on it. The gym_shoe_1 is visible on the table, but it is not on top of the table; it is on the floor near the table. Therefore, the gym_shoe_1 is not on top of the table_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto gym_shoe_1,sock_2": ["no", 0.999998648786573, 1.3512134270142746e-06, "In the image, the gym_shoe_1 is located on the table, and the sock_2 is on the same table but positioned further away from the gym_shoe_1. The sock_2 is not directly next to the gym_shoe_1; there is some space between them. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the gym_shoe_1 is located on the table, and the sock_2 is on the same table but positioned further away from the gym_shoe_1. The sock_2 is not directly next to the gym_shoe_1; there is some space between them. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto gym_shoe_1,table_1": ["yes", 1.806720340599101e-08, 0.9999999819327966, "The image shows a robotic arm reaching towards a table with some objects on it. The gym_shoe_1 is visible on the table, and it is positioned close to the edge of the table. The question asks if the gym_shoe_1 is next to the table_1. Since the gym_shoe_1 is on the table and close to its edge, it can be considered next to the table. Therefore, the answer is \"Yes\".", false, "<explanation>\nThe image shows a robotic arm reaching towards a table with some objects on it. The gym_shoe_1 is visible on the table, and it is positioned close to the edge of the table. The question asks if the gym_shoe_1 is next to the table_1. Since the gym_shoe_1 is on the table and close to its edge, it can be considered next to the table. Therefore, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "ontop gym_shoe_1,sock_1": {"before": false, "after": false}, "ontop gym_shoe_1,table_2": {"before": false, "after": false}, "ontop gym_shoe_1,cabinet_1": {"before": false, "after": false}, "nextto gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "nextto gym_shoe_1,sock_1": {"before": false, "after": false}, "nextto gym_shoe_1,table_2": {"before": false, "after": false}, "nextto gym_shoe_1,cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 1.300770960496688e-12, 0.9999999999986993, "The image shows a robotic arm (agent) reaching towards a shelf with various objects. The gym_shoe_1 is located on the table, near the edge, and appears to be within the reach of the robotic arm, which is extended towards the objects on the table. Since the arm is close to the shoe and seems capable of grasping it, the shoe is likely within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a shelf with various objects. The gym_shoe_1 is located on the table, near the edge, and appears to be within the reach of the robotic arm, which is extended towards the objects on the table. Since the arm is close to the shoe and seems capable of grasping it, the shoe is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding sock_2": ["no", 0.9999999972395232, 2.7604768714878984e-09, "The image shows a robotic arm reaching towards a sock on the table, but it is not clear if the robotic arm is actually holding the sock. The sock is on the table, and the robotic arm appears to be close to it, but there is no visible grasp or hold on the sock. Therefore, based on the image, the agent is not holding the sock.", true, "<explanation>\nThe image shows a robotic arm reaching towards a sock on the table, but it is not clear if the robotic arm is actually holding the sock. The sock is on the table, and the robotic arm appears to be close to it, but there is no visible grasp or hold on the sock. Therefore, based on the image, the agent is not holding the sock.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_1": ["no", "yes"], "holding gym_shoe_1": ["yes", "yes"], "holding sock_2": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["yes", "no"], "nextto gym_shoe_1,table_1": ["yes", "no"], "nextto sock_2,gym_shoe_1": ["yes", "no"], "nextto sock_2,table_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6923076923076923, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 6, "no_total": 9, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.25, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.25, "no_correct": 1, "no_total": 4}}}, "step": 3, "actions": ["place-next-to(gym_shoe_1, sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)", "navigate-to(gym_shoe_1)", "grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "holding gym_shoe_1": ["no", "no"], "holding sock_2": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_1": ["yes", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["no", "yes"], "nextto gym_shoe_1,table_1": ["yes", "no"], "nextto sock_2,gym_shoe_1": ["no", "yes"], "nextto sock_2,table_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.6923076923076923, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.75, "no_correct": 6, "no_total": 8, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "nextto": {"accuracy": 0.25, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}}}, "step": 4, "actions": ["grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "holding gym_shoe_1": ["no", "yes"], "holding sock_2": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_1": ["yes", "no"], "nextto gym_shoe_1,sock_2": ["no", "no"], "nextto gym_shoe_1,table_1": ["no", "no"], "nextto sock_2,gym_shoe_1": ["yes", "no"], "nextto sock_2,table_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6923076923076923, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 6, "no_total": 9, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 2, "no_total": 4}}}, "step": 5, "actions": ["grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}], "remaining_actions": ["navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, "data/planning/igibson/medium/collect_misplaced_items_medium.pddl_Beechwood_0_int_24": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(gym_shoe_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable gym_shoe_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable gym_shoe_1": ["yes", 1.1654282391726324e-10, 0.9999999998834572, "The image shows a robotic arm (agent) in a virtual household environment. The gym_shoe_1 is located on the floor near the corner of the room, close to the wall. The robotic arm is positioned in the corner, with its gripper close to the shoe. Given the proximity of the arm to the shoe, it appears that the shoe is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The gym_shoe_1 is located on the floor near the corner of the room, close to the wall. The robotic arm is positioned in the corner, with its gripper close to the shoe. Given the proximity of the arm to the shoe, it appears that the shoe is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable sock_1": {"before": false, "after": false}, "reachable sock_2": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}, "reachable table_2": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(gym_shoe_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable gym_shoe_1": ["yes", 1.107692701150418e-10, 0.9999999998892307, "The image shows a robotic arm (agent) in a virtual household environment. The gym_shoe_1 is located on the floor near the corner of the room, close to the wall. The robotic arm is positioned in the corner, with its gripper near the shoe. Given the proximity of the arm to the shoe, it appears that the shoe is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The gym_shoe_1 is located on the floor near the corner of the room, close to the wall. The robotic arm is positioned in the corner, with its gripper near the shoe. Given the proximity of the arm to the shoe, it appears that the shoe is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "holding sock_2": [true, false, false], "all_correct": true}, "effects_results": {"holding gym_shoe_1": ["yes", 1.6180715544077167e-10, 0.9999999998381929, "The image shows a robotic arm holding a gym shoe, which is positioned on a stand or rack. The shoe appears to be a gym shoe, and the robotic arm is gripping it. Since the question asks if the agent is holding \"gym_shoe_1,\" and the shoe in the image is labeled as \"gym_shoe_1,\" the answer is yes.", true, "<explanation>\nThe image shows a robotic arm holding a gym shoe, which is positioned on a stand or rack. The shoe appears to be a gym shoe, and the robotic arm is gripping it. Since the question asks if the agent is holding \"gym_shoe_1,\" and the shoe in the image is labeled as \"gym_shoe_1,\" the answer is yes.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"ontop gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "ontop gym_shoe_1,sock_1": {"before": false, "after": false}, "ontop gym_shoe_1,sock_2": {"before": false, "after": false}, "ontop gym_shoe_1,table_1": {"before": false, "after": false}, "ontop gym_shoe_1,table_2": {"before": false, "after": false}, "ontop gym_shoe_1,cabinet_1": {"before": false, "after": false}, "nextto gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "nextto gym_shoe_1,sock_1": {"before": false, "after": false}, "nextto gym_shoe_1,sock_2": {"before": false, "after": false}, "nextto gym_shoe_1,table_1": {"before": false, "after": false}, "nextto gym_shoe_1,table_2": {"before": false, "after": false}, "nextto gym_shoe_1,cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(sock_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable sock_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable sock_2": ["yes", 4.11146534296693e-09, 0.9999999958885346, "The image shows a robotic arm holding a shoe, and there is a sock on the floor. The sock_2 appears to be close to the robotic arm, which is reaching towards it. Since the sock is on the floor and the robotic arm is extended towards it, it is likely within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm holding a shoe, and there is a sock on the floor. The sock_2 appears to be close to the robotic arm, which is reaching towards it. Since the sock is on the floor and the robotic arm is extended towards it, it is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable gym_shoe_1": ["yes", 5.477092142478642e-07, 0.9999994522907858, "The image shows a robotic arm holding a gym shoe, which appears to be close to the agent. Since the robotic arm is actively holding the gym shoe and is extended towards the shoe, it indicates that the shoe is within reach of the agent. Therefore, the gym_shoe_1 is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm holding a gym shoe, which appears to be close to the agent. Since the robotic arm is actively holding the gym shoe and is extended towards the shoe, it indicates that the shoe is within reach of the agent. Therefore, the gym_shoe_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable table_1": ["no", 0.9999999999912289, 8.77110411824727e-12, "The image shows a robotic arm (agent) holding a shoe, and there is a table (table_1) in the background. The table appears to be at a distance from the robotic arm, which is actively holding an object and not directly interacting with the table. Based on the perspective, the table does not seem to be within immediate reach of the robotic arm, as the arm is extended towards the shoe and not towards the table.", true, "<explanation>\nThe image shows a robotic arm (agent) holding a shoe, and there is a table (table_1) in the background. The table appears to be at a distance from the robotic arm, which is actively holding an object and not directly interacting with the table. Based on the perspective, the table does not seem to be within immediate reach of the robotic arm, as the arm is extended towards the shoe and not towards the table.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable sock_1": {"before": false, "after": false}, "reachable table_2": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-next-to(gym_shoe_1, sock_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding gym_shoe_1": ["yes", 0.000736393102253983, 0.9992636068977461, "The image shows a robotic arm, which is the agent, holding a gym shoe. The shoe is clearly grasped by the robotic arm, indicating that the agent is indeed holding the gym_shoe_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding a gym shoe. The shoe is clearly grasped by the robotic arm, indicating that the agent is indeed holding the gym_shoe_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sock_2": ["yes", 2.401437981271884e-08, 0.9999999759856202, "The image shows a robotic arm holding a shoe, and there is a sock on the floor. The sock appears to be close to the robotic arm, which is extended towards it. Given the proximity of the sock to the robotic arm and the fact that the arm is reaching out, it is reasonable to conclude that the sock_2 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm holding a shoe, and there is a sock on the floor. The sock appears to be close to the robotic arm, which is extended towards it. Given the proximity of the sock to the robotic arm and the fact that the arm is reaching out, it is reasonable to conclude that the sock_2 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"nextto gym_shoe_1,sock_2": ["no", 0.9999905155438109, 9.484456189087027e-06, "In the image, the gym_shoe_1 is located on the table, and the sock_2 is on the floor near the table. The sock_2 is not directly next to the gym_shoe_1; there is some space between them. Therefore, the answer is \"No\".", false, "<explanation>\nIn the image, the gym_shoe_1 is located on the table, and the sock_2 is on the floor near the table. The sock_2 is not directly next to the gym_shoe_1; there is some space between them. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "holding gym_shoe_1": ["no", 0.9999734511133681, 2.6548886631920752e-05, "In the image, the robotic arm (agent) is visible, but it is not holding any object. The gym_shoe_1 is on the floor, not in the robotic arm's grasp. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the robotic arm (agent) is visible, but it is not holding any object. The gym_shoe_1 is on the floor, not in the robotic arm's grasp. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 3.965322680354919e-10, 0.9999999996034677, "The image shows a robotic arm (agent) in a virtual household environment. The gym_shoe_1 is located on the floor near the center of the image, close to the robotic arm. Given the proximity of the shoe to the arm, it appears to be within reach of the agent, which can extend or move to grasp objects nearby.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The gym_shoe_1 is located on the floor near the center of the image, close to the robotic arm. Given the proximity of the shoe to the arm, it appears to be within reach of the agent, which can extend or move to grasp objects nearby.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding sock_2": ["no", 0.9999773701838739, 2.2629816126086037e-05, "In the image, the robotic arm (agent) is visible, but it is not holding any objects. The sock_2 is on the floor, and there is no indication that the robotic arm is grasping or holding it. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the robotic arm (agent) is visible, but it is not holding any objects. The sock_2 is on the floor, and there is no indication that the robotic arm is grasping or holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "all_correct": true}, "effects_results": {"holding gym_shoe_1": ["yes", 0.0004403857505075809, 0.9995596142494925, "The image shows a robotic arm, which is the agent, holding a gym shoe. The shoe is clearly grasped by the robotic arm, indicating that the agent is indeed holding the gym_shoe_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding a gym shoe. The shoe is clearly grasped by the robotic arm, indicating that the agent is indeed holding the gym_shoe_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop gym_shoe_1,sock_2": ["no", 0.9999992985194441, 7.014805558760127e-07, "In the image, the gym_shoe_1 is being held by the robotic arm, and the sock_2 is on the floor nearby. The sock_2 is not positioned underneath or on top of the gym_shoe_1; instead, it is separate and on the ground. Therefore, the gym_shoe_1 is not on top of the sock_2.", true, "<explanation>\nIn the image, the gym_shoe_1 is being held by the robotic arm, and the sock_2 is on the floor nearby. The sock_2 is not positioned underneath or on top of the gym_shoe_1; instead, it is separate and on the ground. Therefore, the gym_shoe_1 is not on top of the sock_2.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop gym_shoe_1,table_1": ["no", 0.9999999999502764, 4.972350640561551e-11, "The image shows a robotic arm holding a gym shoe, which is positioned near a small table. The shoe appears to be resting on the table, but it is not clear if it is directly on top of the table or on an object on the table. Since the shoe is close to the table but not visibly on it, I cannot confirm that it is on top of the table.", true, "<explanation>\nThe image shows a robotic arm holding a gym shoe, which is positioned near a small table. The shoe appears to be resting on the table, but it is not clear if it is directly on top of the table or on an object on the table. Since the shoe is close to the table but not visibly on it, I cannot confirm that it is on top of the table.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto gym_shoe_1,sock_2": ["yes", 1.3448511583042594e-08, 0.9999999865514884, "In the image, the gym_shoe_1 is positioned on a surface, and there is a sock_2 nearby. The sock_2 appears to be on the same surface, close to the gym_shoe_1. Since they are close to each other and on the same surface, it can be concluded that the gym_shoe_1 is next to the sock_2.", false, "<explanation>\nIn the image, the gym_shoe_1 is positioned on a surface, and there is a sock_2 nearby. The sock_2 appears to be on the same surface, close to the gym_shoe_1. Since they are close to each other and on the same surface, it can be concluded that the gym_shoe_1 is next to the sock_2.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto gym_shoe_1,table_1": ["no", 0.9999999983126211, 1.6873789451307144e-09, "In the image, the gym_shoe_1 is positioned on the floor, and there is a small table nearby. The shoe appears to be placed close to the table, but it is not directly next to it. It is slightly in front of the table, but not adjacent or touching it. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the gym_shoe_1 is positioned on the floor, and there is a small table nearby. The shoe appears to be placed close to the table, but it is not directly next to it. It is slightly in front of the table, but not adjacent or touching it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "ontop gym_shoe_1,sock_1": {"before": false, "after": false}, "ontop gym_shoe_1,table_2": {"before": false, "after": false}, "ontop gym_shoe_1,cabinet_1": {"before": false, "after": false}, "nextto gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "nextto gym_shoe_1,sock_1": {"before": false, "after": false}, "nextto gym_shoe_1,table_2": {"before": false, "after": false}, "nextto gym_shoe_1,cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-next-to(gym_shoe_1, table_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"holding gym_shoe_1": ["yes", 0.00032368479604982103, 0.9996763152039502, "The image shows a robotic arm, which is the agent, holding a gym shoe. The shoe is clearly grasped by the robotic arm, indicating that the agent is indeed holding the gym_shoe_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding a gym shoe. The shoe is clearly grasped by the robotic arm, indicating that the agent is indeed holding the gym_shoe_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable table_1": ["yes", 2.643394171969651e-09, 0.9999999973566058, "The image shows a robotic arm (agent) near a table with objects on it. The table appears to be close to the robotic arm, and the arm is positioned in a way that suggests it can reach the objects on the table. Since the table is within the arm's vicinity and the arm is extended towards it, it is likely within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) near a table with objects on it. The table appears to be close to the robotic arm, and the arm is positioned in a way that suggests it can reach the objects on the table. Since the table is within the arm's vicinity and the arm is extended towards it, it is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"nextto gym_shoe_1,table_1": ["yes", 8.857441723989311e-11, 0.9999999999114256, "The image shows a robotic arm and a table with various objects on it. The gym_shoe_1 is visible on the table, and the question is whether it is next to the table_1. Since the gym_shoe_1 is on the table and the table_1 is the table itself, the shoe is indeed on or very close to the table, which can be considered as being next to it.", true, "<explanation>\nThe image shows a robotic arm and a table with various objects on it. The gym_shoe_1 is visible on the table, and the question is whether it is next to the table_1. Since the gym_shoe_1 is on the table and the table_1 is the table itself, the shoe is indeed on or very close to the table, which can be considered as being next to it.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding gym_shoe_1": ["no", 0.9999999908102666, 9.189733405180244e-09, "The image shows a robotic arm, which is the agent, but it is not holding the gym_shoe_1. Instead, the arm appears to be empty or holding something that is not visible in the current view. The gym_shoe_1 is not seen in the image, and there is no indication that the robotic arm is holding it. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm, which is the agent, but it is not holding the gym_shoe_1. Instead, the arm appears to be empty or holding something that is not visible in the current view. The gym_shoe_1 is not seen in the image, and there is no indication that the robotic arm is holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(sock_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable sock_2": ["no", 0.9999999999999999, 1.0530417918116792e-16, "The image shows a robotic arm (agent) in a household environment. The sock_2 is located on the floor near the bottom center of the image. The robotic arm appears to be positioned above a shelf with books and other objects, which is on the right side of the image. The sock_2 is on the floor, and the arm is not extending towards that area; it is positioned higher and to the right. Based on this, the sock_2 does not seem to be within the immediate reach of the robotic arm in its current position.", false, "<explanation>\nThe image shows a robotic arm (agent) in a household environment. The sock_2 is located on the floor near the bottom center of the image. The robotic arm appears to be positioned above a shelf with books and other objects, which is on the right side of the image. The sock_2 is on the floor, and the arm is not extending towards that area; it is positioned higher and to the right. Based on this, the sock_2 does not seem to be within the immediate reach of the robotic arm in its current position.\n</explanation>\n<answer>\nNo\n</answer>", false], "holding gym_shoe_1": ["no", 0.9999997320679623, 2.679320376552588e-07, "The image shows a robotic arm, which is the agent, but it is not holding any object. The arm appears to be extended towards the shelf with books and other items, but there is no indication that it is grasping or holding the gym_shoe_1 or any other object. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm, which is the agent, but it is not holding any object. The arm appears to be extended towards the shelf with books and other items, but there is no indication that it is grasping or holding the gym_shoe_1 or any other object. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(sock_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable sock_2": ["yes", 8.205638014837584e-10, 0.9999999991794362, "The image shows a robotic arm (agent) in a virtual household environment. The sock_2 is located on the floor near the bottom center of the image. The robotic arm appears to be positioned to the right of the sock_2, with its gripper close to the sock. Given the proximity of the robotic arm to the sock_2, it is likely within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) in a virtual household environment. The sock_2 is located on the floor near the bottom center of the image. The robotic arm appears to be positioned to the right of the sock_2, with its gripper close to the sock. Given the proximity of the robotic arm to the sock_2, it is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding gym_shoe_1": ["no", 0.9999999922234681, 7.776531848407804e-09, "The image shows a robotic arm, which is the agent, but it is not holding the gym_shoe_1. Instead, the arm appears to be empty or holding something that is not visible in the current view. The gym_shoe_1 is not seen in the image, and there is no indication that the robotic arm is holding it. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm, which is the agent, but it is not holding the gym_shoe_1. Instead, the arm appears to be empty or holding something that is not visible in the current view. The gym_shoe_1 is not seen in the image, and there is no indication that the robotic arm is holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "all_correct": true}, "effects_results": {"holding sock_2": ["yes", 6.018492079698776e-12, 0.9999999999939815, "The image shows a robotic arm, which is the agent, reaching towards a sock labeled \"sock_2\" on a shelf. The robotic arm appears to be in the process of grasping or holding an object, and the sock_2 is located on the shelf in front of the arm. Since the arm is positioned very close to the sock_2 and appears to be gripping or about to grip it, it is reasonable to conclude that the agent is holding sock_2.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, reaching towards a sock labeled \"sock_2\" on a shelf. The robotic arm appears to be in the process of grasping or holding an object, and the sock_2 is located on the shelf in front of the arm. Since the arm is positioned very close to the sock_2 and appears to be gripping or about to grip it, it is reasonable to conclude that the agent is holding sock_2.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop sock_2,gym_shoe_1": ["no", 0.9999998735497887, 1.2645021134759537e-07, "The image shows a robotic arm holding a white sock, labeled as sock_2, and a gym shoe labeled as gym_shoe_1. The sock_2 is being held above the gym_shoe_1, but it is not placed on top of it. The sock is suspended in the air, not resting on the shoe. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm holding a white sock, labeled as sock_2, and a gym shoe labeled as gym_shoe_1. The sock_2 is being held above the gym_shoe_1, but it is not placed on top of it. The sock is suspended in the air, not resting on the shoe. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop sock_2,table_1": ["no", 0.9999999826593107, 1.7340689351693095e-08, "In the image, the sock_2 is being held by the robotic arm, and the table_1 is located in the room. The sock_2 appears to be near the table_1, but it is not on top of it; it is being held above or near the table. Therefore, the sock_2 is not on top of the table_1.", true, "<explanation>\nIn the image, the sock_2 is being held by the robotic arm, and the table_1 is located in the room. The sock_2 appears to be near the table_1, but it is not on top of it; it is being held above or near the table. Therefore, the sock_2 is not on top of the table_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto sock_2,gym_shoe_1": ["no", 0.9999999927661456, 7.233854423042181e-09, "In the image, the sock_2 is held by the robotic arm and is not positioned next to the gym_shoe_1. The gym_shoe_1 is on the floor near the wall, while sock_2 is being held in the air by the robotic arm, which is closer to the center of the image. Therefore, sock_2 is not next to gym_shoe_1.", true, "<explanation>\nIn the image, the sock_2 is held by the robotic arm and is not positioned next to the gym_shoe_1. The gym_shoe_1 is on the floor near the wall, while sock_2 is being held in the air by the robotic arm, which is closer to the center of the image. Therefore, sock_2 is not next to gym_shoe_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto sock_2,table_1": ["yes", 4.3657147564810483e-10, 0.9999999995634286, "The image shows a robotic arm reaching towards a sock labeled \"sock_2\" which is placed on a small table or shelf. The sock_2 is positioned very close to the edge of the table_1, which is also visible in the image. Since the sock_2 is directly on or very near the surface of the table_1, it can be considered next to the table_1.", false, "<explanation>\nThe image shows a robotic arm reaching towards a sock labeled \"sock_2\" which is placed on a small table or shelf. The sock_2 is positioned very close to the edge of the table_1, which is also visible in the image. Since the sock_2 is directly on or very near the surface of the table_1, it can be considered next to the table_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop sock_2,sock_1": {"before": false, "after": false}, "ontop sock_2,sock_2": {"before": null, "after": false}, "ontop sock_2,table_2": {"before": false, "after": false}, "ontop sock_2,cabinet_1": {"before": false, "after": false}, "nextto sock_2,sock_1": {"before": false, "after": false}, "nextto sock_2,sock_2": {"before": null, "after": false}, "nextto sock_2,table_2": {"before": false, "after": false}, "nextto sock_2,cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(table_2)", "action_correct": true, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable table_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable table_2": ["yes", 2.8327862926552126e-15, 0.9999999999999971, "The image shows a robotic arm (agent) positioned above a table, with the arm extending towards the center of the table. The table appears to be within the arm's reach, as the robotic arm is actively reaching or holding an object close to the table surface. Since the arm is extended towards the table and the table is directly beneath the arm, it is reasonable to conclude that the table is within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned above a table, with the arm extending towards the center of the table. The table appears to be within the arm's reach, as the robotic arm is actively reaching or holding an object close to the table surface. Since the arm is extended towards the table and the table is directly beneath the arm, it is reasonable to conclude that the table is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sock_2": ["no", 0.9999999998218523, 1.7814771431037004e-10, "The image shows a robotic arm (agent) reaching towards an object on a table. The object in question, sock_2, is not clearly visible in the image, so I cannot definitively determine its position relative to the robotic arm. Since the sock_2 is not explicitly shown or identified in the image, I cannot confirm whether it is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an object on a table. The object in question, sock_2, is not clearly visible in the image, so I cannot definitively determine its position relative to the robotic arm. Since the sock_2 is not explicitly shown or identified in the image, I cannot confirm whether it is within reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {"reachable gym_shoe_1": {"before": true, "after": false}, "reachable sock_1": {"before": false, "after": false}, "reachable table_1": {"before": true, "after": false}, "reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_1": ["no", "yes"], "holding gym_shoe_1": ["yes", "yes"], "holding sock_2": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["no", "no"], "nextto gym_shoe_1,table_1": ["yes", "no"], "nextto sock_2,gym_shoe_1": ["yes", "no"], "nextto sock_2,table_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7692307692307693, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.7777777777777778, "no_correct": 7, "no_total": 9, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 2, "no_total": 4}}}, "step": 3, "actions": ["place-next-to(gym_shoe_1, sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)", "navigate-to(gym_shoe_1)", "grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "holding gym_shoe_1": ["no", "no"], "holding sock_2": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["yes", "yes"], "nextto gym_shoe_1,table_1": ["no", "no"], "nextto sock_2,gym_shoe_1": ["yes", "yes"], "nextto sock_2,table_1": ["no", "no"]}, "enum_metrics": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 5, "yes_total": 5, "no_accuracy": 1.0, "no_correct": 8, "no_total": 8, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}}}, "step": 4, "actions": ["grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "holding gym_shoe_1": ["yes", "yes"], "holding sock_2": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["yes", "no"], "nextto gym_shoe_1,table_1": ["yes", "no"], "nextto sock_2,gym_shoe_1": ["yes", "no"], "nextto sock_2,table_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6923076923076923, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.5555555555555556, "no_correct": 5, "no_total": 9, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 4}}}, "step": 5, "actions": ["place-next-to(gym_shoe_1, table_1)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)", "navigate-to(gym_shoe_1)", "grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["no", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "holding gym_shoe_1": ["no", "no"], "holding sock_2": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["no", "no"], "nextto gym_shoe_1,table_1": ["no", "yes"], "nextto sock_2,gym_shoe_1": ["no", "no"], "nextto sock_2,table_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8461538461538461, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 9, "no_total": 9, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.75, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}}}, "step": 7, "actions": ["grasp(sock_2)", "navigate-to(gym_shoe_1)", "navigate-to(table_2)", "place-on(sock_2, table_2)", "navigate-to(gym_shoe_1)", "grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "holding gym_shoe_1": ["yes", "no"], "holding sock_2": ["yes", "yes"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["yes", "no"], "nextto gym_shoe_1,table_1": ["yes", "yes"], "nextto sock_2,gym_shoe_1": ["no", "no"], "nextto sock_2,table_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8461538461538461, "yes_accuracy": 1.0, "yes_correct": 5, "yes_total": 5, "no_accuracy": 0.75, "no_correct": 6, "no_total": 8, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "nextto": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}}}, "step": 8, "actions": ["navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "place-on(sock_2, table_2)"]}], "remaining_actions": ["place-on(sock_2, table_2)"]}, "data/planning/igibson/medium/collect_misplaced_items_medium.pddl_Merom_1_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable gym_shoe_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable gym_shoe_1": ["yes", 1.798275112731295e-13, 0.9999999999998201, "The image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, within a reachable distance, considering the proximity to the chair and the arm's position. Therefore, it is likely that the gym_shoe_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, within a reachable distance, considering the proximity to the chair and the arm's position. Therefore, it is likely that the gym_shoe_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sock_1": ["yes", 1.8474052953041803e-13, 0.9999999999998153, "The image shows a robotic arm (agent) extending towards a wall with a sock labeled \"sock_1\" on the floor near a chair. The sock appears to be close to the arm's reach, as the arm is extended in that direction and the sock is within the visible area of the arm's reach. Based on the position and extension of the robotic arm, it seems possible for the agent to reach the sock.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards a wall with a sock labeled \"sock_1\" on the floor near a chair. The sock appears to be close to the arm's reach, as the arm is extended in that direction and the sock is within the visible area of the arm's reach. Based on the position and extension of the robotic arm, it seems possible for the agent to reach the sock.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable table_1": ["no", 0.9999999999999961, 3.881221010006344e-15, "The image shows a robotic arm (agent) positioned near a wall, with a view of a dining area that includes two tables labeled \"table_1\" and \"table_2.\" The \"table_1\" is located at the far end of the room, near the windows, and appears to be quite a distance from the robotic arm, which is closer to the camera and the kitchen area. Given the perspective, the distance between the robotic arm and \"table_1\" seems too great for the arm to reach comfortably without moving closer.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near a wall, with a view of a dining area that includes two tables labeled \"table_1\" and \"table_2.\" The \"table_1\" is located at the far end of the room, near the windows, and appears to be quite a distance from the robotic arm, which is closer to the camera and the kitchen area. Given the perspective, the distance between the robotic arm and \"table_1\" seems too great for the arm to reach comfortably without moving closer.\n</explanation>\n<answer>\nNo\n</answer>", true], "reachable table_2": ["no", 1.0, 5.548051072135287e-23, "The image shows a robotic arm (agent) positioned near a wall, with a view of a kitchen and dining area. The table_2 is labeled and located behind the person sitting at the table, which is in the same room. The robotic arm appears to be extended towards the area near the person, but the table_2 is further back in the room, beyond the person and the table_1. Given the perspective, the robotic arm does not seem to be close enough to reach table_2 directly, as it is positioned in the foreground near the wall and the person.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near a wall, with a view of a kitchen and dining area. The table_2 is labeled and located behind the person sitting at the table, which is in the same room. The robotic arm appears to be extended towards the area near the person, but the table_2 is further back in the room, beyond the person and the table_1. Given the perspective, the robotic arm does not seem to be close enough to reach table_2 directly, as it is positioned in the foreground near the wall and the person.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable sock_2": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 3.3667086725850254e-13, 0.9999999999996634, "The image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, within a reachable distance, considering the proximity to the chair and the arm's extension. Therefore, it is likely that the gym_shoe_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, within a reachable distance, considering the proximity to the chair and the arm's extension. Therefore, it is likely that the gym_shoe_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 7.815301200257897e-14, 0.9999999999999218, "The image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, within a reachable distance, considering the proximity to the chair and the arm's extension. Therefore, it is likely that the gym_shoe_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, within a reachable distance, considering the proximity to the chair and the arm's extension. Therefore, it is likely that the gym_shoe_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 8.619395402799062e-14, 0.9999999999999138, "The image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, which is near the wall and the monitor. Given the proximity of the shoe to the agent, it is likely within reach or very close to it.", false, "<explanation>\nThe image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, which is near the wall and the monitor. Given the proximity of the shoe to the agent, it is likely within reach or very close to it.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 9.420427303930688e-14, 0.9999999999999057, "The image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, within a reachable distance, considering the proximity to the chair and the arm's extension. Therefore, it is likely that the gym_shoe_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near a wall with a monitor, and there is a gym_shoe_1 on the floor near a chair. The gym_shoe_1 appears to be close to the agent's current position, within a reachable distance, considering the proximity to the chair and the arm's extension. Therefore, it is likely that the gym_shoe_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding sock_1": ["no", 0.9999999998910188, 1.0898112676201353e-10, "The image shows a robotic arm extending towards a wall, but there is no visible sock_1 in the robotic arm's grasp or in the immediate vicinity being held by the agent. The sock_1 is not visible in the image, and the robotic arm appears to be empty or holding nothing identifiable as sock_1. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm extending towards a wall, but there is no visible sock_1 in the robotic arm's grasp or in the immediate vicinity being held by the agent. The sock_1 is not visible in the image, and the robotic arm appears to be empty or holding nothing identifiable as sock_1. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sock_2": [true, false, false], "all_correct": true}, "effects_results": {"holding gym_shoe_1": ["yes", 2.4909675583202787e-09, 0.9999999975090325, "The image shows a robotic arm (agent) reaching towards a table, but it is holding a black object that appears to be a gym_shoe_1, based on the context provided. The gym_shoe_1 is located on the table, and the agent's hand is gripping it. Therefore, the agent is indeed holding the gym_shoe_1.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a table, but it is holding a black object that appears to be a gym_shoe_1, based on the context provided. The gym_shoe_1 is located on the table, and the agent's hand is gripping it. Therefore, the agent is indeed holding the gym_shoe_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop gym_shoe_1,sock_1": ["no", 0.9999998566098136, 1.4339018643126002e-07, "The image shows a robotic arm holding a sock_1, which is placed on a table. The gym_shoe_1 is visible on the table, but it is not on top of the sock_1; instead, it is positioned further along the table. Therefore, the gym_shoe_1 is not on top of the sock_1.", true, "<explanation>\nThe image shows a robotic arm holding a sock_1, which is placed on a table. The gym_shoe_1 is visible on the table, but it is not on top of the sock_1; instead, it is positioned further along the table. Therefore, the gym_shoe_1 is not on top of the sock_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop gym_shoe_1,table_1": ["yes", 4.04667881049075e-11, 0.9999999999595333, "The image shows a robotic arm holding an object near a table. The object in the robotic hand appears to be a gym shoe, specifically labeled as \"gym_shoe_1.\" The table in the image is labeled as \"table_1.\" The gym_shoe_1 is positioned directly on top of the surface of table_1, as it is resting on the table's surface and not beside or underneath it. Therefore, the gym_shoe_1 is on top of table_1.", false, "<explanation>\nThe image shows a robotic arm holding an object near a table. The object in the robotic hand appears to be a gym shoe, specifically labeled as \"gym_shoe_1.\" The table in the image is labeled as \"table_1.\" The gym_shoe_1 is positioned directly on top of the surface of table_1, as it is resting on the table's surface and not beside or underneath it. Therefore, the gym_shoe_1 is on top of table_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "ontop gym_shoe_1,table_2": ["yes", 4.678386407835525e-10, 0.9999999995321613, "The image shows a robotic arm holding an object labeled \"gym_shoe_1\" near a table. The object \"table_2\" is visible beneath the \"gym_shoe_1\" and appears to be a part of the table surface. Since \"gym_shoe_1\" is positioned directly on the surface of \"table_2\" and not elevated above it, it is on top of \"table_2\".", false, "<explanation>\nThe image shows a robotic arm holding an object labeled \"gym_shoe_1\" near a table. The object \"table_2\" is visible beneath the \"gym_shoe_1\" and appears to be a part of the table surface. Since \"gym_shoe_1\" is positioned directly on the surface of \"table_2\" and not elevated above it, it is on top of \"table_2\".\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto gym_shoe_1,sock_1": ["yes", 3.8758657137057326e-08, 0.9999999612413428, "The image shows a robotic arm holding a sock, with a gym_shoe_1 visible on the table. The sock_1 is also visible on the table, near the gym_shoe_1. Since both objects are on the same surface and close to each other, the gym_shoe_1 is next to the sock_1.", false, "<explanation>\nThe image shows a robotic arm holding a sock, with a gym_shoe_1 visible on the table. The sock_1 is also visible on the table, near the gym_shoe_1. Since both objects are on the same surface and close to each other, the gym_shoe_1 is next to the sock_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto gym_shoe_1,table_1": ["yes", 2.5350580898379578e-12, 0.9999999999974649, "The image shows a robotic arm holding an object near a table. The object in the robotic arm's hand appears to be a gym_shoe_1, which is located on the table. The table_1 is visible in the image, and the gym_shoe_1 is placed directly on it, close to the edge. Since the gym_shoe_1 is on the table and very close to the table_1, it can be considered next to it.", false, "<explanation>\nThe image shows a robotic arm holding an object near a table. The object in the robotic arm's hand appears to be a gym_shoe_1, which is located on the table. The table_1 is visible in the image, and the gym_shoe_1 is placed directly on it, close to the edge. Since the gym_shoe_1 is on the table and very close to the table_1, it can be considered next to it.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto gym_shoe_1,table_2": ["no", 1.0, 2.514777010458885e-25, "The image shows a robotic arm holding an object near a table. The table_2 is located in the foreground, and the gym_shoe_1 is positioned on the table, close to the edge. The shoe appears to be next to the table_2, but it is not directly adjacent or touching it. It is on the surface of the table, but not necessarily \"next to\" in the sense of being immediately beside the table. Since the question asks if the gym_shoe_1 is next to the table_2, and considering it is on the table rather than beside it, the answer depends on the interpretation. Given the typical understanding of \"next to\" as being adjacent or very close, and the shoe being on the table, I will conclude that it is not next to the table but on it.", true, "<explanation>\nThe image shows a robotic arm holding an object near a table. The table_2 is located in the foreground, and the gym_shoe_1 is positioned on the table, close to the edge. The shoe appears to be next to the table_2, but it is not directly adjacent or touching it. It is on the surface of the table, but not necessarily \"next to\" in the sense of being immediately beside the table. Since the question asks if the gym_shoe_1 is next to the table_2, and considering it is on the table rather than beside it, the answer depends on the interpretation. Given the typical understanding of \"next to\" as being adjacent or very close, and the shoe being on the table, I will conclude that it is not next to the table but on it.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "ontop gym_shoe_1,sock_2": {"before": false, "after": false}, "ontop gym_shoe_1,cabinet_1": {"before": false, "after": false}, "nextto gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "nextto gym_shoe_1,sock_2": {"before": false, "after": false}, "nextto gym_shoe_1,cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(sock_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable sock_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable sock_2": ["yes", 4.451133747024568e-10, 0.9999999995548866, "The image shows a robotic arm holding a sock, which appears to be sock_2, in a household environment. The sock is being held close to the arm, and the arm is extended towards the sock, indicating that the sock is within the reach of the robotic arm. Since the sock is being held by the robotic arm, it suggests that the sock is indeed within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm holding a sock, which appears to be sock_2, in a household environment. The sock is being held close to the arm, and the arm is extended towards the sock, indicating that the sock is within the reach of the robotic arm. Since the sock is being held by the robotic arm, it suggests that the sock is indeed within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable gym_shoe_1": ["yes", 3.220516347641372e-06, 0.9999967794836524, "The image shows a robotic arm holding a gym shoe, which appears to be within the agent\u2019s reach. Since the shoe is being held by the robotic arm, it indicates that the shoe is accessible to the agent and within its reach.", false, "<explanation>\nThe image shows a robotic arm holding a gym shoe, which appears to be within the agent\u2019s reach. Since the shoe is being held by the robotic arm, it indicates that the shoe is accessible to the agent and within its reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_1": ["yes", 1.51928658042841e-10, 0.9999999998480713, "The image shows a robotic arm holding a shoe, and in the background, there is a cabinet labeled \"cabinet_1.\" The cabinet is positioned against the wall, and the robotic arm is extended towards the shoe, which is close to the cabinet. Given the perspective, the cabinet appears to be within the reach of the robotic arm, as the arm is extended in that direction and the cabinet is nearby.", false, "<explanation>\nThe image shows a robotic arm holding a shoe, and in the background, there is a cabinet labeled \"cabinet_1.\" The cabinet is positioned against the wall, and the robotic arm is extended towards the shoe, which is close to the cabinet. Given the perspective, the cabinet appears to be within the reach of the robotic arm, as the arm is extended in that direction and the cabinet is nearby.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable sock_1": {"before": true, "after": false}, "reachable table_1": {"before": true, "after": false}, "reachable table_2": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(table_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable table_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable table_2": ["no", 0.9999999999687635, 3.1236497517687465e-11, "The image shows a robotic arm holding a shoe, and the environment appears to be a household with furniture. However, there is no clear view of a table labeled \"table_2\" or any specific object named \"table_2\" in the image. Without visual confirmation of \"table_2\" or its proximity to the robotic arm, I cannot determine if it is within reach. Therefore, based on the available information, I cannot confirm that \"table_2\" is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm holding a shoe, and the environment appears to be a household with furniture. However, there is no clear view of a table labeled \"table_2\" or any specific object named \"table_2\" in the image. Without visual confirmation of \"table_2\" or its proximity to the robotic arm, I cannot determine if it is within reach. Therefore, based on the available information, I cannot confirm that \"table_2\" is in reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable gym_shoe_1": ["yes", 6.080441773773713e-09, 0.9999999939195582, "The image shows a robotic arm holding a piece of paper, and a gym shoe is placed on top of the paper. The shoe appears to be close to the robotic arm, which suggests it is within reach. Since the robotic arm is actively holding the paper and the shoe is on top of it, the shoe is likely within the arm's reach.", false, "<explanation>\nThe image shows a robotic arm holding a piece of paper, and a gym shoe is placed on top of the paper. The shoe appears to be close to the robotic arm, which suggests it is within reach. Since the robotic arm is actively holding the paper and the shoe is on top of it, the shoe is likely within the arm's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable sock_1": {"before": false, "after": false}, "reachable sock_2": {"before": true, "after": false}, "reachable table_1": {"before": false, "after": false}, "reachable cabinet_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(sock_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable sock_2": [true, false, false], "all_correct": true}, "effects_results": {"reachable sock_2": ["yes", 5.455587283740936e-09, 0.9999999945444127, "The image shows a robotic arm holding a shoe, and there is a sock on the floor. The sock appears to be close to the robotic arm, which is extended towards it. Given the perspective and the position of the robotic arm, it seems that the sock is within reach of the agent, as the arm is already extended in that direction.", true, "<explanation>\nThe image shows a robotic arm holding a shoe, and there is a sock on the floor. The sock appears to be close to the robotic arm, which is extended towards it. Given the perspective and the position of the robotic arm, it seems that the sock is within reach of the agent, as the arm is already extended in that direction.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable gym_shoe_1": ["yes", 6.2728409268701425e-06, 0.9999937271590731, "The image shows a robotic arm holding a gym shoe, which appears to be close to the agent. Since the shoe is being held by the robotic arm, it indicates that the shoe is within the agent's reach. Therefore, the gym_shoe_1 is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm holding a gym shoe, which appears to be close to the agent. Since the shoe is being held by the robotic arm, it indicates that the shoe is within the agent's reach. Therefore, the gym_shoe_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable cabinet_1": ["yes", 7.133987502784072e-09, 0.9999999928660125, "The image shows a robotic arm holding a shoe, with a cabinet visible in the background. The cabinet appears to be at a standard height, and the robotic arm is extended towards the cabinet. Given the perspective and the typical reach of such robotic arms, it is likely that the cabinet is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm holding a shoe, with a cabinet visible in the background. The cabinet appears to be at a standard height, and the robotic arm is extended towards the cabinet. Given the perspective and the typical reach of such robotic arms, it is likely that the cabinet is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable sock_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}, "reachable table_2": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-next-to(gym_shoe_1, sock_2)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"holding gym_shoe_1": ["yes", 2.867570931699951e-07, 0.9999997132429068, "The image shows a robotic arm holding a gym shoe, which appears to be a black and gray athletic shoe. The question asks if the agent is holding the gym_shoe_1. Since the shoe in the image matches the description of a gym shoe and is being held by the robotic arm, the answer is \"Yes\".", true, "<explanation>\nThe image shows a robotic arm holding a gym shoe, which appears to be a black and gray athletic shoe. The question asks if the agent is holding the gym_shoe_1. Since the shoe in the image matches the description of a gym shoe and is being held by the robotic arm, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable sock_2": ["yes", 1.0376975255827476e-08, 0.9999999896230247, "The image shows a robotic arm holding a shoe, and there is a sock on the floor. The sock appears to be close to the robotic arm, which is extended towards it. Given the perspective and the position of the robotic arm, it seems that the sock is within reach of the agent, as the arm is already extended in that direction.", true, "<explanation>\nThe image shows a robotic arm holding a shoe, and there is a sock on the floor. The sock appears to be close to the robotic arm, which is extended towards it. Given the perspective and the position of the robotic arm, it seems that the sock is within reach of the agent, as the arm is already extended in that direction.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"nextto gym_shoe_1,sock_2": ["yes", 2.286115998454707e-06, 0.9999977138840015, "In the image, there are two objects labeled as gym_shoe_1 and sock_2. The gym_shoe_1 is located to the left of sock_2, and they are positioned very close to each other on the floor. Since they are adjacent and next to each other, the answer is \"Yes\".", true, "<explanation>\nIn the image, there are two objects labeled as gym_shoe_1 and sock_2. The gym_shoe_1 is located to the left of sock_2, and they are positioned very close to each other on the floor. Since they are adjacent and next to each other, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", true], "holding gym_shoe_1": ["no", 0.9999999999745471, 2.545284931400853e-11, "The image shows a robotic arm reaching towards a pair of shoes on the floor. The arm appears to be in the process of grasping or about to grasp an object, but it is not clear from the image whether it is holding any object at this moment. The shoes are on the floor, and there is no visible indication that the robotic arm is currently holding or gripping the gym_shoe_1. Therefore, based on the image, the agent is not holding the gym_shoe_1.", true, "<explanation>\nThe image shows a robotic arm reaching towards a pair of shoes on the floor. The arm appears to be in the process of grasping or about to grasp an object, but it is not clear from the image whether it is holding any object at this moment. The shoes are on the floor, and there is no visible indication that the robotic arm is currently holding or gripping the gym_shoe_1. Therefore, based on the image, the agent is not holding the gym_shoe_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "grasp(sock_2)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable sock_2": ["yes", 9.4794380857946e-13, 0.9999999999990521, "The image shows a robotic arm (agent) extending towards the floor, with two socks visible near the wall. The sock_2 is the sock on the right, which appears to be close to the robotic arm's reach. Since the sock_2 is on the floor and near the arm's extension, it is likely within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards the floor, with two socks visible near the wall. The sock_2 is the sock on the right, which appears to be close to the robotic arm's reach. Since the sock_2 is on the floor and near the arm's extension, it is likely within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding gym_shoe_1": ["no", 0.9999633575797005, 3.664242029959816e-05, "The image shows a robotic arm, which is the agent, but it is not holding anything. The gym_shoe_1 is on the floor, and there is no indication that the robotic arm is gripping or holding it. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm, which is the agent, but it is not holding anything. The gym_shoe_1 is on the floor, and there is no indication that the robotic arm is gripping or holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "all_correct": true}, "effects_results": {"holding sock_2": ["no", 0.99998315069103, 1.6849308969916777e-05, "The image shows a robotic arm with a gloved hand, but it is not holding anything. The sock_2 is visible on the floor, and there is no indication that the robotic arm is gripping or holding it. Therefore, the answer is \"No\".", false, "<explanation>\nThe image shows a robotic arm with a gloved hand, but it is not holding anything. The sock_2 is visible on the floor, and there is no indication that the robotic arm is gripping or holding it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop sock_2,gym_shoe_1": ["no", 0.99999908673605, 9.132639499940022e-07, "The image shows a sock labeled \"sock_2\" on the floor near a wall, and a gym shoe labeled \"gym_shoe_1\" also on the floor. The sock is positioned closer to the wall, while the gym shoe is nearby but not directly on top of the sock. There is no indication that sock_2 is placed on top of gym_shoe_1; they are separate objects on the floor.", true, "<explanation>\nThe image shows a sock labeled \"sock_2\" on the floor near a wall, and a gym shoe labeled \"gym_shoe_1\" also on the floor. The sock is positioned closer to the wall, while the gym shoe is nearby but not directly on top of the sock. There is no indication that sock_2 is placed on top of gym_shoe_1; they are separate objects on the floor.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop sock_2,table_2": ["no", 0.9999912206359156, 8.779364084347825e-06, "The image shows a sock on the floor near a wall, and a table in the background. The sock is not on top of the table; it is on the floor, below the table. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a sock on the floor near a wall, and a table in the background. The sock is not on top of the table; it is on the floor, below the table. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop sock_2,cabinet_1": ["no", 0.9999950921511642, 4.907848835734408e-06, "The image shows a sock on the floor near a cabinet, but there is no indication that sock_2 is on top of the cabinet_1. The sock appears to be on the ground, and the cabinet is behind it. Therefore, the sock_2 is not on top of the cabinet_1.", true, "<explanation>\nThe image shows a sock on the floor near a cabinet, but there is no indication that sock_2 is on top of the cabinet_1. The sock appears to be on the ground, and the cabinet is behind it. Therefore, the sock_2 is not on top of the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto sock_2,gym_shoe_1": ["yes", 1.1201739937633697e-06, 0.9999988798260062, "In the image, there is a sock labeled \"sock_2\" on the floor near the wall, and a gym shoe labeled \"gym_shoe_1\" is also visible on the floor. The sock_2 appears to be very close to the gym_shoe_1, with only a small gap between them. Based on their proximity, it can be concluded that sock_2 is next to gym_shoe_1.", false, "<explanation>\nIn the image, there is a sock labeled \"sock_2\" on the floor near the wall, and a gym shoe labeled \"gym_shoe_1\" is also visible on the floor. The sock_2 appears to be very close to the gym_shoe_1, with only a small gap between them. Based on their proximity, it can be concluded that sock_2 is next to gym_shoe_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto sock_2,table_2": ["no", 0.9999999948546068, 5.145393191773213e-09, "The image shows a sock on the floor near a wall, with a table visible in the background. The sock_2 is on the floor, and the table_2 is also in the scene. However, the sock_2 is not next to the table_2; it is located further away from the table, closer to the wall. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a sock on the floor near a wall, with a table visible in the background. The sock_2 is on the floor, and the table_2 is also in the scene. However, the sock_2 is not next to the table_2; it is located further away from the table, closer to the wall. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto sock_2,cabinet_1": ["no", 0.9999971456032337, 2.854396766331436e-06, "The image shows a sock on the floor near a wall and a cabinet. The sock is positioned close to the cabinet, but it is not directly next to it; there is some space between the sock and the cabinet. Therefore, the sock_2 is not next to the cabinet_1.", true, "<explanation>\nThe image shows a sock on the floor near a wall and a cabinet. The sock is positioned close to the cabinet, but it is not directly next to it; there is some space between the sock and the cabinet. Therefore, the sock_2 is not next to the cabinet_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop sock_2,sock_1": {"before": false, "after": false}, "ontop sock_2,sock_2": {"before": null, "after": false}, "ontop sock_2,table_1": {"before": false, "after": false}, "nextto sock_2,sock_1": {"before": false, "after": false}, "nextto sock_2,sock_2": {"before": null, "after": false}, "nextto sock_2,table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 7.616669069413145e-11, 0.9999999999238333, "The image shows a robotic arm extended towards the floor, with a gym shoe (gym_shoe_1) located nearby. The shoe is on the floor, and the robotic arm appears to be close to it, suggesting that the shoe is within reach of the agent. Since the shoe is on the floor and the arm is extended towards it, it is reasonable to conclude that the gym_shoe_1 is within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm extended towards the floor, with a gym shoe (gym_shoe_1) located nearby. The shoe is on the floor, and the robotic arm appears to be close to it, suggesting that the shoe is within reach of the agent. Since the shoe is on the floor and the arm is extended towards it, it is reasonable to conclude that the gym_shoe_1 is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding sock_2": ["no", 0.9999622171072909, 3.778289270904022e-05, "The image shows a robotic arm with a gloved hand, but it is not holding anything. There is a sock on the floor, but the arm is not grasping or holding it. Therefore, the agent is not holding sock_2.", true, "<explanation>\nThe image shows a robotic arm with a gloved hand, but it is not holding anything. There is a sock on the floor, but the arm is not grasping or holding it. Therefore, the agent is not holding sock_2.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "grasp(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 1.406124976381238e-09, 0.999999998593875, "The image shows a robotic arm extended towards the floor, with a gym_shoe_1 object visible nearby. The shoe is on the floor, and the robotic arm appears to be close to it, suggesting that the object is within reach of the agent. Since the arm is extended directly towards the shoe, it indicates that the shoe is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm extended towards the floor, with a gym_shoe_1 object visible nearby. The shoe is on the floor, and the robotic arm appears to be close to it, suggesting that the object is within reach of the agent. Since the arm is extended directly towards the shoe, it indicates that the shoe is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding sock_2": ["no", 0.9999999999994929, 5.071457073346381e-13, "The image shows a robotic arm extending towards a sock on the floor. The robotic hand appears to be gripping an object, but it is not clear if the object is sock_2 or another item. Since the question asks if the agent is holding sock_2, I need to determine if sock_2 is the object being held. The sock on the floor is visible, but there is no clear indication that the robotic arm is holding sock_2 specifically. Therefore, based on the image, I cannot confirm that the agent is holding sock_2.", true, "<explanation>\nThe image shows a robotic arm extending towards a sock on the floor. The robotic hand appears to be gripping an object, but it is not clear if the object is sock_2 or another item. Since the question asks if the agent is holding sock_2, I need to determine if sock_2 is the object being held. The sock on the floor is visible, but there is no clear indication that the robotic arm is holding sock_2 specifically. Therefore, based on the image, I cannot confirm that the agent is holding sock_2.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding sock_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable gym_shoe_1": ["no", "yes"], "reachable notebook_1": ["yes", "yes"], "reachable sock_1": ["yes", "no"], "reachable table_1": ["no", "no"], "reachable table_2": ["yes", "yes"], "reachable sofa_1": ["yes", "no"], "holding gym_shoe_1": ["no", "no"], "holding notebook_1": ["no", "no"], "holding sock_1": ["no", "no"], "ontop gym_shoe_1,notebook_1": ["no", "no"], "ontop gym_shoe_1,sock_1": ["no", "no"], "ontop gym_shoe_1,table_1": ["yes", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,sofa_1": ["no", "no"], "ontop notebook_1,gym_shoe_1": ["no", "no"], "ontop notebook_1,sock_1": ["no", "no"], "ontop notebook_1,table_1": ["yes", "no"], "ontop notebook_1,table_2": ["yes", "no"], "ontop notebook_1,sofa_1": ["no", "no"], "ontop sock_1,gym_shoe_1": ["no", "no"], "ontop sock_1,notebook_1": ["no", "no"], "ontop sock_1,table_1": ["no", "no"], "ontop sock_1,table_2": ["no", "no"], "ontop sock_1,sofa_1": ["no", "yes"], "nextto gym_shoe_1,notebook_1": ["no", "no"], "nextto gym_shoe_1,sock_1": ["yes", "no"], "nextto gym_shoe_1,table_1": ["no", "no"], "nextto gym_shoe_1,table_2": ["yes", "yes"], "nextto gym_shoe_1,sofa_1": ["yes", "no"], "nextto notebook_1,gym_shoe_1": ["no", "no"], "nextto notebook_1,sock_1": ["no", "no"], "nextto notebook_1,table_1": ["yes", "no"], "nextto notebook_1,table_2": ["yes", "yes"], "nextto notebook_1,sofa_1": ["yes", "no"], "nextto sock_1,gym_shoe_1": ["yes", "no"], "nextto sock_1,notebook_1": ["no", "no"], "nextto sock_1,table_1": ["no", "no"], "nextto sock_1,table_2": ["yes", "no"], "nextto sock_1,sofa_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.7142857142857143, "yes_correct": 5, "yes_total": 7, "no_accuracy": 0.65625, "no_correct": 21, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.7333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.7857142857142857, "no_correct": 11, "no_total": 14}, "nextto": {"accuracy": 0.6, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.5, "no_correct": 6, "no_total": 12}}}, "step": 1, "actions": ["navigate-to(gym_shoe_1)", "grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["no", "yes"], "reachable notebook_1": ["no", "yes"], "reachable sock_1": ["yes", "no"], "reachable table_1": ["no", "no"], "reachable table_2": ["no", "yes"], "reachable sofa_1": ["yes", "no"], "holding gym_shoe_1": ["no", "no"], "holding notebook_1": ["no", "no"], "holding sock_1": ["no", "no"], "ontop gym_shoe_1,notebook_1": ["no", "no"], "ontop gym_shoe_1,sock_1": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,sofa_1": ["no", "no"], "ontop notebook_1,gym_shoe_1": ["no", "no"], "ontop notebook_1,sock_1": ["no", "no"], "ontop notebook_1,table_1": ["yes", "no"], "ontop notebook_1,table_2": ["yes", "no"], "ontop notebook_1,sofa_1": ["no", "no"], "ontop sock_1,gym_shoe_1": ["no", "no"], "ontop sock_1,notebook_1": ["no", "no"], "ontop sock_1,table_1": ["no", "no"], "ontop sock_1,table_2": ["no", "no"], "ontop sock_1,sofa_1": ["no", "yes"], "nextto gym_shoe_1,notebook_1": ["no", "no"], "nextto gym_shoe_1,sock_1": ["yes", "no"], "nextto gym_shoe_1,table_1": ["no", "no"], "nextto gym_shoe_1,table_2": ["no", "yes"], "nextto gym_shoe_1,sofa_1": ["yes", "no"], "nextto notebook_1,gym_shoe_1": ["no", "no"], "nextto notebook_1,sock_1": ["no", "no"], "nextto notebook_1,table_1": ["yes", "no"], "nextto notebook_1,table_2": ["yes", "yes"], "nextto notebook_1,sofa_1": ["yes", "no"], "nextto sock_1,gym_shoe_1": ["yes", "no"], "nextto sock_1,notebook_1": ["no", "no"], "nextto sock_1,table_1": ["no", "no"], "nextto sock_1,table_2": ["no", "no"], "nextto sock_1,sofa_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6153846153846154, "yes_accuracy": 0.14285714285714285, "yes_correct": 1, "yes_total": 7, "no_accuracy": 0.71875, "no_correct": 23, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.16666666666666666, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 3, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.8, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14}, "nextto": {"accuracy": 0.5333333333333333, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.5833333333333334, "no_correct": 7, "no_total": 12}}}, "step": 2, "actions": ["navigate-to(gym_shoe_1)", "grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["no", "yes"], "reachable notebook_1": ["yes", "yes"], "reachable sock_1": ["yes", "no"], "reachable table_1": ["no", "no"], "reachable table_2": ["no", "yes"], "reachable sofa_1": ["yes", "no"], "holding gym_shoe_1": ["no", "no"], "holding notebook_1": ["no", "no"], "holding sock_1": ["no", "no"], "ontop gym_shoe_1,notebook_1": ["no", "no"], "ontop gym_shoe_1,sock_1": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,sofa_1": ["no", "no"], "ontop notebook_1,gym_shoe_1": ["no", "no"], "ontop notebook_1,sock_1": ["no", "no"], "ontop notebook_1,table_1": ["yes", "no"], "ontop notebook_1,table_2": ["no", "no"], "ontop notebook_1,sofa_1": ["no", "no"], "ontop sock_1,gym_shoe_1": ["no", "no"], "ontop sock_1,notebook_1": ["no", "no"], "ontop sock_1,table_1": ["no", "no"], "ontop sock_1,table_2": ["no", "no"], "ontop sock_1,sofa_1": ["no", "yes"], "nextto gym_shoe_1,notebook_1": ["no", "no"], "nextto gym_shoe_1,sock_1": ["yes", "no"], "nextto gym_shoe_1,table_1": ["yes", "no"], "nextto gym_shoe_1,table_2": ["yes", "yes"], "nextto gym_shoe_1,sofa_1": ["yes", "no"], "nextto notebook_1,gym_shoe_1": ["no", "no"], "nextto notebook_1,sock_1": ["no", "no"], "nextto notebook_1,table_1": ["yes", "no"], "nextto notebook_1,table_2": ["yes", "yes"], "nextto notebook_1,sofa_1": ["yes", "no"], "nextto sock_1,gym_shoe_1": ["yes", "no"], "nextto sock_1,notebook_1": ["no", "no"], "nextto sock_1,table_1": ["no", "no"], "nextto sock_1,table_2": ["no", "no"], "nextto sock_1,sofa_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.42857142857142855, "yes_correct": 3, "yes_total": 7, "no_accuracy": 0.71875, "no_correct": 23, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.8666666666666667, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.9285714285714286, "no_correct": 13, "no_total": 14}, "nextto": {"accuracy": 0.5333333333333333, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.5, "no_correct": 6, "no_total": 12}}}, "step": 3, "actions": ["navigate-to(gym_shoe_1)", "grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable notebook_1": ["yes", "yes"], "reachable sock_1": ["yes", "no"], "reachable table_1": ["no", "no"], "reachable table_2": ["no", "yes"], "reachable sofa_1": ["no", "no"], "holding gym_shoe_1": ["no", "no"], "holding notebook_1": ["no", "no"], "holding sock_1": ["no", "no"], "ontop gym_shoe_1,notebook_1": ["no", "no"], "ontop gym_shoe_1,sock_1": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,sofa_1": ["no", "no"], "ontop notebook_1,gym_shoe_1": ["no", "no"], "ontop notebook_1,sock_1": ["no", "no"], "ontop notebook_1,table_1": ["yes", "no"], "ontop notebook_1,table_2": ["yes", "no"], "ontop notebook_1,sofa_1": ["no", "no"], "ontop sock_1,gym_shoe_1": ["no", "no"], "ontop sock_1,notebook_1": ["no", "no"], "ontop sock_1,table_1": ["no", "no"], "ontop sock_1,table_2": ["no", "no"], "ontop sock_1,sofa_1": ["no", "yes"], "nextto gym_shoe_1,notebook_1": ["no", "no"], "nextto gym_shoe_1,sock_1": ["yes", "no"], "nextto gym_shoe_1,table_1": ["yes", "no"], "nextto gym_shoe_1,table_2": ["yes", "yes"], "nextto gym_shoe_1,sofa_1": ["yes", "no"], "nextto notebook_1,gym_shoe_1": ["no", "no"], "nextto notebook_1,sock_1": ["no", "no"], "nextto notebook_1,table_1": ["yes", "no"], "nextto notebook_1,table_2": ["yes", "yes"], "nextto notebook_1,sofa_1": ["no", "no"], "nextto sock_1,gym_shoe_1": ["yes", "no"], "nextto sock_1,notebook_1": ["no", "no"], "nextto sock_1,table_1": ["no", "no"], "nextto sock_1,table_2": ["no", "no"], "nextto sock_1,sofa_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.7435897435897436, "yes_accuracy": 0.7142857142857143, "yes_correct": 5, "yes_total": 7, "no_accuracy": 0.75, "no_correct": 24, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.8, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14}, "nextto": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.5833333333333334, "no_correct": 7, "no_total": 12}}}, "step": 4, "actions": ["grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable notebook_1": ["yes", "yes"], "reachable sock_1": ["yes", "no"], "reachable table_1": ["yes", "no"], "reachable table_2": ["no", "yes"], "reachable sofa_1": ["no", "no"], "holding gym_shoe_1": ["yes", "yes"], "holding notebook_1": ["yes", "no"], "holding sock_1": ["yes", "no"], "ontop gym_shoe_1,notebook_1": ["no", "no"], "ontop gym_shoe_1,sock_1": ["no", "no"], "ontop gym_shoe_1,table_1": ["yes", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,sofa_1": ["no", "no"], "ontop notebook_1,gym_shoe_1": ["no", "no"], "ontop notebook_1,sock_1": ["no", "no"], "ontop notebook_1,table_1": ["yes", "no"], "ontop notebook_1,table_2": ["no", "no"], "ontop notebook_1,sofa_1": ["no", "no"], "ontop sock_1,gym_shoe_1": ["no", "no"], "ontop sock_1,notebook_1": ["no", "no"], "ontop sock_1,table_1": ["yes", "no"], "ontop sock_1,table_2": ["no", "no"], "ontop sock_1,sofa_1": ["no", "yes"], "nextto gym_shoe_1,notebook_1": ["yes", "no"], "nextto gym_shoe_1,sock_1": ["yes", "no"], "nextto gym_shoe_1,table_1": ["no", "no"], "nextto gym_shoe_1,table_2": ["no", "no"], "nextto gym_shoe_1,sofa_1": ["yes", "no"], "nextto notebook_1,gym_shoe_1": ["yes", "no"], "nextto notebook_1,sock_1": ["no", "no"], "nextto notebook_1,table_1": ["yes", "no"], "nextto notebook_1,table_2": ["yes", "yes"], "nextto notebook_1,sofa_1": ["no", "no"], "nextto sock_1,gym_shoe_1": ["yes", "no"], "nextto sock_1,notebook_1": ["yes", "no"], "nextto sock_1,table_1": ["yes", "no"], "nextto sock_1,table_2": ["no", "no"], "nextto sock_1,sofa_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5384615384615384, "yes_accuracy": 0.5714285714285714, "yes_correct": 4, "yes_total": 7, "no_accuracy": 0.53125, "no_correct": 17, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3}, "holding": {"accuracy": 0.3333333333333333, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "ontop": {"accuracy": 0.7333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.7857142857142857, "no_correct": 11, "no_total": 14}, "nextto": {"accuracy": 0.4, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.38461538461538464, "no_correct": 5, "no_total": 13}}}, "step": 5, "actions": ["navigate-to(sock_2)", "place-next-to(sock_1, sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable cabinet_1": ["yes", "no"], "holding gym_shoe_1": ["yes", "yes"], "holding sock_2": ["yes", "no"], "open cabinet_1": ["yes", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,cabinet_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,cabinet_1": ["no", "no"], "inside gym_shoe_1,cabinet_1": ["no", "no"], "inside sock_2,cabinet_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["no", "no"], "nextto gym_shoe_1,cabinet_1": ["no", "no"], "nextto sock_2,gym_shoe_1": ["yes", "no"], "nextto sock_2,cabinet_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6875, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.6153846153846154, "no_correct": 8, "no_total": 13, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 4, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 2, "no_total": 4}}}, "step": 6, "actions": ["navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable table_2": ["no", "yes"], "holding gym_shoe_1": ["no", "yes"], "ontop gym_shoe_1,table_2": ["yes", "no"], "nextto gym_shoe_1,table_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.4, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "ontop": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}}}, "step": 7, "actions": ["navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable cabinet_1": ["yes", "no"], "holding gym_shoe_1": ["yes", "yes"], "holding sock_2": ["no", "no"], "open cabinet_1": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,cabinet_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["yes", "no"], "ontop sock_2,cabinet_1": ["no", "no"], "inside gym_shoe_1,cabinet_1": ["no", "no"], "inside sock_2,cabinet_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["no", "no"], "nextto gym_shoe_1,cabinet_1": ["yes", "no"], "nextto sock_2,gym_shoe_1": ["yes", "no"], "nextto sock_2,cabinet_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6875, "yes_accuracy": 1.0, "yes_correct": 3, "yes_total": 3, "no_accuracy": 0.6153846153846154, "no_correct": 8, "no_total": 13, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 3, "no_total": 4}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.25, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.25, "no_correct": 1, "no_total": 4}}}, "step": 8, "actions": ["place-next-to(gym_shoe_1, sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)", "navigate-to(gym_shoe_1)", "grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_2": ["no", "no"], "reachable cabinet_1": ["yes", "no"], "holding gym_shoe_1": ["no", "no"], "holding sock_2": ["no", "yes"], "open cabinet_1": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,cabinet_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_2": ["no", "no"], "ontop sock_2,cabinet_1": ["no", "no"], "inside gym_shoe_1,cabinet_1": ["no", "no"], "inside sock_2,cabinet_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["yes", "no"], "nextto gym_shoe_1,table_2": ["no", "no"], "nextto gym_shoe_1,cabinet_1": ["yes", "no"], "nextto sock_2,gym_shoe_1": ["yes", "no"], "nextto sock_2,table_2": ["no", "no"], "nextto sock_2,cabinet_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7619047619047619, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.7777777777777778, "no_correct": 14, "no_total": 18, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "holding": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 3, "no_total": 6}}}, "step": 10, "actions": ["grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable sock_2": ["yes", "yes"], "reachable table_2": ["no", "no"], "reachable cabinet_1": ["yes", "no"], "holding gym_shoe_1": ["no", "no"], "holding sock_2": ["no", "yes"], "open cabinet_1": ["no", "no"], "ontop gym_shoe_1,sock_2": ["no", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,cabinet_1": ["no", "no"], "ontop sock_2,gym_shoe_1": ["no", "no"], "ontop sock_2,table_2": ["no", "no"], "ontop sock_2,cabinet_1": ["no", "no"], "inside gym_shoe_1,cabinet_1": ["no", "no"], "inside sock_2,cabinet_1": ["no", "no"], "nextto gym_shoe_1,sock_2": ["yes", "no"], "nextto gym_shoe_1,table_2": ["no", "no"], "nextto gym_shoe_1,cabinet_1": ["yes", "no"], "nextto sock_2,gym_shoe_1": ["yes", "no"], "nextto sock_2,table_2": ["no", "no"], "nextto sock_2,cabinet_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7619047619047619, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.7777777777777778, "no_correct": 14, "no_total": 18, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "holding": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "nextto": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 3, "no_total": 6}}}, "step": 11, "actions": ["grasp(gym_shoe_1)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}], "remaining_actions": ["navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, "data/planning/igibson/medium/collect_misplaced_items_medium.pddl_Merom_1_int_22": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable gym_shoe_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable gym_shoe_1": ["no", 0.9999999999999977, 2.3795118088900447e-15, "The image shows a robotic arm (agent) extending towards a wall with a mounted device, and there is a table with objects in the scene. However, there is no visible gym_shoe_1 in the image, nor any indication of its position or proximity to the agent. Since the question asks specifically about gym_shoe_1 and whether it is within reach, and it is not visible in the scene, I conclude that it is not in reach of the agent based on the provided image.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards a wall with a mounted device, and there is a table with objects in the scene. However, there is no visible gym_shoe_1 in the image, nor any indication of its position or proximity to the agent. Since the question asks specifically about gym_shoe_1 and whether it is within reach, and it is not visible in the scene, I conclude that it is not in reach of the agent based on the provided image.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable sock_1": ["yes", 1.558774194262237e-13, 0.9999999999998441, "The image shows a robotic arm (agent) extending towards a wall with a sock labeled \"sock_1\" on the floor near a chair. The sock appears to be close to the robotic arm's reach, as the arm is extended in that direction and the sock is within the area that the arm can likely access. Based on the position and the arm's extension, it seems that the sock_1 is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards a wall with a sock labeled \"sock_1\" on the floor near a chair. The sock appears to be close to the robotic arm's reach, as the arm is extended in that direction and the sock is within the area that the arm can likely access. Based on the position and the arm's extension, it seems that the sock_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable table_1": ["no", 0.9999999999999537, 4.6320042921509056e-14, "The image shows a robotic arm (agent) positioned near a wall, with a table labeled \"table_1\" in front of it. The table_1 is located at the far end of the room, beyond the chairs and other objects. The robotic arm appears to be close to the wall and not directly aligned with the table_1, which is farther away. Given the perspective, it seems unlikely that the robotic arm can reach table_1 without moving closer. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near a wall, with a table labeled \"table_1\" in front of it. The table_1 is located at the far end of the room, beyond the chairs and other objects. The robotic arm appears to be close to the wall and not directly aligned with the table_1, which is farther away. Given the perspective, it seems unlikely that the robotic arm can reach table_1 without moving closer. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "reachable table_2": ["no", 0.9999999999999999, 6.829704263450792e-17, "The image shows a robotic arm (agent) positioned near a wall, with a view of a kitchen and dining area. The table_2 is labeled and located behind the table_1, closer to the wall and further from the robotic arm. Given the perspective, the robotic arm appears to be quite close to table_1 but not directly in front of or near table_2. The distance between the robotic arm and table_2 seems to be beyond the typical reach of the robotic arm based on the image's perspective.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near a wall, with a view of a kitchen and dining area. The table_2 is labeled and located behind the table_1, closer to the wall and further from the robotic arm. Given the perspective, the robotic arm appears to be quite close to table_1 but not directly in front of or near table_2. The distance between the robotic arm and table_2 seems to be beyond the typical reach of the robotic arm based on the image's perspective.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable sock_2": {"before": false, "after": false}, "reachable cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 8.747870072584665e-18, 1.0, "The image shows a robotic arm (agent) extending towards a wall with a mounted device, and there is a chair with a shoe on it labeled \"gym_shoe_1\" near the center of the image. The shoe is on the chair, which is close to the agent's current position. Given the proximity of the shoe to the agent and the fact that the shoe is on a chair within the room, it appears to be within reach of the robotic arm.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards a wall with a mounted device, and there is a chair with a shoe on it labeled \"gym_shoe_1\" near the center of the image. The shoe is on the chair, which is close to the agent's current position. Given the proximity of the shoe to the agent and the fact that the shoe is on a chair within the room, it appears to be within reach of the robotic arm.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(gym_shoe_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable gym_shoe_1": ["yes", 1.0583982291095993e-14, 0.9999999999999895, "The image shows a robotic arm (agent) extending towards a wall with a mounted device, and there is a shoe labeled \"gym_shoe_1\" on the floor near a chair. The shoe appears to be close to the agent's reach, as it is within the same room and not obstructed by other objects. Given the proximity and the typical reach of a robotic arm in such a setting, it is reasonable to conclude that the gym_shoe_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards a wall with a mounted device, and there is a shoe labeled \"gym_shoe_1\" on the floor near a chair. The shoe appears to be close to the agent's reach, as it is within the same room and not obstructed by other objects. Given the proximity and the typical reach of a robotic arm in such a setting, it is reasonable to conclude that the gym_shoe_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding sock_1": ["no", 0.9999999999987716, 1.228376274637905e-12, "The image shows a robotic arm (agent) extending towards a wall with a sock hanging on a rack. The sock_1 is located on the wall rack, and the robotic arm appears to be reaching towards it. However, the robotic arm is not visibly holding or grasping the sock_1; it is just extended in its direction. Therefore, the agent is not holding sock_1.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards a wall with a sock hanging on a rack. The sock_1 is located on the wall rack, and the robotic arm appears to be reaching towards it. However, the robotic arm is not visibly holding or grasping the sock_1; it is just extended in its direction. Therefore, the agent is not holding sock_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding sock_2": [true, false, false], "all_correct": true}, "effects_results": {"holding gym_shoe_1": ["no", 0.9999999997544858, 2.4551419601664797e-10, "The image shows a robotic arm (agent) holding an object, but the object appears to be a gym shoe, not a gym_shoe_1. The label \"gym_shoe_1\" is not visible in the image, and the object being held looks like a shoe, but without a clear label or distinctive features that confirm it as \"gym_shoe_1.\" Therefore, based on the available information, the agent is not holding the gym_shoe_1.", false, "<explanation>\nThe image shows a robotic arm (agent) holding an object, but the object appears to be a gym shoe, not a gym_shoe_1. The label \"gym_shoe_1\" is not visible in the image, and the object being held looks like a shoe, but without a clear label or distinctive features that confirm it as \"gym_shoe_1.\" Therefore, based on the available information, the agent is not holding the gym_shoe_1.\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop gym_shoe_1,sock_1": ["no", 0.9999987560269453, 1.2439730546733492e-06, "The image shows a robotic arm holding a gym_shoe_1, which is positioned on a table. The sock_1 is located on a chair, underneath the table. Since the sock_1 is on the chair and the gym_shoe_1 is on the table, the gym_shoe_1 is not on top of the sock_1. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm holding a gym_shoe_1, which is positioned on a table. The sock_1 is located on a chair, underneath the table. Since the sock_1 is on the chair and the gym_shoe_1 is on the table, the gym_shoe_1 is not on top of the sock_1. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop gym_shoe_1,table_1": ["no", 0.9999999999408994, 5.910065732306934e-11, "The image shows a robotic arm holding an object labeled \"gym_shoe_1\" near a table labeled \"table_1\". The shoe appears to be positioned above the surface of \"table_1\" but not directly on top of it; it is held in the air close to the table's edge. Since \"on top of\" implies the object is resting directly on the surface, and the shoe is being held above the table rather than resting on it, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm holding an object labeled \"gym_shoe_1\" near a table labeled \"table_1\". The shoe appears to be positioned above the surface of \"table_1\" but not directly on top of it; it is held in the air close to the table's edge. Since \"on top of\" implies the object is resting directly on the surface, and the shoe is being held above the table rather than resting on it, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop gym_shoe_1,table_2": ["no", 0.999999999999893, 1.0705359173158464e-13, "The image shows a robotic arm holding an object labeled \"gym_shoe_1\" near a table labeled \"table_2\". The shoe appears to be positioned above the surface of \"table_2\" but is not clearly on top of it; it looks like it is being held close to or just above the table, not resting on it. Since the question asks if the gym_shoe_1 is on top of table_2, and based on the visual evidence, it is not definitively on the table but rather held near it.", true, "<explanation>\nThe image shows a robotic arm holding an object labeled \"gym_shoe_1\" near a table labeled \"table_2\". The shoe appears to be positioned above the surface of \"table_2\" but is not clearly on top of it; it looks like it is being held close to or just above the table, not resting on it. Since the question asks if the gym_shoe_1 is on top of table_2, and based on the visual evidence, it is not definitively on the table but rather held near it.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto gym_shoe_1,sock_1": ["no", 0.999999999988316, 1.1683935703256569e-11, "The image shows a robotic arm holding an object, with a table and some objects on it. The objects visible include a sock labeled \"sock_1\" and a shoe labeled \"gym_shoe_1.\" The sock_1 is on the table, and the gym_shoe_1 is also on the table, but further away from sock_1. The gym_shoe_1 is not directly next to sock_1; there is some space between them.", true, "<explanation>\nThe image shows a robotic arm holding an object, with a table and some objects on it. The objects visible include a sock labeled \"sock_1\" and a shoe labeled \"gym_shoe_1.\" The sock_1 is on the table, and the gym_shoe_1 is also on the table, but further away from sock_1. The gym_shoe_1 is not directly next to sock_1; there is some space between them.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto gym_shoe_1,table_1": ["yes", 1.1741988537553797e-11, 0.9999999999882581, "The image shows a robotic arm holding an object near a table. The object labeled \"gym_shoe_1\" is visible on the floor, close to the table. The object labeled \"table_1\" is on the table surface. The gym_shoe_1 appears to be positioned next to the table_1, on the floor near the edge of the table. Therefore, gym_shoe_1 is next to table_1.", false, "<explanation>\nThe image shows a robotic arm holding an object near a table. The object labeled \"gym_shoe_1\" is visible on the floor, close to the table. The object labeled \"table_1\" is on the table surface. The gym_shoe_1 appears to be positioned next to the table_1, on the floor near the edge of the table. Therefore, gym_shoe_1 is next to table_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto gym_shoe_1,table_2": ["no", 0.9999999999999989, 1.091564828673374e-15, "The image shows a robotic arm holding an object near a table. The table_2 is located in the foreground, with a chair partially visible underneath it. The gym_shoe_1 is positioned on the floor, next to the table_2, but not directly next to it; it is slightly to the side and behind the table. Since \"next to\" generally implies very close proximity, the gym_shoe_1 is not immediately adjacent to the table_2.", true, "<explanation>\nThe image shows a robotic arm holding an object near a table. The table_2 is located in the foreground, with a chair partially visible underneath it. The gym_shoe_1 is positioned on the floor, next to the table_2, but not directly next to it; it is slightly to the side and behind the table. Since \"next to\" generally implies very close proximity, the gym_shoe_1 is not immediately adjacent to the table_2.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "ontop gym_shoe_1,sock_2": {"before": false, "after": false}, "ontop gym_shoe_1,cabinet_1": {"before": false, "after": false}, "nextto gym_shoe_1,gym_shoe_1": {"before": null, "after": false}, "nextto gym_shoe_1,sock_2": {"before": false, "after": false}, "nextto gym_shoe_1,cabinet_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-next-to(sock_1, table_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding sock_1": ["yes", 3.21246901494187e-08, 0.9999999678753099, "The image shows a robotic arm, which is the agent, holding an object. The object appears to be a sock, specifically sock_1, based on the label. The sock_1 is located near the edge of the table, and the robotic arm is grasping it. Therefore, the agent is indeed holding sock_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding an object. The object appears to be a sock, specifically sock_1, based on the label. The sock_1 is located near the edge of the table, and the robotic arm is grasping it. Therefore, the agent is indeed holding sock_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable table_1": ["yes", 9.953315294270301e-09, 0.9999999900466847, "The image shows a robotic arm (agent) reaching towards a table labeled \"table_1.\" The arm is extended and appears to be close to or touching the table. Since the arm is within a close distance and actively reaching towards \"table_1,\" it indicates that the table is within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a table labeled \"table_1.\" The arm is extended and appears to be close to or touching the table. Since the arm is within a close distance and actively reaching towards \"table_1,\" it indicates that the table is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "place-next-to(sock_1, table_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding sock_1": ["yes", 4.612817007205202e-06, 0.9999953871829927, "The image shows a robotic arm, which is the agent, holding an object. The object appears to be a sock, and it is labeled as \"sock_1\" in the description. Since the robotic arm is grasping this object, the agent is indeed holding sock_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding an object. The object appears to be a sock, and it is labeled as \"sock_1\" in the description. Since the robotic arm is grasping this object, the agent is indeed holding sock_1.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable table_1": ["yes", 7.356826313167524e-07, 0.9999992643173686, "The image shows a robotic arm (agent) reaching towards a table labeled \"table_1.\" The arm is extended and appears to be close to or touching the table. Since the arm is actively reaching towards \"table_1,\" it indicates that the table is within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a table labeled \"table_1.\" The arm is extended and appears to be close to or touching the table. Since the arm is actively reaching towards \"table_1,\" it indicates that the table is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable gym_shoe_1": ["no", "yes"], "reachable notebook_1": ["no", "yes"], "reachable sock_1": ["yes", "no"], "reachable table_1": ["no", "no"], "reachable table_2": ["yes", "yes"], "reachable sofa_1": ["no", "no"], "holding gym_shoe_1": ["no", "no"], "holding notebook_1": ["no", "no"], "holding sock_1": ["no", "no"], "ontop gym_shoe_1,notebook_1": ["no", "no"], "ontop gym_shoe_1,sock_1": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,sofa_1": ["no", "no"], "ontop notebook_1,gym_shoe_1": ["no", "no"], "ontop notebook_1,sock_1": ["no", "no"], "ontop notebook_1,table_1": ["yes", "no"], "ontop notebook_1,table_2": ["no", "no"], "ontop notebook_1,sofa_1": ["no", "no"], "ontop sock_1,gym_shoe_1": ["no", "no"], "ontop sock_1,notebook_1": ["no", "no"], "ontop sock_1,table_1": ["no", "no"], "ontop sock_1,table_2": ["no", "no"], "ontop sock_1,sofa_1": ["no", "yes"], "nextto gym_shoe_1,notebook_1": ["no", "no"], "nextto gym_shoe_1,sock_1": ["yes", "no"], "nextto gym_shoe_1,table_1": ["no", "no"], "nextto gym_shoe_1,table_2": ["no", "yes"], "nextto gym_shoe_1,sofa_1": ["yes", "no"], "nextto notebook_1,gym_shoe_1": ["no", "no"], "nextto notebook_1,sock_1": ["no", "no"], "nextto notebook_1,table_1": ["yes", "no"], "nextto notebook_1,table_2": ["no", "yes"], "nextto notebook_1,sofa_1": ["yes", "no"], "nextto sock_1,gym_shoe_1": ["no", "no"], "nextto sock_1,notebook_1": ["no", "no"], "nextto sock_1,table_1": ["no", "no"], "nextto sock_1,table_2": ["no", "no"], "nextto sock_1,sofa_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.717948717948718, "yes_accuracy": 0.2857142857142857, "yes_correct": 2, "yes_total": 7, "no_accuracy": 0.8125, "no_correct": 26, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.8666666666666667, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.9285714285714286, "no_correct": 13, "no_total": 14}, "nextto": {"accuracy": 0.6, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.6666666666666666, "no_correct": 8, "no_total": 12}}}, "step": 1, "actions": ["navigate-to(gym_shoe_1)", "grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable notebook_1": ["no", "yes"], "reachable sock_1": ["yes", "no"], "reachable table_1": ["yes", "no"], "reachable table_2": ["no", "yes"], "reachable sofa_1": ["no", "no"], "holding gym_shoe_1": ["no", "no"], "holding notebook_1": ["no", "no"], "holding sock_1": ["no", "no"], "ontop gym_shoe_1,notebook_1": ["no", "no"], "ontop gym_shoe_1,sock_1": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,sofa_1": ["no", "no"], "ontop notebook_1,gym_shoe_1": ["no", "no"], "ontop notebook_1,sock_1": ["no", "no"], "ontop notebook_1,table_1": ["yes", "no"], "ontop notebook_1,table_2": ["yes", "no"], "ontop notebook_1,sofa_1": ["no", "no"], "ontop sock_1,gym_shoe_1": ["no", "no"], "ontop sock_1,notebook_1": ["no", "no"], "ontop sock_1,table_1": ["no", "no"], "ontop sock_1,table_2": ["no", "no"], "ontop sock_1,sofa_1": ["no", "yes"], "nextto gym_shoe_1,notebook_1": ["no", "no"], "nextto gym_shoe_1,sock_1": ["yes", "no"], "nextto gym_shoe_1,table_1": ["no", "no"], "nextto gym_shoe_1,table_2": ["yes", "yes"], "nextto gym_shoe_1,sofa_1": ["yes", "no"], "nextto notebook_1,gym_shoe_1": ["no", "no"], "nextto notebook_1,sock_1": ["no", "no"], "nextto notebook_1,table_1": ["yes", "no"], "nextto notebook_1,table_2": ["no", "yes"], "nextto notebook_1,sofa_1": ["yes", "no"], "nextto sock_1,gym_shoe_1": ["yes", "no"], "nextto sock_1,notebook_1": ["no", "no"], "nextto sock_1,table_1": ["no", "no"], "nextto sock_1,table_2": ["no", "no"], "nextto sock_1,sofa_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.6410256410256411, "yes_accuracy": 0.2857142857142857, "yes_correct": 2, "yes_total": 7, "no_accuracy": 0.71875, "no_correct": 23, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.3333333333333333, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3}, "ontop": {"accuracy": 0.8, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14}, "nextto": {"accuracy": 0.5333333333333333, "yes_accuracy": 0.3333333333333333, "yes_correct": 1, "yes_total": 3, "no_accuracy": 0.5833333333333334, "no_correct": 7, "no_total": 12}}}, "step": 2, "actions": ["grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable notebook_1": ["yes", "yes"], "reachable sock_1": ["yes", "no"], "reachable table_1": ["yes", "no"], "reachable table_2": ["no", "yes"], "reachable sofa_1": ["no", "no"], "holding gym_shoe_1": ["no", "yes"], "holding notebook_1": ["yes", "no"], "holding sock_1": ["yes", "no"], "ontop gym_shoe_1,notebook_1": ["no", "no"], "ontop gym_shoe_1,sock_1": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,sofa_1": ["no", "no"], "ontop notebook_1,gym_shoe_1": ["no", "no"], "ontop notebook_1,sock_1": ["no", "no"], "ontop notebook_1,table_1": ["yes", "no"], "ontop notebook_1,table_2": ["yes", "no"], "ontop notebook_1,sofa_1": ["no", "no"], "ontop sock_1,gym_shoe_1": ["no", "no"], "ontop sock_1,notebook_1": ["no", "no"], "ontop sock_1,table_1": ["no", "no"], "ontop sock_1,table_2": ["no", "no"], "ontop sock_1,sofa_1": ["no", "yes"], "nextto gym_shoe_1,notebook_1": ["yes", "no"], "nextto gym_shoe_1,sock_1": ["yes", "no"], "nextto gym_shoe_1,table_1": ["yes", "no"], "nextto gym_shoe_1,table_2": ["yes", "no"], "nextto gym_shoe_1,sofa_1": ["yes", "no"], "nextto notebook_1,gym_shoe_1": ["no", "no"], "nextto notebook_1,sock_1": ["no", "no"], "nextto notebook_1,table_1": ["no", "no"], "nextto notebook_1,table_2": ["no", "yes"], "nextto notebook_1,sofa_1": ["no", "no"], "nextto sock_1,gym_shoe_1": ["no", "no"], "nextto sock_1,notebook_1": ["no", "no"], "nextto sock_1,table_1": ["no", "no"], "nextto sock_1,table_2": ["no", "no"], "nextto sock_1,sofa_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.6153846153846154, "yes_accuracy": 0.42857142857142855, "yes_correct": 3, "yes_total": 7, "no_accuracy": 0.65625, "no_correct": 21, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "ontop": {"accuracy": 0.8, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14}, "nextto": {"accuracy": 0.6, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": 0.6153846153846154, "no_correct": 8, "no_total": 13}}}, "step": 3, "actions": ["place-next-to(sock_1, table_1)", "grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, {"enum_results": {"reachable gym_shoe_1": ["yes", "yes"], "reachable notebook_1": ["yes", "yes"], "reachable sock_1": ["yes", "no"], "reachable table_1": ["yes", "no"], "reachable table_2": ["no", "yes"], "reachable sofa_1": ["no", "no"], "holding gym_shoe_1": ["no", "yes"], "holding notebook_1": ["yes", "no"], "holding sock_1": ["yes", "no"], "ontop gym_shoe_1,notebook_1": ["no", "no"], "ontop gym_shoe_1,sock_1": ["no", "no"], "ontop gym_shoe_1,table_1": ["no", "no"], "ontop gym_shoe_1,table_2": ["no", "no"], "ontop gym_shoe_1,sofa_1": ["no", "no"], "ontop notebook_1,gym_shoe_1": ["no", "no"], "ontop notebook_1,sock_1": ["no", "no"], "ontop notebook_1,table_1": ["yes", "no"], "ontop notebook_1,table_2": ["yes", "no"], "ontop notebook_1,sofa_1": ["no", "no"], "ontop sock_1,gym_shoe_1": ["no", "no"], "ontop sock_1,notebook_1": ["no", "no"], "ontop sock_1,table_1": ["no", "no"], "ontop sock_1,table_2": ["no", "no"], "ontop sock_1,sofa_1": ["no", "yes"], "nextto gym_shoe_1,notebook_1": ["no", "no"], "nextto gym_shoe_1,sock_1": ["yes", "no"], "nextto gym_shoe_1,table_1": ["yes", "no"], "nextto gym_shoe_1,table_2": ["no", "no"], "nextto gym_shoe_1,sofa_1": ["no", "no"], "nextto notebook_1,gym_shoe_1": ["no", "no"], "nextto notebook_1,sock_1": ["no", "no"], "nextto notebook_1,table_1": ["yes", "no"], "nextto notebook_1,table_2": ["no", "yes"], "nextto notebook_1,sofa_1": ["no", "no"], "nextto sock_1,gym_shoe_1": ["no", "no"], "nextto sock_1,notebook_1": ["no", "no"], "nextto sock_1,table_1": ["yes", "no"], "nextto sock_1,table_2": ["yes", "no"], "nextto sock_1,sofa_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5897435897435898, "yes_accuracy": 0.2857142857142857, "yes_correct": 2, "yes_total": 7, "no_accuracy": 0.65625, "no_correct": 21, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.6666666666666666, "yes_correct": 2, "yes_total": 3, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}, "ontop": {"accuracy": 0.8, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.8571428571428571, "no_correct": 12, "no_total": 14}, "nextto": {"accuracy": 0.5333333333333333, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.6153846153846154, "no_correct": 8, "no_total": 13}}}, "step": 4, "actions": ["place-next-to(sock_1, table_1)", "grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}], "remaining_actions": ["grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"]}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Beechwood_0_int_23": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(apple_1)", "action_correct": true, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 2.690846915786497e-10, 0.9999999997309154, "The image shows a robotic arm (agent) extending towards objects on the countertop. There are two apples labeled \"apple_1\" and \"apple_2\". The apple labeled \"apple_1\" appears to be very close to the robotic arm, within the reach of the arm's extension. Since the arm is positioned directly above or near \"apple_1\", it is reasonable to conclude that \"apple_1\" is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards objects on the countertop. There are two apples labeled \"apple_1\" and \"apple_2\". The apple labeled \"apple_1\" appears to be very close to the robotic arm, within the reach of the arm's extension. Since the arm is positioned directly above or near \"apple_1\", it is reasonable to conclude that \"apple_1\" is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_2": ["no", 0.999999999999966, 3.402561181551839e-14, "The image shows a robotic arm (agent) extending towards objects on the countertop. There are two apples labeled \"apple_1\" and \"apple_2.\" The apple_2 appears to be positioned further to the right, beyond the reach of the robotic arm, which is extending towards the left side of the counter. Since the arm is not reaching towards the apple_2 and it appears to be located farther away, it is likely out of reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards objects on the countertop. There are two apples labeled \"apple_1\" and \"apple_2.\" The apple_2 appears to be positioned further to the right, beyond the reach of the robotic arm, which is extending towards the left side of the counter. Since the arm is not reaching towards the apple_2 and it appears to be located farther away, it is likely out of reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable electric_refrigerator_1": ["no", 0.9999999996380364, 3.619635411061829e-10, "The image shows a robotic arm (agent) extending towards objects on the countertop. The electric_refrigerator_1 is located to the left of the countertop, behind the robotic arm. Since the robotic arm is reaching towards objects on the countertop and the refrigerator is positioned behind those objects, it appears to be out of reach of the robotic arm at this moment.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards objects on the countertop. The electric_refrigerator_1 is located to the left of the countertop, behind the robotic arm. Since the robotic arm is reaching towards objects on the countertop and the refrigerator is positioned behind those objects, it appears to be out of reach of the robotic arm at this moment.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {"reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999999999939024, 6.097571898111433e-12, "The image shows a robotic arm (agent) extending towards objects on the countertop. The electric_refrigerator_1 is located to the left of the countertop, behind the robotic arm. Since the robotic arm is reaching towards objects on the counter, and the refrigerator is positioned further back and to the side, it appears to be out of reach of the robotic arm in this position. Therefore, the refrigerator is not within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards objects on the countertop. The electric_refrigerator_1 is located to the left of the countertop, behind the robotic arm. Since the robotic arm is reaching towards objects on the counter, and the refrigerator is positioned further back and to the side, it appears to be out of reach of the robotic arm in this position. Therefore, the refrigerator is not within reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 2.063728512152299e-09, 0.9999999979362715, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against a wall, and the robotic arm is extended towards it. Given the proximity of the arm to the refrigerator, it seems to be within reach of the agent. Therefore, the refrigerator is accessible to the robotic arm.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against a wall, and the robotic arm is extended towards it. Given the proximity of the arm to the refrigerator, it seems to be within reach of the agent. Therefore, the refrigerator is accessible to the robotic arm.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_1": {"before": true, "after": false}, "reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 2.5510748705499448e-08, 0.9999999744892513, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is indeed within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is indeed within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 6.1633895984865494e-09, 0.9999999938366104, "The image shows a robotic arm holding a black object near a white door. The door appears to be part of an appliance, likely a refrigerator, given the context. The door is slightly ajar, indicating it is open. Since the question asks if the electric refrigerator is open, and the door is visibly open, the answer is yes.", false, "<explanation>\nThe image shows a robotic arm holding a black object near a white door. The door appears to be part of an appliance, likely a refrigerator, given the context. The door is slightly ajar, indicating it is open. Since the question asks if the electric refrigerator is open, and the door is visibly open, the answer is yes.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding apple_1": [true, false, false], "holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 1.0082071410464897e-11, 0.999999999989918, "The image shows a robotic arm (agent) positioned above a kitchen counter, with an apple labeled \"apple_1\" nearby. The apple_1 appears to be on the counter close to the robotic arm, and the arm is extended towards objects on the counter. Given the proximity of the apple_1 to the robotic arm and the arm's position, it seems that the apple_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned above a kitchen counter, with an apple labeled \"apple_1\" nearby. The apple_1 appears to be on the counter close to the robotic arm, and the arm is extended towards objects on the counter. Given the proximity of the apple_1 to the robotic arm and the arm's position, it seems that the apple_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_2": ["yes", 4.686633126609912e-10, 0.9999999995313367, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled apple_1 and apple_2. The apple_2 is positioned further to the right, closer to the edge of the counter, and appears to be within the reach of the robotic arm, which is extended towards the objects. Since the arm is already reaching towards apple_2, it indicates that apple_2 is within the agent's reach.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled apple_1 and apple_2. The apple_2 is positioned further to the right, closer to the edge of the counter, and appears to be within the reach of the robotic arm, which is extended towards the objects. Since the arm is already reaching towards apple_2, it indicates that apple_2 is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["no", 0.9999999999937976, 6.202343061599245e-12, "The image shows a robotic arm (agent) positioned in a kitchen environment. The electric_refrigerator_1 is located to the left of the robotic arm, which is actively reaching towards objects on the countertop. Given the perspective, the refrigerator appears to be quite far from the robotic arm, beyond the immediate reach of the arm's extension. Therefore, the refrigerator is not within the reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned in a kitchen environment. The electric_refrigerator_1 is located to the left of the robotic arm, which is actively reaching towards objects on the countertop. Given the perspective, the refrigerator appears to be quite far from the robotic arm, beyond the immediate reach of the arm's extension. Therefore, the refrigerator is not within the reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable apple_1": ["yes", 1.8648256833598697e-11, 0.9999999999813517, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled apple_1 and apple_2. The apple_1 is positioned close to the robotic arm, and it appears to be within the arm's reach based on the proximity and the arm's extension towards it. Since the arm is actively reaching towards apple_1, it indicates that the apple_1 is indeed within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled apple_1 and apple_2. The apple_1 is positioned close to the robotic arm, and it appears to be within the arm's reach based on the proximity and the arm's extension towards it. Since the arm is actively reaching towards apple_1, it indicates that the apple_1 is indeed within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding apple_2": ["no", 0.9999999999538437, 4.615632403689792e-11, "The image shows a robotic arm in a virtual household environment, with objects labeled as apples and other items. The apple_2 is located on the right side of the image, on the countertop. The robotic arm is positioned above the apple_2, but there is no indication that it is gripping or holding the apple. The arm appears to be near the apple, but not holding it.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment, with objects labeled as apples and other items. The apple_2 is located on the right side of the image, on the countertop. The robotic arm is positioned above the apple_2, but there is no indication that it is gripping or holding the apple. The arm appears to be near the apple, but not holding it.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding orange_1": [true, false, false], "all_correct": true}, "effects_results": {"holding apple_1": ["yes", 0.00024365473164965717, 0.9997563452683503, "The image shows a robotic arm holding an object labeled \"apple_1.\" Since the label \"apple_1\" is directly associated with the object being held by the robotic arm, it indicates that the agent is indeed holding the apple_1.", true, "<explanation>\nThe image shows a robotic arm holding an object labeled \"apple_1.\" Since the label \"apple_1\" is directly associated with the object being held by the robotic arm, it indicates that the agent is indeed holding the apple_1.\n</explanation>\n<answer>\nYes\n</answer>", true], "ontop apple_1,apple_2": ["no", 0.9999999993323686, 6.676313701895554e-10, "In the image, the apple_1 is located on the countertop, while the apple_2 is positioned on a different part of the countertop, to the right of apple_1. The apple_1 is not directly above or on top of apple_2; they are placed side by side on the same surface. Therefore, the answer is \"No\".", true, "<explanation>\nIn the image, the apple_1 is located on the countertop, while the apple_2 is positioned on a different part of the countertop, to the right of apple_1. The apple_1 is not directly above or on top of apple_2; they are placed side by side on the same surface. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop apple_1,electric_refrigerator_1": ["no", 0.999999998780299, 1.2197009684044968e-09, "The image shows an apple labeled \"apple_1\" positioned on a black object, which appears to be a robotic arm or a similar device, not on the electric refrigerator. The electric refrigerator is located further back in the scene, and the apple is not placed on it. Therefore, the answer is \"No\".", true, "<explanation>\nThe image shows an apple labeled \"apple_1\" positioned on a black object, which appears to be a robotic arm or a similar device, not on the electric refrigerator. The electric refrigerator is located further back in the scene, and the apple is not placed on it. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto apple_1,apple_2": ["yes", 1.1338925334927509e-08, 0.9999999886610746, "In the image, the apple_1 is located on the right side of the image, on the kitchen counter. The apple_2 is also on the same counter, but further to the right and slightly behind the apple_1. Since both apples are on the same surface and close to each other, apple_1 is next to apple_2.", false, "<explanation>\nIn the image, the apple_1 is located on the right side of the image, on the kitchen counter. The apple_2 is also on the same counter, but further to the right and slightly behind the apple_1. Since both apples are on the same surface and close to each other, apple_1 is next to apple_2.\n</explanation>\n<answer>\nYes\n</answer>", false], "nextto apple_1,electric_refrigerator_1": ["no", 0.9999999999994844, 5.156220447362715e-13, "The image shows an apple labeled \"apple_1\" on a kitchen counter. The electric refrigerator is also visible in the scene. The apple_1 appears to be placed on the counter, and the refrigerator is positioned nearby. Based on the perspective, the apple_1 is close to the refrigerator, but it is not directly next to it; it is on the counter in front of the refrigerator. Therefore, the apple_1 is not next to the electric refrigerator.", true, "<explanation>\nThe image shows an apple labeled \"apple_1\" on a kitchen counter. The electric refrigerator is also visible in the scene. The apple_1 appears to be placed on the counter, and the refrigerator is positioned nearby. Based on the perspective, the apple_1 is close to the refrigerator, but it is not directly next to it; it is on the counter in front of the refrigerator. Therefore, the apple_1 is not next to the electric refrigerator.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop apple_1,apple_1": {"before": null, "after": false}, "ontop apple_1,orange_1": {"before": false, "after": false}, "ontop apple_1,table_1": {"before": false, "after": false}, "nextto apple_1,apple_1": {"before": null, "after": false}, "nextto apple_1,orange_1": {"before": false, "after": false}, "nextto apple_1,table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999999999999993, 6.205103428925967e-16, "The image shows a robotic arm holding an object, and the environment appears to be a kitchen with various objects, including an electric refrigerator labeled \"electric_refrigerator_1.\" The refrigerator is positioned on the left side of the image, and the robotic arm is in the center, holding an object close to the countertop. Given the perspective, the refrigerator is not directly within the reach of the robotic arm, which is focused on the countertop area. The refrigerator is somewhat distant from the arm's current position.", true, "<explanation>\nThe image shows a robotic arm holding an object, and the environment appears to be a kitchen with various objects, including an electric refrigerator labeled \"electric_refrigerator_1.\" The refrigerator is positioned on the left side of the image, and the robotic arm is in the center, holding an object close to the countertop. Given the perspective, the refrigerator is not directly within the reach of the robotic arm, which is focused on the countertop area. The refrigerator is somewhat distant from the arm's current position.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 2.0143335500387543e-07, 0.999999798566645, "The image shows a robotic arm (agent) reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Therefore, the electric_refrigerator_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Therefore, the electric_refrigerator_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_1": ["yes", 4.219730084172227e-09, 0.9999999957802699, "The image shows a robotic arm (agent) reaching towards a green apple. The apple appears to be close to the robotic arm, and the arm's position suggests it is within the reach of the agent. Since the arm is extended towards the apple, it indicates that the apple is indeed within the agent's reach.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a green apple. The apple appears to be close to the robotic arm, and the arm's position suggests it is within the reach of the agent. Since the arm is extended towards the apple, it indicates that the apple is indeed within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_2": {"before": true, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-inside(apple_1, electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding apple_1": ["yes", 2.8038533307406433e-05, 0.9999719614666925, "The image shows a robotic arm with a black object in its grip, which appears to be an apple. The apple is green and positioned at the end of the robotic arm, indicating that the agent is indeed holding the apple.", true, "<explanation>\nThe image shows a robotic arm with a black object in its grip, which appears to be an apple. The apple is green and positioned at the end of the robotic arm, indicating that the agent is indeed holding the apple.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["yes", 5.586885667091194e-09, 0.9999999944131144, "The image shows a robotic arm (agent) reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned directly in front of the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is close enough to interact with the refrigerator, it can be considered to be in reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned directly in front of the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is close enough to interact with the refrigerator, it can be considered to be in reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 2.815972452168014e-09, 0.9999999971840275, "The image shows a robotic arm holding an object near a white door, which appears to be an appliance. The door is slightly ajar, indicating that the refrigerator door is open. Since the question asks if the electric refrigerator is open, and the door is visibly not fully closed, the answer is \"Yes\".", true, "<explanation>\nThe image shows a robotic arm holding an object near a white door, which appears to be an appliance. The door is slightly ajar, indicating that the refrigerator door is open. Since the question asks if the electric refrigerator is open, and the door is visibly not fully closed, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "place-inside(apple_1, electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding apple_1": ["yes", 5.465232233527388e-07, 0.9999994534767767, "The image shows a robotic arm with a black object in its grip, which appears to be an apple. The apple is green and round, and it is positioned at the end of the robotic arm, indicating that the agent is indeed holding the apple.", true, "<explanation>\nThe image shows a robotic arm with a black object in its grip, which appears to be an apple. The apple is green and round, and it is positioned at the end of the robotic arm, indicating that the agent is indeed holding the apple.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["yes", 8.665394951077993e-08, 0.9999999133460505, "The image shows a robotic arm (agent's hand) reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned directly in front of the robotic arm, and the arm is extended towards it, indicating that it is within reach. Therefore, the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm (agent's hand) reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned directly in front of the robotic arm, and the arm is extended towards it, indicating that it is within reach. Therefore, the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 2.3204078801296886e-09, 0.9999999976795921, "The image shows a robotic arm holding an object near a white door, which appears to be an appliance. The door is slightly ajar, indicating that it is open. Since the appliance is labeled as \"electric_refrigerator_1,\" and the door is open, the refrigerator is open.", true, "<explanation>\nThe image shows a robotic arm holding an object near a white door, which appears to be an appliance. The door is slightly ajar, indicating that it is open. Since the appliance is labeled as \"electric_refrigerator_1,\" and the door is open, the refrigerator is open.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable cabinet_1": ["yes", "no"], "reachable electric_refrigerator_1": ["yes", "yes"], "open cabinet_1": ["yes", "no"], "open electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.25, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 3, "actions": ["navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["yes", "yes"], "reachable countertop_1": ["yes", "yes"], "reachable carrot_1": ["yes", "yes"], "reachable carrot_2": ["yes", "yes"], "reachable carrot_3": ["no", "yes"], "reachable apple_1": ["yes", "yes"], "reachable apple_2": ["no", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["yes", "no"], "ontop bread_1,countertop_1": ["yes", "yes"], "ontop bread_1,carrot_1": ["yes", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["yes", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,cabinet_1": ["no", "no"], "ontop bread_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["yes", "yes"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,cabinet_1": ["no", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["yes", "yes"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["yes", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,cabinet_1": ["no", "no"], "ontop carrot_2,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["yes", "yes"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,cabinet_1": ["no", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["no", "yes"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,cabinet_1": ["no", "no"], "ontop apple_2,electric_refrigerator_1": ["no", "no"], "inside bread_1,cabinet_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,cabinet_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_2,cabinet_1": ["no", "no"], "inside carrot_2,electric_refrigerator_1": ["no", "no"], "inside carrot_3,cabinet_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_2,cabinet_1": ["no", "no"], "inside apple_2,electric_refrigerator_1": ["no", "no"], "nextto bread_1,countertop_1": ["yes", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["no", "no"], "nextto bread_1,carrot_3": ["no", "no"], "nextto bread_1,apple_1": ["no", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,cabinet_1": ["yes", "no"], "nextto bread_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,bread_1": ["yes", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_2": ["yes", "no"], "nextto countertop_1,carrot_3": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_1,bread_1": ["yes", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,carrot_2": ["yes", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,apple_1": ["yes", "no"], "nextto carrot_1,apple_2": ["yes", "yes"], "nextto carrot_1,cabinet_1": ["no", "no"], "nextto carrot_1,electric_refrigerator_1": ["no", "no"], "nextto carrot_2,bread_1": ["no", "no"], "nextto carrot_2,countertop_1": ["no", "no"], "nextto carrot_2,carrot_1": ["no", "no"], "nextto carrot_2,carrot_3": ["yes", "yes"], "nextto carrot_2,apple_1": ["no", "no"], "nextto carrot_2,apple_2": ["yes", "no"], "nextto carrot_2,cabinet_1": ["no", "no"], "nextto carrot_2,electric_refrigerator_1": ["no", "no"], "nextto carrot_3,bread_1": ["yes", "no"], "nextto carrot_3,countertop_1": ["no", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["no", "yes"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["yes", "no"], "nextto carrot_3,cabinet_1": ["yes", "no"], "nextto carrot_3,electric_refrigerator_1": ["no", "no"], "nextto apple_1,bread_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,carrot_1": ["yes", "no"], "nextto apple_1,carrot_2": ["yes", "no"], "nextto apple_1,carrot_3": ["no", "no"], "nextto apple_1,apple_2": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["yes", "no"], "nextto apple_2,bread_1": ["no", "no"], "nextto apple_2,countertop_1": ["no", "no"], "nextto apple_2,carrot_1": ["yes", "yes"], "nextto apple_2,carrot_2": ["yes", "no"], "nextto apple_2,carrot_3": ["yes", "no"], "nextto apple_2,apple_1": ["yes", "no"], "nextto apple_2,cabinet_1": ["no", "no"], "nextto apple_2,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7152777777777778, "yes_accuracy": 0.6666666666666666, "yes_correct": 12, "yes_total": 18, "no_accuracy": 0.7222222222222222, "no_correct": 91, "no_total": 126, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 0.625, "yes_correct": 5, "yes_total": 8, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.8928571428571429, "yes_accuracy": 0.6666666666666666, "yes_correct": 4, "yes_total": 6, "no_accuracy": 0.92, "no_correct": 46, "no_total": 50}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}, "nextto": {"accuracy": 0.44642857142857145, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.4230769230769231, "no_correct": 22, "no_total": 52}}}, "step": 4, "actions": ["grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["yes", "yes"], "reachable countertop_1": ["yes", "yes"], "reachable carrot_1": ["yes", "yes"], "reachable carrot_2": ["yes", "yes"], "reachable carrot_3": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable apple_2": ["yes", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "holding bread_1": ["yes", "no"], "holding countertop_1": ["yes", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["yes", "no"], "holding carrot_3": ["yes", "no"], "holding apple_1": ["yes", "yes"], "holding apple_2": ["yes", "no"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["no", "no"], "ontop bread_1,countertop_1": ["yes", "yes"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["yes", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,cabinet_1": ["yes", "no"], "ontop bread_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["no", "yes"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,cabinet_1": ["no", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["no", "yes"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["yes", "no"], "ontop carrot_2,apple_2": ["yes", "no"], "ontop carrot_2,cabinet_1": ["no", "no"], "ontop carrot_2,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["yes", "yes"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,cabinet_1": ["no", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "no"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["yes", "yes"], "ontop apple_2,carrot_1": ["yes", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,cabinet_1": ["no", "no"], "ontop apple_2,electric_refrigerator_1": ["no", "no"], "inside bread_1,cabinet_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,cabinet_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_2,cabinet_1": ["no", "no"], "inside carrot_2,electric_refrigerator_1": ["no", "no"], "inside carrot_3,cabinet_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_2,cabinet_1": ["no", "no"], "inside apple_2,electric_refrigerator_1": ["no", "no"], "nextto bread_1,countertop_1": ["yes", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["yes", "no"], "nextto bread_1,carrot_3": ["no", "no"], "nextto bread_1,apple_1": ["yes", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,cabinet_1": ["no", "no"], "nextto bread_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,bread_1": ["no", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_2": ["yes", "no"], "nextto countertop_1,carrot_3": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["no", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_1,bread_1": ["no", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,carrot_2": ["no", "no"], "nextto carrot_1,carrot_3": ["yes", "no"], "nextto carrot_1,apple_1": ["yes", "no"], "nextto carrot_1,apple_2": ["no", "yes"], "nextto carrot_1,cabinet_1": ["no", "no"], "nextto carrot_1,electric_refrigerator_1": ["no", "no"], "nextto carrot_2,bread_1": ["no", "no"], "nextto carrot_2,countertop_1": ["no", "no"], "nextto carrot_2,carrot_1": ["no", "no"], "nextto carrot_2,carrot_3": ["yes", "yes"], "nextto carrot_2,apple_1": ["no", "no"], "nextto carrot_2,apple_2": ["yes", "no"], "nextto carrot_2,cabinet_1": ["no", "no"], "nextto carrot_2,electric_refrigerator_1": ["no", "no"], "nextto carrot_3,bread_1": ["yes", "no"], "nextto carrot_3,countertop_1": ["yes", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["no", "yes"], "nextto carrot_3,apple_1": ["yes", "no"], "nextto carrot_3,apple_2": ["yes", "no"], "nextto carrot_3,cabinet_1": ["no", "no"], "nextto carrot_3,electric_refrigerator_1": ["no", "no"], "nextto apple_1,bread_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "no"], "nextto apple_1,carrot_3": ["yes", "no"], "nextto apple_1,apple_2": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_2,bread_1": ["no", "no"], "nextto apple_2,countertop_1": ["no", "no"], "nextto apple_2,carrot_1": ["no", "yes"], "nextto apple_2,carrot_2": ["no", "no"], "nextto apple_2,carrot_3": ["yes", "no"], "nextto apple_2,apple_1": ["yes", "no"], "nextto apple_2,cabinet_1": ["yes", "no"], "nextto apple_2,electric_refrigerator_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7013888888888888, "yes_accuracy": 0.7222222222222222, "yes_correct": 13, "yes_total": 18, "no_accuracy": 0.6984126984126984, "no_correct": 88, "no_total": 126, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 8, "yes_total": 8, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 0.2857142857142857, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.16666666666666666, "no_correct": 1, "no_total": 6}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.8392857142857143, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.8627450980392157, "no_correct": 44, "no_total": 51}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}, "nextto": {"accuracy": 0.48214285714285715, "yes_accuracy": 0.25, "yes_correct": 1, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 26, "no_total": 52}}}, "step": 5, "actions": ["navigate-to(electric_refrigerator_1)", "place-next-to(apple_2, electric_refrigerator_1)", "place-next-to(apple_1, electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "yes"], "holding apple_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 6, "actions": ["place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "yes"], "holding apple_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 7, "actions": ["place-inside(apple_1, electric_refrigerator_1)"]}], "remaining_actions": []}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Beechwood_0_int_24": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(apple_1)", "action_correct": true, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 6.674493210491313e-09, 0.9999999933255068, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is located on the counter, and the robotic arm appears to be extended towards it. Given the proximity of the arm to the apple_1, it seems to be within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is located on the counter, and the robotic arm appears to be extended towards it. Given the proximity of the arm to the apple_1, it seems to be within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_2": ["no", 1.0, 2.1245871905377884e-18, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled \"apple\" and \"apple_1,\" and another object labeled \"apple_2.\" The apple_2 is located further to the right, near some utensils. The robotic arm appears to be reaching towards the apple, but it is not clear if it is specifically reaching towards apple_2. Since apple_2 is positioned further to the right and the arm is extending towards the middle of the counter, it is unlikely that apple_2 is within the immediate reach of the robotic arm.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled \"apple\" and \"apple_1,\" and another object labeled \"apple_2.\" The apple_2 is located further to the right, near some utensils. The robotic arm appears to be reaching towards the apple, but it is not clear if it is specifically reaching towards apple_2. Since apple_2 is positioned further to the right and the arm is extending towards the middle of the counter, it is unlikely that apple_2 is within the immediate reach of the robotic arm.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable electric_refrigerator_1": ["no", 0.9999999999999933, 6.6198579139365254e-15, "The image shows a robotic arm (agent) positioned near a countertop with objects on it, including an apple and some labeled items. The electric_refrigerator_1 is located to the left of the countertop, behind the microwave and oven. Given the perspective, the refrigerator appears to be some distance away from the robotic arm, which is actively interacting with objects on the countertop. The arm does not seem to be close enough to reach the refrigerator directly, as it is positioned on the right side of the image, near the objects on the countertop.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near a countertop with objects on it, including an apple and some labeled items. The electric_refrigerator_1 is located to the left of the countertop, behind the microwave and oven. Given the perspective, the refrigerator appears to be some distance away from the robotic arm, which is actively interacting with objects on the countertop. The arm does not seem to be close enough to reach the refrigerator directly, as it is positioned on the right side of the image, near the objects on the countertop.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {"reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.999999999999987, 1.2989644135661733e-14, "The image shows a robotic arm (agent) positioned near a countertop with objects on it, including an apple and some labeled items. The electric_refrigerator_1 is located to the left of the countertop, behind the microwave and oven. Given the perspective, the refrigerator appears to be some distance away from the robotic arm, which is actively interacting with objects on the countertop. The arm does not seem to be close enough to reach the refrigerator directly, as it is positioned on the right side of the image, near the objects on the counter.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near a countertop with objects on it, including an apple and some labeled items. The electric_refrigerator_1 is located to the left of the countertop, behind the microwave and oven. Given the perspective, the refrigerator appears to be some distance away from the robotic arm, which is actively interacting with objects on the countertop. The arm does not seem to be close enough to reach the refrigerator directly, as it is positioned on the right side of the image, near the objects on the counter.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 1.1994325911894065e-07, 0.9999998800567409, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against the wall, and the robotic arm is extended towards it. Given the proximity of the arm to the refrigerator, it seems to be within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against the wall, and the robotic arm is extended towards it. Given the proximity of the arm to the refrigerator, it seems to be within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_1": {"before": true, "after": false}, "reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 4.7320235507675836e-08, 0.9999999526797645, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is indeed within the agent's reach.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is indeed within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 4.987596533877807e-07, 0.9999995012403466, "The image shows a robotic arm holding a door of an appliance, which appears to be an electric refrigerator. The door is tilted open, revealing the interior of the refrigerator. Since the door is visibly open, the refrigerator is not closed.", false, "<explanation>\nThe image shows a robotic arm holding a door of an appliance, which appears to be an electric refrigerator. The door is tilted open, revealing the interior of the refrigerator. Since the door is visibly open, the refrigerator is not closed.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding apple_1": [true, false, false], "holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 1.1169803733794886e-09, 0.9999999988830196, "The image shows a robotic arm in a virtual household environment, with objects labeled \"apple_1\" and \"apple_2\" on the countertop. The apple_1 appears to be positioned close to the robotic arm, which is extending towards the objects. Given the proximity of apple_1 to the robotic arm and the typical reach of such an arm in this simulation, it is reasonable to conclude that apple_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment, with objects labeled \"apple_1\" and \"apple_2\" on the countertop. The apple_1 appears to be positioned close to the robotic arm, which is extending towards the objects. Given the proximity of apple_1 to the robotic arm and the typical reach of such an arm in this simulation, it is reasonable to conclude that apple_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_2": ["yes", 4.919906789578303e-12, 0.99999999999508, "The image shows a robotic arm in a virtual household environment, with objects including two apples labeled apple_1 and apple_2. The apple_2 is positioned on the countertop, and the robotic arm is extended towards the objects. Based on the perspective, the apple_2 appears to be within the reach of the robotic arm, as it is close to the arm's current position and within the same surface area.", false, "<explanation>\nThe image shows a robotic arm in a virtual household environment, with objects including two apples labeled apple_1 and apple_2. The apple_2 is positioned on the countertop, and the robotic arm is extended towards the objects. Based on the perspective, the apple_2 appears to be within the reach of the robotic arm, as it is close to the arm's current position and within the same surface area.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["yes", 8.912758559267708e-12, 0.9999999999910872, "The image shows a robotic arm (agent) positioned near objects on a kitchen counter. The electric_refrigerator_1 is located to the left of the robotic arm, which is actively reaching towards objects on the counter. Given the proximity of the robotic arm to the refrigerator and the typical reach of such a robotic arm in a household setting, it is likely within reach. Therefore, the electric_refrigerator_1 appears to be within the reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) positioned near objects on a kitchen counter. The electric_refrigerator_1 is located to the left of the robotic arm, which is actively reaching towards objects on the counter. Given the proximity of the robotic arm to the refrigerator and the typical reach of such a robotic arm in a household setting, it is likely within reach. Therefore, the electric_refrigerator_1 appears to be within the reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 2.2913073380335956e-12, 0.9999999999977087, "The image shows a robotic arm (agent) positioned near objects on a kitchen counter. The electric_refrigerator_1 is located to the left of the robotic arm, which is actively reaching towards objects on the counter. Since the refrigerator is adjacent to the counter and the robotic arm is close to the objects on the counter, it is likely within reach of the agent. The proximity suggests that the refrigerator is accessible to the robotic arm.", false, "<explanation>\nThe image shows a robotic arm (agent) positioned near objects on a kitchen counter. The electric_refrigerator_1 is located to the left of the robotic arm, which is actively reaching towards objects on the counter. Since the refrigerator is adjacent to the counter and the robotic arm is close to the objects on the counter, it is likely within reach of the agent. The proximity suggests that the refrigerator is accessible to the robotic arm.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable apple_1": ["yes", 8.897306269378259e-10, 0.9999999991102694, "The image shows a robotic arm (agent) positioned near the objects on the kitchen counter. The apple_1 is located close to the robotic arm, and based on the perspective, it appears to be within the reach of the robotic arm. Since the arm is capable of interacting with objects on the counter and the apple_1 is nearby, it is reasonable to conclude that the apple_1 is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near the objects on the kitchen counter. The apple_1 is located close to the robotic arm, and based on the perspective, it appears to be within the reach of the robotic arm. Since the arm is capable of interacting with objects on the counter and the apple_1 is nearby, it is reasonable to conclude that the apple_1 is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "holding apple_2": ["no", 0.9999999999998993, 1.007415072930014e-13, "The image shows a robotic arm in a virtual household environment, with objects labeled as \"apple_1\" and \"apple_2.\" The robotic arm appears to be positioned near the objects, but there is no clear indication that it is holding \"apple_2.\" The arm's grip and position do not suggest it is grasping or holding the second apple, as it seems to be focused on the first apple or the area around it. Therefore, based on the visual evidence, the agent is not holding \"apple_2.\"", true, "<explanation>\nThe image shows a robotic arm in a virtual household environment, with objects labeled as \"apple_1\" and \"apple_2.\" The robotic arm appears to be positioned near the objects, but there is no clear indication that it is holding \"apple_2.\" The arm's grip and position do not suggest it is grasping or holding the second apple, as it seems to be focused on the first apple or the area around it. Therefore, based on the visual evidence, the agent is not holding \"apple_2.\"\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding orange_1": [true, false, false], "all_correct": true}, "effects_results": {"holding apple_1": ["no", 0.9999999778074002, 2.2192599742185522e-08, "The image shows a robotic arm, which is the agent, holding an object. However, the object appears to be a gray, rounded item that does not resemble an apple. There is no clear indication that the object being held is an apple, and the label \"apple_1\" is not visible in the image. Therefore, based on the visual evidence, the agent is not holding an apple.", false, "<explanation>\nThe image shows a robotic arm, which is the agent, holding an object. However, the object appears to be a gray, rounded item that does not resemble an apple. There is no clear indication that the object being held is an apple, and the label \"apple_1\" is not visible in the image. Therefore, based on the visual evidence, the agent is not holding an apple.\n</explanation>\n<answer>\nNo\n</answer>", false], "ontop apple_1,orange_1": ["no", 0.9999999996073109, 3.926890735387517e-10, "The image shows a robotic arm holding an object, but the objects are not clearly labeled as apple_1 or orange_1. There is no visible indication that apple_1 is on top of orange_1, and the objects in the image do not appear to be an apple or an orange. Therefore, based on the provided image, I cannot confirm that apple_1 is on top of orange_1.", true, "<explanation>\nThe image shows a robotic arm holding an object, but the objects are not clearly labeled as apple_1 or orange_1. There is no visible indication that apple_1 is on top of orange_1, and the objects in the image do not appear to be an apple or an orange. Therefore, based on the provided image, I cannot confirm that apple_1 is on top of orange_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "ontop apple_1,table_1": ["no", 0.9999974889691621, 2.511030837911723e-06, "The image shows a robotic arm holding an object labeled \"apple_1.\" The table_1 is visible in the scene, with chairs around it. The apple_1 appears to be in the robotic arm's grasp, not on the table. Therefore, the apple_1 is not on top of the table_1.", true, "<explanation>\nThe image shows a robotic arm holding an object labeled \"apple_1.\" The table_1 is visible in the scene, with chairs around it. The apple_1 appears to be in the robotic arm's grasp, not on the table. Therefore, the apple_1 is not on top of the table_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto apple_1,orange_1": ["no", 0.9999991495902293, 8.504097707284696e-07, "The image shows a robotic arm holding an object, but the objects labeled \"apple_1\" and \"orange_1\" are not clearly visible or identifiable in the image. There is no clear indication that \"apple_1\" is next to \"orange_1\" based on the current view. Therefore, I cannot confirm that \"apple_1\" is next to \"orange_1\".", true, "<explanation>\nThe image shows a robotic arm holding an object, but the objects labeled \"apple_1\" and \"orange_1\" are not clearly visible or identifiable in the image. There is no clear indication that \"apple_1\" is next to \"orange_1\" based on the current view. Therefore, I cannot confirm that \"apple_1\" is next to \"orange_1\".\n</explanation>\n<answer>\nNo\n</answer>", true], "nextto apple_1,table_1": ["no", 0.9999999999967929, 3.2070481421130795e-12, "The image shows a robotic arm holding an object, but the objects labeled as apple_1 and table_1 are not clearly visible or identifiable in the image. The table is visible in the background, but there is no clear indication that apple_1 is next to it. Since the question asks specifically about the position of apple_1 relative to table_1, and there is no evidence in the image to confirm this, the answer cannot be determined with certainty.", true, "<explanation>\nThe image shows a robotic arm holding an object, but the objects labeled as apple_1 and table_1 are not clearly visible or identifiable in the image. The table is visible in the background, but there is no clear indication that apple_1 is next to it. Since the question asks specifically about the position of apple_1 relative to table_1, and there is no evidence in the image to confirm this, the answer cannot be determined with certainty.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"ontop apple_1,apple_1": {"before": null, "after": false}, "ontop apple_1,apple_2": {"before": false, "after": false}, "ontop apple_1,electric_refrigerator_1": {"before": false, "after": false}, "nextto apple_1,apple_1": {"before": null, "after": false}, "nextto apple_1,apple_2": {"before": false, "after": false}, "nextto apple_1,electric_refrigerator_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable electric_refrigerator_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["no", 0.9999999999940956, 5.9044122812616025e-12, "The image shows a robotic arm holding a green apple, and the arm is positioned near a white door or wall. There is no visible electric refrigerator in the image, and the only object in the scene is the door or wall with the apple. Since the electric_refrigerator_1 is not visible in the image, I cannot determine if it is within reach of the agent. Therefore, the answer is \"No\".", false, "<explanation>\nThe image shows a robotic arm holding a green apple, and the arm is positioned near a white door or wall. There is no visible electric refrigerator in the image, and the only object in the scene is the door or wall with the apple. Since the electric_refrigerator_1 is not visible in the image, I cannot determine if it is within reach of the agent. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable apple_1": ["yes", 6.325995367590345e-08, 0.9999999367400463, "The image shows a robotic arm holding an apple near a door. The apple appears to be close to the robotic arm's grasp, which suggests it is within reach of the agent. Since the arm is actively holding the apple and is positioned near the door, it indicates that the apple is indeed in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm holding an apple near a door. The apple appears to be close to the robotic arm's grasp, which suggests it is within reach of the agent. Since the arm is actively holding the apple and is positioned near the door, it indicates that the apple is indeed in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999999739621518, 2.6037848164388646e-08, "The image shows a robotic arm holding a green apple, and the arm is positioned near a white door or wall. There is no visible electric refrigerator in the image, so I cannot determine if it is within reach of the agent. Since the question asks about a specific object that is not visible, the answer is \"No\".", true, "<explanation>\nThe image shows a robotic arm holding a green apple, and the arm is positioned near a white door or wall. There is no visible electric refrigerator in the image, so I cannot determine if it is within reach of the agent. Since the question asks about a specific object that is not visible, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["no", 0.9999998933079265, 1.0669207346387462e-07, "The image shows a robotic arm holding a green object near a white wall or surface. There is no visible electric refrigerator in the image, only the robotic arm and the green object. Since the question asks if the electric_refrigerator_1 is in reach of the agent, and no refrigerator is visible in the image, it is not possible to determine that it is within reach. Therefore, the answer is \"No\".", false, "<explanation>\nThe image shows a robotic arm holding a green object near a white wall or surface. There is no visible electric refrigerator in the image, only the robotic arm and the green object. Since the question asks if the electric_refrigerator_1 is in reach of the agent, and no refrigerator is visible in the image, it is not possible to determine that it is within reach. Therefore, the answer is \"No\".\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable apple_1": ["yes", 9.821039095225006e-11, 0.9999999999017896, "The image shows a robotic arm holding an apple near a wall or surface. To determine if the apple is in reach of the agent, I need to consider the position of the apple relative to the robotic arm's current position. The apple appears to be very close to the robotic arm's hand, which suggests that it is within reach. Since the robotic arm is holding the apple, it indicates that the apple is indeed reachable by the agent.", false, "<explanation>\nThe image shows a robotic arm holding an apple near a wall or surface. To determine if the apple is in reach of the agent, I need to consider the position of the apple relative to the robotic arm's current position. The apple appears to be very close to the robotic arm's hand, which suggests that it is within reach. Since the robotic arm is holding the apple, it indicates that the apple is indeed reachable by the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999998755112689, 1.2448873113839663e-07, "The image shows a robotic arm holding a green object near a white wall, but there is no visible electric refrigerator in the image. The question asks if the electric_refrigerator_1 is in reach of the agent. Since the refrigerator is not visible in the image, I cannot determine its position relative to the agent. Therefore, based on the provided image, I cannot confirm that the refrigerator is in reach.", true, "<explanation>\nThe image shows a robotic arm holding a green object near a white wall, but there is no visible electric refrigerator in the image. The question asks if the electric_refrigerator_1 is in reach of the agent. Since the refrigerator is not visible in the image, I cannot determine its position relative to the agent. Therefore, based on the provided image, I cannot confirm that the refrigerator is in reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["no", 0.9999999999733932, 2.6606820370971662e-11, "The image shows a robotic arm (agent) reaching towards a green apple on a whiteboard or surface. The question asks if the electric_refrigerator_1 is in reach of the agent. Since the image only shows the robotic arm and a surface with an apple, and there is no visible electric refrigerator in the image, I cannot determine if the refrigerator is within reach. Therefore, based on the provided image, the refrigerator is not visible or confirmed to be in reach.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a green apple on a whiteboard or surface. The question asks if the electric_refrigerator_1 is in reach of the agent. Since the image only shows the robotic arm and a surface with an apple, and there is no visible electric refrigerator in the image, I cannot determine if the refrigerator is within reach. Therefore, based on the provided image, the refrigerator is not visible or confirmed to be in reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable apple_1": ["yes", 2.970843265055806e-10, 0.9999999997029156, "The image shows a robotic arm (agent) reaching towards an apple on a whiteboard or surface. The apple appears to be very close to the robotic arm's grasping area, suggesting that it is within reach. Since the arm is extended towards the apple and the apple is positioned near the arm's grasping point, it indicates that the apple is accessible to the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an apple on a whiteboard or surface. The apple appears to be very close to the robotic arm's grasping area, suggesting that it is within reach. Since the arm is extended towards the apple and the apple is positioned near the arm's grasping point, it indicates that the apple is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable apple_1": ["yes", 5.582961890102578e-10, 0.9999999994417038, "The image shows a robotic arm (agent) reaching towards an apple on a whiteboard or surface. The apple appears to be very close to the robotic arm's gripper, which suggests that it is within reach. Since the arm is extended towards the apple and the apple is positioned near the arm's grasp, it indicates that the apple is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards an apple on a whiteboard or surface. The apple appears to be very close to the robotic arm's gripper, which suggests that it is within reach. Since the arm is extended towards the apple and the apple is positioned near the arm's grasp, it indicates that the apple is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999999999337763, 6.622373205198059e-11, "The image shows a robotic arm (agent) reaching towards a green apple on a whiteboard or surface. The question asks if the electric_refrigerator_1 is in reach of the agent. Since the image only shows the robotic arm and a surface with an apple, and there is no visible electric refrigerator in the image, I cannot determine if the refrigerator is within reach. Therefore, based on the provided image, the refrigerator is not visible and cannot be confirmed to be in reach.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a green apple on a whiteboard or surface. The question asks if the electric_refrigerator_1 is in reach of the agent. Since the image only shows the robotic arm and a surface with an apple, and there is no visible electric refrigerator in the image, I cannot determine if the refrigerator is within reach. Therefore, based on the provided image, the refrigerator is not visible and cannot be confirmed to be in reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "open electric_refrigerator_1": ["no", 0.9999999010122766, 9.898772334100742e-08, "The image shows a robotic arm holding an apple near a white surface, which appears to be a refrigerator door. There is no visible handle or indication that the refrigerator door is open; it looks closed. Since the question asks if the electric_refrigerator_1 is open, and based on the visual evidence, the refrigerator door appears to be shut.", true, "<explanation>\nThe image shows a robotic arm holding an apple near a white surface, which appears to be a refrigerator door. There is no visible handle or indication that the refrigerator door is open; it looks closed. Since the question asks if the electric_refrigerator_1 is open, and based on the visual evidence, the refrigerator door appears to be shut.\n</explanation>\n<answer>\nNo\n</answer>", true], "holding apple_1": ["no", 0.9999999999984733, 1.5267124759569226e-12, "The image shows a robotic arm, which is the agent, positioned near an apple on a whiteboard or similar surface. The arm appears to be in a position that suggests it is holding or about to hold the apple, but it is not clearly gripping or holding the apple in the current view. Since the question asks if the agent is holding the apple, and there is no definitive visual evidence of the apple being grasped by the robotic arm, the safest conclusion is that the agent is not currently holding the apple.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, positioned near an apple on a whiteboard or similar surface. The arm appears to be in a position that suggests it is holding or about to hold the apple, but it is not clearly gripping or holding the apple in the current view. Since the question asks if the agent is holding the apple, and there is no definitive visual evidence of the apple being grasped by the robotic arm, the safest conclusion is that the agent is not currently holding the apple.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "grasp(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable apple_1": ["yes", 4.4459935054211995e-07, 0.9999995554006494, "The image shows a robotic arm reaching towards an apple on a whiteboard or surface. The apple appears to be very close to the robotic arm's gripper, which suggests that it is within the arm's reach. Since the arm is actively extending towards the apple, it indicates that the apple is indeed reachable by the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards an apple on a whiteboard or surface. The apple appears to be very close to the robotic arm's gripper, which suggests that it is within the arm's reach. Since the arm is actively extending towards the apple, it indicates that the apple is indeed reachable by the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999999989218978, 1.0781021415309521e-09, "The image shows a robotic arm (agent) reaching towards a green apple on a whiteboard or surface. The question asks if the electric_refrigerator_1 is in reach of the agent. Since the image only shows the robotic arm and a surface with an apple, there is no visible electric_refrigerator_1 in the scene. Therefore, based on the provided image, the electric_refrigerator_1 is not visible and cannot be confirmed to be in reach.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards a green apple on a whiteboard or surface. The question asks if the electric_refrigerator_1 is in reach of the agent. Since the image only shows the robotic arm and a surface with an apple, there is no visible electric_refrigerator_1 in the scene. Therefore, based on the provided image, the electric_refrigerator_1 is not visible and cannot be confirmed to be in reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["no", 0.9999999979572837, 2.0427162760442156e-09, "The image shows a robotic arm holding an apple near a whiteboard. The environment description mentions objects and furniture, including an electric refrigerator. However, the image does not show the electric_refrigerator_1 or its position relative to the robotic arm. Since the question asks if the electric_refrigerator_1 is in reach of the agent, and there is no visual evidence of the refrigerator or its proximity, I cannot determine if it is within reach based on this image alone.", false, "<explanation>\nThe image shows a robotic arm holding an apple near a whiteboard. The environment description mentions objects and furniture, including an electric refrigerator. However, the image does not show the electric_refrigerator_1 or its position relative to the robotic arm. Since the question asks if the electric_refrigerator_1 is in reach of the agent, and there is no visual evidence of the refrigerator or its proximity, I cannot determine if it is within reach based on this image alone.\n</explanation>\n<answer>\nNo\n</answer>", false], "reachable apple_1": ["yes", 6.583693770142412e-07, 0.999999341630623, "The image shows a robotic arm holding an apple near a whiteboard. The apple appears to be close to the arm, which suggests it is within reach of the agent. Since the arm is actively holding the apple and is positioned near the whiteboard, it indicates that the apple is accessible to the agent.", false, "<explanation>\nThe image shows a robotic arm holding an apple near a whiteboard. The apple appears to be close to the arm, which suggests it is within reach of the agent. Since the arm is actively holding the apple and is positioned near the whiteboard, it indicates that the apple is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999999292864922, 7.071350780623586e-08, "The image shows a robotic arm holding an apple near a whiteboard. The environment description mentions objects and furniture, including an electric refrigerator. However, the image does not show the electric_refrigerator_1 or its position relative to the robotic arm. Since the refrigerator is not visible in the image, I cannot determine whether it is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm holding an apple near a whiteboard. The environment description mentions objects and furniture, including an electric refrigerator. However, the image does not show the electric_refrigerator_1 or its position relative to the robotic arm. Since the refrigerator is not visible in the image, I cannot determine whether it is within reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 3.8490762909411063e-10, 0.9999999996150923, "The image shows a robotic arm holding an apple near a white wall, which appears to be a refrigerator door. The object labeled \"electric_refrigerator_1\" is not explicitly visible in the image, but the context suggests that the refrigerator is the white appliance the robotic arm is interacting with. Since the robotic arm is holding an apple close to the refrigerator door, it indicates that the refrigerator is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm holding an apple near a white wall, which appears to be a refrigerator door. The object labeled \"electric_refrigerator_1\" is not explicitly visible in the image, but the context suggests that the refrigerator is the white appliance the robotic arm is interacting with. Since the robotic arm is holding an apple close to the refrigerator door, it indicates that the refrigerator is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_1": ["yes", 3.260142006682406e-08, 0.9999999673985799, "The image shows a robotic arm holding an apple near a wall. The apple appears to be close to the arm, but it is not clear if it is within the arm's reach. Since the arm is holding the apple, it suggests that the apple is within reach of the agent. Therefore, the apple_1 is in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm holding an apple near a wall. The apple appears to be close to the arm, but it is not clear if it is within the arm's reach. Since the arm is holding the apple, it suggests that the apple is within reach of the agent. Therefore, the apple_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable cabinet_1": ["yes", "no"], "reachable electric_refrigerator_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}}}, "step": 3, "actions": ["navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["yes", "yes"], "reachable countertop_1": ["yes", "yes"], "reachable carrot_1": ["yes", "yes"], "reachable carrot_2": ["yes", "yes"], "reachable carrot_3": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable apple_2": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["no", "no"], "ontop bread_1,countertop_1": ["yes", "yes"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,cabinet_1": ["no", "no"], "ontop bread_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["yes", "yes"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,cabinet_1": ["no", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["yes", "yes"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,cabinet_1": ["no", "no"], "ontop carrot_2,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["yes", "yes"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,cabinet_1": ["no", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["yes", "yes"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,cabinet_1": ["no", "no"], "ontop apple_2,electric_refrigerator_1": ["no", "no"], "inside bread_1,cabinet_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,cabinet_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_2,cabinet_1": ["no", "no"], "inside carrot_2,electric_refrigerator_1": ["no", "no"], "inside carrot_3,cabinet_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_2,cabinet_1": ["no", "no"], "inside apple_2,electric_refrigerator_1": ["no", "no"], "nextto bread_1,countertop_1": ["yes", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["no", "no"], "nextto bread_1,carrot_3": ["no", "no"], "nextto bread_1,apple_1": ["no", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,cabinet_1": ["yes", "no"], "nextto bread_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,bread_1": ["yes", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_2": ["yes", "no"], "nextto countertop_1,carrot_3": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_1,bread_1": ["yes", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,carrot_2": ["yes", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,apple_1": ["yes", "no"], "nextto carrot_1,apple_2": ["yes", "yes"], "nextto carrot_1,cabinet_1": ["no", "no"], "nextto carrot_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_2,bread_1": ["no", "no"], "nextto carrot_2,countertop_1": ["no", "no"], "nextto carrot_2,carrot_1": ["no", "no"], "nextto carrot_2,carrot_3": ["yes", "yes"], "nextto carrot_2,apple_1": ["yes", "no"], "nextto carrot_2,apple_2": ["yes", "no"], "nextto carrot_2,cabinet_1": ["no", "no"], "nextto carrot_2,electric_refrigerator_1": ["no", "no"], "nextto carrot_3,bread_1": ["no", "no"], "nextto carrot_3,countertop_1": ["no", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["no", "yes"], "nextto carrot_3,apple_1": ["yes", "no"], "nextto carrot_3,apple_2": ["yes", "no"], "nextto carrot_3,cabinet_1": ["no", "no"], "nextto carrot_3,electric_refrigerator_1": ["yes", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["yes", "no"], "nextto apple_1,carrot_3": ["no", "no"], "nextto apple_1,apple_2": ["yes", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_2,bread_1": ["yes", "no"], "nextto apple_2,countertop_1": ["no", "no"], "nextto apple_2,carrot_1": ["yes", "yes"], "nextto apple_2,carrot_2": ["yes", "no"], "nextto apple_2,carrot_3": ["no", "no"], "nextto apple_2,apple_1": ["yes", "no"], "nextto apple_2,cabinet_1": ["no", "no"], "nextto apple_2,electric_refrigerator_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.8333333333333334, "yes_correct": 15, "yes_total": 18, "no_accuracy": 0.7698412698412699, "no_correct": 97, "no_total": 126, "predicates": {"reachable": {"accuracy": 0.8888888888888888, "yes_accuracy": 0.875, "yes_correct": 7, "yes_total": 8, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.9642857142857143, "yes_accuracy": 0.8333333333333334, "yes_correct": 5, "yes_total": 6, "no_accuracy": 0.98, "no_correct": 49, "no_total": 50}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}, "nextto": {"accuracy": 0.48214285714285715, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.46153846153846156, "no_correct": 24, "no_total": 52}}}, "step": 4, "actions": ["navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["yes", "yes"], "reachable countertop_1": ["yes", "yes"], "reachable carrot_1": ["yes", "yes"], "reachable carrot_2": ["yes", "yes"], "reachable carrot_3": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable apple_2": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable electric_refrigerator_1": ["yes", "no"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["yes", "no"], "ontop bread_1,countertop_1": ["yes", "yes"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,cabinet_1": ["no", "no"], "ontop bread_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["yes", "yes"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,cabinet_1": ["no", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["yes", "yes"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,cabinet_1": ["no", "no"], "ontop carrot_2,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["yes", "yes"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,cabinet_1": ["no", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["yes", "yes"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,cabinet_1": ["no", "no"], "ontop apple_2,electric_refrigerator_1": ["no", "no"], "inside bread_1,cabinet_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,cabinet_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_2,cabinet_1": ["no", "no"], "inside carrot_2,electric_refrigerator_1": ["no", "no"], "inside carrot_3,cabinet_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_2,cabinet_1": ["no", "no"], "inside apple_2,electric_refrigerator_1": ["no", "no"], "nextto bread_1,countertop_1": ["yes", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["yes", "no"], "nextto bread_1,carrot_3": ["yes", "no"], "nextto bread_1,apple_1": ["yes", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,cabinet_1": ["no", "no"], "nextto bread_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,bread_1": ["yes", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_2": ["yes", "no"], "nextto countertop_1,carrot_3": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_1,bread_1": ["yes", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,carrot_2": ["yes", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,apple_1": ["yes", "no"], "nextto carrot_1,apple_2": ["yes", "yes"], "nextto carrot_1,cabinet_1": ["no", "no"], "nextto carrot_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_2,bread_1": ["yes", "no"], "nextto carrot_2,countertop_1": ["yes", "no"], "nextto carrot_2,carrot_1": ["no", "no"], "nextto carrot_2,carrot_3": ["yes", "yes"], "nextto carrot_2,apple_1": ["yes", "no"], "nextto carrot_2,apple_2": ["yes", "no"], "nextto carrot_2,cabinet_1": ["no", "no"], "nextto carrot_2,electric_refrigerator_1": ["no", "no"], "nextto carrot_3,bread_1": ["yes", "no"], "nextto carrot_3,countertop_1": ["yes", "no"], "nextto carrot_3,carrot_1": ["yes", "no"], "nextto carrot_3,carrot_2": ["yes", "yes"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["no", "no"], "nextto carrot_3,cabinet_1": ["no", "no"], "nextto carrot_3,electric_refrigerator_1": ["no", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "no"], "nextto apple_1,carrot_3": ["yes", "no"], "nextto apple_1,apple_2": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_2,bread_1": ["yes", "no"], "nextto apple_2,countertop_1": ["yes", "no"], "nextto apple_2,carrot_1": ["yes", "yes"], "nextto apple_2,carrot_2": ["no", "no"], "nextto apple_2,carrot_3": ["no", "no"], "nextto apple_2,apple_1": ["yes", "no"], "nextto apple_2,cabinet_1": ["yes", "no"], "nextto apple_2,electric_refrigerator_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7430555555555556, "yes_accuracy": 0.9444444444444444, "yes_correct": 17, "yes_total": 18, "no_accuracy": 0.7142857142857143, "no_correct": 90, "no_total": 126, "predicates": {"reachable": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.875, "yes_correct": 7, "yes_total": 8, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.9821428571428571, "yes_accuracy": 1.0, "yes_correct": 6, "yes_total": 6, "no_accuracy": 0.98, "no_correct": 49, "no_total": 50}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}, "nextto": {"accuracy": 0.4107142857142857, "yes_accuracy": 1.0, "yes_correct": 4, "yes_total": 4, "no_accuracy": 0.36538461538461536, "no_correct": 19, "no_total": 52}}}, "step": 5, "actions": ["grasp(apple_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable milk_1": ["no", "no"], "reachable chair_1": ["yes", "no"], "reachable meat_1": ["no", "no"], "reachable table_1": ["yes", "no"], "reachable cheese_1": ["no", "no"], "reachable yogurt_1": ["yes", "no"], "reachable soup_1": ["yes", "no"], "reachable apple_1": ["no", "yes"], "reachable orange_1": ["no", "no"], "reachable orange_2": ["no", "no"], "reachable orange_3": ["no", "no"], "holding meat_1": ["no", "no"], "holding cheese_1": ["no", "no"], "holding yogurt_1": ["yes", "no"], "holding soup_1": ["no", "no"], "holding apple_1": ["no", "yes"], "holding orange_1": ["no", "no"], "holding orange_2": ["yes", "no"], "holding orange_3": ["yes", "no"], "ontop meat_1,milk_1": ["no", "no"], "ontop meat_1,chair_1": ["no", "no"], "ontop meat_1,table_1": ["no", "yes"], "ontop meat_1,cheese_1": ["no", "no"], "ontop meat_1,yogurt_1": ["no", "no"], "ontop meat_1,soup_1": ["no", "no"], "ontop meat_1,apple_1": ["no", "no"], "ontop meat_1,orange_1": ["no", "no"], "ontop meat_1,orange_2": ["no", "no"], "ontop meat_1,orange_3": ["no", "no"], "ontop cheese_1,milk_1": ["no", "no"], "ontop cheese_1,chair_1": ["no", "no"], "ontop cheese_1,meat_1": ["no", "no"], "ontop cheese_1,table_1": ["no", "yes"], "ontop cheese_1,yogurt_1": ["no", "no"], "ontop cheese_1,soup_1": ["no", "no"], "ontop cheese_1,apple_1": ["no", "no"], "ontop cheese_1,orange_1": ["no", "no"], "ontop cheese_1,orange_2": ["no", "no"], "ontop cheese_1,orange_3": ["no", "no"], "ontop yogurt_1,milk_1": ["no", "no"], "ontop yogurt_1,chair_1": ["no", "no"], "ontop yogurt_1,meat_1": ["no", "no"], "ontop yogurt_1,table_1": ["no", "yes"], "ontop yogurt_1,cheese_1": ["no", "no"], "ontop yogurt_1,soup_1": ["no", "no"], "ontop yogurt_1,apple_1": ["no", "no"], "ontop yogurt_1,orange_1": ["no", "no"], "ontop yogurt_1,orange_2": ["no", "no"], "ontop yogurt_1,orange_3": ["no", "no"], "ontop soup_1,milk_1": ["no", "no"], "ontop soup_1,chair_1": ["no", "no"], "ontop soup_1,meat_1": ["no", "no"], "ontop soup_1,table_1": ["no", "yes"], "ontop soup_1,cheese_1": ["no", "no"], "ontop soup_1,yogurt_1": ["no", "no"], "ontop soup_1,apple_1": ["no", "no"], "ontop soup_1,orange_1": ["no", "no"], "ontop soup_1,orange_2": ["no", "no"], "ontop soup_1,orange_3": ["no", "no"], "ontop apple_1,milk_1": ["no", "no"], "ontop apple_1,chair_1": ["no", "no"], "ontop apple_1,meat_1": ["no", "no"], "ontop apple_1,table_1": ["no", "no"], "ontop apple_1,cheese_1": ["no", "no"], "ontop apple_1,yogurt_1": ["no", "no"], "ontop apple_1,soup_1": ["no", "no"], "ontop apple_1,orange_1": ["no", "no"], "ontop apple_1,orange_2": ["no", "no"], "ontop apple_1,orange_3": ["no", "no"], "ontop orange_1,milk_1": ["no", "no"], "ontop orange_1,chair_1": ["no", "no"], "ontop orange_1,meat_1": ["no", "no"], "ontop orange_1,table_1": ["no", "yes"], "ontop orange_1,cheese_1": ["no", "no"], "ontop orange_1,yogurt_1": ["no", "no"], "ontop orange_1,soup_1": ["no", "no"], "ontop orange_1,apple_1": ["no", "no"], "ontop orange_1,orange_2": ["no", "no"], "ontop orange_1,orange_3": ["no", "no"], "ontop orange_2,milk_1": ["no", "no"], "ontop orange_2,chair_1": ["no", "no"], "ontop orange_2,meat_1": ["no", "no"], "ontop orange_2,table_1": ["no", "yes"], "ontop orange_2,cheese_1": ["no", "no"], "ontop orange_2,yogurt_1": ["no", "no"], "ontop orange_2,soup_1": ["no", "no"], "ontop orange_2,apple_1": ["no", "no"], "ontop orange_2,orange_1": ["no", "no"], "ontop orange_2,orange_3": ["no", "no"], "ontop orange_3,milk_1": ["no", "no"], "ontop orange_3,chair_1": ["no", "no"], "ontop orange_3,meat_1": ["no", "no"], "ontop orange_3,table_1": ["no", "yes"], "ontop orange_3,cheese_1": ["no", "no"], "ontop orange_3,yogurt_1": ["no", "no"], "ontop orange_3,soup_1": ["no", "no"], "ontop orange_3,apple_1": ["no", "no"], "ontop orange_3,orange_1": ["no", "no"], "ontop orange_3,orange_2": ["no", "no"], "nextto meat_1,milk_1": ["no", "no"], "nextto meat_1,chair_1": ["no", "no"], "nextto meat_1,table_1": ["no", "no"], "nextto meat_1,cheese_1": ["no", "no"], "nextto meat_1,yogurt_1": ["no", "no"], "nextto meat_1,soup_1": ["no", "no"], "nextto meat_1,apple_1": ["no", "no"], "nextto meat_1,orange_1": ["no", "no"], "nextto meat_1,orange_2": ["no", "yes"], "nextto meat_1,orange_3": ["no", "no"], "nextto cheese_1,milk_1": ["no", "no"], "nextto cheese_1,chair_1": ["no", "yes"], "nextto cheese_1,meat_1": ["no", "no"], "nextto cheese_1,table_1": ["no", "no"], "nextto cheese_1,yogurt_1": ["no", "no"], "nextto cheese_1,soup_1": ["no", "no"], "nextto cheese_1,apple_1": ["no", "no"], "nextto cheese_1,orange_1": ["no", "yes"], "nextto cheese_1,orange_2": ["no", "no"], "nextto cheese_1,orange_3": ["no", "no"], "nextto yogurt_1,milk_1": ["no", "no"], "nextto yogurt_1,chair_1": ["no", "yes"], "nextto yogurt_1,meat_1": ["no", "no"], "nextto yogurt_1,table_1": ["no", "no"], "nextto yogurt_1,cheese_1": ["no", "no"], "nextto yogurt_1,soup_1": ["no", "yes"], "nextto yogurt_1,apple_1": ["no", "no"], "nextto yogurt_1,orange_1": ["no", "no"], "nextto yogurt_1,orange_2": ["no", "no"], "nextto yogurt_1,orange_3": ["yes", "no"], "nextto soup_1,milk_1": ["no", "no"], "nextto soup_1,chair_1": ["no", "no"], "nextto soup_1,meat_1": ["no", "no"], "nextto soup_1,table_1": ["no", "no"], "nextto soup_1,cheese_1": ["no", "no"], "nextto soup_1,yogurt_1": ["no", "yes"], "nextto soup_1,apple_1": ["no", "no"], "nextto soup_1,orange_1": ["no", "no"], "nextto soup_1,orange_2": ["no", "no"], "nextto soup_1,orange_3": ["no", "no"], "nextto apple_1,milk_1": ["no", "no"], "nextto apple_1,chair_1": ["no", "no"], "nextto apple_1,meat_1": ["no", "no"], "nextto apple_1,table_1": ["no", "no"], "nextto apple_1,cheese_1": ["no", "no"], "nextto apple_1,yogurt_1": ["no", "no"], "nextto apple_1,soup_1": ["no", "no"], "nextto apple_1,orange_1": ["no", "no"], "nextto apple_1,orange_2": ["no", "no"], "nextto apple_1,orange_3": ["no", "no"], "nextto orange_1,milk_1": ["no", "no"], "nextto orange_1,chair_1": ["no", "yes"], "nextto orange_1,meat_1": ["no", "no"], "nextto orange_1,table_1": ["yes", "no"], "nextto orange_1,cheese_1": ["no", "yes"], "nextto orange_1,yogurt_1": ["no", "no"], "nextto orange_1,soup_1": ["no", "no"], "nextto orange_1,apple_1": ["no", "no"], "nextto orange_1,orange_2": ["yes", "no"], "nextto orange_1,orange_3": ["yes", "no"], "nextto orange_2,milk_1": ["yes", "no"], "nextto orange_2,chair_1": ["yes", "no"], "nextto orange_2,meat_1": ["no", "yes"], "nextto orange_2,table_1": ["yes", "no"], "nextto orange_2,cheese_1": ["no", "no"], "nextto orange_2,yogurt_1": ["no", "no"], "nextto orange_2,soup_1": ["no", "no"], "nextto orange_2,apple_1": ["no", "no"], "nextto orange_2,orange_1": ["yes", "no"], "nextto orange_2,orange_3": ["no", "no"], "nextto orange_3,milk_1": ["no", "no"], "nextto orange_3,chair_1": ["yes", "no"], "nextto orange_3,meat_1": ["no", "no"], "nextto orange_3,table_1": ["yes", "no"], "nextto orange_3,cheese_1": ["no", "no"], "nextto orange_3,yogurt_1": ["no", "no"], "nextto orange_3,soup_1": ["no", "no"], "nextto orange_3,apple_1": ["no", "no"], "nextto orange_3,orange_1": ["yes", "no"], "nextto orange_3,orange_2": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7988826815642458, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 18, "no_accuracy": 0.8881987577639752, "no_correct": 143, "no_total": 161, "predicates": {"reachable": {"accuracy": 0.5454545454545454, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.6, "no_correct": 6, "no_total": 10}, "holding": {"accuracy": 0.5, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": 0.5714285714285714, "no_correct": 4, "no_total": 7}, "ontop": {"accuracy": 0.9125, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 7, "no_accuracy": 1.0, "no_correct": 73, "no_total": 73}, "nextto": {"accuracy": 0.75, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 9, "no_accuracy": 0.8450704225352113, "no_correct": 60, "no_total": 71}}}, "step": 6, "actions": ["navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(orange_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)", "navigate-to(orange_1)", "grasp(orange_1)", "navigate-to(table_1)", "place-on(orange_1, table_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "yes"], "holding apple_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 7, "actions": ["navigate-to(electric_refrigerator_1)", "place-next-to(apple_1, electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "yes"], "holding apple_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5714285714285714, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 8, "actions": ["navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "yes"], "holding apple_1": ["no", "yes"], "open electric_refrigerator_1": ["yes", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.5714285714285714, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 9, "actions": ["grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "yes"], "holding apple_1": ["no", "yes"], "open electric_refrigerator_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.8571428571428571, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 10, "actions": ["open-container(electric_refrigerator_1)", "grasp(apple_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "yes"], "holding apple_1": ["no", "yes"], "open electric_refrigerator_1": ["yes", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.5714285714285714, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 0.6666666666666666, "no_correct": 2, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 11, "actions": ["grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "yes"], "holding apple_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.8571428571428571, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 12, "actions": ["navigate-to(electric_refrigerator_1)", "place-next-to(apple_1, electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["no", "yes"], "holding apple_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.5, "yes_correct": 2, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 13, "actions": ["navigate-to(electric_refrigerator_1)", "place-next-to(apple_1, electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable apple_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "yes"], "holding apple_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.8571428571428571, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 1.0, "no_correct": 3, "no_total": 3, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 2, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "nextto": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 14, "actions": ["place-next-to(apple_1, apple_1)", "open-container(electric_refrigerator_1)", "grasp(apple_1)", "place-inside(apple_1, electric_refrigerator_1)"]}], "remaining_actions": ["open-container(electric_refrigerator_1)", "grasp(apple_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Beechwood_0_int_29": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(apple_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 8.958376356253039e-09, 0.9999999910416236, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is located on the counter, close to the robotic arm. Given the perspective, the apple_1 appears to be within the reach of the robotic arm, as it is positioned directly in front of it and not obstructed by other objects.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is located on the counter, close to the robotic arm. Given the perspective, the apple_1 appears to be within the reach of the robotic arm, as it is positioned directly in front of it and not obstructed by other objects.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["no", 0.9999999999999549, 4.5113344130885233e-14, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The electric_refrigerator_1 is located behind the counter, near the wall, and appears to be a tall appliance. The robotic arm is positioned over the counter, close to the lime and carrot, but it is not extending towards the refrigerator. Given the perspective, the refrigerator is not within the immediate reach of the robotic arm, which is focused on objects on the counter.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The electric_refrigerator_1 is located behind the counter, near the wall, and appears to be a tall appliance. The robotic arm is positioned over the counter, close to the lime and carrot, but it is not extending towards the refrigerator. Given the perspective, the refrigerator is not within the immediate reach of the robotic arm, which is focused on objects on the counter.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999999999999937, 6.376931151339105e-15, "The image shows a robotic arm (agent) reaching towards objects on the kitchen counter. The electric_refrigerator_1 is located behind the counter, near the wall, and appears to be a tall appliance. The robotic arm is positioned over the counter, close to the carrot and lime, but it does not seem to extend towards the refrigerator. Given the perspective, the refrigerator is not within the immediate reach of the robotic arm, which is focused on objects on the counter.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on the kitchen counter. The electric_refrigerator_1 is located behind the counter, near the wall, and appears to be a tall appliance. The robotic arm is positioned over the counter, close to the carrot and lime, but it does not seem to extend towards the refrigerator. Given the perspective, the refrigerator is not within the immediate reach of the robotic arm, which is focused on objects on the counter.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 7.971697052480644e-08, 0.9999999202830294, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_1": {"before": true, "after": false}, "reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 2.1107503282255943e-07, 0.9999997889249672, "The image shows a robotic arm reaching towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 5.518844366125627e-07, 0.9999994481155634, "The image shows a robotic arm holding a door, which appears to be part of an appliance. The door is slightly ajar, indicating that the refrigerator door is not fully closed. Since the door is not completely shut, it suggests that the refrigerator is open.", false, "<explanation>\nThe image shows a robotic arm holding a door, which appears to be part of an appliance. The door is slightly ajar, indicating that the refrigerator door is not fully closed. Since the door is not completely shut, it suggests that the refrigerator is open.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding apple_1": [true, false, false], "holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 3.829571523184767e-08, 0.9999999617042847, "The image shows a robotic arm in a kitchen environment, with an apple labeled \"apple_1\" on the counter. The apple is positioned close to the edge of the counter, and the robotic arm appears to be extended towards it. Given the proximity of the apple to the robotic arm, it is likely within reach of the agent. Therefore, the apple_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm in a kitchen environment, with an apple labeled \"apple_1\" on the counter. The apple is positioned close to the edge of the counter, and the robotic arm appears to be extended towards it. Given the proximity of the apple to the robotic arm, it is likely within reach of the agent. Therefore, the apple_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["yes", 5.145079867909098e-15, 0.9999999999999949, "The image shows a robotic arm (agent) positioned near a countertop with a green object and a carrot. The electric_refrigerator_1 is located to the left of the countertop, behind the robotic arm. Given the perspective, the refrigerator appears to be quite close to the agent, and the arm is extended towards the objects on the countertop. Since the refrigerator is adjacent to the countertop and the arm is near the objects on the counter, it is likely within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) positioned near a countertop with a green object and a carrot. The electric_refrigerator_1 is located to the left of the countertop, behind the robotic arm. Given the perspective, the refrigerator appears to be quite close to the agent, and the arm is extended towards the objects on the countertop. Since the refrigerator is adjacent to the countertop and the arm is near the objects on the counter, it is likely within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.999999999999999, 9.712141980811074e-16, "The image shows a robotic arm (agent) positioned near a countertop with a green object and some labeled items. The electric_refrigerator_1 is located to the left of the robotic arm, behind the countertop and cabinets. Given the perspective, the refrigerator appears to be quite a distance away from the robotic arm, which is actively engaged with objects on the countertop. The arm does not seem to be close enough to reach the refrigerator directly, considering typical reach distances in such a virtual environment.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned near a countertop with a green object and some labeled items. The electric_refrigerator_1 is located to the left of the robotic arm, behind the countertop and cabinets. Given the perspective, the refrigerator appears to be quite a distance away from the robotic arm, which is actively engaged with objects on the countertop. The arm does not seem to be close enough to reach the refrigerator directly, considering typical reach distances in such a virtual environment.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 4.740314268317879e-08, 0.9999999525968574, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_1": {"before": true, "after": false}, "reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 7.050775267383003e-08, 0.9999999294922474, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against a wall, and the robotic arm is extended towards it. Given the proximity of the arm to the refrigerator, it seems to be within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against a wall, and the robotic arm is extended towards it. Given the proximity of the arm to the refrigerator, it seems to be within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 2.2355633914422658e-08, 0.9999999776443661, "The image shows a robotic arm holding a black object near a white door. The door appears to be part of an appliance, likely an electric refrigerator, given the context. The door is slightly ajar, indicating that it is open. Since the question asks if the electric refrigerator is open, and the door is visibly not fully closed, the answer is \"Yes\".", false, "<explanation>\nThe image shows a robotic arm holding a black object near a white door. The door appears to be part of an appliance, likely an electric refrigerator, given the context. The door is slightly ajar, indicating that it is open. Since the question asks if the electric refrigerator is open, and the door is visibly not fully closed, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding apple_1": [true, false, false], "holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 6.846825201494174e-08, 0.9999999315317479, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled apple_1 and apple_2. The apple_1 is positioned closer to the robotic arm than apple_2, and it appears to be within the reach of the robotic arm based on its proximity and the arm's current position. Therefore, apple_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled apple_1 and apple_2. The apple_1 is positioned closer to the robotic arm than apple_2, and it appears to be within the reach of the robotic arm based on its proximity and the arm's current position. Therefore, apple_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_2": ["yes", 1.926739828937369e-12, 0.9999999999980732, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled apple_1 and apple_2. The apple_2 is positioned further to the right, closer to the edge of the counter, and appears to be within the reach of the robotic arm, which is extended towards the objects. Since the arm is already reaching towards the objects and apple_2 is on the same counter within the arm's reach, it is likely accessible to the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled apple_1 and apple_2. The apple_2 is positioned further to the right, closer to the edge of the counter, and appears to be within the reach of the robotic arm, which is extended towards the objects. Since the arm is already reaching towards the objects and apple_2 is on the same counter within the arm's reach, it is likely accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["no", 0.9999999999999498, 5.0169055814698254e-14, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The electric_refrigerator_1 is located to the left of the image, next to the oven and microwave. The robotic arm is positioned to the right, near the apples and carrots, and is extending towards the objects on the counter. Since the refrigerator is on the far left and the robotic arm is on the right side of the image, it does not appear to be within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The electric_refrigerator_1 is located to the left of the image, next to the oven and microwave. The robotic arm is positioned to the right, near the apples and carrots, and is extending towards the objects on the counter. Since the refrigerator is on the far left and the robotic arm is on the right side of the image, it does not appear to be within reach of the agent.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999999999994829, 5.171503980893393e-13, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The electric_refrigerator_1 is located to the left of the image, next to the oven and microwave. The robotic arm is positioned to the right, near the apples and carrots on the counter. Since the refrigerator is on the far left and the robotic arm is on the right side of the image, it appears that the refrigerator is not within the reach of the robotic arm.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The electric_refrigerator_1 is located to the left of the image, next to the oven and microwave. The robotic arm is positioned to the right, near the apples and carrots on the counter. Since the refrigerator is on the far left and the robotic arm is on the right side of the image, it appears that the refrigerator is not within the reach of the robotic arm.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 6.228775319674272e-08, 0.9999999377122468, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_1": {"before": true, "after": false}, "reachable apple_2": {"before": true, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 2.994929942767434e-08, 0.9999999700507006, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 8.355004368188133e-07, 0.9999991644995632, "The image shows a robotic arm holding a door, which appears to be part of an appliance. The door is slightly ajar, indicating that the refrigerator door is not fully closed. Since the question asks if the electric_refrigerator_1 is open, and the door is indeed open, the answer is \"Yes\".", false, "<explanation>\nThe image shows a robotic arm holding a door, which appears to be part of an appliance. The door is slightly ajar, indicating that the refrigerator door is not fully closed. Since the question asks if the electric_refrigerator_1 is open, and the door is indeed open, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding apple_1": [true, false, false], "holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 5.926187975702377e-07, 0.9999994073812024, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is located near the center of the counter, close to the robotic arm. Given the position of the robotic arm and the proximity of the apple_1, it appears that the apple_1 is within reach of the agent. Therefore, the answer is \"Yes\".", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is located near the center of the counter, close to the robotic arm. Given the position of the robotic arm and the proximity of the apple_1, it appears that the apple_1 is within reach of the agent. Therefore, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_2": ["yes", 1.0129886907975956e-07, 0.9999998987011309, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_2 is located near the center of the counter, close to the robotic arm. Given the position of the robotic arm and the proximity of apple_2, it appears to be within the reach of the agent. Therefore, the apple_2 is likely accessible to the robotic arm.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_2 is located near the center of the counter, close to the robotic arm. Given the position of the robotic arm and the proximity of apple_2, it appears to be within the reach of the agent. Therefore, the apple_2 is likely accessible to the robotic arm.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable orange_1": {"before": false, "after": false}, "reachable electric_refrigerator_1": {"before": true, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable electric_refrigerator_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 5.771937982736053e-08, 0.9999999422806202, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against the wall, and the robotic arm is extended towards it. Given the proximity of the arm to the refrigerator, it seems to be within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against the wall, and the robotic arm is extended towards it. Given the proximity of the arm to the refrigerator, it seems to be within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_1": {"before": true, "after": false}, "reachable apple_2": {"before": true, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 4.904220838072676e-08, 0.9999999509577916, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against a wall, and the robotic arm is extended towards it. Given the proximity of the robotic arm to the refrigerator, it seems to be within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against a wall, and the robotic arm is extended towards it. Given the proximity of the robotic arm to the refrigerator, it seems to be within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 3.051050374260567e-07, 0.9999996948949625, "The image shows a robotic arm holding a black object near a white door. The door appears to be a refrigerator door, and it is slightly ajar, indicating that it is open. Since the question asks if the electric refrigerator 1 is open, and the door is visibly open, the answer is \"Yes\".", false, "<explanation>\nThe image shows a robotic arm holding a black object near a white door. The door appears to be a refrigerator door, and it is slightly ajar, indicating that it is open. Since the question asks if the electric refrigerator 1 is open, and the door is visibly open, the answer is \"Yes\".\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding apple_1": [true, false, false], "holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 1.9269302731652037e-11, 0.9999999999807307, "The image shows a robotic arm (agent) positioned above a kitchen counter, with two apples labeled \"apple_1\" and \"apple_2\" on the counter. The apple labeled \"apple_1\" is located closer to the robotic arm than \"apple_2\" and appears to be within the reach of the robotic arm, which is extended downward towards the apple. Given the proximity and the position of the robotic arm, it is reasonable to conclude that \"apple_1\" is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned above a kitchen counter, with two apples labeled \"apple_1\" and \"apple_2\" on the counter. The apple labeled \"apple_1\" is located closer to the robotic arm than \"apple_2\" and appears to be within the reach of the robotic arm, which is extended downward towards the apple. Given the proximity and the position of the robotic arm, it is reasonable to conclude that \"apple_1\" is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_2": ["yes", 1.2161256251824832e-13, 0.9999999999998784, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled \"apple_1\" and \"apple_2.\" The apple_2 is positioned further to the right, near the edge of the counter, and appears to be within the reach of the robotic arm, which is extended towards the objects. Since the arm is already reaching towards the objects and apple_2 is close to the edge, it is likely within the agent's reach.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. There are two apples labeled \"apple_1\" and \"apple_2.\" The apple_2 is positioned further to the right, near the edge of the counter, and appears to be within the reach of the robotic arm, which is extended towards the objects. Since the arm is already reaching towards the objects and apple_2 is close to the edge, it is likely within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["no", 0.999999999999967, 3.298273683513259e-14, "The image shows a robotic arm (agent) reaching towards objects on the kitchen counter. The electric_refrigerator_1 is located to the left of the counter, behind the microwave and oven. The robotic arm is positioned above the counter, reaching towards objects on the surface, but it is not close to or directly in front of the electric_refrigerator_1. Based on the image, the refrigerator is not within the reach of the robotic arm.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on the kitchen counter. The electric_refrigerator_1 is located to the left of the counter, behind the microwave and oven. The robotic arm is positioned above the counter, reaching towards objects on the surface, but it is not close to or directly in front of the electric_refrigerator_1. Based on the image, the refrigerator is not within the reach of the robotic arm.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": false, "all_state_correct": true, "updated_non_visible_preds": {"reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable electric_refrigerator_1": ["no", 0.9999999999999931, 6.903935548611897e-15, "The image shows a robotic arm (agent) positioned above a kitchen counter, with objects on the counter including apples. The electric_refrigerator_1 is located to the left of the counter, behind the microwave and oven. Given the typical distance between kitchen appliances and the position of the robotic arm, the refrigerator appears to be out of reach of the agent, which is actively working on the counter area. The refrigerator is not directly accessible from the current position of the robotic arm.", true, "<explanation>\nThe image shows a robotic arm (agent) positioned above a kitchen counter, with objects on the counter including apples. The electric_refrigerator_1 is located to the left of the counter, behind the microwave and oven. Given the typical distance between kitchen appliances and the position of the robotic arm, the refrigerator appears to be out of reach of the agent, which is actively working on the counter area. The refrigerator is not directly accessible from the current position of the robotic arm.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 3.782001050061594e-08, 0.9999999621799895, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against the wall, and the robotic arm is extended towards it. Given the arm's position and extension, it seems to be within reach of the refrigerator. Therefore, the refrigerator is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned against the wall, and the robotic arm is extended towards it. Given the arm's position and extension, it seems to be within reach of the refrigerator. Therefore, the refrigerator is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_1": {"before": true, "after": false}, "reachable apple_2": {"before": true, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 3.71619026765515e-08, 0.9999999628380973, "The image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm reaching towards a white object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it, indicating that it is within reach. Since the arm is actively reaching towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 2.7944644760724047e-07, 0.9999997205535524, "The image shows a robotic arm holding a tool near a white door. The door appears to be a refrigerator door, and it is slightly ajar, revealing the interior. Since the door is not fully closed and the hinge side is visible, it indicates that the refrigerator door is open.", false, "<explanation>\nThe image shows a robotic arm holding a tool near a white door. The door appears to be a refrigerator door, and it is slightly ajar, revealing the interior. Since the door is not fully closed and the hinge side is visible, it indicates that the refrigerator door is open.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding apple_1": [true, false, false], "holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(apple_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable apple_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable apple_1": ["yes", 4.816402824099114e-08, 0.9999999518359718, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is positioned on the counter, and the robotic arm appears to be extending towards the area where the apple_1 is located. Given the proximity of the arm to the apple_1, it seems to be within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is positioned on the counter, and the robotic arm appears to be extending towards the area where the apple_1 is located. Given the proximity of the arm to the apple_1, it seems to be within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable electric_refrigerator_1": {"before": true, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "grasp(apple_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {"reachable apple_1": ["yes", 5.3726328682436206e-09, 0.9999999946273671, "The image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is positioned on the counter, and the robotic arm appears to be extending towards it. Given the proximity of the apple_1 to the robotic arm's reach, it is likely within the arm's reach. Therefore, the apple_1 is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) reaching towards objects on a kitchen counter. The apple_1 is positioned on the counter, and the robotic arm appears to be extending towards it. Given the proximity of the apple_1 to the robotic arm's reach, it is likely within the arm's reach. Therefore, the apple_1 is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": {"updated_non_visible_preds": {"holding apple_1": {"before": false, "after": true}, "ontop apple_1,apple_1": {"before": null, "after": false}, "ontop apple_1,apple_2": {"before": false, "after": false}, "ontop apple_1,orange_1": {"before": false, "after": false}, "ontop apple_1,electric_refrigerator_1": {"before": false, "after": false}, "ontop apple_1,table_1": {"before": false, "after": false}, "nextto apple_1,apple_1": {"before": null, "after": false}, "nextto apple_1,apple_2": {"before": false, "after": false}, "nextto apple_1,orange_1": {"before": false, "after": false}, "nextto apple_1,electric_refrigerator_1": {"before": false, "after": false}, "nextto apple_1,table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable electric_refrigerator_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 5.17244250658669e-09, 0.9999999948275575, "The image shows a robotic arm (agent) near a refrigerator, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it. Given the proximity and the typical reach of such robotic arms, it is reasonable to conclude that the refrigerator is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) near a refrigerator, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it. Given the proximity and the typical reach of such robotic arms, it is reasonable to conclude that the refrigerator is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_1": ["no", 1.0, 5.033864634997832e-17, "The image shows a green apple on top of a black object, which is near a white wall and a piece of furniture. The robotic arm (agent) is visible, but it is not clear whether it is extended or positioned close enough to reach the apple. Since the apple is placed on top of the black object and the arm is not visibly extended towards it, it is uncertain if the apple is within reach. Based on the image, it appears that the apple is not directly within the arm's current reach.", true, "<explanation>\nThe image shows a green apple on top of a black object, which is near a white wall and a piece of furniture. The robotic arm (agent) is visible, but it is not clear whether it is extended or positioned close enough to reach the apple. Since the apple is placed on top of the black object and the arm is not visibly extended towards it, it is uncertain if the apple is within reach. Based on the image, it appears that the apple is not directly within the arm's current reach.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false, "updated_non_visible_preds": {"reachable apple_2": {"before": false, "after": false}, "reachable orange_1": {"before": false, "after": false}, "reachable table_1": {"before": false, "after": false}}}, "action_info": "success"}, {"action": "place-inside(apple_1, electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding apple_1": ["yes", 3.7392456210889392e-06, 0.9999962607543789, "The image shows a robotic arm, which is the agent, holding an object that appears to be an apple. The apple is green and round, and the robotic arm is grasping it near the top. Based on the visual evidence, the agent is indeed holding the apple.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding an object that appears to be an apple. The apple is green and round, and the robotic arm is grasping it near the top. Based on the visual evidence, the agent is indeed holding the apple.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["yes", 2.9419556577318597e-09, 0.9999999970580443, "The image shows a robotic arm (agent) near a refrigerator, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it. Given the proximity and the typical reach of a robotic arm in such a simulation, it is reasonable to conclude that the refrigerator is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) near a refrigerator, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it. Given the proximity and the typical reach of a robotic arm in such a simulation, it is reasonable to conclude that the refrigerator is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 8.785358211246638e-05, 0.9999121464178875, "In the image, the door of the electric refrigerator is visibly ajar, indicating that it is open. The door is swung outward, revealing the interior of the refrigerator.", true, "<explanation>\nIn the image, the door of the electric refrigerator is visibly ajar, indicating that it is open. The door is swung outward, revealing the interior of the refrigerator.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}, {"action": "place-inside(apple_1, electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"holding apple_1": ["yes", 2.840325450261976e-06, 0.9999971596745497, "The image shows a robotic arm, which is the agent, holding an object that appears to be an apple. The apple is green and round, and the robotic arm is gripping it. Based on the visual evidence, the agent is indeed holding the apple.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, holding an object that appears to be an apple. The apple is green and round, and the robotic arm is gripping it. Based on the visual evidence, the agent is indeed holding the apple.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable electric_refrigerator_1": ["yes", 5.790991425814103e-10, 0.9999999994209009, "The image shows a robotic arm (agent) near a refrigerator, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it. Given the proximity and the typical reach of a robotic arm in such a simulation, it is reasonable to conclude that the refrigerator is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) near a refrigerator, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is extended towards it. Given the proximity and the typical reach of a robotic arm in such a simulation, it is reasonable to conclude that the refrigerator is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["yes", 2.6867750632844275e-05, 0.9999731322493671, "In the image, the door of the electric refrigerator is visible and appears to be slightly ajar, indicating that it is open. The door is not fully closed, which suggests that the refrigerator is indeed open.", true, "<explanation>\nIn the image, the door of the electric refrigerator is visible and appears to be slightly ajar, indicating that it is open. The door is not fully closed, which suggests that the refrigerator is indeed open.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable electric_refrigerator_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}}}, "step": 3, "actions": ["navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["yes", "yes"], "reachable countertop_1": ["yes", "yes"], "reachable carrot_1": ["yes", "yes"], "reachable carrot_2": ["yes", "yes"], "reachable carrot_3": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["no", "no"], "ontop bread_1,countertop_1": ["yes", "yes"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,cabinet_1": ["no", "no"], "ontop bread_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["yes", "yes"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,cabinet_1": ["no", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["no", "yes"], "ontop carrot_2,carrot_1": ["yes", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,cabinet_1": ["no", "no"], "ontop carrot_2,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["no", "yes"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,cabinet_1": ["no", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "inside bread_1,cabinet_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,cabinet_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_2,cabinet_1": ["no", "no"], "inside carrot_2,electric_refrigerator_1": ["no", "no"], "inside carrot_3,cabinet_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto bread_1,countertop_1": ["no", "no"], "nextto bread_1,carrot_1": ["no", "no"], "nextto bread_1,carrot_2": ["no", "no"], "nextto bread_1,carrot_3": ["no", "no"], "nextto bread_1,apple_1": ["no", "no"], "nextto bread_1,cabinet_1": ["no", "no"], "nextto bread_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,bread_1": ["yes", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_2": ["yes", "no"], "nextto countertop_1,carrot_3": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_1,bread_1": ["no", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,carrot_2": ["no", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,apple_1": ["yes", "no"], "nextto carrot_1,cabinet_1": ["no", "no"], "nextto carrot_1,electric_refrigerator_1": ["no", "no"], "nextto carrot_2,bread_1": ["no", "no"], "nextto carrot_2,countertop_1": ["no", "no"], "nextto carrot_2,carrot_1": ["no", "no"], "nextto carrot_2,carrot_3": ["no", "yes"], "nextto carrot_2,apple_1": ["no", "no"], "nextto carrot_2,cabinet_1": ["no", "no"], "nextto carrot_2,electric_refrigerator_1": ["no", "no"], "nextto carrot_3,bread_1": ["no", "no"], "nextto carrot_3,countertop_1": ["no", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["no", "yes"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,cabinet_1": ["no", "no"], "nextto carrot_3,electric_refrigerator_1": ["no", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "no"], "nextto apple_1,carrot_3": ["yes", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.8482142857142857, "yes_accuracy": 0.6428571428571429, "yes_correct": 9, "yes_total": 14, "no_accuracy": 0.8775510204081632, "no_correct": 86, "no_total": 98, "predicates": {"reachable": {"accuracy": 0.875, "yes_accuracy": 0.8571428571428571, "yes_correct": 6, "yes_total": 7, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.9285714285714286, "yes_accuracy": 0.6, "yes_correct": 3, "yes_total": 5, "no_accuracy": 0.972972972972973, "no_correct": 36, "no_total": 37}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 12, "no_total": 12}, "nextto": {"accuracy": 0.6904761904761905, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 2, "no_accuracy": 0.725, "no_correct": 29, "no_total": 40}}}, "step": 4, "actions": ["navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "no"], "reachable electric_refrigerator_1": ["yes", "yes"], "open cabinet_1": ["yes", "no"], "open electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.25, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 6, "actions": ["navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["no", "yes"], "reachable countertop_1": ["yes", "yes"], "reachable carrot_1": ["yes", "yes"], "reachable carrot_2": ["no", "yes"], "reachable carrot_3": ["no", "yes"], "reachable broccoli_1": ["yes", "yes"], "reachable apple_1": ["yes", "yes"], "reachable apple_2": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding broccoli_1": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["no", "no"], "ontop bread_1,countertop_1": ["yes", "yes"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,broccoli_1": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,cabinet_1": ["no", "no"], "ontop bread_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,broccoli_1": ["yes", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["yes", "yes"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,broccoli_1": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,cabinet_1": ["yes", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["no", "yes"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,broccoli_1": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,cabinet_1": ["yes", "no"], "ontop carrot_2,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["no", "yes"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,broccoli_1": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,cabinet_1": ["no", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop broccoli_1,bread_1": ["no", "no"], "ontop broccoli_1,countertop_1": ["yes", "yes"], "ontop broccoli_1,carrot_1": ["no", "no"], "ontop broccoli_1,carrot_2": ["no", "no"], "ontop broccoli_1,carrot_3": ["no", "no"], "ontop broccoli_1,apple_1": ["no", "no"], "ontop broccoli_1,apple_2": ["no", "no"], "ontop broccoli_1,cabinet_1": ["yes", "no"], "ontop broccoli_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,broccoli_1": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["no", "yes"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,broccoli_1": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,cabinet_1": ["no", "no"], "ontop apple_2,electric_refrigerator_1": ["no", "no"], "inside bread_1,cabinet_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,cabinet_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_2,cabinet_1": ["no", "no"], "inside carrot_2,electric_refrigerator_1": ["no", "no"], "inside carrot_3,cabinet_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside broccoli_1,cabinet_1": ["no", "no"], "inside broccoli_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_2,cabinet_1": ["no", "no"], "inside apple_2,electric_refrigerator_1": ["no", "no"], "nextto bread_1,countertop_1": ["no", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["no", "no"], "nextto bread_1,carrot_3": ["no", "no"], "nextto bread_1,broccoli_1": ["no", "no"], "nextto bread_1,apple_1": ["yes", "no"], "nextto bread_1,apple_2": ["no", "no"], "nextto bread_1,cabinet_1": ["no", "no"], "nextto bread_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,bread_1": ["no", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_2": ["no", "no"], "nextto countertop_1,carrot_3": ["no", "no"], "nextto countertop_1,broccoli_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_1,bread_1": ["no", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,carrot_2": ["yes", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,broccoli_1": ["no", "no"], "nextto carrot_1,apple_1": ["yes", "no"], "nextto carrot_1,apple_2": ["yes", "yes"], "nextto carrot_1,cabinet_1": ["no", "no"], "nextto carrot_1,electric_refrigerator_1": ["no", "no"], "nextto carrot_2,bread_1": ["yes", "no"], "nextto carrot_2,countertop_1": ["yes", "no"], "nextto carrot_2,carrot_1": ["yes", "no"], "nextto carrot_2,carrot_3": ["no", "yes"], "nextto carrot_2,broccoli_1": ["yes", "no"], "nextto carrot_2,apple_1": ["yes", "no"], "nextto carrot_2,apple_2": ["yes", "no"], "nextto carrot_2,cabinet_1": ["yes", "no"], "nextto carrot_2,electric_refrigerator_1": ["no", "no"], "nextto carrot_3,bread_1": ["no", "no"], "nextto carrot_3,countertop_1": ["yes", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["no", "yes"], "nextto carrot_3,broccoli_1": ["no", "no"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["no", "no"], "nextto carrot_3,cabinet_1": ["no", "no"], "nextto carrot_3,electric_refrigerator_1": ["no", "no"], "nextto broccoli_1,bread_1": ["no", "no"], "nextto broccoli_1,countertop_1": ["yes", "no"], "nextto broccoli_1,carrot_1": ["no", "no"], "nextto broccoli_1,carrot_2": ["no", "no"], "nextto broccoli_1,carrot_3": ["no", "no"], "nextto broccoli_1,apple_1": ["no", "no"], "nextto broccoli_1,apple_2": ["no", "yes"], "nextto broccoli_1,cabinet_1": ["no", "no"], "nextto broccoli_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "no"], "nextto apple_1,carrot_3": ["no", "no"], "nextto apple_1,broccoli_1": ["no", "no"], "nextto apple_1,apple_2": ["yes", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_2,bread_1": ["yes", "no"], "nextto apple_2,countertop_1": ["yes", "no"], "nextto apple_2,carrot_1": ["yes", "yes"], "nextto apple_2,carrot_2": ["yes", "no"], "nextto apple_2,carrot_3": ["no", "no"], "nextto apple_2,broccoli_1": ["yes", "yes"], "nextto apple_2,apple_1": ["yes", "no"], "nextto apple_2,cabinet_1": ["yes", "no"], "nextto apple_2,electric_refrigerator_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7555555555555555, "yes_accuracy": 0.5454545454545454, "yes_correct": 12, "yes_total": 22, "no_accuracy": 0.7848101265822784, "no_correct": 124, "no_total": 158, "predicates": {"reachable": {"accuracy": 0.6, "yes_accuracy": 0.5555555555555556, "yes_correct": 5, "yes_total": 9, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 8, "no_total": 8}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.8888888888888888, "yes_accuracy": 0.5714285714285714, "yes_correct": 4, "yes_total": 7, "no_accuracy": 0.9230769230769231, "no_correct": 60, "no_total": 65}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 16, "no_total": 16}, "nextto": {"accuracy": 0.5555555555555556, "yes_accuracy": 0.5, "yes_correct": 3, "yes_total": 6, "no_accuracy": 0.5606060606060606, "no_correct": 37, "no_total": 66}}}, "step": 7, "actions": ["navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable electric_refrigerator_1": ["yes", "yes"], "open electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}}}, "step": 9, "actions": ["navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["yes", "yes"], "reachable countertop_1": ["yes", "yes"], "reachable carrot_1": ["yes", "yes"], "reachable carrot_2": ["yes", "yes"], "reachable carrot_3": ["no", "yes"], "reachable apple_1": ["yes", "yes"], "reachable apple_2": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "open cabinet_1": ["no", "no"], "ontop bread_1,countertop_1": ["yes", "yes"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,cabinet_1": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["yes", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["yes", "yes"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,cabinet_1": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["no", "yes"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,cabinet_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["yes", "yes"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,cabinet_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["yes", "yes"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,cabinet_1": ["no", "no"], "inside bread_1,cabinet_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside carrot_1,cabinet_1": ["no", "no"], "inside carrot_2,cabinet_1": ["no", "no"], "inside carrot_3,cabinet_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside apple_2,cabinet_1": ["no", "no"], "nextto bread_1,countertop_1": ["yes", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["no", "no"], "nextto bread_1,carrot_3": ["no", "no"], "nextto bread_1,apple_1": ["yes", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,cabinet_1": ["no", "no"], "nextto countertop_1,bread_1": ["yes", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_2": ["yes", "no"], "nextto countertop_1,carrot_3": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto carrot_1,bread_1": ["yes", "no"], "nextto carrot_1,countertop_1": ["no", "no"], "nextto carrot_1,carrot_2": ["yes", "no"], "nextto carrot_1,carrot_3": ["yes", "no"], "nextto carrot_1,apple_1": ["no", "no"], "nextto carrot_1,apple_2": ["no", "yes"], "nextto carrot_1,cabinet_1": ["no", "no"], "nextto carrot_2,bread_1": ["no", "no"], "nextto carrot_2,countertop_1": ["no", "no"], "nextto carrot_2,carrot_1": ["yes", "no"], "nextto carrot_2,carrot_3": ["yes", "yes"], "nextto carrot_2,apple_1": ["no", "no"], "nextto carrot_2,apple_2": ["no", "no"], "nextto carrot_2,cabinet_1": ["no", "no"], "nextto carrot_3,bread_1": ["no", "no"], "nextto carrot_3,countertop_1": ["yes", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["no", "yes"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["yes", "no"], "nextto carrot_3,cabinet_1": ["yes", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "no"], "nextto apple_1,carrot_3": ["no", "no"], "nextto apple_1,apple_2": ["yes", "no"], "nextto apple_1,cabinet_1": ["no", "no"], "nextto apple_2,bread_1": ["no", "no"], "nextto apple_2,countertop_1": ["yes", "no"], "nextto apple_2,carrot_1": ["no", "yes"], "nextto apple_2,carrot_2": ["no", "no"], "nextto apple_2,carrot_3": ["no", "no"], "nextto apple_2,apple_1": ["yes", "no"], "nextto apple_2,cabinet_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7603305785123967, "yes_accuracy": 0.6666666666666666, "yes_correct": 12, "yes_total": 18, "no_accuracy": 0.7766990291262136, "no_correct": 80, "no_total": 103, "predicates": {"reachable": {"accuracy": 0.75, "yes_accuracy": 0.75, "yes_correct": 6, "yes_total": 8, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.9387755102040817, "yes_accuracy": 0.8333333333333334, "yes_correct": 5, "yes_total": 6, "no_accuracy": 0.9534883720930233, "no_correct": 41, "no_total": 43}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "nextto": {"accuracy": 0.5102040816326531, "yes_accuracy": 0.25, "yes_correct": 1, "yes_total": 4, "no_accuracy": 0.5333333333333333, "no_correct": 24, "no_total": 45}}}, "step": 10, "actions": ["navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "no"], "reachable electric_refrigerator_1": ["yes", "yes"], "open cabinet_1": ["yes", "no"], "open electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.25, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.0, "no_correct": 0, "no_total": 2}}}, "step": 12, "actions": ["navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["yes", "yes"], "reachable countertop_1": ["yes", "yes"], "reachable carrot_1": ["yes", "yes"], "reachable carrot_2": ["yes", "yes"], "reachable carrot_3": ["no", "yes"], "reachable apple_1": ["yes", "yes"], "reachable apple_2": ["yes", "yes"], "reachable cabinet_1": ["no", "yes"], "reachable electric_refrigerator_1": ["no", "no"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["no", "no"], "ontop bread_1,countertop_1": ["yes", "yes"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,cabinet_1": ["no", "no"], "ontop bread_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["yes", "yes"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,cabinet_1": ["no", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["yes", "yes"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,cabinet_1": ["no", "no"], "ontop carrot_2,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["no", "yes"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,cabinet_1": ["no", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,cabinet_1": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["yes", "yes"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,cabinet_1": ["yes", "no"], "ontop apple_2,electric_refrigerator_1": ["no", "no"], "inside bread_1,cabinet_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,cabinet_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_2,cabinet_1": ["no", "no"], "inside carrot_2,electric_refrigerator_1": ["no", "no"], "inside carrot_3,cabinet_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_2,cabinet_1": ["no", "no"], "inside apple_2,electric_refrigerator_1": ["no", "no"], "nextto bread_1,countertop_1": ["yes", "no"], "nextto bread_1,carrot_1": ["no", "no"], "nextto bread_1,carrot_2": ["no", "no"], "nextto bread_1,carrot_3": ["yes", "no"], "nextto bread_1,apple_1": ["yes", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,cabinet_1": ["no", "no"], "nextto bread_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,bread_1": ["yes", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_2": ["yes", "no"], "nextto countertop_1,carrot_3": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_1,bread_1": ["yes", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,carrot_2": ["no", "no"], "nextto carrot_1,carrot_3": ["yes", "no"], "nextto carrot_1,apple_1": ["no", "no"], "nextto carrot_1,apple_2": ["no", "yes"], "nextto carrot_1,cabinet_1": ["yes", "no"], "nextto carrot_1,electric_refrigerator_1": ["no", "no"], "nextto carrot_2,bread_1": ["no", "no"], "nextto carrot_2,countertop_1": ["yes", "no"], "nextto carrot_2,carrot_1": ["yes", "no"], "nextto carrot_2,carrot_3": ["no", "yes"], "nextto carrot_2,apple_1": ["no", "no"], "nextto carrot_2,apple_2": ["yes", "no"], "nextto carrot_2,cabinet_1": ["yes", "no"], "nextto carrot_2,electric_refrigerator_1": ["yes", "no"], "nextto carrot_3,bread_1": ["no", "no"], "nextto carrot_3,countertop_1": ["yes", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["no", "yes"], "nextto carrot_3,apple_1": ["yes", "no"], "nextto carrot_3,apple_2": ["yes", "no"], "nextto carrot_3,cabinet_1": ["no", "no"], "nextto carrot_3,electric_refrigerator_1": ["no", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "no"], "nextto apple_1,carrot_3": ["no", "no"], "nextto apple_1,apple_2": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["no", "no"], "nextto apple_2,bread_1": ["no", "no"], "nextto apple_2,countertop_1": ["no", "no"], "nextto apple_2,carrot_1": ["no", "yes"], "nextto apple_2,carrot_2": ["yes", "no"], "nextto apple_2,carrot_3": ["yes", "no"], "nextto apple_2,apple_1": ["no", "no"], "nextto apple_2,cabinet_1": ["yes", "no"], "nextto apple_2,electric_refrigerator_1": ["no", "no"]}, "enum_metrics": {"accuracy": 0.7361111111111112, "yes_accuracy": 0.6111111111111112, "yes_correct": 11, "yes_total": 18, "no_accuracy": 0.753968253968254, "no_correct": 95, "no_total": 126, "predicates": {"reachable": {"accuracy": 0.7777777777777778, "yes_accuracy": 0.75, "yes_correct": 6, "yes_total": 8, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 7, "no_total": 7}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 2, "no_total": 2}, "ontop": {"accuracy": 0.9464285714285714, "yes_accuracy": 0.8333333333333334, "yes_correct": 5, "yes_total": 6, "no_accuracy": 0.96, "no_correct": 48, "no_total": 50}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}, "nextto": {"accuracy": 0.4107142857142857, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 4, "no_accuracy": 0.4423076923076923, "no_correct": 23, "no_total": 52}}}, "step": 13, "actions": ["navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable cabinet_1": ["yes", "no"], "reachable electric_refrigerator_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.3333333333333333, "no_correct": 1, "no_total": 3, "predicates": {"reachable": {"accuracy": 0.5, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.0, "no_correct": 0, "no_total": 1}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}}}, "step": 15, "actions": ["navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable countertop_1": ["yes", "yes"], "reachable carrot_2": ["yes", "yes"], "reachable apple_1": ["no", "yes"], "reachable cabinet_1": ["yes", "yes"], "reachable electric_refrigerator_1": ["yes", "yes"], "holding countertop_1": ["no", "no"], "holding carrot_2": ["yes", "no"], "holding apple_1": ["yes", "yes"], "open cabinet_1": ["no", "no"], "open electric_refrigerator_1": ["yes", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,cabinet_1": ["yes", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_2,countertop_1": ["yes", "yes"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,cabinet_1": ["yes", "no"], "ontop carrot_2,electric_refrigerator_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,cabinet_1": ["yes", "no"], "ontop apple_1,electric_refrigerator_1": ["yes", "no"], "inside countertop_1,cabinet_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside carrot_2,cabinet_1": ["no", "no"], "inside carrot_2,electric_refrigerator_1": ["no", "no"], "inside apple_1,cabinet_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "nextto countertop_1,carrot_2": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,cabinet_1": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_2,countertop_1": ["yes", "no"], "nextto carrot_2,apple_1": ["yes", "no"], "nextto carrot_2,cabinet_1": ["yes", "no"], "nextto carrot_2,electric_refrigerator_1": ["yes", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,carrot_2": ["no", "no"], "nextto apple_1,cabinet_1": ["yes", "no"], "nextto apple_1,electric_refrigerator_1": ["yes", "yes"]}, "enum_metrics": {"accuracy": 0.55, "yes_accuracy": 0.875, "yes_correct": 7, "yes_total": 8, "no_accuracy": 0.46875, "no_correct": 15, "no_total": 32, "predicates": {"reachable": {"accuracy": 0.8, "yes_accuracy": 0.8, "yes_correct": 4, "yes_total": 5, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "holding": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "open": {"accuracy": 0.5, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.5, "no_correct": 1, "no_total": 2}, "ontop": {"accuracy": 0.5833333333333334, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.5454545454545454, "no_correct": 6, "no_total": 11}, "inside": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 6, "no_total": 6}, "nextto": {"accuracy": 0.16666666666666666, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.09090909090909091, "no_correct": 1, "no_total": 11}}}, "step": 19, "actions": ["place-inside(apple_1, electric_refrigerator_1)"]}], "remaining_actions": []}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Pomaria_1_int_0": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable apple_1": ["yes", 1.5891162494694672e-13, 0.9999999999998411, "The image shows a robotic arm (agent) reaching towards the table, with various objects on the table, including an apple labeled \"apple_1.\" The apple_1 is located on the right side of the table, near the orange and other objects. The robotic arm appears to be extended towards the apple_1, suggesting it is within reach. Since the arm is close to the apple_1 and appears to be reaching for it, it is likely that the apple_1 is within the agent's reach.", false, "<explanation>\nThe image shows a robotic arm (agent) reaching towards the table, with various objects on the table, including an apple labeled \"apple_1.\" The apple_1 is located on the right side of the table, near the orange and other objects. The robotic arm appears to be extended towards the apple_1, suggesting it is within reach. Since the arm is close to the apple_1 and appears to be reaching for it, it is likely that the apple_1 is within the agent's reach.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable apple_1": ["yes", 2.9153056553708956e-15, 0.9999999999999971, "The image shows a robotic arm (agent) extending towards the table, with various objects on the table, including an apple labeled \"apple_1.\" The apple_1 is located on the right side of the table, near the orange and other objects. The robotic arm appears to be reaching towards the center of the table, but it is not clear if it is close enough to reach the apple_1 specifically. Since the apple_1 is on the right side of the table and the robotic arm is extending from the top right, it is likely within reach, but not definitively confirmed from this angle.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the table, with various objects on the table, including an apple labeled \"apple_1.\" The apple_1 is located on the right side of the table, near the orange and other objects. The robotic arm appears to be reaching towards the center of the table, but it is not clear if it is close enough to reach the apple_1 specifically. Since the apple_1 is on the right side of the table and the robotic arm is extending from the top right, it is likely within reach, but not definitively confirmed from this angle.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable electric_refrigerator_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 1.1718813267579234e-08, 0.9999999882811867, "The image shows a robotic arm (agent) extending towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is reaching towards it, indicating that it is within reach. Since the arm is actively extending towards the refrigerator, it suggests that the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is reaching towards it, indicating that it is within reach. Since the arm is actively extending towards the refrigerator, it suggests that the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_1": ["yes", 2.1427065409411928e-17, 1.0, "The image shows a robotic arm (agent) extending towards a wall with objects attached to it. The objects include a label indicating \"apple_1\" and \"apple_2\" in red text. The apple_1 appears to be located on the wall, near the robotic arm. Given the position of the robotic arm and the proximity of the apple_1 to the arm's reach, it seems that the apple_1 is within the arm's reach or very close to it. Therefore, the apple_1 is likely in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards a wall with objects attached to it. The objects include a label indicating \"apple_1\" and \"apple_2\" in red text. The apple_1 appears to be located on the wall, near the robotic arm. Given the position of the robotic arm and the proximity of the apple_1 to the arm's reach, it seems that the apple_1 is within the arm's reach or very close to it. Therefore, the apple_1 is likely in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable apple_2": ["yes", 4.884387092407902e-14, 0.9999999999999512, "The image shows a robotic arm (agent) near a refrigerator, with some objects and text labels. The label \"apple_2\" is visible in red text, indicating the location of the apple. The apple appears to be on the refrigerator door, close to the robotic arm. Given the proximity of the robotic arm to the apple and the typical reach of such an arm in a household simulator, it is likely within reach. Therefore, the apple_2 is probably in reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) near a refrigerator, with some objects and text labels. The label \"apple_2\" is visible in red text, indicating the location of the apple. The apple appears to be on the refrigerator door, close to the robotic arm. Given the proximity of the robotic arm to the apple and the typical reach of such an arm in a household simulator, it is likely within reach. Therefore, the apple_2 is probably in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable orange_1": {"before": true, "after": false}, "reachable table_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 7.609115244282097e-08, 0.9999999239088475, "The image shows a robotic arm (agent) extending towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is reaching towards it. Given the proximity and the extension of the robotic arm, it is reasonable to conclude that the refrigerator is within reach of the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards an object, which appears to be an electric refrigerator. The refrigerator is positioned close to the robotic arm, and the arm is reaching towards it. Given the proximity and the extension of the robotic arm, it is reasonable to conclude that the refrigerator is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["no", 0.9999999971079894, 2.8920106433834046e-09, "The image shows a robotic arm near a refrigerator, but the refrigerator door is not visible as being open or closed. The perspective and angle do not clearly reveal the state of the refrigerator door. Therefore, based on the available visual information, I cannot determine if the electric_refrigerator_1 is open.", true, "<explanation>\nThe image shows a robotic arm near a refrigerator, but the refrigerator door is not visible as being open or closed. The perspective and angle do not clearly reveal the state of the refrigerator door. Therefore, based on the available visual information, I cannot determine if the electric_refrigerator_1 is open.\n</explanation>\n<answer>\nNo\n</answer>", true], "holding apple_1": ["no", 0.9999999974830954, 2.516904551339193e-09, "The image shows a robotic arm, which is the agent, extending towards a surface. There is a red label indicating \"apple_1\" nearby, but the robotic arm does not appear to be holding or grasping any object, including the apple. Since the arm is extended but not gripping anything, the agent is not holding the apple_1.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, extending towards a surface. There is a red label indicating \"apple_1\" nearby, but the robotic arm does not appear to be holding or grasping any object, including the apple. Since the arm is extended but not gripping anything, the agent is not holding the apple_1.\n</explanation>\n<answer>\nNo\n</answer>", true], "holding apple_2": ["yes", 1.5574871559310993e-09, 0.9999999984425129, "The image shows a robotic arm, which is the agent, holding an object. The object appears to be an apple, and there is a label \"apple_2\" in red text near the object. Since the label \"apple_2\" is close to the object being held by the robotic arm, it suggests that the agent is holding the apple labeled \"apple_2\". Therefore, the agent is indeed holding the apple_2.", false, "<explanation>\nThe image shows a robotic arm, which is the agent, holding an object. The object appears to be an apple, and there is a label \"apple_2\" in red text near the object. Since the label \"apple_2\" is close to the object being held by the robotic arm, it suggests that the agent is holding the apple labeled \"apple_2\". Therefore, the agent is indeed holding the apple_2.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": null}], "replans": [{"enum_results": {"reachable bread_1": ["no", "no"], "reachable countertop_1": ["yes", "no"], "reachable flour_1": ["no", "no"], "reachable milk_1": ["no", "yes"], "reachable chair_1": ["yes", "yes"], "reachable meat_1": ["no", "yes"], "reachable table_1": ["yes", "yes"], "reachable cheese_1": ["yes", "yes"], "reachable yogurt_1": ["yes", "yes"], "reachable soup_1": ["no", "yes"], "reachable carrot_1": ["yes", "no"], "reachable carrot_2": ["yes", "no"], "reachable carrot_3": ["yes", "no"], "reachable apple_1": ["no", "no"], "reachable apple_2": ["yes", "no"], "reachable orange_1": ["yes", "yes"], "reachable orange_3": ["yes", "yes"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding flour_1": ["no", "no"], "holding meat_1": ["no", "no"], "holding cheese_1": ["no", "no"], "holding yogurt_1": ["no", "no"], "holding soup_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "holding orange_1": ["no", "no"], "holding orange_3": ["no", "no"], "ontop bread_1,countertop_1": ["no", "yes"], "ontop bread_1,flour_1": ["yes", "no"], "ontop bread_1,milk_1": ["no", "no"], "ontop bread_1,chair_1": ["no", "no"], "ontop bread_1,meat_1": ["yes", "no"], "ontop bread_1,table_1": ["yes", "no"], "ontop bread_1,cheese_1": ["no", "no"], "ontop bread_1,yogurt_1": ["yes", "no"], "ontop bread_1,soup_1": ["no", "no"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,orange_1": ["no", "no"], "ontop bread_1,orange_3": ["yes", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,flour_1": ["no", "no"], "ontop countertop_1,milk_1": ["no", "no"], "ontop countertop_1,chair_1": ["no", "no"], "ontop countertop_1,meat_1": ["no", "no"], "ontop countertop_1,table_1": ["no", "no"], "ontop countertop_1,cheese_1": ["no", "no"], "ontop countertop_1,yogurt_1": ["no", "no"], "ontop countertop_1,soup_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,orange_1": ["no", "no"], "ontop countertop_1,orange_3": ["no", "no"], "ontop flour_1,bread_1": ["yes", "no"], "ontop flour_1,countertop_1": ["no", "no"], "ontop flour_1,milk_1": ["no", "no"], "ontop flour_1,chair_1": ["no", "no"], "ontop flour_1,meat_1": ["yes", "no"], "ontop flour_1,table_1": ["yes", "no"], "ontop flour_1,cheese_1": ["no", "no"], "ontop flour_1,yogurt_1": ["no", "no"], "ontop flour_1,soup_1": ["no", "no"], "ontop flour_1,carrot_1": ["no", "no"], "ontop flour_1,carrot_2": ["no", "no"], "ontop flour_1,carrot_3": ["no", "no"], "ontop flour_1,apple_1": ["no", "no"], "ontop flour_1,apple_2": ["no", "no"], "ontop flour_1,orange_1": ["yes", "no"], "ontop flour_1,orange_3": ["yes", "no"], "ontop meat_1,bread_1": ["no", "no"], "ontop meat_1,countertop_1": ["no", "no"], "ontop meat_1,flour_1": ["no", "no"], "ontop meat_1,milk_1": ["no", "no"], "ontop meat_1,chair_1": ["no", "no"], "ontop meat_1,table_1": ["yes", "yes"], "ontop meat_1,cheese_1": ["no", "no"], "ontop meat_1,yogurt_1": ["yes", "no"], "ontop meat_1,soup_1": ["no", "no"], "ontop meat_1,carrot_1": ["no", "no"], "ontop meat_1,carrot_2": ["no", "no"], "ontop meat_1,carrot_3": ["no", "no"], "ontop meat_1,apple_1": ["no", "no"], "ontop meat_1,apple_2": ["no", "no"], "ontop meat_1,orange_1": ["no", "no"], "ontop meat_1,orange_3": ["no", "no"], "ontop cheese_1,bread_1": ["no", "no"], "ontop cheese_1,countertop_1": ["no", "no"], "ontop cheese_1,flour_1": ["yes", "no"], "ontop cheese_1,milk_1": ["yes", "no"], "ontop cheese_1,chair_1": ["no", "no"], "ontop cheese_1,meat_1": ["yes", "no"], "ontop cheese_1,table_1": ["yes", "yes"], "ontop cheese_1,yogurt_1": ["yes", "no"], "ontop cheese_1,soup_1": ["no", "no"], "ontop cheese_1,carrot_1": ["no", "no"], "ontop cheese_1,carrot_2": ["no", "no"], "ontop cheese_1,carrot_3": ["no", "no"], "ontop cheese_1,apple_1": ["no", "no"], "ontop cheese_1,apple_2": ["no", "no"], "ontop cheese_1,orange_1": ["no", "no"], "ontop cheese_1,orange_3": ["yes", "no"], "ontop yogurt_1,bread_1": ["no", "no"], "ontop yogurt_1,countertop_1": ["no", "no"], "ontop yogurt_1,flour_1": ["no", "no"], "ontop yogurt_1,milk_1": ["yes", "no"], "ontop yogurt_1,chair_1": ["no", "no"], "ontop yogurt_1,meat_1": ["no", "no"], "ontop yogurt_1,table_1": ["yes", "yes"], "ontop yogurt_1,cheese_1": ["no", "no"], "ontop yogurt_1,soup_1": ["no", "no"], "ontop yogurt_1,carrot_1": ["no", "no"], "ontop yogurt_1,carrot_2": ["no", "no"], "ontop yogurt_1,carrot_3": ["no", "no"], "ontop yogurt_1,apple_1": ["no", "no"], "ontop yogurt_1,apple_2": ["yes", "no"], "ontop yogurt_1,orange_1": ["no", "no"], "ontop yogurt_1,orange_3": ["yes", "no"], "ontop soup_1,bread_1": ["yes", "no"], "ontop soup_1,countertop_1": ["no", "no"], "ontop soup_1,flour_1": ["no", "no"], "ontop soup_1,milk_1": ["no", "no"], "ontop soup_1,chair_1": ["no", "no"], "ontop soup_1,meat_1": ["no", "no"], "ontop soup_1,table_1": ["yes", "yes"], "ontop soup_1,cheese_1": ["yes", "no"], "ontop soup_1,yogurt_1": ["no", "no"], "ontop soup_1,carrot_1": ["no", "no"], "ontop soup_1,carrot_2": ["yes", "no"], "ontop soup_1,carrot_3": ["no", "no"], "ontop soup_1,apple_1": ["no", "no"], "ontop soup_1,apple_2": ["no", "no"], "ontop soup_1,orange_1": ["no", "no"], "ontop soup_1,orange_3": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["no", "yes"], "ontop carrot_1,flour_1": ["no", "no"], "ontop carrot_1,milk_1": ["no", "no"], "ontop carrot_1,chair_1": ["no", "no"], "ontop carrot_1,meat_1": ["no", "no"], "ontop carrot_1,table_1": ["yes", "no"], "ontop carrot_1,cheese_1": ["yes", "no"], "ontop carrot_1,yogurt_1": ["no", "no"], "ontop carrot_1,soup_1": ["no", "no"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,orange_1": ["no", "no"], "ontop carrot_1,orange_3": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["no", "yes"], "ontop carrot_2,flour_1": ["no", "no"], "ontop carrot_2,milk_1": ["no", "no"], "ontop carrot_2,chair_1": ["no", "no"], "ontop carrot_2,meat_1": ["no", "no"], "ontop carrot_2,table_1": ["yes", "no"], "ontop carrot_2,cheese_1": ["no", "no"], "ontop carrot_2,yogurt_1": ["no", "no"], "ontop carrot_2,soup_1": ["no", "no"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,orange_1": ["yes", "no"], "ontop carrot_2,orange_3": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["no", "yes"], "ontop carrot_3,flour_1": ["no", "no"], "ontop carrot_3,milk_1": ["no", "no"], "ontop carrot_3,chair_1": ["no", "no"], "ontop carrot_3,meat_1": ["no", "no"], "ontop carrot_3,table_1": ["yes", "no"], "ontop carrot_3,cheese_1": ["no", "no"], "ontop carrot_3,yogurt_1": ["no", "no"], "ontop carrot_3,soup_1": ["no", "no"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,orange_1": ["no", "no"], "ontop carrot_3,orange_3": ["yes", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,flour_1": ["no", "no"], "ontop apple_1,milk_1": ["no", "no"], "ontop apple_1,chair_1": ["no", "no"], "ontop apple_1,meat_1": ["no", "no"], "ontop apple_1,table_1": ["yes", "no"], "ontop apple_1,cheese_1": ["no", "no"], "ontop apple_1,yogurt_1": ["no", "no"], "ontop apple_1,soup_1": ["no", "no"], "ontop apple_1,carrot_1": ["yes", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,orange_1": ["no", "no"], "ontop apple_1,orange_3": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["no", "yes"], "ontop apple_2,flour_1": ["no", "no"], "ontop apple_2,milk_1": ["no", "no"], "ontop apple_2,chair_1": ["no", "no"], "ontop apple_2,meat_1": ["no", "no"], "ontop apple_2,table_1": ["no", "no"], "ontop apple_2,cheese_1": ["no", "no"], "ontop apple_2,yogurt_1": ["no", "no"], "ontop apple_2,soup_1": ["no", "no"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,orange_1": ["no", "no"], "ontop apple_2,orange_3": ["no", "no"], "ontop orange_1,bread_1": ["no", "no"], "ontop orange_1,countertop_1": ["no", "no"], "ontop orange_1,flour_1": ["no", "no"], "ontop orange_1,milk_1": ["no", "no"], "ontop orange_1,chair_1": ["no", "no"], "ontop orange_1,meat_1": ["no", "no"], "ontop orange_1,table_1": ["yes", "yes"], "ontop orange_1,cheese_1": ["no", "no"], "ontop orange_1,yogurt_1": ["no", "no"], "ontop orange_1,soup_1": ["no", "no"], "ontop orange_1,carrot_1": ["no", "no"], "ontop orange_1,carrot_2": ["yes", "no"], "ontop orange_1,carrot_3": ["yes", "no"], "ontop orange_1,apple_1": ["no", "no"], "ontop orange_1,apple_2": ["no", "no"], "ontop orange_1,orange_3": ["no", "no"], "ontop orange_3,bread_1": ["yes", "no"], "ontop orange_3,countertop_1": ["no", "no"], "ontop orange_3,flour_1": ["no", "no"], "ontop orange_3,milk_1": ["no", "no"], "ontop orange_3,chair_1": ["no", "no"], "ontop orange_3,meat_1": ["yes", "no"], "ontop orange_3,table_1": ["yes", "yes"], "ontop orange_3,cheese_1": ["no", "no"], "ontop orange_3,yogurt_1": ["no", "no"], "ontop orange_3,soup_1": ["no", "no"], "ontop orange_3,carrot_1": ["yes", "no"], "ontop orange_3,carrot_2": ["yes", "no"], "ontop orange_3,carrot_3": ["yes", "no"], "ontop orange_3,apple_1": ["no", "no"], "ontop orange_3,apple_2": ["no", "no"], "ontop orange_3,orange_1": ["yes", "no"], "nextto bread_1,countertop_1": ["no", "no"], "nextto bread_1,flour_1": ["no", "no"], "nextto bread_1,milk_1": ["yes", "no"], "nextto bread_1,chair_1": ["no", "no"], "nextto bread_1,meat_1": ["no", "no"], "nextto bread_1,table_1": ["yes", "no"], "nextto bread_1,cheese_1": ["yes", "no"], "nextto bread_1,yogurt_1": ["yes", "no"], "nextto bread_1,soup_1": ["no", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["yes", "yes"], "nextto bread_1,carrot_3": ["yes", "yes"], "nextto bread_1,apple_1": ["yes", "no"], "nextto bread_1,apple_2": ["no", "no"], "nextto bread_1,orange_1": ["yes", "no"], "nextto bread_1,orange_3": ["yes", "no"], "nextto countertop_1,bread_1": ["no", "no"], "nextto countertop_1,flour_1": ["no", "no"], "nextto countertop_1,milk_1": ["no", "no"], "nextto countertop_1,chair_1": ["no", "no"], "nextto countertop_1,meat_1": ["no", "no"], "nextto countertop_1,table_1": ["no", "no"], "nextto countertop_1,cheese_1": ["no", "no"], "nextto countertop_1,yogurt_1": ["no", "no"], "nextto countertop_1,soup_1": ["no", "no"], "nextto countertop_1,carrot_1": ["no", "no"], "nextto countertop_1,carrot_2": ["yes", "no"], "nextto countertop_1,carrot_3": ["no", "no"], "nextto countertop_1,apple_1": ["no", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,orange_1": ["no", "no"], "nextto countertop_1,orange_3": ["no", "no"], "nextto flour_1,bread_1": ["yes", "no"], "nextto flour_1,countertop_1": ["no", "no"], "nextto flour_1,milk_1": ["yes", "no"], "nextto flour_1,chair_1": ["no", "no"], "nextto flour_1,meat_1": ["yes", "no"], "nextto flour_1,table_1": ["yes", "no"], "nextto flour_1,cheese_1": ["yes", "no"], "nextto flour_1,yogurt_1": ["no", "no"], "nextto flour_1,soup_1": ["yes", "no"], "nextto flour_1,carrot_1": ["no", "no"], "nextto flour_1,carrot_2": ["no", "no"], "nextto flour_1,carrot_3": ["yes", "no"], "nextto flour_1,apple_1": ["no", "no"], "nextto flour_1,apple_2": ["no", "no"], "nextto flour_1,orange_1": ["yes", "no"], "nextto flour_1,orange_3": ["yes", "no"], "nextto meat_1,bread_1": ["yes", "no"], "nextto meat_1,countertop_1": ["no", "no"], "nextto meat_1,flour_1": ["yes", "no"], "nextto meat_1,milk_1": ["no", "no"], "nextto meat_1,chair_1": ["no", "no"], "nextto meat_1,table_1": ["yes", "no"], "nextto meat_1,cheese_1": ["no", "no"], "nextto meat_1,yogurt_1": ["no", "no"], "nextto meat_1,soup_1": ["no", "no"], "nextto meat_1,carrot_1": ["no", "no"], "nextto meat_1,carrot_2": ["yes", "no"], "nextto meat_1,carrot_3": ["yes", "no"], "nextto meat_1,apple_1": ["no", "no"], "nextto meat_1,apple_2": ["no", "no"], "nextto meat_1,orange_1": ["yes", "no"], "nextto meat_1,orange_3": ["yes", "yes"], "nextto cheese_1,bread_1": ["yes", "no"], "nextto cheese_1,countertop_1": ["no", "no"], "nextto cheese_1,flour_1": ["no", "no"], "nextto cheese_1,milk_1": ["yes", "no"], "nextto cheese_1,chair_1": ["no", "no"], "nextto cheese_1,meat_1": ["no", "no"], "nextto cheese_1,table_1": ["yes", "no"], "nextto cheese_1,yogurt_1": ["no", "no"], "nextto cheese_1,soup_1": ["no", "yes"], "nextto cheese_1,carrot_1": ["yes", "no"], "nextto cheese_1,carrot_2": ["yes", "no"], "nextto cheese_1,carrot_3": ["yes", "no"], "nextto cheese_1,apple_1": ["no", "no"], "nextto cheese_1,apple_2": ["no", "no"], "nextto cheese_1,orange_1": ["no", "yes"], "nextto cheese_1,orange_3": ["no", "no"], "nextto yogurt_1,bread_1": ["yes", "no"], "nextto yogurt_1,countertop_1": ["no", "no"], "nextto yogurt_1,flour_1": ["yes", "no"], "nextto yogurt_1,milk_1": ["yes", "no"], "nextto yogurt_1,chair_1": ["no", "no"], "nextto yogurt_1,meat_1": ["no", "no"], "nextto yogurt_1,table_1": ["no", "no"], "nextto yogurt_1,cheese_1": ["yes", "no"], "nextto yogurt_1,soup_1": ["no", "no"], "nextto yogurt_1,carrot_1": ["yes", "no"], "nextto yogurt_1,carrot_2": ["no", "no"], "nextto yogurt_1,carrot_3": ["yes", "no"], "nextto yogurt_1,apple_1": ["yes", "no"], "nextto yogurt_1,apple_2": ["yes", "no"], "nextto yogurt_1,orange_1": ["no", "no"], "nextto yogurt_1,orange_3": ["yes", "no"], "nextto soup_1,bread_1": ["yes", "no"], "nextto soup_1,countertop_1": ["no", "no"], "nextto soup_1,flour_1": ["no", "no"], "nextto soup_1,milk_1": ["no", "no"], "nextto soup_1,chair_1": ["no", "no"], "nextto soup_1,meat_1": ["no", "no"], "nextto soup_1,table_1": ["yes", "no"], "nextto soup_1,cheese_1": ["yes", "yes"], "nextto soup_1,yogurt_1": ["no", "no"], "nextto soup_1,carrot_1": ["yes", "no"], "nextto soup_1,carrot_2": ["no", "no"], "nextto soup_1,carrot_3": ["no", "no"], "nextto soup_1,apple_1": ["no", "no"], "nextto soup_1,apple_2": ["no", "no"], "nextto soup_1,orange_1": ["yes", "no"], "nextto soup_1,orange_3": ["yes", "no"], "nextto carrot_1,bread_1": ["yes", "no"], "nextto carrot_1,countertop_1": ["no", "no"], "nextto carrot_1,flour_1": ["no", "no"], "nextto carrot_1,milk_1": ["yes", "no"], "nextto carrot_1,chair_1": ["no", "no"], "nextto carrot_1,meat_1": ["no", "no"], "nextto carrot_1,table_1": ["yes", "no"], "nextto carrot_1,cheese_1": ["yes", "no"], "nextto carrot_1,yogurt_1": ["no", "no"], "nextto carrot_1,soup_1": ["no", "no"], "nextto carrot_1,carrot_2": ["yes", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,apple_1": ["no", "no"], "nextto carrot_1,apple_2": ["no", "no"], "nextto carrot_1,orange_1": ["no", "no"], "nextto carrot_1,orange_3": ["yes", "no"], "nextto carrot_2,bread_1": ["yes", "yes"], "nextto carrot_2,countertop_1": ["no", "no"], "nextto carrot_2,flour_1": ["no", "no"], "nextto carrot_2,milk_1": ["no", "no"], "nextto carrot_2,chair_1": ["no", "no"], "nextto carrot_2,meat_1": ["no", "no"], "nextto carrot_2,table_1": ["yes", "no"], "nextto carrot_2,cheese_1": ["no", "no"], "nextto carrot_2,yogurt_1": ["no", "no"], "nextto carrot_2,soup_1": ["no", "no"], "nextto carrot_2,carrot_1": ["yes", "no"], "nextto carrot_2,carrot_3": ["yes", "yes"], "nextto carrot_2,apple_1": ["no", "yes"], "nextto carrot_2,apple_2": ["no", "no"], "nextto carrot_2,orange_1": ["no", "no"], "nextto carrot_2,orange_3": ["yes", "no"], "nextto carrot_3,bread_1": ["yes", "yes"], "nextto carrot_3,countertop_1": ["no", "no"], "nextto carrot_3,flour_1": ["no", "no"], "nextto carrot_3,milk_1": ["no", "no"], "nextto carrot_3,chair_1": ["no", "no"], "nextto carrot_3,meat_1": ["no", "no"], "nextto carrot_3,table_1": ["yes", "no"], "nextto carrot_3,cheese_1": ["no", "no"], "nextto carrot_3,yogurt_1": ["yes", "no"], "nextto carrot_3,soup_1": ["no", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["no", "yes"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["no", "no"], "nextto carrot_3,orange_1": ["no", "no"], "nextto carrot_3,orange_3": ["no", "no"], "nextto apple_1,bread_1": ["yes", "no"], "nextto apple_1,countertop_1": ["no", "no"], "nextto apple_1,flour_1": ["no", "no"], "nextto apple_1,milk_1": ["no", "no"], "nextto apple_1,chair_1": ["no", "no"], "nextto apple_1,meat_1": ["no", "no"], "nextto apple_1,table_1": ["yes", "no"], "nextto apple_1,cheese_1": ["no", "no"], "nextto apple_1,yogurt_1": ["no", "no"], "nextto apple_1,soup_1": ["no", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "yes"], "nextto apple_1,carrot_3": ["yes", "no"], "nextto apple_1,apple_2": ["no", "yes"], "nextto apple_1,orange_1": ["yes", "no"], "nextto apple_1,orange_3": ["no", "no"], "nextto apple_2,bread_1": ["no", "no"], "nextto apple_2,countertop_1": ["no", "no"], "nextto apple_2,flour_1": ["no", "no"], "nextto apple_2,milk_1": ["no", "no"], "nextto apple_2,chair_1": ["no", "no"], "nextto apple_2,meat_1": ["no", "no"], "nextto apple_2,table_1": ["yes", "no"], "nextto apple_2,cheese_1": ["yes", "no"], "nextto apple_2,yogurt_1": ["no", "no"], "nextto apple_2,soup_1": ["no", "no"], "nextto apple_2,carrot_1": ["yes", "no"], "nextto apple_2,carrot_2": ["no", "no"], "nextto apple_2,carrot_3": ["no", "no"], "nextto apple_2,apple_1": ["no", "yes"], "nextto apple_2,orange_1": ["no", "no"], "nextto apple_2,orange_3": ["no", "no"], "nextto orange_1,bread_1": ["no", "no"], "nextto orange_1,countertop_1": ["no", "no"], "nextto orange_1,flour_1": ["no", "no"], "nextto orange_1,milk_1": ["yes", "no"], "nextto orange_1,chair_1": ["no", "no"], "nextto orange_1,meat_1": ["no", "no"], "nextto orange_1,table_1": ["yes", "no"], "nextto orange_1,cheese_1": ["no", "yes"], "nextto orange_1,yogurt_1": ["yes", "no"], "nextto orange_1,soup_1": ["no", "no"], "nextto orange_1,carrot_1": ["no", "no"], "nextto orange_1,carrot_2": ["yes", "no"], "nextto orange_1,carrot_3": ["yes", "no"], "nextto orange_1,apple_1": ["no", "no"], "nextto orange_1,apple_2": ["no", "no"], "nextto orange_1,orange_3": ["yes", "no"], "nextto orange_3,bread_1": ["yes", "no"], "nextto orange_3,countertop_1": ["no", "no"], "nextto orange_3,flour_1": ["no", "no"], "nextto orange_3,milk_1": ["no", "no"], "nextto orange_3,chair_1": ["no", "yes"], "nextto orange_3,meat_1": ["yes", "yes"], "nextto orange_3,table_1": ["yes", "no"], "nextto orange_3,cheese_1": ["no", "no"], "nextto orange_3,yogurt_1": ["yes", "no"], "nextto orange_3,soup_1": ["no", "no"], "nextto orange_3,carrot_1": ["yes", "no"], "nextto orange_3,carrot_2": ["yes", "no"], "nextto orange_3,carrot_3": ["yes", "no"], "nextto orange_3,apple_1": ["no", "no"], "nextto orange_3,apple_2": ["no", "no"], "nextto orange_3,orange_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7139874739039666, "yes_accuracy": 0.5263157894736842, "yes_correct": 20, "yes_total": 38, "no_accuracy": 0.7301587301587301, "no_correct": 322, "no_total": 441, "predicates": {"reachable": {"accuracy": 0.5294117647058824, "yes_accuracy": 0.6666666666666666, "yes_correct": 6, "yes_total": 9, "no_accuracy": 0.375, "no_correct": 3, "no_total": 8}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}, "ontop": {"accuracy": 0.8035714285714286, "yes_accuracy": 0.5, "yes_correct": 6, "yes_total": 12, "no_accuracy": 0.8207547169811321, "no_correct": 174, "no_total": 212}, "nextto": {"accuracy": 0.6205357142857143, "yes_accuracy": 0.47058823529411764, "yes_correct": 8, "yes_total": 17, "no_accuracy": 0.6328502415458938, "no_correct": 131, "no_total": 207}}}, "step": 1, "actions": ["navigate-to(apple_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["no", "no"], "reachable countertop_1": ["yes", "no"], "reachable flour_1": ["yes", "no"], "reachable milk_1": ["yes", "yes"], "reachable chair_1": ["yes", "yes"], "reachable meat_1": ["no", "yes"], "reachable table_1": ["yes", "yes"], "reachable cheese_1": ["yes", "yes"], "reachable yogurt_1": ["yes", "yes"], "reachable soup_1": ["yes", "yes"], "reachable carrot_1": ["yes", "no"], "reachable carrot_2": ["yes", "no"], "reachable carrot_3": ["no", "no"], "reachable apple_1": ["yes", "no"], "reachable apple_2": ["yes", "no"], "reachable orange_1": ["yes", "yes"], "reachable orange_3": ["no", "yes"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding flour_1": ["no", "no"], "holding meat_1": ["no", "no"], "holding cheese_1": ["no", "no"], "holding yogurt_1": ["no", "no"], "holding soup_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "holding orange_1": ["no", "no"], "holding orange_3": ["no", "no"], "ontop bread_1,countertop_1": ["no", "yes"], "ontop bread_1,flour_1": ["yes", "no"], "ontop bread_1,milk_1": ["yes", "no"], "ontop bread_1,chair_1": ["no", "no"], "ontop bread_1,meat_1": ["yes", "no"], "ontop bread_1,table_1": ["yes", "no"], "ontop bread_1,cheese_1": ["yes", "no"], "ontop bread_1,yogurt_1": ["no", "no"], "ontop bread_1,soup_1": ["yes", "no"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,orange_1": ["no", "no"], "ontop bread_1,orange_3": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,flour_1": ["no", "no"], "ontop countertop_1,milk_1": ["no", "no"], "ontop countertop_1,chair_1": ["no", "no"], "ontop countertop_1,meat_1": ["no", "no"], "ontop countertop_1,table_1": ["no", "no"], "ontop countertop_1,cheese_1": ["no", "no"], "ontop countertop_1,yogurt_1": ["no", "no"], "ontop countertop_1,soup_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,orange_1": ["no", "no"], "ontop countertop_1,orange_3": ["no", "no"], "ontop flour_1,bread_1": ["no", "no"], "ontop flour_1,countertop_1": ["no", "no"], "ontop flour_1,milk_1": ["no", "no"], "ontop flour_1,chair_1": ["no", "no"], "ontop flour_1,meat_1": ["no", "no"], "ontop flour_1,table_1": ["no", "no"], "ontop flour_1,cheese_1": ["yes", "no"], "ontop flour_1,yogurt_1": ["no", "no"], "ontop flour_1,soup_1": ["no", "no"], "ontop flour_1,carrot_1": ["no", "no"], "ontop flour_1,carrot_2": ["no", "no"], "ontop flour_1,carrot_3": ["no", "no"], "ontop flour_1,apple_1": ["no", "no"], "ontop flour_1,apple_2": ["no", "no"], "ontop flour_1,orange_1": ["no", "no"], "ontop flour_1,orange_3": ["no", "no"], "ontop meat_1,bread_1": ["no", "no"], "ontop meat_1,countertop_1": ["no", "no"], "ontop meat_1,flour_1": ["no", "no"], "ontop meat_1,milk_1": ["no", "no"], "ontop meat_1,chair_1": ["no", "no"], "ontop meat_1,table_1": ["yes", "yes"], "ontop meat_1,cheese_1": ["no", "no"], "ontop meat_1,yogurt_1": ["no", "no"], "ontop meat_1,soup_1": ["no", "no"], "ontop meat_1,carrot_1": ["yes", "no"], "ontop meat_1,carrot_2": ["no", "no"], "ontop meat_1,carrot_3": ["no", "no"], "ontop meat_1,apple_1": ["no", "no"], "ontop meat_1,apple_2": ["no", "no"], "ontop meat_1,orange_1": ["no", "no"], "ontop meat_1,orange_3": ["no", "no"], "ontop cheese_1,bread_1": ["yes", "no"], "ontop cheese_1,countertop_1": ["no", "no"], "ontop cheese_1,flour_1": ["no", "no"], "ontop cheese_1,milk_1": ["yes", "no"], "ontop cheese_1,chair_1": ["no", "no"], "ontop cheese_1,meat_1": ["no", "no"], "ontop cheese_1,table_1": ["yes", "yes"], "ontop cheese_1,yogurt_1": ["no", "no"], "ontop cheese_1,soup_1": ["no", "no"], "ontop cheese_1,carrot_1": ["no", "no"], "ontop cheese_1,carrot_2": ["no", "no"], "ontop cheese_1,carrot_3": ["no", "no"], "ontop cheese_1,apple_1": ["no", "no"], "ontop cheese_1,apple_2": ["no", "no"], "ontop cheese_1,orange_1": ["no", "no"], "ontop cheese_1,orange_3": ["no", "no"], "ontop yogurt_1,bread_1": ["no", "no"], "ontop yogurt_1,countertop_1": ["no", "no"], "ontop yogurt_1,flour_1": ["no", "no"], "ontop yogurt_1,milk_1": ["no", "no"], "ontop yogurt_1,chair_1": ["no", "no"], "ontop yogurt_1,meat_1": ["yes", "no"], "ontop yogurt_1,table_1": ["yes", "yes"], "ontop yogurt_1,cheese_1": ["no", "no"], "ontop yogurt_1,soup_1": ["no", "no"], "ontop yogurt_1,carrot_1": ["no", "no"], "ontop yogurt_1,carrot_2": ["no", "no"], "ontop yogurt_1,carrot_3": ["no", "no"], "ontop yogurt_1,apple_1": ["no", "no"], "ontop yogurt_1,apple_2": ["yes", "no"], "ontop yogurt_1,orange_1": ["yes", "no"], "ontop yogurt_1,orange_3": ["yes", "no"], "ontop soup_1,bread_1": ["yes", "no"], "ontop soup_1,countertop_1": ["no", "no"], "ontop soup_1,flour_1": ["no", "no"], "ontop soup_1,milk_1": ["no", "no"], "ontop soup_1,chair_1": ["no", "no"], "ontop soup_1,meat_1": ["no", "no"], "ontop soup_1,table_1": ["no", "yes"], "ontop soup_1,cheese_1": ["no", "no"], "ontop soup_1,yogurt_1": ["no", "no"], "ontop soup_1,carrot_1": ["no", "no"], "ontop soup_1,carrot_2": ["no", "no"], "ontop soup_1,carrot_3": ["no", "no"], "ontop soup_1,apple_1": ["no", "no"], "ontop soup_1,apple_2": ["yes", "no"], "ontop soup_1,orange_1": ["no", "no"], "ontop soup_1,orange_3": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["no", "yes"], "ontop carrot_1,flour_1": ["no", "no"], "ontop carrot_1,milk_1": ["no", "no"], "ontop carrot_1,chair_1": ["no", "no"], "ontop carrot_1,meat_1": ["no", "no"], "ontop carrot_1,table_1": ["yes", "no"], "ontop carrot_1,cheese_1": ["no", "no"], "ontop carrot_1,yogurt_1": ["no", "no"], "ontop carrot_1,soup_1": ["no", "no"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,orange_1": ["no", "no"], "ontop carrot_1,orange_3": ["yes", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["no", "yes"], "ontop carrot_2,flour_1": ["no", "no"], "ontop carrot_2,milk_1": ["no", "no"], "ontop carrot_2,chair_1": ["no", "no"], "ontop carrot_2,meat_1": ["no", "no"], "ontop carrot_2,table_1": ["yes", "no"], "ontop carrot_2,cheese_1": ["no", "no"], "ontop carrot_2,yogurt_1": ["no", "no"], "ontop carrot_2,soup_1": ["no", "no"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,orange_1": ["no", "no"], "ontop carrot_2,orange_3": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["no", "yes"], "ontop carrot_3,flour_1": ["no", "no"], "ontop carrot_3,milk_1": ["no", "no"], "ontop carrot_3,chair_1": ["no", "no"], "ontop carrot_3,meat_1": ["no", "no"], "ontop carrot_3,table_1": ["yes", "no"], "ontop carrot_3,cheese_1": ["no", "no"], "ontop carrot_3,yogurt_1": ["no", "no"], "ontop carrot_3,soup_1": ["no", "no"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,orange_1": ["yes", "no"], "ontop carrot_3,orange_3": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,flour_1": ["no", "no"], "ontop apple_1,milk_1": ["no", "no"], "ontop apple_1,chair_1": ["no", "no"], "ontop apple_1,meat_1": ["no", "no"], "ontop apple_1,table_1": ["no", "no"], "ontop apple_1,cheese_1": ["no", "no"], "ontop apple_1,yogurt_1": ["no", "no"], "ontop apple_1,soup_1": ["no", "no"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,orange_1": ["no", "no"], "ontop apple_1,orange_3": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["no", "yes"], "ontop apple_2,flour_1": ["no", "no"], "ontop apple_2,milk_1": ["no", "no"], "ontop apple_2,chair_1": ["no", "no"], "ontop apple_2,meat_1": ["no", "no"], "ontop apple_2,table_1": ["no", "no"], "ontop apple_2,cheese_1": ["no", "no"], "ontop apple_2,yogurt_1": ["no", "no"], "ontop apple_2,soup_1": ["no", "no"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,orange_1": ["no", "no"], "ontop apple_2,orange_3": ["no", "no"], "ontop orange_1,bread_1": ["no", "no"], "ontop orange_1,countertop_1": ["no", "no"], "ontop orange_1,flour_1": ["no", "no"], "ontop orange_1,milk_1": ["no", "no"], "ontop orange_1,chair_1": ["no", "no"], "ontop orange_1,meat_1": ["no", "no"], "ontop orange_1,table_1": ["yes", "yes"], "ontop orange_1,cheese_1": ["no", "no"], "ontop orange_1,yogurt_1": ["no", "no"], "ontop orange_1,soup_1": ["no", "no"], "ontop orange_1,carrot_1": ["yes", "no"], "ontop orange_1,carrot_2": ["no", "no"], "ontop orange_1,carrot_3": ["yes", "no"], "ontop orange_1,apple_1": ["no", "no"], "ontop orange_1,apple_2": ["no", "no"], "ontop orange_1,orange_3": ["no", "no"], "ontop orange_3,bread_1": ["no", "no"], "ontop orange_3,countertop_1": ["no", "no"], "ontop orange_3,flour_1": ["no", "no"], "ontop orange_3,milk_1": ["no", "no"], "ontop orange_3,chair_1": ["no", "no"], "ontop orange_3,meat_1": ["no", "no"], "ontop orange_3,table_1": ["yes", "yes"], "ontop orange_3,cheese_1": ["no", "no"], "ontop orange_3,yogurt_1": ["no", "no"], "ontop orange_3,soup_1": ["no", "no"], "ontop orange_3,carrot_1": ["no", "no"], "ontop orange_3,carrot_2": ["yes", "no"], "ontop orange_3,carrot_3": ["yes", "no"], "ontop orange_3,apple_1": ["no", "no"], "ontop orange_3,apple_2": ["no", "no"], "ontop orange_3,orange_1": ["yes", "no"], "nextto bread_1,countertop_1": ["no", "no"], "nextto bread_1,flour_1": ["yes", "no"], "nextto bread_1,milk_1": ["yes", "no"], "nextto bread_1,chair_1": ["no", "no"], "nextto bread_1,meat_1": ["no", "no"], "nextto bread_1,table_1": ["no", "no"], "nextto bread_1,cheese_1": ["no", "no"], "nextto bread_1,yogurt_1": ["yes", "no"], "nextto bread_1,soup_1": ["no", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["yes", "yes"], "nextto bread_1,carrot_3": ["yes", "yes"], "nextto bread_1,apple_1": ["yes", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,orange_1": ["yes", "no"], "nextto bread_1,orange_3": ["yes", "no"], "nextto countertop_1,bread_1": ["no", "no"], "nextto countertop_1,flour_1": ["no", "no"], "nextto countertop_1,milk_1": ["no", "no"], "nextto countertop_1,chair_1": ["no", "no"], "nextto countertop_1,meat_1": ["no", "no"], "nextto countertop_1,table_1": ["no", "no"], "nextto countertop_1,cheese_1": ["no", "no"], "nextto countertop_1,yogurt_1": ["no", "no"], "nextto countertop_1,soup_1": ["no", "no"], "nextto countertop_1,carrot_1": ["no", "no"], "nextto countertop_1,carrot_2": ["no", "no"], "nextto countertop_1,carrot_3": ["no", "no"], "nextto countertop_1,apple_1": ["no", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,orange_1": ["no", "no"], "nextto countertop_1,orange_3": ["no", "no"], "nextto flour_1,bread_1": ["yes", "no"], "nextto flour_1,countertop_1": ["yes", "no"], "nextto flour_1,milk_1": ["yes", "no"], "nextto flour_1,chair_1": ["no", "no"], "nextto flour_1,meat_1": ["yes", "no"], "nextto flour_1,table_1": ["yes", "no"], "nextto flour_1,cheese_1": ["no", "no"], "nextto flour_1,yogurt_1": ["yes", "no"], "nextto flour_1,soup_1": ["yes", "no"], "nextto flour_1,carrot_1": ["yes", "no"], "nextto flour_1,carrot_2": ["yes", "no"], "nextto flour_1,carrot_3": ["yes", "no"], "nextto flour_1,apple_1": ["no", "no"], "nextto flour_1,apple_2": ["no", "no"], "nextto flour_1,orange_1": ["yes", "no"], "nextto flour_1,orange_3": ["yes", "no"], "nextto meat_1,bread_1": ["yes", "no"], "nextto meat_1,countertop_1": ["no", "no"], "nextto meat_1,flour_1": ["no", "no"], "nextto meat_1,milk_1": ["yes", "no"], "nextto meat_1,chair_1": ["no", "no"], "nextto meat_1,table_1": ["yes", "no"], "nextto meat_1,cheese_1": ["no", "no"], "nextto meat_1,yogurt_1": ["no", "no"], "nextto meat_1,soup_1": ["yes", "no"], "nextto meat_1,carrot_1": ["no", "no"], "nextto meat_1,carrot_2": ["yes", "no"], "nextto meat_1,carrot_3": ["yes", "no"], "nextto meat_1,apple_1": ["no", "no"], "nextto meat_1,apple_2": ["no", "no"], "nextto meat_1,orange_1": ["yes", "no"], "nextto meat_1,orange_3": ["no", "yes"], "nextto cheese_1,bread_1": ["yes", "no"], "nextto cheese_1,countertop_1": ["no", "no"], "nextto cheese_1,flour_1": ["no", "no"], "nextto cheese_1,milk_1": ["yes", "no"], "nextto cheese_1,chair_1": ["no", "no"], "nextto cheese_1,meat_1": ["no", "no"], "nextto cheese_1,table_1": ["yes", "no"], "nextto cheese_1,yogurt_1": ["yes", "no"], "nextto cheese_1,soup_1": ["no", "yes"], "nextto cheese_1,carrot_1": ["yes", "no"], "nextto cheese_1,carrot_2": ["yes", "no"], "nextto cheese_1,carrot_3": ["yes", "no"], "nextto cheese_1,apple_1": ["no", "no"], "nextto cheese_1,apple_2": ["no", "no"], "nextto cheese_1,orange_1": ["yes", "yes"], "nextto cheese_1,orange_3": ["yes", "no"], "nextto yogurt_1,bread_1": ["yes", "no"], "nextto yogurt_1,countertop_1": ["no", "no"], "nextto yogurt_1,flour_1": ["yes", "no"], "nextto yogurt_1,milk_1": ["yes", "no"], "nextto yogurt_1,chair_1": ["no", "no"], "nextto yogurt_1,meat_1": ["no", "no"], "nextto yogurt_1,table_1": ["yes", "no"], "nextto yogurt_1,cheese_1": ["yes", "no"], "nextto yogurt_1,soup_1": ["no", "no"], "nextto yogurt_1,carrot_1": ["no", "no"], "nextto yogurt_1,carrot_2": ["yes", "no"], "nextto yogurt_1,carrot_3": ["yes", "no"], "nextto yogurt_1,apple_1": ["yes", "no"], "nextto yogurt_1,apple_2": ["yes", "no"], "nextto yogurt_1,orange_1": ["no", "no"], "nextto yogurt_1,orange_3": ["yes", "no"], "nextto soup_1,bread_1": ["yes", "no"], "nextto soup_1,countertop_1": ["no", "no"], "nextto soup_1,flour_1": ["no", "no"], "nextto soup_1,milk_1": ["yes", "no"], "nextto soup_1,chair_1": ["no", "no"], "nextto soup_1,meat_1": ["no", "no"], "nextto soup_1,table_1": ["yes", "no"], "nextto soup_1,cheese_1": ["yes", "yes"], "nextto soup_1,yogurt_1": ["yes", "no"], "nextto soup_1,carrot_1": ["yes", "no"], "nextto soup_1,carrot_2": ["no", "no"], "nextto soup_1,carrot_3": ["yes", "no"], "nextto soup_1,apple_1": ["no", "no"], "nextto soup_1,apple_2": ["no", "no"], "nextto soup_1,orange_1": ["no", "no"], "nextto soup_1,orange_3": ["yes", "no"], "nextto carrot_1,bread_1": ["no", "no"], "nextto carrot_1,countertop_1": ["no", "no"], "nextto carrot_1,flour_1": ["no", "no"], "nextto carrot_1,milk_1": ["yes", "no"], "nextto carrot_1,chair_1": ["no", "no"], "nextto carrot_1,meat_1": ["no", "no"], "nextto carrot_1,table_1": ["yes", "no"], "nextto carrot_1,cheese_1": ["no", "no"], "nextto carrot_1,yogurt_1": ["yes", "no"], "nextto carrot_1,soup_1": ["no", "no"], "nextto carrot_1,carrot_2": ["yes", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,apple_1": ["no", "no"], "nextto carrot_1,apple_2": ["no", "no"], "nextto carrot_1,orange_1": ["yes", "no"], "nextto carrot_1,orange_3": ["yes", "no"], "nextto carrot_2,bread_1": ["yes", "yes"], "nextto carrot_2,countertop_1": ["no", "no"], "nextto carrot_2,flour_1": ["no", "no"], "nextto carrot_2,milk_1": ["no", "no"], "nextto carrot_2,chair_1": ["no", "no"], "nextto carrot_2,meat_1": ["no", "no"], "nextto carrot_2,table_1": ["yes", "no"], "nextto carrot_2,cheese_1": ["yes", "no"], "nextto carrot_2,yogurt_1": ["no", "no"], "nextto carrot_2,soup_1": ["no", "no"], "nextto carrot_2,carrot_1": ["no", "no"], "nextto carrot_2,carrot_3": ["yes", "yes"], "nextto carrot_2,apple_1": ["no", "yes"], "nextto carrot_2,apple_2": ["no", "no"], "nextto carrot_2,orange_1": ["no", "no"], "nextto carrot_2,orange_3": ["yes", "no"], "nextto carrot_3,bread_1": ["yes", "yes"], "nextto carrot_3,countertop_1": ["no", "no"], "nextto carrot_3,flour_1": ["no", "no"], "nextto carrot_3,milk_1": ["no", "no"], "nextto carrot_3,chair_1": ["no", "no"], "nextto carrot_3,meat_1": ["no", "no"], "nextto carrot_3,table_1": ["yes", "no"], "nextto carrot_3,cheese_1": ["no", "no"], "nextto carrot_3,yogurt_1": ["yes", "no"], "nextto carrot_3,soup_1": ["no", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["yes", "yes"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["no", "no"], "nextto carrot_3,orange_1": ["no", "no"], "nextto carrot_3,orange_3": ["yes", "no"], "nextto apple_1,bread_1": ["yes", "no"], "nextto apple_1,countertop_1": ["no", "no"], "nextto apple_1,flour_1": ["no", "no"], "nextto apple_1,milk_1": ["no", "no"], "nextto apple_1,chair_1": ["no", "no"], "nextto apple_1,meat_1": ["no", "no"], "nextto apple_1,table_1": ["yes", "no"], "nextto apple_1,cheese_1": ["no", "no"], "nextto apple_1,yogurt_1": ["no", "no"], "nextto apple_1,soup_1": ["no", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "yes"], "nextto apple_1,carrot_3": ["yes", "no"], "nextto apple_1,apple_2": ["no", "yes"], "nextto apple_1,orange_1": ["yes", "no"], "nextto apple_1,orange_3": ["no", "no"], "nextto apple_2,bread_1": ["no", "no"], "nextto apple_2,countertop_1": ["no", "no"], "nextto apple_2,flour_1": ["no", "no"], "nextto apple_2,milk_1": ["yes", "no"], "nextto apple_2,chair_1": ["no", "no"], "nextto apple_2,meat_1": ["no", "no"], "nextto apple_2,table_1": ["yes", "no"], "nextto apple_2,cheese_1": ["no", "no"], "nextto apple_2,yogurt_1": ["no", "no"], "nextto apple_2,soup_1": ["no", "no"], "nextto apple_2,carrot_1": ["yes", "no"], "nextto apple_2,carrot_2": ["yes", "no"], "nextto apple_2,carrot_3": ["yes", "no"], "nextto apple_2,apple_1": ["yes", "yes"], "nextto apple_2,orange_1": ["no", "no"], "nextto apple_2,orange_3": ["no", "no"], "nextto orange_1,bread_1": ["no", "no"], "nextto orange_1,countertop_1": ["no", "no"], "nextto orange_1,flour_1": ["no", "no"], "nextto orange_1,milk_1": ["no", "no"], "nextto orange_1,chair_1": ["no", "no"], "nextto orange_1,meat_1": ["no", "no"], "nextto orange_1,table_1": ["yes", "no"], "nextto orange_1,cheese_1": ["no", "yes"], "nextto orange_1,yogurt_1": ["yes", "no"], "nextto orange_1,soup_1": ["no", "no"], "nextto orange_1,carrot_1": ["no", "no"], "nextto orange_1,carrot_2": ["yes", "no"], "nextto orange_1,carrot_3": ["yes", "no"], "nextto orange_1,apple_1": ["no", "no"], "nextto orange_1,apple_2": ["no", "no"], "nextto orange_1,orange_3": ["yes", "no"], "nextto orange_3,bread_1": ["yes", "no"], "nextto orange_3,countertop_1": ["no", "no"], "nextto orange_3,flour_1": ["no", "no"], "nextto orange_3,milk_1": ["yes", "no"], "nextto orange_3,chair_1": ["no", "yes"], "nextto orange_3,meat_1": ["yes", "yes"], "nextto orange_3,table_1": ["yes", "no"], "nextto orange_3,cheese_1": ["no", "no"], "nextto orange_3,yogurt_1": ["no", "no"], "nextto orange_3,soup_1": ["no", "no"], "nextto orange_3,carrot_1": ["yes", "no"], "nextto orange_3,carrot_2": ["yes", "no"], "nextto orange_3,carrot_3": ["yes", "no"], "nextto orange_3,apple_1": ["no", "no"], "nextto orange_3,apple_2": ["no", "no"], "nextto orange_3,orange_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7202505219206681, "yes_accuracy": 0.5789473684210527, "yes_correct": 22, "yes_total": 38, "no_accuracy": 0.7324263038548753, "no_correct": 323, "no_total": 441, "predicates": {"reachable": {"accuracy": 0.5294117647058824, "yes_accuracy": 0.7777777777777778, "yes_correct": 7, "yes_total": 9, "no_accuracy": 0.25, "no_correct": 2, "no_total": 8}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}, "ontop": {"accuracy": 0.8526785714285714, "yes_accuracy": 0.4166666666666667, "yes_correct": 5, "yes_total": 12, "no_accuracy": 0.8773584905660378, "no_correct": 186, "no_total": 212}, "nextto": {"accuracy": 0.5848214285714286, "yes_accuracy": 0.5882352941176471, "yes_correct": 10, "yes_total": 17, "no_accuracy": 0.5845410628019324, "no_correct": 121, "no_total": 207}}}, "step": 2, "actions": ["navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["no", "no"], "reachable countertop_1": ["yes", "no"], "reachable flour_1": ["no", "no"], "reachable carrot_1": ["yes", "no"], "reachable carrot_3": ["yes", "no"], "reachable broccoli_1": ["no", "no"], "reachable apple_1": ["yes", "no"], "reachable apple_2": ["yes", "no"], "reachable electric_refrigerator_1": ["yes", "yes"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding flour_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_3": ["no", "no"], "holding broccoli_1": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "open electric_refrigerator_1": ["no", "no"], "ontop bread_1,countertop_1": ["no", "yes"], "ontop bread_1,flour_1": ["no", "no"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,broccoli_1": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,electric_refrigerator_1": ["yes", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,flour_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,broccoli_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop flour_1,bread_1": ["no", "no"], "ontop flour_1,countertop_1": ["no", "no"], "ontop flour_1,carrot_1": ["no", "no"], "ontop flour_1,carrot_3": ["no", "no"], "ontop flour_1,broccoli_1": ["no", "no"], "ontop flour_1,apple_1": ["no", "no"], "ontop flour_1,apple_2": ["no", "no"], "ontop flour_1,electric_refrigerator_1": ["yes", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["no", "yes"], "ontop carrot_1,flour_1": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,broccoli_1": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["yes", "yes"], "ontop carrot_3,flour_1": ["no", "no"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,broccoli_1": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop broccoli_1,bread_1": ["no", "no"], "ontop broccoli_1,countertop_1": ["no", "yes"], "ontop broccoli_1,flour_1": ["no", "no"], "ontop broccoli_1,carrot_1": ["no", "no"], "ontop broccoli_1,carrot_3": ["no", "no"], "ontop broccoli_1,apple_1": ["no", "no"], "ontop broccoli_1,apple_2": ["no", "no"], "ontop broccoli_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,flour_1": ["no", "no"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,broccoli_1": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["yes", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["no", "yes"], "ontop apple_2,flour_1": ["no", "no"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,broccoli_1": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,electric_refrigerator_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["yes", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside flour_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside broccoli_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["no", "no"], "inside apple_2,electric_refrigerator_1": ["no", "no"], "nextto bread_1,countertop_1": ["no", "no"], "nextto bread_1,flour_1": ["no", "no"], "nextto bread_1,carrot_1": ["no", "no"], "nextto bread_1,carrot_3": ["yes", "yes"], "nextto bread_1,broccoli_1": ["no", "no"], "nextto bread_1,apple_1": ["no", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,bread_1": ["yes", "no"], "nextto countertop_1,flour_1": ["yes", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_3": ["yes", "no"], "nextto countertop_1,broccoli_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto flour_1,bread_1": ["yes", "no"], "nextto flour_1,countertop_1": ["no", "no"], "nextto flour_1,carrot_1": ["no", "no"], "nextto flour_1,carrot_3": ["yes", "no"], "nextto flour_1,broccoli_1": ["no", "no"], "nextto flour_1,apple_1": ["no", "no"], "nextto flour_1,apple_2": ["no", "no"], "nextto flour_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_1,bread_1": ["no", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,flour_1": ["yes", "no"], "nextto carrot_1,carrot_3": ["yes", "no"], "nextto carrot_1,broccoli_1": ["no", "no"], "nextto carrot_1,apple_1": ["no", "no"], "nextto carrot_1,apple_2": ["no", "no"], "nextto carrot_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_3,bread_1": ["yes", "yes"], "nextto carrot_3,countertop_1": ["yes", "no"], "nextto carrot_3,flour_1": ["yes", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,broccoli_1": ["no", "no"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["no", "no"], "nextto carrot_3,electric_refrigerator_1": ["yes", "no"], "nextto broccoli_1,bread_1": ["yes", "no"], "nextto broccoli_1,countertop_1": ["yes", "no"], "nextto broccoli_1,flour_1": ["no", "no"], "nextto broccoli_1,carrot_1": ["yes", "no"], "nextto broccoli_1,carrot_3": ["yes", "no"], "nextto broccoli_1,apple_1": ["no", "no"], "nextto broccoli_1,apple_2": ["no", "no"], "nextto broccoli_1,electric_refrigerator_1": ["yes", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,flour_1": ["yes", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_3": ["no", "no"], "nextto apple_1,broccoli_1": ["no", "no"], "nextto apple_1,apple_2": ["no", "yes"], "nextto apple_1,electric_refrigerator_1": ["yes", "no"], "nextto apple_2,bread_1": ["yes", "no"], "nextto apple_2,countertop_1": ["yes", "no"], "nextto apple_2,flour_1": ["yes", "no"], "nextto apple_2,carrot_1": ["yes", "no"], "nextto apple_2,carrot_3": ["no", "no"], "nextto apple_2,broccoli_1": ["yes", "no"], "nextto apple_2,apple_1": ["yes", "yes"], "nextto apple_2,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.6883116883116883, "yes_accuracy": 0.5454545454545454, "yes_correct": 6, "yes_total": 11, "no_accuracy": 0.6993006993006993, "no_correct": 100, "no_total": 143, "predicates": {"reachable": {"accuracy": 0.4444444444444444, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.375, "no_correct": 3, "no_total": 8}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 8, "no_total": 8}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.890625, "yes_accuracy": 0.3333333333333333, "yes_correct": 2, "yes_total": 6, "no_accuracy": 0.9482758620689655, "no_correct": 55, "no_total": 58}, "inside": {"accuracy": 0.875, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.875, "no_correct": 7, "no_total": 8}, "nextto": {"accuracy": 0.453125, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.43333333333333335, "no_correct": 26, "no_total": 60}}}, "step": 3, "actions": ["open-container(electric_refrigerator_1)", "grasp(apple_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["no", "no"], "reachable countertop_1": ["yes", "no"], "reachable flour_1": ["no", "no"], "reachable carrot_1": ["yes", "no"], "reachable carrot_3": ["yes", "no"], "reachable broccoli_1": ["no", "no"], "reachable apple_1": ["yes", "no"], "reachable apple_2": ["yes", "no"], "reachable electric_refrigerator_1": ["yes", "yes"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding flour_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_3": ["no", "no"], "holding broccoli_1": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "open electric_refrigerator_1": ["no", "no"], "ontop bread_1,countertop_1": ["no", "yes"], "ontop bread_1,flour_1": ["no", "no"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,broccoli_1": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,electric_refrigerator_1": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,flour_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,broccoli_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop flour_1,bread_1": ["no", "no"], "ontop flour_1,countertop_1": ["yes", "no"], "ontop flour_1,carrot_1": ["no", "no"], "ontop flour_1,carrot_3": ["no", "no"], "ontop flour_1,broccoli_1": ["no", "no"], "ontop flour_1,apple_1": ["no", "no"], "ontop flour_1,apple_2": ["no", "no"], "ontop flour_1,electric_refrigerator_1": ["yes", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["no", "yes"], "ontop carrot_1,flour_1": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,broccoli_1": ["yes", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["yes", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["yes", "yes"], "ontop carrot_3,flour_1": ["no", "no"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,broccoli_1": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop broccoli_1,bread_1": ["no", "no"], "ontop broccoli_1,countertop_1": ["yes", "yes"], "ontop broccoli_1,flour_1": ["no", "no"], "ontop broccoli_1,carrot_1": ["no", "no"], "ontop broccoli_1,carrot_3": ["no", "no"], "ontop broccoli_1,apple_1": ["no", "no"], "ontop broccoli_1,apple_2": ["no", "no"], "ontop broccoli_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,flour_1": ["yes", "no"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,broccoli_1": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["no", "yes"], "ontop apple_2,flour_1": ["no", "no"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,broccoli_1": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,electric_refrigerator_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside flour_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside broccoli_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["yes", "no"], "inside apple_2,electric_refrigerator_1": ["no", "no"], "nextto bread_1,countertop_1": ["no", "no"], "nextto bread_1,flour_1": ["no", "no"], "nextto bread_1,carrot_1": ["no", "no"], "nextto bread_1,carrot_3": ["no", "yes"], "nextto bread_1,broccoli_1": ["no", "no"], "nextto bread_1,apple_1": ["no", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,bread_1": ["yes", "no"], "nextto countertop_1,flour_1": ["yes", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_3": ["no", "no"], "nextto countertop_1,broccoli_1": ["yes", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto flour_1,bread_1": ["no", "no"], "nextto flour_1,countertop_1": ["yes", "no"], "nextto flour_1,carrot_1": ["no", "no"], "nextto flour_1,carrot_3": ["no", "no"], "nextto flour_1,broccoli_1": ["no", "no"], "nextto flour_1,apple_1": ["no", "no"], "nextto flour_1,apple_2": ["no", "no"], "nextto flour_1,electric_refrigerator_1": ["no", "no"], "nextto carrot_1,bread_1": ["no", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,flour_1": ["yes", "no"], "nextto carrot_1,carrot_3": ["yes", "no"], "nextto carrot_1,broccoli_1": ["no", "no"], "nextto carrot_1,apple_1": ["no", "no"], "nextto carrot_1,apple_2": ["no", "no"], "nextto carrot_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_3,bread_1": ["no", "yes"], "nextto carrot_3,countertop_1": ["yes", "no"], "nextto carrot_3,flour_1": ["no", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,broccoli_1": ["no", "no"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["yes", "no"], "nextto carrot_3,electric_refrigerator_1": ["yes", "no"], "nextto broccoli_1,bread_1": ["no", "no"], "nextto broccoli_1,countertop_1": ["yes", "no"], "nextto broccoli_1,flour_1": ["no", "no"], "nextto broccoli_1,carrot_1": ["no", "no"], "nextto broccoli_1,carrot_3": ["no", "no"], "nextto broccoli_1,apple_1": ["no", "no"], "nextto broccoli_1,apple_2": ["no", "no"], "nextto broccoli_1,electric_refrigerator_1": ["no", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,flour_1": ["yes", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_3": ["yes", "no"], "nextto apple_1,broccoli_1": ["no", "no"], "nextto apple_1,apple_2": ["no", "yes"], "nextto apple_1,electric_refrigerator_1": ["yes", "no"], "nextto apple_2,bread_1": ["yes", "no"], "nextto apple_2,countertop_1": ["yes", "no"], "nextto apple_2,flour_1": ["no", "no"], "nextto apple_2,carrot_1": ["yes", "no"], "nextto apple_2,carrot_3": ["no", "no"], "nextto apple_2,broccoli_1": ["no", "no"], "nextto apple_2,apple_1": ["yes", "yes"], "nextto apple_2,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7207792207792207, "yes_accuracy": 0.45454545454545453, "yes_correct": 5, "yes_total": 11, "no_accuracy": 0.7412587412587412, "no_correct": 106, "no_total": 143, "predicates": {"reachable": {"accuracy": 0.4444444444444444, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.375, "no_correct": 3, "no_total": 8}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 8, "no_total": 8}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.875, "yes_accuracy": 0.5, "yes_correct": 3, "yes_total": 6, "no_accuracy": 0.9137931034482759, "no_correct": 53, "no_total": 58}, "inside": {"accuracy": 0.875, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.875, "no_correct": 7, "no_total": 8}, "nextto": {"accuracy": 0.546875, "yes_accuracy": 0.25, "yes_correct": 1, "yes_total": 4, "no_accuracy": 0.5666666666666667, "no_correct": 34, "no_total": 60}}}, "step": 4, "actions": []}], "remaining_actions": []}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Pomaria_1_int_20": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable apple_1": ["yes", 3.099986299531941e-15, 0.9999999999999969, "The image shows a robotic arm (agent) extending towards the table, with various objects on the table, including an apple labeled \"apple_1.\" The apple_1 is located on the right side of the table, near the orange and other objects. The robotic arm appears to be reaching towards the center of the table, but it is not clear if it is close enough to reach the apple_1 specifically. Since the apple_1 is on the right side of the table and the robotic arm is extending from the top right, it is likely within reach, but not definitively so based on the image alone.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the table, with various objects on the table, including an apple labeled \"apple_1.\" The apple_1 is located on the right side of the table, near the orange and other objects. The robotic arm appears to be reaching towards the center of the table, but it is not clear if it is close enough to reach the apple_1 specifically. Since the apple_1 is on the right side of the table and the robotic arm is extending from the top right, it is likely within reach, but not definitively so based on the image alone.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": true, "action_state_correct": true, "preconditions_results": {}, "non_visible_precond_results": {"reachable electric_refrigerator_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 2.9756246687862348e-08, 0.9999999702437533, "The image shows a robotic arm, which is the agent, reaching towards a refrigerator. The refrigerator appears to be close to the robotic arm, with the arm extending directly towards it. Given the position and the extension of the robotic arm, it seems to be within reach of the refrigerator. Therefore, the refrigerator is in reach of the agent.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, reaching towards a refrigerator. The refrigerator appears to be close to the robotic arm, with the arm extending directly towards it. Given the position and the extension of the robotic arm, it seems to be within reach of the refrigerator. Therefore, the refrigerator is in reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "all_correct": true, "all_state_correct": true, "updated_non_visible_preds": {"reachable apple_1": {"before": true, "after": false}, "reachable apple_2": {"before": true, "after": false}, "reachable orange_1": {"before": true, "after": false}, "reachable table_1": {"before": true, "after": false}}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 1.4532648700598353e-11, 0.9999999999854674, "The image shows a robotic arm, which is the agent, reaching towards a metallic object that appears to be a refrigerator. The refrigerator is positioned next to a wall and is in close proximity to the robotic arm. Given the arm's position and the typical size of such objects, it seems that the refrigerator is within the reach of the robotic arm.", true, "<explanation>\nThe image shows a robotic arm, which is the agent, reaching towards a metallic object that appears to be a refrigerator. The refrigerator is positioned next to a wall and is in close proximity to the robotic arm. Given the arm's position and the typical size of such objects, it seems that the refrigerator is within the reach of the robotic arm.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["no", 0.9999999863613868, 1.3638613291303976e-08, "The image shows a refrigerator with a robotic arm near it. The refrigerator door appears to be closed, as there is no visible gap or opening indicating that it is open. Typically, an open refrigerator door would show the interior or a noticeable gap. Since the door looks flush and closed, the refrigerator is not open.", true, "<explanation>\nThe image shows a refrigerator with a robotic arm near it. The refrigerator door appears to be closed, as there is no visible gap or opening indicating that it is open. Typically, an open refrigerator door would show the interior or a noticeable gap. Since the door looks flush and closed, the refrigerator is not open.\n</explanation>\n<answer>\nNo\n</answer>", true], "all_correct": true, "all_state_correct": true}, "non_visible_precond_results": {"holding apple_1": [true, false, false], "holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": {"open electric_refrigerator_1": ["no", 0.9999999992933754, 7.066246400674982e-10, "The image shows a robotic arm inside a cabinet or refrigerator, but the door of the refrigerator is not visible as being open. The perspective suggests the door is closed because the interior shelves are visible and there is no indication of the door being ajar or open. Therefore, the electric refrigerator appears to be closed.", false, "<explanation>\nThe image shows a robotic arm inside a cabinet or refrigerator, but the door of the refrigerator is not visible as being open. The perspective suggests the door is closed because the interior shelves are visible and there is no indication of the door being ajar or open. Therefore, the electric refrigerator appears to be closed.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {}}, "action_info": "success"}, {"action": "open-container(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable electric_refrigerator_1": ["yes", 2.9950221350239306e-17, 1.0, "The image shows a robotic arm (agent) inside a kitchen environment, with the arm extended towards a shelf. The electric refrigerator is located to the right of the robotic arm, and the arm appears to be reaching into the shelf area, which is close to the refrigerator. Given the proximity of the arm to the refrigerator and the typical reach of such robotic arms, it is likely within reach of the refrigerator. Therefore, the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) inside a kitchen environment, with the arm extended towards a shelf. The electric refrigerator is located to the right of the robotic arm, and the arm appears to be reaching into the shelf area, which is close to the refrigerator. Given the proximity of the arm to the refrigerator and the typical reach of such robotic arms, it is likely within reach of the refrigerator. Therefore, the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "open electric_refrigerator_1": ["no", 0.9999999999996785, 3.2148701693384204e-13, "The image shows a robotic arm inside a cabinet or refrigerator, but the door of the refrigerator is not visible in the image. Since the question asks if the electric refrigerator 1 is open, I need to determine if the door is open or closed. Based on the image, the door appears to be closed, as the interior of the refrigerator is not visible and the door's edge is aligned with the rest of the refrigerator. Therefore, the refrigerator is not open.", true, "<explanation>\nThe image shows a robotic arm inside a cabinet or refrigerator, but the door of the refrigerator is not visible in the image. Since the question asks if the electric refrigerator 1 is open, I need to determine if the door is open or closed. Based on the image, the door appears to be closed, as the interior of the refrigerator is not visible and the door's edge is aligned with the rest of the refrigerator. Therefore, the refrigerator is not open.\n</explanation>\n<answer>\nNo\n</answer>", false], "all_correct": true, "all_state_correct": false}, "non_visible_precond_results": {"holding apple_1": [true, false, false], "holding apple_2": [true, false, false], "holding orange_1": [true, false, false], "all_correct": true}, "effects_results": null, "action_info": "not legal"}], "replans": [{"enum_results": {"reachable bread_1": ["yes", "no"], "reachable countertop_1": ["yes", "no"], "reachable flour_1": ["no", "no"], "reachable milk_1": ["no", "yes"], "reachable chair_1": ["yes", "yes"], "reachable meat_1": ["no", "yes"], "reachable table_1": ["yes", "yes"], "reachable cheese_1": ["yes", "yes"], "reachable yogurt_1": ["yes", "yes"], "reachable soup_1": ["no", "yes"], "reachable carrot_1": ["yes", "no"], "reachable carrot_2": ["yes", "no"], "reachable carrot_3": ["yes", "no"], "reachable apple_1": ["yes", "no"], "reachable apple_2": ["yes", "no"], "reachable orange_1": ["yes", "yes"], "reachable orange_3": ["yes", "yes"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding flour_1": ["no", "no"], "holding meat_1": ["no", "no"], "holding cheese_1": ["no", "no"], "holding yogurt_1": ["no", "no"], "holding soup_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "holding orange_1": ["no", "no"], "holding orange_3": ["no", "no"], "ontop bread_1,countertop_1": ["no", "yes"], "ontop bread_1,flour_1": ["no", "no"], "ontop bread_1,milk_1": ["yes", "no"], "ontop bread_1,chair_1": ["no", "no"], "ontop bread_1,meat_1": ["yes", "no"], "ontop bread_1,table_1": ["yes", "no"], "ontop bread_1,cheese_1": ["yes", "no"], "ontop bread_1,yogurt_1": ["yes", "no"], "ontop bread_1,soup_1": ["yes", "no"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,orange_1": ["no", "no"], "ontop bread_1,orange_3": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,flour_1": ["no", "no"], "ontop countertop_1,milk_1": ["yes", "no"], "ontop countertop_1,chair_1": ["no", "no"], "ontop countertop_1,meat_1": ["no", "no"], "ontop countertop_1,table_1": ["no", "no"], "ontop countertop_1,cheese_1": ["no", "no"], "ontop countertop_1,yogurt_1": ["no", "no"], "ontop countertop_1,soup_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,orange_1": ["no", "no"], "ontop countertop_1,orange_3": ["no", "no"], "ontop flour_1,bread_1": ["no", "no"], "ontop flour_1,countertop_1": ["no", "no"], "ontop flour_1,milk_1": ["no", "no"], "ontop flour_1,chair_1": ["no", "no"], "ontop flour_1,meat_1": ["no", "no"], "ontop flour_1,table_1": ["no", "no"], "ontop flour_1,cheese_1": ["no", "no"], "ontop flour_1,yogurt_1": ["no", "no"], "ontop flour_1,soup_1": ["no", "no"], "ontop flour_1,carrot_1": ["no", "no"], "ontop flour_1,carrot_2": ["no", "no"], "ontop flour_1,carrot_3": ["no", "no"], "ontop flour_1,apple_1": ["no", "no"], "ontop flour_1,apple_2": ["no", "no"], "ontop flour_1,orange_1": ["no", "no"], "ontop flour_1,orange_3": ["no", "no"], "ontop meat_1,bread_1": ["no", "no"], "ontop meat_1,countertop_1": ["no", "no"], "ontop meat_1,flour_1": ["no", "no"], "ontop meat_1,milk_1": ["no", "no"], "ontop meat_1,chair_1": ["no", "no"], "ontop meat_1,table_1": ["yes", "yes"], "ontop meat_1,cheese_1": ["no", "no"], "ontop meat_1,yogurt_1": ["no", "no"], "ontop meat_1,soup_1": ["no", "no"], "ontop meat_1,carrot_1": ["no", "no"], "ontop meat_1,carrot_2": ["no", "no"], "ontop meat_1,carrot_3": ["no", "no"], "ontop meat_1,apple_1": ["no", "no"], "ontop meat_1,apple_2": ["no", "no"], "ontop meat_1,orange_1": ["no", "no"], "ontop meat_1,orange_3": ["no", "no"], "ontop cheese_1,bread_1": ["no", "no"], "ontop cheese_1,countertop_1": ["no", "no"], "ontop cheese_1,flour_1": ["yes", "no"], "ontop cheese_1,milk_1": ["no", "no"], "ontop cheese_1,chair_1": ["no", "no"], "ontop cheese_1,meat_1": ["no", "no"], "ontop cheese_1,table_1": ["yes", "yes"], "ontop cheese_1,yogurt_1": ["no", "no"], "ontop cheese_1,soup_1": ["no", "no"], "ontop cheese_1,carrot_1": ["no", "no"], "ontop cheese_1,carrot_2": ["no", "no"], "ontop cheese_1,carrot_3": ["no", "no"], "ontop cheese_1,apple_1": ["no", "no"], "ontop cheese_1,apple_2": ["no", "no"], "ontop cheese_1,orange_1": ["no", "no"], "ontop cheese_1,orange_3": ["no", "no"], "ontop yogurt_1,bread_1": ["no", "no"], "ontop yogurt_1,countertop_1": ["no", "no"], "ontop yogurt_1,flour_1": ["no", "no"], "ontop yogurt_1,milk_1": ["no", "no"], "ontop yogurt_1,chair_1": ["no", "no"], "ontop yogurt_1,meat_1": ["no", "no"], "ontop yogurt_1,table_1": ["yes", "yes"], "ontop yogurt_1,cheese_1": ["yes", "no"], "ontop yogurt_1,soup_1": ["no", "no"], "ontop yogurt_1,carrot_1": ["no", "no"], "ontop yogurt_1,carrot_2": ["no", "no"], "ontop yogurt_1,carrot_3": ["no", "no"], "ontop yogurt_1,apple_1": ["no", "no"], "ontop yogurt_1,apple_2": ["yes", "no"], "ontop yogurt_1,orange_1": ["no", "no"], "ontop yogurt_1,orange_3": ["yes", "no"], "ontop soup_1,bread_1": ["yes", "no"], "ontop soup_1,countertop_1": ["no", "no"], "ontop soup_1,flour_1": ["no", "no"], "ontop soup_1,milk_1": ["no", "no"], "ontop soup_1,chair_1": ["no", "no"], "ontop soup_1,meat_1": ["no", "no"], "ontop soup_1,table_1": ["yes", "yes"], "ontop soup_1,cheese_1": ["no", "no"], "ontop soup_1,yogurt_1": ["no", "no"], "ontop soup_1,carrot_1": ["no", "no"], "ontop soup_1,carrot_2": ["no", "no"], "ontop soup_1,carrot_3": ["no", "no"], "ontop soup_1,apple_1": ["no", "no"], "ontop soup_1,apple_2": ["no", "no"], "ontop soup_1,orange_1": ["yes", "no"], "ontop soup_1,orange_3": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["no", "yes"], "ontop carrot_1,flour_1": ["no", "no"], "ontop carrot_1,milk_1": ["no", "no"], "ontop carrot_1,chair_1": ["no", "no"], "ontop carrot_1,meat_1": ["no", "no"], "ontop carrot_1,table_1": ["yes", "no"], "ontop carrot_1,cheese_1": ["no", "no"], "ontop carrot_1,yogurt_1": ["no", "no"], "ontop carrot_1,soup_1": ["no", "no"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,orange_1": ["no", "no"], "ontop carrot_1,orange_3": ["yes", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["no", "yes"], "ontop carrot_2,flour_1": ["no", "no"], "ontop carrot_2,milk_1": ["no", "no"], "ontop carrot_2,chair_1": ["no", "no"], "ontop carrot_2,meat_1": ["no", "no"], "ontop carrot_2,table_1": ["yes", "no"], "ontop carrot_2,cheese_1": ["no", "no"], "ontop carrot_2,yogurt_1": ["yes", "no"], "ontop carrot_2,soup_1": ["no", "no"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,orange_1": ["yes", "no"], "ontop carrot_2,orange_3": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["no", "yes"], "ontop carrot_3,flour_1": ["no", "no"], "ontop carrot_3,milk_1": ["no", "no"], "ontop carrot_3,chair_1": ["no", "no"], "ontop carrot_3,meat_1": ["no", "no"], "ontop carrot_3,table_1": ["yes", "no"], "ontop carrot_3,cheese_1": ["no", "no"], "ontop carrot_3,yogurt_1": ["no", "no"], "ontop carrot_3,soup_1": ["no", "no"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,orange_1": ["no", "no"], "ontop carrot_3,orange_3": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,flour_1": ["no", "no"], "ontop apple_1,milk_1": ["no", "no"], "ontop apple_1,chair_1": ["no", "no"], "ontop apple_1,meat_1": ["no", "no"], "ontop apple_1,table_1": ["yes", "no"], "ontop apple_1,cheese_1": ["no", "no"], "ontop apple_1,yogurt_1": ["no", "no"], "ontop apple_1,soup_1": ["no", "no"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,orange_1": ["no", "no"], "ontop apple_1,orange_3": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["no", "yes"], "ontop apple_2,flour_1": ["no", "no"], "ontop apple_2,milk_1": ["no", "no"], "ontop apple_2,chair_1": ["no", "no"], "ontop apple_2,meat_1": ["no", "no"], "ontop apple_2,table_1": ["no", "no"], "ontop apple_2,cheese_1": ["no", "no"], "ontop apple_2,yogurt_1": ["no", "no"], "ontop apple_2,soup_1": ["no", "no"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,orange_1": ["no", "no"], "ontop apple_2,orange_3": ["no", "no"], "ontop orange_1,bread_1": ["no", "no"], "ontop orange_1,countertop_1": ["no", "no"], "ontop orange_1,flour_1": ["yes", "no"], "ontop orange_1,milk_1": ["no", "no"], "ontop orange_1,chair_1": ["no", "no"], "ontop orange_1,meat_1": ["no", "no"], "ontop orange_1,table_1": ["yes", "yes"], "ontop orange_1,cheese_1": ["no", "no"], "ontop orange_1,yogurt_1": ["no", "no"], "ontop orange_1,soup_1": ["no", "no"], "ontop orange_1,carrot_1": ["yes", "no"], "ontop orange_1,carrot_2": ["no", "no"], "ontop orange_1,carrot_3": ["yes", "no"], "ontop orange_1,apple_1": ["no", "no"], "ontop orange_1,apple_2": ["no", "no"], "ontop orange_1,orange_3": ["yes", "no"], "ontop orange_3,bread_1": ["yes", "no"], "ontop orange_3,countertop_1": ["no", "no"], "ontop orange_3,flour_1": ["no", "no"], "ontop orange_3,milk_1": ["no", "no"], "ontop orange_3,chair_1": ["no", "no"], "ontop orange_3,meat_1": ["no", "no"], "ontop orange_3,table_1": ["yes", "yes"], "ontop orange_3,cheese_1": ["no", "no"], "ontop orange_3,yogurt_1": ["no", "no"], "ontop orange_3,soup_1": ["no", "no"], "ontop orange_3,carrot_1": ["no", "no"], "ontop orange_3,carrot_2": ["yes", "no"], "ontop orange_3,carrot_3": ["yes", "no"], "ontop orange_3,apple_1": ["no", "no"], "ontop orange_3,apple_2": ["no", "no"], "ontop orange_3,orange_1": ["yes", "no"], "nextto bread_1,countertop_1": ["no", "no"], "nextto bread_1,flour_1": ["yes", "no"], "nextto bread_1,milk_1": ["yes", "no"], "nextto bread_1,chair_1": ["no", "no"], "nextto bread_1,meat_1": ["no", "no"], "nextto bread_1,table_1": ["yes", "no"], "nextto bread_1,cheese_1": ["no", "no"], "nextto bread_1,yogurt_1": ["yes", "no"], "nextto bread_1,soup_1": ["no", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["yes", "yes"], "nextto bread_1,carrot_3": ["yes", "yes"], "nextto bread_1,apple_1": ["no", "no"], "nextto bread_1,apple_2": ["no", "no"], "nextto bread_1,orange_1": ["yes", "no"], "nextto bread_1,orange_3": ["yes", "no"], "nextto countertop_1,bread_1": ["no", "no"], "nextto countertop_1,flour_1": ["no", "no"], "nextto countertop_1,milk_1": ["no", "no"], "nextto countertop_1,chair_1": ["no", "no"], "nextto countertop_1,meat_1": ["no", "no"], "nextto countertop_1,table_1": ["no", "no"], "nextto countertop_1,cheese_1": ["no", "no"], "nextto countertop_1,yogurt_1": ["no", "no"], "nextto countertop_1,soup_1": ["no", "no"], "nextto countertop_1,carrot_1": ["no", "no"], "nextto countertop_1,carrot_2": ["no", "no"], "nextto countertop_1,carrot_3": ["no", "no"], "nextto countertop_1,apple_1": ["yes", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,orange_1": ["no", "no"], "nextto countertop_1,orange_3": ["no", "no"], "nextto flour_1,bread_1": ["yes", "no"], "nextto flour_1,countertop_1": ["yes", "no"], "nextto flour_1,milk_1": ["no", "no"], "nextto flour_1,chair_1": ["no", "no"], "nextto flour_1,meat_1": ["yes", "no"], "nextto flour_1,table_1": ["yes", "no"], "nextto flour_1,cheese_1": ["yes", "no"], "nextto flour_1,yogurt_1": ["yes", "no"], "nextto flour_1,soup_1": ["yes", "no"], "nextto flour_1,carrot_1": ["yes", "no"], "nextto flour_1,carrot_2": ["no", "no"], "nextto flour_1,carrot_3": ["yes", "no"], "nextto flour_1,apple_1": ["no", "no"], "nextto flour_1,apple_2": ["no", "no"], "nextto flour_1,orange_1": ["no", "no"], "nextto flour_1,orange_3": ["yes", "no"], "nextto meat_1,bread_1": ["no", "no"], "nextto meat_1,countertop_1": ["no", "no"], "nextto meat_1,flour_1": ["no", "no"], "nextto meat_1,milk_1": ["yes", "no"], "nextto meat_1,chair_1": ["no", "no"], "nextto meat_1,table_1": ["yes", "no"], "nextto meat_1,cheese_1": ["no", "no"], "nextto meat_1,yogurt_1": ["no", "no"], "nextto meat_1,soup_1": ["no", "no"], "nextto meat_1,carrot_1": ["no", "no"], "nextto meat_1,carrot_2": ["yes", "no"], "nextto meat_1,carrot_3": ["yes", "no"], "nextto meat_1,apple_1": ["no", "no"], "nextto meat_1,apple_2": ["no", "no"], "nextto meat_1,orange_1": ["yes", "no"], "nextto meat_1,orange_3": ["yes", "yes"], "nextto cheese_1,bread_1": ["yes", "no"], "nextto cheese_1,countertop_1": ["no", "no"], "nextto cheese_1,flour_1": ["no", "no"], "nextto cheese_1,milk_1": ["yes", "no"], "nextto cheese_1,chair_1": ["no", "no"], "nextto cheese_1,meat_1": ["no", "no"], "nextto cheese_1,table_1": ["yes", "no"], "nextto cheese_1,yogurt_1": ["yes", "no"], "nextto cheese_1,soup_1": ["yes", "yes"], "nextto cheese_1,carrot_1": ["yes", "no"], "nextto cheese_1,carrot_2": ["yes", "no"], "nextto cheese_1,carrot_3": ["yes", "no"], "nextto cheese_1,apple_1": ["yes", "no"], "nextto cheese_1,apple_2": ["no", "no"], "nextto cheese_1,orange_1": ["no", "yes"], "nextto cheese_1,orange_3": ["yes", "no"], "nextto yogurt_1,bread_1": ["yes", "no"], "nextto yogurt_1,countertop_1": ["no", "no"], "nextto yogurt_1,flour_1": ["yes", "no"], "nextto yogurt_1,milk_1": ["yes", "no"], "nextto yogurt_1,chair_1": ["no", "no"], "nextto yogurt_1,meat_1": ["no", "no"], "nextto yogurt_1,table_1": ["yes", "no"], "nextto yogurt_1,cheese_1": ["yes", "no"], "nextto yogurt_1,soup_1": ["yes", "no"], "nextto yogurt_1,carrot_1": ["yes", "no"], "nextto yogurt_1,carrot_2": ["yes", "no"], "nextto yogurt_1,carrot_3": ["yes", "no"], "nextto yogurt_1,apple_1": ["yes", "no"], "nextto yogurt_1,apple_2": ["yes", "no"], "nextto yogurt_1,orange_1": ["yes", "no"], "nextto yogurt_1,orange_3": ["yes", "no"], "nextto soup_1,bread_1": ["yes", "no"], "nextto soup_1,countertop_1": ["no", "no"], "nextto soup_1,flour_1": ["no", "no"], "nextto soup_1,milk_1": ["no", "no"], "nextto soup_1,chair_1": ["no", "no"], "nextto soup_1,meat_1": ["no", "no"], "nextto soup_1,table_1": ["yes", "no"], "nextto soup_1,cheese_1": ["no", "yes"], "nextto soup_1,yogurt_1": ["yes", "no"], "nextto soup_1,carrot_1": ["yes", "no"], "nextto soup_1,carrot_2": ["no", "no"], "nextto soup_1,carrot_3": ["yes", "no"], "nextto soup_1,apple_1": ["no", "no"], "nextto soup_1,apple_2": ["no", "no"], "nextto soup_1,orange_1": ["no", "no"], "nextto soup_1,orange_3": ["yes", "no"], "nextto carrot_1,bread_1": ["no", "no"], "nextto carrot_1,countertop_1": ["no", "no"], "nextto carrot_1,flour_1": ["no", "no"], "nextto carrot_1,milk_1": ["no", "no"], "nextto carrot_1,chair_1": ["no", "no"], "nextto carrot_1,meat_1": ["no", "no"], "nextto carrot_1,table_1": ["yes", "no"], "nextto carrot_1,cheese_1": ["no", "no"], "nextto carrot_1,yogurt_1": ["no", "no"], "nextto carrot_1,soup_1": ["no", "no"], "nextto carrot_1,carrot_2": ["no", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,apple_1": ["no", "no"], "nextto carrot_1,apple_2": ["yes", "no"], "nextto carrot_1,orange_1": ["no", "no"], "nextto carrot_1,orange_3": ["yes", "no"], "nextto carrot_2,bread_1": ["yes", "yes"], "nextto carrot_2,countertop_1": ["no", "no"], "nextto carrot_2,flour_1": ["no", "no"], "nextto carrot_2,milk_1": ["no", "no"], "nextto carrot_2,chair_1": ["no", "no"], "nextto carrot_2,meat_1": ["no", "no"], "nextto carrot_2,table_1": ["yes", "no"], "nextto carrot_2,cheese_1": ["no", "no"], "nextto carrot_2,yogurt_1": ["no", "no"], "nextto carrot_2,soup_1": ["no", "no"], "nextto carrot_2,carrot_1": ["no", "no"], "nextto carrot_2,carrot_3": ["yes", "yes"], "nextto carrot_2,apple_1": ["no", "yes"], "nextto carrot_2,apple_2": ["no", "no"], "nextto carrot_2,orange_1": ["no", "no"], "nextto carrot_2,orange_3": ["yes", "no"], "nextto carrot_3,bread_1": ["no", "yes"], "nextto carrot_3,countertop_1": ["no", "no"], "nextto carrot_3,flour_1": ["no", "no"], "nextto carrot_3,milk_1": ["no", "no"], "nextto carrot_3,chair_1": ["no", "no"], "nextto carrot_3,meat_1": ["no", "no"], "nextto carrot_3,table_1": ["yes", "no"], "nextto carrot_3,cheese_1": ["no", "no"], "nextto carrot_3,yogurt_1": ["no", "no"], "nextto carrot_3,soup_1": ["no", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["yes", "yes"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["no", "no"], "nextto carrot_3,orange_1": ["yes", "no"], "nextto carrot_3,orange_3": ["no", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["no", "no"], "nextto apple_1,flour_1": ["no", "no"], "nextto apple_1,milk_1": ["no", "no"], "nextto apple_1,chair_1": ["no", "no"], "nextto apple_1,meat_1": ["no", "no"], "nextto apple_1,table_1": ["yes", "no"], "nextto apple_1,cheese_1": ["no", "no"], "nextto apple_1,yogurt_1": ["no", "no"], "nextto apple_1,soup_1": ["no", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "yes"], "nextto apple_1,carrot_3": ["yes", "no"], "nextto apple_1,apple_2": ["no", "yes"], "nextto apple_1,orange_1": ["yes", "no"], "nextto apple_1,orange_3": ["no", "no"], "nextto apple_2,bread_1": ["no", "no"], "nextto apple_2,countertop_1": ["no", "no"], "nextto apple_2,flour_1": ["no", "no"], "nextto apple_2,milk_1": ["no", "no"], "nextto apple_2,chair_1": ["no", "no"], "nextto apple_2,meat_1": ["no", "no"], "nextto apple_2,table_1": ["no", "no"], "nextto apple_2,cheese_1": ["no", "no"], "nextto apple_2,yogurt_1": ["no", "no"], "nextto apple_2,soup_1": ["yes", "no"], "nextto apple_2,carrot_1": ["no", "no"], "nextto apple_2,carrot_2": ["no", "no"], "nextto apple_2,carrot_3": ["no", "no"], "nextto apple_2,apple_1": ["yes", "yes"], "nextto apple_2,orange_1": ["no", "no"], "nextto apple_2,orange_3": ["no", "no"], "nextto orange_1,bread_1": ["no", "no"], "nextto orange_1,countertop_1": ["no", "no"], "nextto orange_1,flour_1": ["no", "no"], "nextto orange_1,milk_1": ["no", "no"], "nextto orange_1,chair_1": ["yes", "no"], "nextto orange_1,meat_1": ["no", "no"], "nextto orange_1,table_1": ["yes", "no"], "nextto orange_1,cheese_1": ["no", "yes"], "nextto orange_1,yogurt_1": ["no", "no"], "nextto orange_1,soup_1": ["yes", "no"], "nextto orange_1,carrot_1": ["yes", "no"], "nextto orange_1,carrot_2": ["yes", "no"], "nextto orange_1,carrot_3": ["yes", "no"], "nextto orange_1,apple_1": ["no", "no"], "nextto orange_1,apple_2": ["no", "no"], "nextto orange_1,orange_3": ["yes", "no"], "nextto orange_3,bread_1": ["yes", "no"], "nextto orange_3,countertop_1": ["no", "no"], "nextto orange_3,flour_1": ["no", "no"], "nextto orange_3,milk_1": ["no", "no"], "nextto orange_3,chair_1": ["no", "yes"], "nextto orange_3,meat_1": ["no", "yes"], "nextto orange_3,table_1": ["yes", "no"], "nextto orange_3,cheese_1": ["no", "no"], "nextto orange_3,yogurt_1": ["no", "no"], "nextto orange_3,soup_1": ["no", "no"], "nextto orange_3,carrot_1": ["yes", "no"], "nextto orange_3,carrot_2": ["no", "no"], "nextto orange_3,carrot_3": ["yes", "no"], "nextto orange_3,apple_1": ["no", "no"], "nextto orange_3,apple_2": ["no", "no"], "nextto orange_3,orange_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7348643006263048, "yes_accuracy": 0.5526315789473685, "yes_correct": 21, "yes_total": 38, "no_accuracy": 0.7505668934240363, "no_correct": 331, "no_total": 441, "predicates": {"reachable": {"accuracy": 0.4117647058823529, "yes_accuracy": 0.6666666666666666, "yes_correct": 6, "yes_total": 9, "no_accuracy": 0.125, "no_correct": 1, "no_total": 8}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}, "ontop": {"accuracy": 0.8526785714285714, "yes_accuracy": 0.5833333333333334, "yes_correct": 7, "yes_total": 12, "no_accuracy": 0.8679245283018868, "no_correct": 184, "no_total": 212}, "nextto": {"accuracy": 0.625, "yes_accuracy": 0.47058823529411764, "yes_correct": 8, "yes_total": 17, "no_accuracy": 0.6376811594202898, "no_correct": 132, "no_total": 207}}}, "step": 1, "actions": ["navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable electric_refrigerator_1": ["yes", "yes"], "open electric_refrigerator_1": ["no", "yes"]}, "enum_metrics": {"accuracy": 0.5, "yes_accuracy": 0.5, "yes_correct": 1, "yes_total": 2, "no_accuracy": null, "no_correct": 0, "no_total": 0, "predicates": {"reachable": {"accuracy": 1.0, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}, "open": {"accuracy": 0.0, "yes_accuracy": 0.0, "yes_correct": 0, "yes_total": 1, "no_accuracy": null, "no_correct": 0, "no_total": 0}}}, "step": 3, "actions": ["open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}], "remaining_actions": ["navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Pomaria_1_int_23": {"all_correct": false, "goal_reached": false, "action_results": [{"action": "navigate-to(apple_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {"reachable apple_1": ["yes", 7.481846250435134e-14, 0.9999999999999252, "The image shows a robotic arm (agent) extending towards the table, with objects on the table including an apple_1. The apple_1 is located on the right side of the table, near the orange_1 and orange_3. The robotic arm appears to be reaching towards the objects on the table, and the apple_1 is within the area that the arm is extending to. Based on the position and the arm's reach, it seems that the apple_1 is accessible to the robotic arm.", false, "<explanation>\nThe image shows a robotic arm (agent) extending towards the table, with objects on the table including an apple_1. The apple_1 is located on the right side of the table, near the orange_1 and orange_3. The robotic arm appears to be reaching towards the objects on the table, and the apple_1 is within the area that the arm is extending to. Based on the position and the arm's reach, it seems that the apple_1 is accessible to the robotic arm.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false}, "non_visible_precond_results": {"all_correct": true}, "effects_results": null, "action_info": null}, {"action": "navigate-to(electric_refrigerator_1)", "action_correct": false, "action_state_correct": false, "preconditions_results": {}, "non_visible_precond_results": {"reachable electric_refrigerator_1": [true, false, false], "all_correct": true}, "effects_results": {"reachable electric_refrigerator_1": ["yes", 9.653536013196127e-09, 0.999999990346464, "The image shows a robotic arm (agent) extending towards an object, which appears to be an electric refrigerator. The refrigerator is positioned on the right side of the image, and the robotic arm is reaching towards it from the left. Given the proximity and the direction of the robotic arm, it seems to be within reach of the refrigerator. Therefore, the refrigerator is accessible to the agent.", true, "<explanation>\nThe image shows a robotic arm (agent) extending towards an object, which appears to be an electric refrigerator. The refrigerator is positioned on the right side of the image, and the robotic arm is reaching towards it from the left. Given the proximity and the direction of the robotic arm, it seems to be within reach of the refrigerator. Therefore, the refrigerator is accessible to the agent.\n</explanation>\n<answer>\nYes\n</answer>", true], "reachable apple_1": ["yes", 1.3928336856957512e-12, 0.9999999999986071, "The image shows a robotic arm (agent) near a refrigerator or similar appliance. There are objects labeled \"apple_1\" and \"apple_2\" in the scene, with \"apple_1\" being closer to the robotic arm. Since the robotic arm is positioned very close to the objects, and \"apple_1\" appears to be within the vicinity of the arm's reach, it is likely that \"apple_1\" is within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) near a refrigerator or similar appliance. There are objects labeled \"apple_1\" and \"apple_2\" in the scene, with \"apple_1\" being closer to the robotic arm. Since the robotic arm is positioned very close to the objects, and \"apple_1\" appears to be within the vicinity of the arm's reach, it is likely that \"apple_1\" is within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "reachable apple_2": ["yes", 3.327441733333218e-11, 0.9999999999667256, "The image shows a robotic arm (agent) near a refrigerator, with some objects and text labels. The label \"apple_2\" is visible in red text, indicating the location of the apple. The apple_2 appears to be on the refrigerator door, close to the robotic arm. Given the proximity of the robotic arm to the apple_2, it seems to be within reach of the agent.", false, "<explanation>\nThe image shows a robotic arm (agent) near a refrigerator, with some objects and text labels. The label \"apple_2\" is visible in red text, indicating the location of the apple. The apple_2 appears to be on the refrigerator door, close to the robotic arm. Given the proximity of the robotic arm to the apple_2, it seems to be within reach of the agent.\n</explanation>\n<answer>\nYes\n</answer>", false], "all_correct": false, "all_state_correct": false, "updated_non_visible_preds": {"reachable orange_1": {"before": true, "after": false}, "reachable table_1": {"before": true, "after": false}}}, "action_info": "success"}], "replans": [{"enum_results": {"reachable bread_1": ["yes", "no"], "reachable countertop_1": ["yes", "no"], "reachable flour_1": ["yes", "no"], "reachable milk_1": ["no", "yes"], "reachable chair_1": ["yes", "yes"], "reachable meat_1": ["yes", "yes"], "reachable table_1": ["yes", "yes"], "reachable cheese_1": ["yes", "yes"], "reachable yogurt_1": ["no", "yes"], "reachable soup_1": ["no", "yes"], "reachable carrot_1": ["yes", "no"], "reachable carrot_2": ["yes", "no"], "reachable carrot_3": ["yes", "no"], "reachable apple_1": ["yes", "no"], "reachable apple_2": ["yes", "no"], "reachable orange_1": ["yes", "yes"], "reachable orange_3": ["yes", "yes"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding flour_1": ["no", "no"], "holding meat_1": ["no", "no"], "holding cheese_1": ["no", "no"], "holding yogurt_1": ["no", "no"], "holding soup_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_2": ["no", "no"], "holding carrot_3": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "holding orange_1": ["no", "no"], "holding orange_3": ["no", "no"], "ontop bread_1,countertop_1": ["no", "yes"], "ontop bread_1,flour_1": ["yes", "no"], "ontop bread_1,milk_1": ["yes", "no"], "ontop bread_1,chair_1": ["no", "no"], "ontop bread_1,meat_1": ["yes", "no"], "ontop bread_1,table_1": ["yes", "no"], "ontop bread_1,cheese_1": ["yes", "no"], "ontop bread_1,yogurt_1": ["yes", "no"], "ontop bread_1,soup_1": ["no", "no"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_2": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,apple_1": ["yes", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,orange_1": ["yes", "no"], "ontop bread_1,orange_3": ["no", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,flour_1": ["no", "no"], "ontop countertop_1,milk_1": ["no", "no"], "ontop countertop_1,chair_1": ["no", "no"], "ontop countertop_1,meat_1": ["no", "no"], "ontop countertop_1,table_1": ["no", "no"], "ontop countertop_1,cheese_1": ["yes", "no"], "ontop countertop_1,yogurt_1": ["no", "no"], "ontop countertop_1,soup_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_2": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,apple_1": ["yes", "no"], "ontop countertop_1,apple_2": ["yes", "no"], "ontop countertop_1,orange_1": ["no", "no"], "ontop countertop_1,orange_3": ["no", "no"], "ontop flour_1,bread_1": ["no", "no"], "ontop flour_1,countertop_1": ["no", "no"], "ontop flour_1,milk_1": ["no", "no"], "ontop flour_1,chair_1": ["no", "no"], "ontop flour_1,meat_1": ["no", "no"], "ontop flour_1,table_1": ["no", "no"], "ontop flour_1,cheese_1": ["no", "no"], "ontop flour_1,yogurt_1": ["no", "no"], "ontop flour_1,soup_1": ["no", "no"], "ontop flour_1,carrot_1": ["no", "no"], "ontop flour_1,carrot_2": ["no", "no"], "ontop flour_1,carrot_3": ["no", "no"], "ontop flour_1,apple_1": ["no", "no"], "ontop flour_1,apple_2": ["no", "no"], "ontop flour_1,orange_1": ["no", "no"], "ontop flour_1,orange_3": ["no", "no"], "ontop meat_1,bread_1": ["no", "no"], "ontop meat_1,countertop_1": ["no", "no"], "ontop meat_1,flour_1": ["no", "no"], "ontop meat_1,milk_1": ["no", "no"], "ontop meat_1,chair_1": ["no", "no"], "ontop meat_1,table_1": ["yes", "yes"], "ontop meat_1,cheese_1": ["no", "no"], "ontop meat_1,yogurt_1": ["yes", "no"], "ontop meat_1,soup_1": ["no", "no"], "ontop meat_1,carrot_1": ["no", "no"], "ontop meat_1,carrot_2": ["no", "no"], "ontop meat_1,carrot_3": ["no", "no"], "ontop meat_1,apple_1": ["no", "no"], "ontop meat_1,apple_2": ["no", "no"], "ontop meat_1,orange_1": ["no", "no"], "ontop meat_1,orange_3": ["yes", "no"], "ontop cheese_1,bread_1": ["no", "no"], "ontop cheese_1,countertop_1": ["no", "no"], "ontop cheese_1,flour_1": ["yes", "no"], "ontop cheese_1,milk_1": ["yes", "no"], "ontop cheese_1,chair_1": ["no", "no"], "ontop cheese_1,meat_1": ["no", "no"], "ontop cheese_1,table_1": ["yes", "yes"], "ontop cheese_1,yogurt_1": ["no", "no"], "ontop cheese_1,soup_1": ["no", "no"], "ontop cheese_1,carrot_1": ["no", "no"], "ontop cheese_1,carrot_2": ["no", "no"], "ontop cheese_1,carrot_3": ["no", "no"], "ontop cheese_1,apple_1": ["no", "no"], "ontop cheese_1,apple_2": ["no", "no"], "ontop cheese_1,orange_1": ["no", "no"], "ontop cheese_1,orange_3": ["no", "no"], "ontop yogurt_1,bread_1": ["no", "no"], "ontop yogurt_1,countertop_1": ["no", "no"], "ontop yogurt_1,flour_1": ["no", "no"], "ontop yogurt_1,milk_1": ["yes", "no"], "ontop yogurt_1,chair_1": ["no", "no"], "ontop yogurt_1,meat_1": ["no", "no"], "ontop yogurt_1,table_1": ["yes", "yes"], "ontop yogurt_1,cheese_1": ["no", "no"], "ontop yogurt_1,soup_1": ["no", "no"], "ontop yogurt_1,carrot_1": ["no", "no"], "ontop yogurt_1,carrot_2": ["yes", "no"], "ontop yogurt_1,carrot_3": ["no", "no"], "ontop yogurt_1,apple_1": ["no", "no"], "ontop yogurt_1,apple_2": ["no", "no"], "ontop yogurt_1,orange_1": ["yes", "no"], "ontop yogurt_1,orange_3": ["no", "no"], "ontop soup_1,bread_1": ["no", "no"], "ontop soup_1,countertop_1": ["no", "no"], "ontop soup_1,flour_1": ["no", "no"], "ontop soup_1,milk_1": ["yes", "no"], "ontop soup_1,chair_1": ["no", "no"], "ontop soup_1,meat_1": ["no", "no"], "ontop soup_1,table_1": ["yes", "yes"], "ontop soup_1,cheese_1": ["no", "no"], "ontop soup_1,yogurt_1": ["no", "no"], "ontop soup_1,carrot_1": ["yes", "no"], "ontop soup_1,carrot_2": ["no", "no"], "ontop soup_1,carrot_3": ["no", "no"], "ontop soup_1,apple_1": ["yes", "no"], "ontop soup_1,apple_2": ["no", "no"], "ontop soup_1,orange_1": ["no", "no"], "ontop soup_1,orange_3": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["no", "yes"], "ontop carrot_1,flour_1": ["no", "no"], "ontop carrot_1,milk_1": ["no", "no"], "ontop carrot_1,chair_1": ["no", "no"], "ontop carrot_1,meat_1": ["no", "no"], "ontop carrot_1,table_1": ["no", "no"], "ontop carrot_1,cheese_1": ["no", "no"], "ontop carrot_1,yogurt_1": ["no", "no"], "ontop carrot_1,soup_1": ["no", "no"], "ontop carrot_1,carrot_2": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,orange_1": ["no", "no"], "ontop carrot_1,orange_3": ["no", "no"], "ontop carrot_2,bread_1": ["no", "no"], "ontop carrot_2,countertop_1": ["no", "yes"], "ontop carrot_2,flour_1": ["no", "no"], "ontop carrot_2,milk_1": ["no", "no"], "ontop carrot_2,chair_1": ["no", "no"], "ontop carrot_2,meat_1": ["no", "no"], "ontop carrot_2,table_1": ["yes", "no"], "ontop carrot_2,cheese_1": ["no", "no"], "ontop carrot_2,yogurt_1": ["no", "no"], "ontop carrot_2,soup_1": ["no", "no"], "ontop carrot_2,carrot_1": ["no", "no"], "ontop carrot_2,carrot_3": ["no", "no"], "ontop carrot_2,apple_1": ["no", "no"], "ontop carrot_2,apple_2": ["no", "no"], "ontop carrot_2,orange_1": ["yes", "no"], "ontop carrot_2,orange_3": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["no", "yes"], "ontop carrot_3,flour_1": ["no", "no"], "ontop carrot_3,milk_1": ["no", "no"], "ontop carrot_3,chair_1": ["no", "no"], "ontop carrot_3,meat_1": ["no", "no"], "ontop carrot_3,table_1": ["yes", "no"], "ontop carrot_3,cheese_1": ["no", "no"], "ontop carrot_3,yogurt_1": ["no", "no"], "ontop carrot_3,soup_1": ["no", "no"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,carrot_2": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["no", "no"], "ontop carrot_3,orange_1": ["yes", "no"], "ontop carrot_3,orange_3": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["no", "yes"], "ontop apple_1,flour_1": ["no", "no"], "ontop apple_1,milk_1": ["no", "no"], "ontop apple_1,chair_1": ["no", "no"], "ontop apple_1,meat_1": ["no", "no"], "ontop apple_1,table_1": ["no", "no"], "ontop apple_1,cheese_1": ["no", "no"], "ontop apple_1,yogurt_1": ["no", "no"], "ontop apple_1,soup_1": ["no", "no"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_2": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,orange_1": ["no", "no"], "ontop apple_1,orange_3": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["no", "yes"], "ontop apple_2,flour_1": ["no", "no"], "ontop apple_2,milk_1": ["no", "no"], "ontop apple_2,chair_1": ["no", "no"], "ontop apple_2,meat_1": ["no", "no"], "ontop apple_2,table_1": ["no", "no"], "ontop apple_2,cheese_1": ["no", "no"], "ontop apple_2,yogurt_1": ["no", "no"], "ontop apple_2,soup_1": ["no", "no"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_2": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,orange_1": ["no", "no"], "ontop apple_2,orange_3": ["no", "no"], "ontop orange_1,bread_1": ["no", "no"], "ontop orange_1,countertop_1": ["no", "no"], "ontop orange_1,flour_1": ["no", "no"], "ontop orange_1,milk_1": ["no", "no"], "ontop orange_1,chair_1": ["no", "no"], "ontop orange_1,meat_1": ["yes", "no"], "ontop orange_1,table_1": ["yes", "yes"], "ontop orange_1,cheese_1": ["no", "no"], "ontop orange_1,yogurt_1": ["no", "no"], "ontop orange_1,soup_1": ["no", "no"], "ontop orange_1,carrot_1": ["yes", "no"], "ontop orange_1,carrot_2": ["no", "no"], "ontop orange_1,carrot_3": ["yes", "no"], "ontop orange_1,apple_1": ["no", "no"], "ontop orange_1,apple_2": ["no", "no"], "ontop orange_1,orange_3": ["no", "no"], "ontop orange_3,bread_1": ["yes", "no"], "ontop orange_3,countertop_1": ["no", "no"], "ontop orange_3,flour_1": ["no", "no"], "ontop orange_3,milk_1": ["no", "no"], "ontop orange_3,chair_1": ["no", "no"], "ontop orange_3,meat_1": ["yes", "no"], "ontop orange_3,table_1": ["yes", "yes"], "ontop orange_3,cheese_1": ["no", "no"], "ontop orange_3,yogurt_1": ["no", "no"], "ontop orange_3,soup_1": ["no", "no"], "ontop orange_3,carrot_1": ["yes", "no"], "ontop orange_3,carrot_2": ["yes", "no"], "ontop orange_3,carrot_3": ["yes", "no"], "ontop orange_3,apple_1": ["no", "no"], "ontop orange_3,apple_2": ["no", "no"], "ontop orange_3,orange_1": ["yes", "no"], "nextto bread_1,countertop_1": ["no", "no"], "nextto bread_1,flour_1": ["no", "no"], "nextto bread_1,milk_1": ["yes", "no"], "nextto bread_1,chair_1": ["no", "no"], "nextto bread_1,meat_1": ["no", "no"], "nextto bread_1,table_1": ["yes", "no"], "nextto bread_1,cheese_1": ["no", "no"], "nextto bread_1,yogurt_1": ["yes", "no"], "nextto bread_1,soup_1": ["no", "no"], "nextto bread_1,carrot_1": ["yes", "no"], "nextto bread_1,carrot_2": ["yes", "yes"], "nextto bread_1,carrot_3": ["yes", "yes"], "nextto bread_1,apple_1": ["yes", "no"], "nextto bread_1,apple_2": ["yes", "no"], "nextto bread_1,orange_1": ["yes", "no"], "nextto bread_1,orange_3": ["yes", "no"], "nextto countertop_1,bread_1": ["no", "no"], "nextto countertop_1,flour_1": ["no", "no"], "nextto countertop_1,milk_1": ["no", "no"], "nextto countertop_1,chair_1": ["no", "no"], "nextto countertop_1,meat_1": ["no", "no"], "nextto countertop_1,table_1": ["no", "no"], "nextto countertop_1,cheese_1": ["no", "no"], "nextto countertop_1,yogurt_1": ["no", "no"], "nextto countertop_1,soup_1": ["no", "no"], "nextto countertop_1,carrot_1": ["no", "no"], "nextto countertop_1,carrot_2": ["no", "no"], "nextto countertop_1,carrot_3": ["no", "no"], "nextto countertop_1,apple_1": ["no", "no"], "nextto countertop_1,apple_2": ["yes", "no"], "nextto countertop_1,orange_1": ["no", "no"], "nextto countertop_1,orange_3": ["no", "no"], "nextto flour_1,bread_1": ["yes", "no"], "nextto flour_1,countertop_1": ["yes", "no"], "nextto flour_1,milk_1": ["yes", "no"], "nextto flour_1,chair_1": ["no", "no"], "nextto flour_1,meat_1": ["yes", "no"], "nextto flour_1,table_1": ["no", "no"], "nextto flour_1,cheese_1": ["yes", "no"], "nextto flour_1,yogurt_1": ["yes", "no"], "nextto flour_1,soup_1": ["no", "no"], "nextto flour_1,carrot_1": ["no", "no"], "nextto flour_1,carrot_2": ["no", "no"], "nextto flour_1,carrot_3": ["yes", "no"], "nextto flour_1,apple_1": ["yes", "no"], "nextto flour_1,apple_2": ["no", "no"], "nextto flour_1,orange_1": ["no", "no"], "nextto flour_1,orange_3": ["yes", "no"], "nextto meat_1,bread_1": ["yes", "no"], "nextto meat_1,countertop_1": ["no", "no"], "nextto meat_1,flour_1": ["yes", "no"], "nextto meat_1,milk_1": ["yes", "no"], "nextto meat_1,chair_1": ["no", "no"], "nextto meat_1,table_1": ["yes", "no"], "nextto meat_1,cheese_1": ["no", "no"], "nextto meat_1,yogurt_1": ["no", "no"], "nextto meat_1,soup_1": ["no", "no"], "nextto meat_1,carrot_1": ["no", "no"], "nextto meat_1,carrot_2": ["yes", "no"], "nextto meat_1,carrot_3": ["yes", "no"], "nextto meat_1,apple_1": ["no", "no"], "nextto meat_1,apple_2": ["no", "no"], "nextto meat_1,orange_1": ["yes", "no"], "nextto meat_1,orange_3": ["no", "yes"], "nextto cheese_1,bread_1": ["yes", "no"], "nextto cheese_1,countertop_1": ["no", "no"], "nextto cheese_1,flour_1": ["no", "no"], "nextto cheese_1,milk_1": ["yes", "no"], "nextto cheese_1,chair_1": ["no", "no"], "nextto cheese_1,meat_1": ["yes", "no"], "nextto cheese_1,table_1": ["yes", "no"], "nextto cheese_1,yogurt_1": ["yes", "no"], "nextto cheese_1,soup_1": ["no", "yes"], "nextto cheese_1,carrot_1": ["yes", "no"], "nextto cheese_1,carrot_2": ["yes", "no"], "nextto cheese_1,carrot_3": ["yes", "no"], "nextto cheese_1,apple_1": ["no", "no"], "nextto cheese_1,apple_2": ["no", "no"], "nextto cheese_1,orange_1": ["no", "yes"], "nextto cheese_1,orange_3": ["yes", "no"], "nextto yogurt_1,bread_1": ["yes", "no"], "nextto yogurt_1,countertop_1": ["no", "no"], "nextto yogurt_1,flour_1": ["yes", "no"], "nextto yogurt_1,milk_1": ["yes", "no"], "nextto yogurt_1,chair_1": ["no", "no"], "nextto yogurt_1,meat_1": ["no", "no"], "nextto yogurt_1,table_1": ["yes", "no"], "nextto yogurt_1,cheese_1": ["no", "no"], "nextto yogurt_1,soup_1": ["no", "no"], "nextto yogurt_1,carrot_1": ["no", "no"], "nextto yogurt_1,carrot_2": ["no", "no"], "nextto yogurt_1,carrot_3": ["yes", "no"], "nextto yogurt_1,apple_1": ["yes", "no"], "nextto yogurt_1,apple_2": ["yes", "no"], "nextto yogurt_1,orange_1": ["no", "no"], "nextto yogurt_1,orange_3": ["yes", "no"], "nextto soup_1,bread_1": ["no", "no"], "nextto soup_1,countertop_1": ["no", "no"], "nextto soup_1,flour_1": ["no", "no"], "nextto soup_1,milk_1": ["yes", "no"], "nextto soup_1,chair_1": ["no", "no"], "nextto soup_1,meat_1": ["no", "no"], "nextto soup_1,table_1": ["yes", "no"], "nextto soup_1,cheese_1": ["no", "yes"], "nextto soup_1,yogurt_1": ["no", "no"], "nextto soup_1,carrot_1": ["yes", "no"], "nextto soup_1,carrot_2": ["no", "no"], "nextto soup_1,carrot_3": ["yes", "no"], "nextto soup_1,apple_1": ["no", "no"], "nextto soup_1,apple_2": ["no", "no"], "nextto soup_1,orange_1": ["no", "no"], "nextto soup_1,orange_3": ["yes", "no"], "nextto carrot_1,bread_1": ["no", "no"], "nextto carrot_1,countertop_1": ["no", "no"], "nextto carrot_1,flour_1": ["no", "no"], "nextto carrot_1,milk_1": ["no", "no"], "nextto carrot_1,chair_1": ["no", "no"], "nextto carrot_1,meat_1": ["no", "no"], "nextto carrot_1,table_1": ["yes", "no"], "nextto carrot_1,cheese_1": ["yes", "no"], "nextto carrot_1,yogurt_1": ["yes", "no"], "nextto carrot_1,soup_1": ["no", "no"], "nextto carrot_1,carrot_2": ["yes", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,apple_1": ["no", "no"], "nextto carrot_1,apple_2": ["no", "no"], "nextto carrot_1,orange_1": ["no", "no"], "nextto carrot_1,orange_3": ["yes", "no"], "nextto carrot_2,bread_1": ["yes", "yes"], "nextto carrot_2,countertop_1": ["no", "no"], "nextto carrot_2,flour_1": ["no", "no"], "nextto carrot_2,milk_1": ["no", "no"], "nextto carrot_2,chair_1": ["no", "no"], "nextto carrot_2,meat_1": ["no", "no"], "nextto carrot_2,table_1": ["yes", "no"], "nextto carrot_2,cheese_1": ["yes", "no"], "nextto carrot_2,yogurt_1": ["no", "no"], "nextto carrot_2,soup_1": ["no", "no"], "nextto carrot_2,carrot_1": ["no", "no"], "nextto carrot_2,carrot_3": ["yes", "yes"], "nextto carrot_2,apple_1": ["no", "yes"], "nextto carrot_2,apple_2": ["no", "no"], "nextto carrot_2,orange_1": ["no", "no"], "nextto carrot_2,orange_3": ["yes", "no"], "nextto carrot_3,bread_1": ["yes", "yes"], "nextto carrot_3,countertop_1": ["no", "no"], "nextto carrot_3,flour_1": ["no", "no"], "nextto carrot_3,milk_1": ["no", "no"], "nextto carrot_3,chair_1": ["no", "no"], "nextto carrot_3,meat_1": ["no", "no"], "nextto carrot_3,table_1": ["yes", "no"], "nextto carrot_3,cheese_1": ["no", "no"], "nextto carrot_3,yogurt_1": ["no", "no"], "nextto carrot_3,soup_1": ["no", "no"], "nextto carrot_3,carrot_1": ["no", "no"], "nextto carrot_3,carrot_2": ["yes", "yes"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["no", "no"], "nextto carrot_3,orange_1": ["yes", "no"], "nextto carrot_3,orange_3": ["yes", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["no", "no"], "nextto apple_1,flour_1": ["no", "no"], "nextto apple_1,milk_1": ["no", "no"], "nextto apple_1,chair_1": ["no", "no"], "nextto apple_1,meat_1": ["no", "no"], "nextto apple_1,table_1": ["yes", "no"], "nextto apple_1,cheese_1": ["no", "no"], "nextto apple_1,yogurt_1": ["no", "no"], "nextto apple_1,soup_1": ["no", "no"], "nextto apple_1,carrot_1": ["no", "no"], "nextto apple_1,carrot_2": ["no", "yes"], "nextto apple_1,carrot_3": ["no", "no"], "nextto apple_1,apple_2": ["no", "yes"], "nextto apple_1,orange_1": ["yes", "no"], "nextto apple_1,orange_3": ["no", "no"], "nextto apple_2,bread_1": ["no", "no"], "nextto apple_2,countertop_1": ["no", "no"], "nextto apple_2,flour_1": ["no", "no"], "nextto apple_2,milk_1": ["no", "no"], "nextto apple_2,chair_1": ["no", "no"], "nextto apple_2,meat_1": ["no", "no"], "nextto apple_2,table_1": ["yes", "no"], "nextto apple_2,cheese_1": ["no", "no"], "nextto apple_2,yogurt_1": ["yes", "no"], "nextto apple_2,soup_1": ["no", "no"], "nextto apple_2,carrot_1": ["yes", "no"], "nextto apple_2,carrot_2": ["no", "no"], "nextto apple_2,carrot_3": ["yes", "no"], "nextto apple_2,apple_1": ["yes", "yes"], "nextto apple_2,orange_1": ["no", "no"], "nextto apple_2,orange_3": ["no", "no"], "nextto orange_1,bread_1": ["no", "no"], "nextto orange_1,countertop_1": ["no", "no"], "nextto orange_1,flour_1": ["no", "no"], "nextto orange_1,milk_1": ["no", "no"], "nextto orange_1,chair_1": ["no", "no"], "nextto orange_1,meat_1": ["no", "no"], "nextto orange_1,table_1": ["yes", "no"], "nextto orange_1,cheese_1": ["no", "yes"], "nextto orange_1,yogurt_1": ["yes", "no"], "nextto orange_1,soup_1": ["no", "no"], "nextto orange_1,carrot_1": ["yes", "no"], "nextto orange_1,carrot_2": ["yes", "no"], "nextto orange_1,carrot_3": ["yes", "no"], "nextto orange_1,apple_1": ["yes", "no"], "nextto orange_1,apple_2": ["no", "no"], "nextto orange_1,orange_3": ["yes", "no"], "nextto orange_3,bread_1": ["yes", "no"], "nextto orange_3,countertop_1": ["no", "no"], "nextto orange_3,flour_1": ["no", "no"], "nextto orange_3,milk_1": ["no", "no"], "nextto orange_3,chair_1": ["no", "yes"], "nextto orange_3,meat_1": ["yes", "yes"], "nextto orange_3,table_1": ["yes", "no"], "nextto orange_3,cheese_1": ["no", "no"], "nextto orange_3,yogurt_1": ["yes", "no"], "nextto orange_3,soup_1": ["no", "no"], "nextto orange_3,carrot_1": ["yes", "no"], "nextto orange_3,carrot_2": ["no", "no"], "nextto orange_3,carrot_3": ["yes", "no"], "nextto orange_3,apple_1": ["yes", "no"], "nextto orange_3,apple_2": ["no", "no"], "nextto orange_3,orange_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7118997912317327, "yes_accuracy": 0.5263157894736842, "yes_correct": 20, "yes_total": 38, "no_accuracy": 0.7278911564625851, "no_correct": 321, "no_total": 441, "predicates": {"reachable": {"accuracy": 0.35294117647058826, "yes_accuracy": 0.6666666666666666, "yes_correct": 6, "yes_total": 9, "no_accuracy": 0.0, "no_correct": 0, "no_total": 8}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 14, "no_total": 14}, "ontop": {"accuracy": 0.8214285714285714, "yes_accuracy": 0.5, "yes_correct": 6, "yes_total": 12, "no_accuracy": 0.839622641509434, "no_correct": 178, "no_total": 212}, "nextto": {"accuracy": 0.6116071428571429, "yes_accuracy": 0.47058823529411764, "yes_correct": 8, "yes_total": 17, "no_accuracy": 0.6231884057971014, "no_correct": 129, "no_total": 207}}}, "step": 1, "actions": ["navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"]}, {"enum_results": {"reachable bread_1": ["no", "no"], "reachable countertop_1": ["no", "no"], "reachable flour_1": ["no", "no"], "reachable carrot_1": ["no", "no"], "reachable carrot_3": ["yes", "no"], "reachable broccoli_1": ["no", "no"], "reachable apple_1": ["yes", "no"], "reachable apple_2": ["yes", "no"], "reachable electric_refrigerator_1": ["yes", "yes"], "holding bread_1": ["no", "no"], "holding countertop_1": ["no", "no"], "holding flour_1": ["no", "no"], "holding carrot_1": ["no", "no"], "holding carrot_3": ["no", "no"], "holding broccoli_1": ["no", "no"], "holding apple_1": ["no", "no"], "holding apple_2": ["no", "no"], "open electric_refrigerator_1": ["no", "no"], "ontop bread_1,countertop_1": ["no", "yes"], "ontop bread_1,flour_1": ["yes", "no"], "ontop bread_1,carrot_1": ["no", "no"], "ontop bread_1,carrot_3": ["no", "no"], "ontop bread_1,broccoli_1": ["no", "no"], "ontop bread_1,apple_1": ["no", "no"], "ontop bread_1,apple_2": ["no", "no"], "ontop bread_1,electric_refrigerator_1": ["yes", "no"], "ontop countertop_1,bread_1": ["no", "no"], "ontop countertop_1,flour_1": ["no", "no"], "ontop countertop_1,carrot_1": ["no", "no"], "ontop countertop_1,carrot_3": ["no", "no"], "ontop countertop_1,broccoli_1": ["no", "no"], "ontop countertop_1,apple_1": ["no", "no"], "ontop countertop_1,apple_2": ["no", "no"], "ontop countertop_1,electric_refrigerator_1": ["no", "no"], "ontop flour_1,bread_1": ["no", "no"], "ontop flour_1,countertop_1": ["yes", "no"], "ontop flour_1,carrot_1": ["no", "no"], "ontop flour_1,carrot_3": ["no", "no"], "ontop flour_1,broccoli_1": ["no", "no"], "ontop flour_1,apple_1": ["no", "no"], "ontop flour_1,apple_2": ["no", "no"], "ontop flour_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_1,bread_1": ["no", "no"], "ontop carrot_1,countertop_1": ["no", "yes"], "ontop carrot_1,flour_1": ["no", "no"], "ontop carrot_1,carrot_3": ["no", "no"], "ontop carrot_1,broccoli_1": ["no", "no"], "ontop carrot_1,apple_1": ["no", "no"], "ontop carrot_1,apple_2": ["no", "no"], "ontop carrot_1,electric_refrigerator_1": ["no", "no"], "ontop carrot_3,bread_1": ["no", "no"], "ontop carrot_3,countertop_1": ["no", "yes"], "ontop carrot_3,flour_1": ["no", "no"], "ontop carrot_3,carrot_1": ["no", "no"], "ontop carrot_3,broccoli_1": ["no", "no"], "ontop carrot_3,apple_1": ["no", "no"], "ontop carrot_3,apple_2": ["yes", "no"], "ontop carrot_3,electric_refrigerator_1": ["no", "no"], "ontop broccoli_1,bread_1": ["no", "no"], "ontop broccoli_1,countertop_1": ["yes", "yes"], "ontop broccoli_1,flour_1": ["no", "no"], "ontop broccoli_1,carrot_1": ["no", "no"], "ontop broccoli_1,carrot_3": ["no", "no"], "ontop broccoli_1,apple_1": ["no", "no"], "ontop broccoli_1,apple_2": ["no", "no"], "ontop broccoli_1,electric_refrigerator_1": ["no", "no"], "ontop apple_1,bread_1": ["no", "no"], "ontop apple_1,countertop_1": ["yes", "yes"], "ontop apple_1,flour_1": ["no", "no"], "ontop apple_1,carrot_1": ["no", "no"], "ontop apple_1,carrot_3": ["no", "no"], "ontop apple_1,broccoli_1": ["no", "no"], "ontop apple_1,apple_2": ["no", "no"], "ontop apple_1,electric_refrigerator_1": ["no", "no"], "ontop apple_2,bread_1": ["no", "no"], "ontop apple_2,countertop_1": ["no", "yes"], "ontop apple_2,flour_1": ["no", "no"], "ontop apple_2,carrot_1": ["no", "no"], "ontop apple_2,carrot_3": ["no", "no"], "ontop apple_2,broccoli_1": ["no", "no"], "ontop apple_2,apple_1": ["no", "no"], "ontop apple_2,electric_refrigerator_1": ["no", "no"], "inside bread_1,electric_refrigerator_1": ["no", "no"], "inside countertop_1,electric_refrigerator_1": ["no", "no"], "inside flour_1,electric_refrigerator_1": ["no", "no"], "inside carrot_1,electric_refrigerator_1": ["no", "no"], "inside carrot_3,electric_refrigerator_1": ["no", "no"], "inside broccoli_1,electric_refrigerator_1": ["no", "no"], "inside apple_1,electric_refrigerator_1": ["yes", "no"], "inside apple_2,electric_refrigerator_1": ["yes", "no"], "nextto bread_1,countertop_1": ["no", "no"], "nextto bread_1,flour_1": ["no", "no"], "nextto bread_1,carrot_1": ["no", "no"], "nextto bread_1,carrot_3": ["yes", "yes"], "nextto bread_1,broccoli_1": ["no", "no"], "nextto bread_1,apple_1": ["yes", "no"], "nextto bread_1,apple_2": ["no", "no"], "nextto bread_1,electric_refrigerator_1": ["yes", "no"], "nextto countertop_1,bread_1": ["yes", "no"], "nextto countertop_1,flour_1": ["yes", "no"], "nextto countertop_1,carrot_1": ["yes", "no"], "nextto countertop_1,carrot_3": ["yes", "no"], "nextto countertop_1,broccoli_1": ["yes", "no"], "nextto countertop_1,apple_1": ["no", "no"], "nextto countertop_1,apple_2": ["no", "no"], "nextto countertop_1,electric_refrigerator_1": ["yes", "no"], "nextto flour_1,bread_1": ["no", "no"], "nextto flour_1,countertop_1": ["yes", "no"], "nextto flour_1,carrot_1": ["yes", "no"], "nextto flour_1,carrot_3": ["no", "no"], "nextto flour_1,broccoli_1": ["yes", "no"], "nextto flour_1,apple_1": ["no", "no"], "nextto flour_1,apple_2": ["no", "no"], "nextto flour_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_1,bread_1": ["yes", "no"], "nextto carrot_1,countertop_1": ["yes", "no"], "nextto carrot_1,flour_1": ["yes", "no"], "nextto carrot_1,carrot_3": ["no", "no"], "nextto carrot_1,broccoli_1": ["no", "no"], "nextto carrot_1,apple_1": ["no", "no"], "nextto carrot_1,apple_2": ["no", "no"], "nextto carrot_1,electric_refrigerator_1": ["yes", "no"], "nextto carrot_3,bread_1": ["no", "yes"], "nextto carrot_3,countertop_1": ["no", "no"], "nextto carrot_3,flour_1": ["yes", "no"], "nextto carrot_3,carrot_1": ["yes", "no"], "nextto carrot_3,broccoli_1": ["no", "no"], "nextto carrot_3,apple_1": ["no", "no"], "nextto carrot_3,apple_2": ["yes", "no"], "nextto carrot_3,electric_refrigerator_1": ["no", "no"], "nextto broccoli_1,bread_1": ["no", "no"], "nextto broccoli_1,countertop_1": ["no", "no"], "nextto broccoli_1,flour_1": ["no", "no"], "nextto broccoli_1,carrot_1": ["no", "no"], "nextto broccoli_1,carrot_3": ["no", "no"], "nextto broccoli_1,apple_1": ["no", "no"], "nextto broccoli_1,apple_2": ["no", "no"], "nextto broccoli_1,electric_refrigerator_1": ["yes", "no"], "nextto apple_1,bread_1": ["no", "no"], "nextto apple_1,countertop_1": ["yes", "no"], "nextto apple_1,flour_1": ["yes", "no"], "nextto apple_1,carrot_1": ["yes", "no"], "nextto apple_1,carrot_3": ["no", "no"], "nextto apple_1,broccoli_1": ["yes", "no"], "nextto apple_1,apple_2": ["yes", "yes"], "nextto apple_1,electric_refrigerator_1": ["yes", "no"], "nextto apple_2,bread_1": ["yes", "no"], "nextto apple_2,countertop_1": ["yes", "no"], "nextto apple_2,flour_1": ["yes", "no"], "nextto apple_2,carrot_1": ["yes", "no"], "nextto apple_2,carrot_3": ["no", "no"], "nextto apple_2,broccoli_1": ["no", "no"], "nextto apple_2,apple_1": ["yes", "yes"], "nextto apple_2,electric_refrigerator_1": ["yes", "no"]}, "enum_metrics": {"accuracy": 0.7142857142857143, "yes_accuracy": 0.5454545454545454, "yes_correct": 6, "yes_total": 11, "no_accuracy": 0.7272727272727273, "no_correct": 104, "no_total": 143, "predicates": {"reachable": {"accuracy": 0.6666666666666666, "yes_accuracy": 1.0, "yes_correct": 1, "yes_total": 1, "no_accuracy": 0.625, "no_correct": 5, "no_total": 8}, "holding": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 8, "no_total": 8}, "open": {"accuracy": 1.0, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 1.0, "no_correct": 1, "no_total": 1}, "ontop": {"accuracy": 0.875, "yes_accuracy": 0.3333333333333333, "yes_correct": 2, "yes_total": 6, "no_accuracy": 0.9310344827586207, "no_correct": 54, "no_total": 58}, "inside": {"accuracy": 0.75, "yes_accuracy": null, "yes_correct": 0, "yes_total": 0, "no_accuracy": 0.75, "no_correct": 6, "no_total": 8}, "nextto": {"accuracy": 0.515625, "yes_accuracy": 0.75, "yes_correct": 3, "yes_total": 4, "no_accuracy": 0.5, "no_correct": 30, "no_total": 60}}}, "step": 2, "actions": []}], "remaining_actions": []}, "problem_stats": {"data/planning/igibson/medium/sorting_books_medium.pddl_Pomaria_1_int_0": {"action_correct": 0, "action_total": 12, "remaining_actions": ["navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/medium/sorting_books_medium.pddl_Pomaria_1_int_20": {"action_correct": 2, "action_total": 12, "remaining_actions": ["navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"], "action_accuracy": 0.16666666666666666, "failed": false}, "data/planning/igibson/medium/sorting_books_medium.pddl_Pomaria_1_int_21": {"action_correct": 1, "action_total": 10, "remaining_actions": ["navigate-to(hardback_1)", "navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"], "action_accuracy": 0.1, "failed": false}, "data/planning/igibson/medium/sorting_books_medium.pddl_Pomaria_1_int_23": {"action_correct": 2, "action_total": 18, "remaining_actions": ["navigate-to(shelf_1)", "place-on(book_1, shelf_1)", "navigate-to(hardback_1)", "grasp(hardback_1)", "navigate-to(shelf_1)", "place-on(hardback_1, shelf_1)"], "action_accuracy": 0.1111111111111111, "failed": false}, "data/planning/igibson/medium/cleaning_out_drawers_medium.pddl_Benevolence_1_int_21": {"action_correct": 1, "action_total": 13, "remaining_actions": ["navigate-to(spoon_1)", "navigate-to(sink_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"], "action_accuracy": 0.07692307692307693, "failed": false}, "data/planning/igibson/medium/cleaning_out_drawers_medium.pddl_Rs_int_0": {"action_correct": 1, "action_total": 15, "remaining_actions": ["open-container(cabinet_1)", "grasp(bowl_1)", "place-on(bowl_1, sink_1)", "navigate-to(spoon_1)", "grasp(spoon_1)", "navigate-to(sink_1)", "place-on(spoon_1, sink_1)"], "action_accuracy": 0.06666666666666667, "failed": false}, "data/planning/igibson/medium/packing_food_for_work_medium.pddl_Beechwood_0_int_0": {"action_correct": 4, "action_total": 26, "remaining_actions": ["open-container(carton_1)", "navigate-to(electric_refrigerator_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"], "action_accuracy": 0.15384615384615385, "failed": false}, "data/planning/igibson/medium/packing_food_for_work_medium.pddl_Beechwood_0_int_20": {"action_correct": 4, "action_total": 15, "remaining_actions": ["place-inside(sandwich_1, carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"], "action_accuracy": 0.26666666666666666, "failed": false}, "data/planning/igibson/medium/packing_food_for_work_medium.pddl_Wainscott_0_int_0": {"action_correct": 0, "action_total": 17, "remaining_actions": ["open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-next-to(sandwich_1, carton_1)", "open-container(carton_1)", "navigate-to(snack_food_1)", "grasp(snack_food_1)", "navigate-to(sandwich_1)", "navigate-to(carton_1)", "place-inside(snack_food_1, carton_1)", "navigate-to(sandwich_1)", "grasp(sandwich_1)", "navigate-to(carton_1)", "place-inside(sandwich_1, carton_1)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/medium/packing_food_for_work_medium.pddl_Wainscott_0_int_20": {"action_correct": 0, "action_total": 10, "remaining_actions": ["open-container(carton_1)", "open-container(electric_refrigerator_1)", "grasp(sandwich_1)", "place-inside(sandwich_1, carton_1)", "grasp(snack_food_1)", "place-inside(snack_food_1, carton_1)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Benevolence_1_int_0": {"action_correct": 0, "action_total": 8, "remaining_actions": ["place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Benevolence_1_int_21": {"action_correct": 0, "action_total": 14, "remaining_actions": ["navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Ihlen_0_int_0": {"action_correct": 1, "action_total": 14, "remaining_actions": ["grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"], "action_accuracy": 0.07142857142857142, "failed": false}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Ihlen_0_int_20": {"action_correct": 1, "action_total": 18, "remaining_actions": ["grasp(plaything_2)", "place-inside(plaything_2, carton_1)", "navigate-to(plaything_4)", "grasp(plaything_4)", "navigate-to(carton_1)", "place-inside(plaything_4, carton_1)"], "action_accuracy": 0.05555555555555555, "failed": false}, "data/planning/igibson/medium/putting_away_toys_medium.pddl_Ihlen_1_int_0": {"action_correct": 0, "action_total": 11, "remaining_actions": ["open-container(carton_1)", "grasp(plaything_4)", "place-inside(plaything_4, carton_1)", "navigate-to(plaything_2)", "grasp(plaything_2)", "navigate-to(carton_1)", "place-inside(plaything_2, carton_1)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/medium/collect_misplaced_items_medium.pddl_Beechwood_0_int_23": {"action_correct": 3, "action_total": 12, "remaining_actions": ["navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"], "action_accuracy": 0.25, "failed": false}, "data/planning/igibson/medium/collect_misplaced_items_medium.pddl_Beechwood_0_int_24": {"action_correct": 3, "action_total": 10, "remaining_actions": ["place-on(sock_2, table_2)"], "action_accuracy": 0.3, "failed": false}, "data/planning/igibson/medium/collect_misplaced_items_medium.pddl_Merom_1_int_0": {"action_correct": 1, "action_total": 18, "remaining_actions": ["navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"], "action_accuracy": 0.05555555555555555, "failed": false}, "data/planning/igibson/medium/collect_misplaced_items_medium.pddl_Merom_1_int_22": {"action_correct": 0, "action_total": 13, "remaining_actions": ["grasp(gym_shoe_1)", "navigate-to(sock_2)", "navigate-to(table_2)", "place-on(gym_shoe_1, table_2)", "navigate-to(sock_2)", "grasp(sock_2)", "navigate-to(table_2)", "place-on(sock_2, table_2)"], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Beechwood_0_int_23": {"action_correct": 3, "action_total": 8, "remaining_actions": [], "action_accuracy": 0.375, "failed": false}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Beechwood_0_int_24": {"action_correct": 1, "action_total": 17, "remaining_actions": ["open-container(electric_refrigerator_1)", "grasp(apple_1)", "place-inside(apple_1, electric_refrigerator_1)"], "action_accuracy": 0.058823529411764705, "failed": false}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Beechwood_0_int_29": {"action_correct": 11, "action_total": 20, "remaining_actions": [], "action_accuracy": 0.55, "failed": false}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Pomaria_1_int_0": {"action_correct": 0, "action_total": 4, "remaining_actions": [], "action_accuracy": 0.0, "failed": false}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Pomaria_1_int_20": {"action_correct": 1, "action_total": 8, "remaining_actions": ["navigate-to(apple_1)", "grasp(apple_1)", "navigate-to(electric_refrigerator_1)", "place-inside(apple_1, electric_refrigerator_1)"], "action_accuracy": 0.125, "failed": false}, "data/planning/igibson/medium/sorting_groceries_medium.pddl_Pomaria_1_int_23": {"action_correct": 0, "action_total": 2, "remaining_actions": [], "action_accuracy": 0.0, "failed": false}}, "predicate_stats": {"reachable": {"accuracy": 0.6480263157894737, "yes_accuracy": 0.7775061124694377, "yes_correct": 318, "yes_total": 409, "no_accuracy": 0.38190954773869346, "no_correct": 76, "no_total": 199, "correct": 394, "total": 608}, "holding": {"accuracy": 0.821917808219178, "yes_accuracy": 0.417910447761194, "yes_correct": 28, "yes_total": 67, "no_accuracy": 0.912751677852349, "no_correct": 272, "no_total": 298, "correct": 300, "total": 365}, "ontop": {"accuracy": 0.8464818763326226, "yes_accuracy": 0.4583333333333333, "yes_correct": 77, "yes_total": 168, "no_accuracy": 0.8764354616444648, "no_correct": 1908, "no_total": 2177, "correct": 1985, "total": 2345}, "nextto": {"accuracy": 0.5671641791044776, "yes_accuracy": 0.4557522123893805, "yes_correct": 103, "yes_total": 226, "no_accuracy": 0.5790467201510147, "no_correct": 1227, "no_total": 2119, "correct": 1330, "total": 2345}, "open": {"accuracy": 0.5470588235294118, "yes_accuracy": 0.47058823529411764, "yes_correct": 32, "yes_total": 68, "no_accuracy": 0.5980392156862745, "no_correct": 61, "no_total": 102, "correct": 93, "total": 170}, "inside": {"accuracy": 0.9205479452054794, "yes_accuracy": 0.625, "yes_correct": 10, "yes_total": 16, "no_accuracy": 0.9340974212034384, "no_correct": 326, "no_total": 349, "correct": 336, "total": 365}}, "predicate_accuracy": 0.7160374314294934, "macro_predicate_accuracy": 0.7251994913634405, "action_accuracy": 0.12307692307692308, "task_accuracy": 0.0, "fail_ratio": 0.0, "metadata": {"model_name": "gpt-4.1-nano", "prompt_path": "data/prompts/benchmark/igibson/prompt_cot.md", "problems_dir": "data/planning/igibson/medium", "seed": 1, "replan": true, "fail_probability": 0.0, "enumerate_initial_state": false, "job_id": "7237149_4"}}